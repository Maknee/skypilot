[33mTailing logs of the last job on cluster 'dd'...[0m
Job ID not provided. Streaming the logs of the latest job.
[2m├── [0m[2mWaiting for task resources on 2 nodes.[0m
[2m└── [0mJob started. Streaming logs... [2m(Ctrl-C to exit log streaming; job will not be killed)[0m
[36m(setup pid=3505)[0m Channels:
[36m(setup pid=3505)[0m  - nvidia
[36m(setup pid=3505)[0m  - defaults
[36m(setup pid=3505)[0m Platform: linux-64
[36m(setup pid=2715, ip=10.102.30.60)[0m Channels:
[36m(setup pid=2715, ip=10.102.30.60)[0m  - nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m  - defaults
[36m(setup pid=2715, ip=10.102.30.60)[0m Platform: linux-64
[36m(setup pid=3505)[0m Collecting package metadata (repodata.json): ...working... done
[36m(setup pid=3505)[0m Solving environment: ...working... done
[36m(setup pid=3505)[0m 
[36m(setup pid=3505)[0m ## Package Plan ##
[36m(setup pid=3505)[0m 
[36m(setup pid=3505)[0m   environment location: /root/miniconda3
[36m(setup pid=3505)[0m 
[36m(setup pid=3505)[0m   added / updated specs:
[36m(setup pid=3505)[0m     - cuda
[36m(setup pid=3505)[0m 
[36m(setup pid=3505)[0m 
[36m(setup pid=3505)[0m The following packages will be downloaded:
[36m(setup pid=3505)[0m 
[36m(setup pid=3505)[0m     package                    |            build
[36m(setup pid=3505)[0m     ---------------------------|-----------------
[36m(setup pid=3505)[0m     _sysroot_linux-64_curr_repodata_hack-3|      haa98f57_10          12 KB
[36m(setup pid=3505)[0m     archspec-0.2.3             |     pyhd3eb1b0_0          47 KB
[36m(setup pid=3505)[0m     binutils_impl_linux-64-2.38|       h2a08ee3_1         5.2 MB
[36m(setup pid=3505)[0m     binutils_linux-64-2.38.0   |       hc2dff05_0          24 KB
[36m(setup pid=3505)[0m     ca-certificates-2025.2.25  |       h06a4308_0         129 KB
[36m(setup pid=3505)[0m     certifi-2025.7.14          |  py310h06a4308_0         160 KB
[36m(setup pid=3505)[0m     conda-24.11.3              |  py310h06a4308_0         930 KB
[36m(setup pid=3505)[0m     cpp-expected-1.1.0         |       hdb19cb5_0         130 KB
[36m(setup pid=3505)[0m     cuda-12.9.1                |                0          17 KB  nvidia
[36m(setup pid=3505)[0m     cuda-cccl_linux-64-12.9.27 |                0         1.1 MB  nvidia
[36m(setup pid=3505)[0m     cuda-command-line-tools-12.9.1|                0          17 KB  nvidia
[36m(setup pid=3505)[0m     cuda-compiler-12.9.1       |                0          17 KB  nvidia
[36m(setup pid=3505)[0m     cuda-crt-dev_linux-64-12.9.86|                0          84 KB  nvidia
[36m(setup pid=3505)[0m     cuda-crt-tools-12.9.86     |                0          20 KB  nvidia
[36m(setup pid=3505)[0m     cuda-cudart-12.9.79        |                0          17 KB  nvidia
[36m(setup pid=3505)[0m     cuda-cudart-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=3505)[0m     cuda-cudart-dev_linux-64-12.9.79|                0         374 KB  nvidia
[36m(setup pid=3505)[0m     cuda-cudart-static-12.9.79 |                0          17 KB  nvidia
[36m(setup pid=3505)[0m     cuda-cudart-static_linux-64-12.9.79|                0         1.1 MB  nvidia
[36m(setup pid=3505)[0m     cuda-cudart_linux-64-12.9.79|                0         189 KB  nvidia
[36m(setup pid=3505)[0m     cuda-cuobjdump-12.9.82     |                1         241 KB  nvidia
[36m(setup pid=3505)[0m     cuda-cupti-12.9.79         |                0         1.8 MB  nvidia
[36m(setup pid=3505)[0m     cuda-cupti-dev-12.9.79     |                0         4.1 MB  nvidia
[36m(setup pid=3505)[0m     cuda-cuxxfilt-12.9.82      |                1         209 KB  nvidia
[36m(setup pid=3505)[0m     cuda-driver-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=3505)[0m     cuda-driver-dev_linux-64-12.9.79|                0          31 KB  nvidia
[36m(setup pid=3505)[0m     cuda-gdb-12.9.79           |                1         374 KB  nvidia
[36m(setup pid=3505)[0m     cuda-libraries-12.9.1      |                0          17 KB  nvidia
[36m(setup pid=3505)[0m     cuda-libraries-dev-12.9.1  |                0          17 KB  nvidia
[36m(setup pid=3505)[0m     cuda-nsight-12.9.79        |                0       113.2 MB  nvidia
[36m(setup pid=3505)[0m     cuda-nvcc-12.9.86          |                0          17 KB  nvidia
[36m(setup pid=3505)[0m     cuda-nvcc-dev_linux-64-12.9.86|                0        13.8 MB  nvidia
[36m(setup pid=3505)[0m     cuda-nvcc-impl-12.9.86     |                0          19 KB  nvidia
[36m(setup pid=3505)[0m     cuda-nvcc-tools-12.9.86    |                0        26.1 MB  nvidia
[36m(setup pid=3505)[0m     cuda-nvcc_linux-64-12.9.86 |                0          20 KB  nvidia
[36m(setup pid=3505)[0m     cuda-nvdisasm-12.9.88      |                1         5.3 MB  nvidia
[36m(setup pid=3505)[0m     cuda-nvml-dev-12.9.79      |                1         136 KB  nvidia
[36m(setup pid=3505)[0m     cuda-nvprof-12.9.79        |                0         2.5 MB  nvidia
[36m(setup pid=3505)[0m     cuda-nvprune-12.9.82       |                1          65 KB  nvidia
[36m(setup pid=3505)[0m     cuda-nvrtc-12.9.86         |                0        64.1 MB  nvidia
[36m(setup pid=3505)[0m     cuda-nvrtc-dev-12.9.86     |                0          31 KB  nvidia
[36m(setup pid=3505)[0m     cuda-nvtx-12.9.79          |                0          24 KB  nvidia
[36m(setup pid=3505)[0m     cuda-nvvm-dev_linux-64-12.9.86|                0          18 KB  nvidia
[36m(setup pid=3505)[0m     cuda-nvvm-impl-12.9.86     |                0        20.5 MB  nvidia
[36m(setup pid=3505)[0m     cuda-nvvm-tools-12.9.86    |                0        23.2 MB  nvidia
[36m(setup pid=3505)[0m     cuda-nvvp-12.9.79          |                1       112.4 MB  nvidia
[36m(setup pid=3505)[0m     cuda-opencl-12.9.19        |                0          25 KB  nvidia
[36m(setup pid=3505)[0m     cuda-opencl-dev-12.9.19    |                0          91 KB  nvidia
[36m(setup pid=3505)[0m     cuda-profiler-api-12.9.79  |                0          19 KB  nvidia
[36m(setup pid=3505)[0m     cuda-runtime-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=3505)[0m     cuda-sanitizer-api-12.9.79 |                1         8.8 MB  nvidia
[36m(setup pid=3505)[0m     cuda-toolkit-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=3505)[0m     cuda-tools-12.9.1          |                0          17 KB  nvidia
[36m(setup pid=3505)[0m     cuda-version-12.9          |                3          17 KB  nvidia
[36m(setup pid=3505)[0m     cuda-visual-tools-12.9.1   |                0          17 KB  nvidia
[36m(setup pid=3505)[0m     dbus-1.13.18               |       hb2f20db_0         504 KB
[36m(setup pid=3505)[0m     expat-2.7.1                |       h6a678d5_0         182 KB
[36m(setup pid=3505)[0m     fontconfig-2.14.1          |       h55d465d_3         281 KB
[36m(setup pid=3505)[0m     freetype-2.13.3            |       h4a9f257_0         686 KB
[36m(setup pid=3505)[0m     frozendict-2.4.2           |  py310h5eee18b_0          55 KB
[36m(setup pid=3505)[0m     gcc_impl_linux-64-11.2.0   |       h1234567_1        22.2 MB
[36m(setup pid=3505)[0m     gcc_linux-64-11.2.0        |       h5c386dc_0          25 KB
[36m(setup pid=3505)[0m     gds-tools-1.14.1.1         |                4        37.7 MB  nvidia
[36m(setup pid=3505)[0m     glib-2.84.2                |       h6a678d5_0         526 KB
[36m(setup pid=3505)[0m     glib-tools-2.84.2          |       h6a678d5_0         119 KB
[36m(setup pid=3505)[0m     gmp-6.3.0                  |       h6a678d5_0         608 KB
[36m(setup pid=3505)[0m     gxx_impl_linux-64-11.2.0   |       h1234567_1        10.6 MB
[36m(setup pid=3505)[0m     gxx_linux-64-11.2.0        |       hc2dff05_0          24 KB
[36m(setup pid=3505)[0m     kernel-headers_linux-64-3.10.0|      h57e8cba_10         952 KB
[36m(setup pid=3505)[0m     libarchive-3.7.7           |       hfab0078_0         936 KB
[36m(setup pid=3505)[0m     libcublas-12.9.1.4         |                0       446.3 MB  nvidia
[36m(setup pid=3505)[0m     libcublas-dev-12.9.1.4     |                0          86 KB  nvidia
[36m(setup pid=3505)[0m     libcufft-11.4.1.4          |                0       154.8 MB  nvidia
[36m(setup pid=3505)[0m     libcufft-dev-11.4.1.4      |                0          29 KB  nvidia
[36m(setup pid=3505)[0m     libcufile-1.14.1.1         |                4         946 KB  nvidia
[36m(setup pid=3505)[0m     libcufile-dev-1.14.1.1     |                4          30 KB  nvidia
[36m(setup pid=3505)[0m     libcurand-10.3.10.19       |                0        44.0 MB  nvidia
[36m(setup pid=3505)[0m     libcurand-dev-10.3.10.19   |                0         238 KB  nvidia
[36m(setup pid=3505)[0m     libcusolver-11.7.5.82      |                0       195.7 MB  nvidia
[36m(setup pid=3505)[0m     libcusolver-dev-11.7.5.82  |                0          57 KB  nvidia
[36m(setup pid=3505)[0m     libcusparse-12.5.10.65     |                0       199.3 MB  nvidia
[36m(setup pid=3505)[0m     libcusparse-dev-12.5.10.65 |                0          46 KB  nvidia
[36m(setup pid=3505)[0m     libgcc-7.2.0               |       h69d50b8_2         269 KB
[36m(setup pid=3505)[0m     libgcc-devel_linux-64-11.2.0|       h1234567_1         2.5 MB
[36m(setup pid=3505)[0m     libglib-2.84.2             |       h37c7471_0         1.7 MB
[36m(setup pid=3505)[0m     libiconv-1.16              |       h5eee18b_3         759 KB
[36m(setup pid=3505)[0m     libmamba-2.0.5             |       haf1ee3a_1         2.2 MB
[36m(setup pid=3505)[0m     libmambapy-2.0.5           |  py310hdb19cb5_1         671 KB
[36m(setup pid=3505)[0m     libnpp-12.4.1.87           |                0       167.6 MB  nvidia
[36m(setup pid=3505)[0m     libnpp-dev-12.4.1.87       |                0         442 KB  nvidia
[36m(setup pid=3505)[0m     libnvfatbin-12.9.82        |                0         799 KB  nvidia
[36m(setup pid=3505)[0m     libnvfatbin-dev-12.9.82    |                0          22 KB  nvidia
[36m(setup pid=3505)[0m     libnvjitlink-12.9.86       |                0        29.2 MB  nvidia
[36m(setup pid=3505)[0m     libnvjitlink-dev-12.9.86   |                0          22 KB  nvidia
[36m(setup pid=3505)[0m     libnvjpeg-12.4.0.76        |                0         3.4 MB  nvidia
[36m(setup pid=3505)[0m     libnvjpeg-dev-12.4.0.76    |                0          27 KB  nvidia
[36m(setup pid=3505)[0m     libpng-1.6.39              |       h5eee18b_0         304 KB
[36m(setup pid=3505)[0m     libsolv-0.7.30             |       he621ea3_1         492 KB
[36m(setup pid=3505)[0m     libstdcxx-devel_linux-64-11.2.0|       h1234567_1        14.6 MB
[36m(setup pid=3505)[0m     libxcb-1.17.0              |       h9b100fa_0         430 KB
[36m(setup pid=3505)[0m     libxkbcommon-1.9.1         |       h69220b7_0         732 KB
[36m(setup pid=3505)[0m     libxml2-2.13.8             |       hfdd30dd_0         739 KB
[36m(setup pid=3505)[0m     nlohmann_json-3.11.2       |       h6a678d5_0         124 KB
[36m(setup pid=3505)[0m     nsight-compute-2025.2.1.3  |                0       319.3 MB  nvidia
[36m(setup pid=3505)[0m     nspr-4.35                  |       h6a678d5_0         244 KB
[36m(setup pid=3505)[0m     nss-3.89.1                 |       h6a678d5_0         2.1 MB
[36m(setup pid=3505)[0m     ocl-icd-2.3.2              |       h5eee18b_1         136 KB
[36m(setup pid=3505)[0m     openssl-3.0.17             |       h5eee18b_0         5.2 MB
[36m(setup pid=3505)[0m     pthread-stubs-0.3          |       h0ce48e5_1           5 KB
[36m(setup pid=3505)[0m     simdjson-3.10.1            |       hdb19cb5_0         258 KB
[36m(setup pid=3505)[0m     spdlog-1.11.0              |       hdb19cb5_0         234 KB
[36m(setup pid=3505)[0m     sysroot_linux-64-2.17      |      h57e8cba_10        32.6 MB
[36m(setup pid=3505)[0m     xkeyboard-config-2.44      |       h5eee18b_0         411 KB
[36m(setup pid=3505)[0m     xorg-libx11-1.8.12         |       h9b100fa_1         895 KB
[36m(setup pid=3505)[0m     xorg-libxau-1.0.12         |       h9b100fa_0          13 KB
[36m(setup pid=3505)[0m     xorg-libxdmcp-1.1.5        |       h9b100fa_0          19 KB
[36m(setup pid=3505)[0m     xorg-xorgproto-2024.1      |       h5eee18b_1         580 KB
[36m(setup pid=3505)[0m     xz-5.6.4                   |       h5eee18b_1         567 KB
[36m(setup pid=3505)[0m     ------------------------------------------------------------
[36m(setup pid=3505)[0m                                            Total:        2.06 GB
[36m(setup pid=3505)[0m 
[36m(setup pid=3505)[0m The following NEW packages will be INSTALLED:
[36m(setup pid=3505)[0m 
[36m(setup pid=3505)[0m   _sysroot_linux-64~ pkgs/main/noarch::_sysroot_linux-64_curr_repodata_hack-3-haa98f57_10 
[36m(setup pid=3505)[0m   binutils_impl_lin~ pkgs/main/linux-64::binutils_impl_linux-64-2.38-h2a08ee3_1 
[36m(setup pid=3505)[0m   binutils_linux-64  pkgs/main/linux-64::binutils_linux-64-2.38.0-hc2dff05_0 
[36m(setup pid=3505)[0m   cpp-expected       pkgs/main/linux-64::cpp-expected-1.1.0-hdb19cb5_0 
[36m(setup pid=3505)[0m   cuda               nvidia/linux-64::cuda-12.9.1-0 
[36m(setup pid=3505)[0m   cuda-cccl_linux-64 nvidia/linux-64::cuda-cccl_linux-64-12.9.27-0 
[36m(setup pid=3505)[0m   cuda-command-line~ nvidia/linux-64::cuda-command-line-tools-12.9.1-0 
[36m(setup pid=3505)[0m   cuda-compiler      nvidia/linux-64::cuda-compiler-12.9.1-0 
[36m(setup pid=3505)[0m   cuda-crt-dev_linu~ nvidia/noarch::cuda-crt-dev_linux-64-12.9.86-0 
[36m(setup pid=3505)[0m   cuda-crt-tools     nvidia/linux-64::cuda-crt-tools-12.9.86-0 
[36m(setup pid=3505)[0m   cuda-cudart        nvidia/linux-64::cuda-cudart-12.9.79-0 
[36m(setup pid=3505)[0m   cuda-cudart-dev    nvidia/linux-64::cuda-cudart-dev-12.9.79-0 
[36m(setup pid=3505)[0m   cuda-cudart-dev_l~ nvidia/noarch::cuda-cudart-dev_linux-64-12.9.79-0 
[36m(setup pid=3505)[0m   cuda-cudart-static nvidia/linux-64::cuda-cudart-static-12.9.79-0 
[36m(setup pid=3505)[0m   cuda-cudart-stati~ nvidia/noarch::cuda-cudart-static_linux-64-12.9.79-0 
[36m(setup pid=3505)[0m   cuda-cudart_linux~ nvidia/noarch::cuda-cudart_linux-64-12.9.79-0 
[36m(setup pid=3505)[0m   cuda-cuobjdump     nvidia/linux-64::cuda-cuobjdump-12.9.82-1 
[36m(setup pid=3505)[0m   cuda-cupti         nvidia/linux-64::cuda-cupti-12.9.79-0 
[36m(setup pid=3505)[0m   cuda-cupti-dev     nvidia/linux-64::cuda-cupti-dev-12.9.79-0 
[36m(setup pid=3505)[0m   cuda-cuxxfilt      nvidia/linux-64::cuda-cuxxfilt-12.9.82-1 
[36m(setup pid=3505)[0m   cuda-driver-dev    nvidia/linux-64::cuda-driver-dev-12.9.79-0 
[36m(setup pid=3505)[0m   cuda-driver-dev_l~ nvidia/noarch::cuda-driver-dev_linux-64-12.9.79-0 
[36m(setup pid=3505)[0m   cuda-gdb           nvidia/linux-64::cuda-gdb-12.9.79-1 
[36m(setup pid=3505)[0m   cuda-libraries     nvidia/linux-64::cuda-libraries-12.9.1-0 
[36m(setup pid=3505)[0m   cuda-libraries-dev nvidia/linux-64::cuda-libraries-dev-12.9.1-0 
[36m(setup pid=3505)[0m   cuda-nsight        nvidia/linux-64::cuda-nsight-12.9.79-0 
[36m(setup pid=3505)[0m   cuda-nvcc          nvidia/linux-64::cuda-nvcc-12.9.86-0 
[36m(setup pid=3505)[0m   cuda-nvcc-dev_lin~ nvidia/noarch::cuda-nvcc-dev_linux-64-12.9.86-0 
[36m(setup pid=3505)[0m   cuda-nvcc-impl     nvidia/linux-64::cuda-nvcc-impl-12.9.86-0 
[36m(setup pid=3505)[0m   cuda-nvcc-tools    nvidia/linux-64::cuda-nvcc-tools-12.9.86-0 
[36m(setup pid=3505)[0m   cuda-nvcc_linux-64 nvidia/linux-64::cuda-nvcc_linux-64-12.9.86-0 
[36m(setup pid=3505)[0m   cuda-nvdisasm      nvidia/linux-64::cuda-nvdisasm-12.9.88-1 
[36m(setup pid=3505)[0m   cuda-nvml-dev      nvidia/linux-64::cuda-nvml-dev-12.9.79-1 
[36m(setup pid=3505)[0m   cuda-nvprof        nvidia/linux-64::cuda-nvprof-12.9.79-0 
[36m(setup pid=3505)[0m   cuda-nvprune       nvidia/linux-64::cuda-nvprune-12.9.82-1 
[36m(setup pid=3505)[0m   cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-12.9.86-0 
[36m(setup pid=3505)[0m   cuda-nvrtc-dev     nvidia/linux-64::cuda-nvrtc-dev-12.9.86-0 
[36m(setup pid=3505)[0m   cuda-nvtx          nvidia/linux-64::cuda-nvtx-12.9.79-0 
[36m(setup pid=3505)[0m   cuda-nvvm-dev_lin~ nvidia/noarch::cuda-nvvm-dev_linux-64-12.9.86-0 
[36m(setup pid=3505)[0m   cuda-nvvm-impl     nvidia/linux-64::cuda-nvvm-impl-12.9.86-0 
[36m(setup pid=3505)[0m   cuda-nvvm-tools    nvidia/linux-64::cuda-nvvm-tools-12.9.86-0 
[36m(setup pid=3505)[0m   cuda-nvvp          nvidia/linux-64::cuda-nvvp-12.9.79-1 
[36m(setup pid=3505)[0m   cuda-opencl        nvidia/linux-64::cuda-opencl-12.9.19-0 
[36m(setup pid=3505)[0m   cuda-opencl-dev    nvidia/linux-64::cuda-opencl-dev-12.9.19-0 
[36m(setup pid=3505)[0m   cuda-profiler-api  nvidia/linux-64::cuda-profiler-api-12.9.79-0 
[36m(setup pid=3505)[0m   cuda-runtime       nvidia/linux-64::cuda-runtime-12.9.1-0 
[36m(setup pid=3505)[0m   cuda-sanitizer-api nvidia/linux-64::cuda-sanitizer-api-12.9.79-1 
[36m(setup pid=3505)[0m   cuda-toolkit       nvidia/linux-64::cuda-toolkit-12.9.1-0 
[36m(setup pid=3505)[0m   cuda-tools         nvidia/linux-64::cuda-tools-12.9.1-0 
[36m(setup pid=3505)[0m   cuda-version       nvidia/noarch::cuda-version-12.9-3 
[36m(setup pid=3505)[0m   cuda-visual-tools  nvidia/linux-64::cuda-visual-tools-12.9.1-0 
[36m(setup pid=3505)[0m   dbus               pkgs/main/linux-64::dbus-1.13.18-hb2f20db_0 
[36m(setup pid=3505)[0m   expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 
[36m(setup pid=3505)[0m   fontconfig         pkgs/main/linux-64::fontconfig-2.14.1-h55d465d_3 
[36m(setup pid=3505)[0m   freetype           pkgs/main/linux-64::freetype-2.13.3-h4a9f257_0 
[36m(setup pid=3505)[0m   frozendict         pkgs/main/linux-64::frozendict-2.4.2-py310h5eee18b_0 
[36m(setup pid=3505)[0m   gcc_impl_linux-64  pkgs/main/linux-64::gcc_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3505)[0m   gcc_linux-64       pkgs/main/linux-64::gcc_linux-64-11.2.0-h5c386dc_0 
[36m(setup pid=3505)[0m   gds-tools          nvidia/linux-64::gds-tools-1.14.1.1-4 
[36m(setup pid=3505)[0m   glib               pkgs/main/linux-64::glib-2.84.2-h6a678d5_0 
[36m(setup pid=3505)[0m   glib-tools         pkgs/main/linux-64::glib-tools-2.84.2-h6a678d5_0 
[36m(setup pid=3505)[0m   gmp                pkgs/main/linux-64::gmp-6.3.0-h6a678d5_0 
[36m(setup pid=3505)[0m   gxx_impl_linux-64  pkgs/main/linux-64::gxx_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3505)[0m   gxx_linux-64       pkgs/main/linux-64::gxx_linux-64-11.2.0-hc2dff05_0 
[36m(setup pid=3505)[0m   kernel-headers_li~ pkgs/main/noarch::kernel-headers_linux-64-3.10.0-h57e8cba_10 
[36m(setup pid=3505)[0m   libcublas          nvidia/linux-64::libcublas-12.9.1.4-0 
[36m(setup pid=3505)[0m   libcublas-dev      nvidia/linux-64::libcublas-dev-12.9.1.4-0 
[36m(setup pid=3505)[0m   libcufft           nvidia/linux-64::libcufft-11.4.1.4-0 
[36m(setup pid=3505)[0m   libcufft-dev       nvidia/linux-64::libcufft-dev-11.4.1.4-0 
[36m(setup pid=3505)[0m   libcufile          nvidia/linux-64::libcufile-1.14.1.1-4 
[36m(setup pid=3505)[0m   libcufile-dev      nvidia/linux-64::libcufile-dev-1.14.1.1-4 
[36m(setup pid=3505)[0m   libcurand          nvidia/linux-64::libcurand-10.3.10.19-0 
[36m(setup pid=3505)[0m   libcurand-dev      nvidia/linux-64::libcurand-dev-10.3.10.19-0 
[36m(setup pid=3505)[0m   libcusolver        nvidia/linux-64::libcusolver-11.7.5.82-0 
[36m(setup pid=3505)[0m   libcusolver-dev    nvidia/linux-64::libcusolver-dev-11.7.5.82-0 
[36m(setup pid=3505)[0m   libcusparse        nvidia/linux-64::libcusparse-12.5.10.65-0 
[36m(setup pid=3505)[0m   libcusparse-dev    nvidia/linux-64::libcusparse-dev-12.5.10.65-0 
[36m(setup pid=3505)[0m   libgcc             pkgs/main/linux-64::libgcc-7.2.0-h69d50b8_2 
[36m(setup pid=3505)[0m   libgcc-devel_linu~ pkgs/main/linux-64::libgcc-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3505)[0m   libglib            pkgs/main/linux-64::libglib-2.84.2-h37c7471_0 
[36m(setup pid=3505)[0m   libiconv           pkgs/main/linux-64::libiconv-1.16-h5eee18b_3 
[36m(setup pid=3505)[0m   libnpp             nvidia/linux-64::libnpp-12.4.1.87-0 
[36m(setup pid=3505)[0m   libnpp-dev         nvidia/linux-64::libnpp-dev-12.4.1.87-0 
[36m(setup pid=3505)[0m   libnvfatbin        nvidia/linux-64::libnvfatbin-12.9.82-0 
[36m(setup pid=3505)[0m   libnvfatbin-dev    nvidia/linux-64::libnvfatbin-dev-12.9.82-0 
[36m(setup pid=3505)[0m   libnvjitlink       nvidia/linux-64::libnvjitlink-12.9.86-0 
[36m(setup pid=3505)[0m   libnvjitlink-dev   nvidia/linux-64::libnvjitlink-dev-12.9.86-0 
[36m(setup pid=3505)[0m   libnvjpeg          nvidia/linux-64::libnvjpeg-12.4.0.76-0 
[36m(setup pid=3505)[0m   libnvjpeg-dev      nvidia/linux-64::libnvjpeg-dev-12.4.0.76-0 
[36m(setup pid=3505)[0m   libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 
[36m(setup pid=3505)[0m   libstdcxx-devel_l~ pkgs/main/linux-64::libstdcxx-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=3505)[0m   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 
[36m(setup pid=3505)[0m   libxkbcommon       pkgs/main/linux-64::libxkbcommon-1.9.1-h69220b7_0 
[36m(setup pid=3505)[0m   nlohmann_json      pkgs/main/linux-64::nlohmann_json-3.11.2-h6a678d5_0 
[36m(setup pid=3505)[0m   nsight-compute     nvidia/linux-64::nsight-compute-2025.2.1.3-0 
[36m(setup pid=3505)[0m   nspr               pkgs/main/linux-64::nspr-4.35-h6a678d5_0 
[36m(setup pid=3505)[0m   nss                pkgs/main/linux-64::nss-3.89.1-h6a678d5_0 
[36m(setup pid=3505)[0m   ocl-icd            pkgs/main/linux-64::ocl-icd-2.3.2-h5eee18b_1 
[36m(setup pid=3505)[0m   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 
[36m(setup pid=3505)[0m   simdjson           pkgs/main/linux-64::simdjson-3.10.1-hdb19cb5_0 
[36m(setup pid=3505)[0m   spdlog             pkgs/main/linux-64::spdlog-1.11.0-hdb19cb5_0 
[36m(setup pid=3505)[0m   sysroot_linux-64   pkgs/main/noarch::sysroot_linux-64-2.17-h57e8cba_10 
[36m(setup pid=3505)[0m   xkeyboard-config   pkgs/main/linux-64::xkeyboard-config-2.44-h5eee18b_0 
[36m(setup pid=3505)[0m   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 
[36m(setup pid=3505)[0m   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 
[36m(setup pid=3505)[0m   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 
[36m(setup pid=3505)[0m   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 
[36m(setup pid=3505)[0m 
[36m(setup pid=3505)[0m The following packages will be UPDATED:
[36m(setup pid=3505)[0m 
[36m(setup pid=3505)[0m   archspec                               0.2.1-pyhd3eb1b0_0 --> 0.2.3-pyhd3eb1b0_0 
[36m(setup pid=3505)[0m   ca-certificates                     2023.12.12-h06a4308_0 --> 2025.2.25-h06a4308_0 
[36m(setup pid=3505)[0m   certifi                        2023.11.17-py310h06a4308_0 --> 2025.7.14-py310h06a4308_0 
[36m(setup pid=3505)[0m   conda                             23.11.0-py310h06a4308_0 --> 24.11.3-py310h06a4308_0 
[36m(setup pid=3505)[0m   libarchive                               3.6.2-h6ac8c49_2 --> 3.7.7-hfab0078_0 
[36m(setup pid=3505)[0m   libmamba                                 1.5.3-haf1ee3a_0 --> 2.0.5-haf1ee3a_1 
[36m(setup pid=3505)[0m   libmambapy                          1.5.3-py310h2dafd23_0 --> 2.0.5-py310hdb19cb5_1 
[36m(setup pid=3505)[0m   libsolv                                 0.7.24-he621ea3_0 --> 0.7.30-he621ea3_1 
[36m(setup pid=3505)[0m   libxml2                                 2.10.4-hf1b16e4_1 --> 2.13.8-hfdd30dd_0 
[36m(setup pid=3505)[0m   openssl                                 3.0.12-h7f8727e_0 --> 3.0.17-h5eee18b_0 
[36m(setup pid=3505)[0m   xz                                       5.4.5-h5eee18b_0 --> 5.6.4-h5eee18b_1 
[36m(setup pid=3505)[0m 
[36m(setup pid=3505)[0m 
[36m(setup pid=3505)[0m Proceed ([y]/n)? 
[36m(setup pid=3505)[0m 
[36m(setup pid=2715, ip=10.102.30.60)[0m Collecting package metadata (repodata.json): ...working... done
[36m(setup pid=2715, ip=10.102.30.60)[0m Solving environment: ...working... done
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=2715, ip=10.102.30.60)[0m ## Package Plan ##
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=2715, ip=10.102.30.60)[0m   environment location: /root/miniconda3
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=2715, ip=10.102.30.60)[0m   added / updated specs:
[36m(setup pid=2715, ip=10.102.30.60)[0m     - cuda
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=2715, ip=10.102.30.60)[0m The following packages will be downloaded:
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=2715, ip=10.102.30.60)[0m     package                    |            build
[36m(setup pid=2715, ip=10.102.30.60)[0m     ---------------------------|-----------------
[36m(setup pid=2715, ip=10.102.30.60)[0m     _sysroot_linux-64_curr_repodata_hack-3|      haa98f57_10          12 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     archspec-0.2.3             |     pyhd3eb1b0_0          47 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     binutils_impl_linux-64-2.38|       h2a08ee3_1         5.2 MB
[36m(setup pid=2715, ip=10.102.30.60)[0m     binutils_linux-64-2.38.0   |       hc2dff05_0          24 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     ca-certificates-2025.2.25  |       h06a4308_0         129 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     certifi-2025.7.14          |  py310h06a4308_0         160 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     conda-24.11.3              |  py310h06a4308_0         930 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     cpp-expected-1.1.0         |       hdb19cb5_0         130 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-12.9.1                |                0          17 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-cccl_linux-64-12.9.27 |                0         1.1 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-command-line-tools-12.9.1|                0          17 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-compiler-12.9.1       |                0          17 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-crt-dev_linux-64-12.9.86|                0          84 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-crt-tools-12.9.86     |                0          20 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-cudart-12.9.79        |                0          17 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-cudart-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-cudart-dev_linux-64-12.9.79|                0         374 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-cudart-static-12.9.79 |                0          17 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-cudart-static_linux-64-12.9.79|                0         1.1 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-cudart_linux-64-12.9.79|                0         189 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-cuobjdump-12.9.82     |                1         241 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-cupti-12.9.79         |                0         1.8 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-cupti-dev-12.9.79     |                0         4.1 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-cuxxfilt-12.9.82      |                1         209 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-driver-dev-12.9.79    |                0          17 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-driver-dev_linux-64-12.9.79|                0          31 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-gdb-12.9.79           |                1         374 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-libraries-12.9.1      |                0          17 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-libraries-dev-12.9.1  |                0          17 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-nsight-12.9.79        |                0       113.2 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-nvcc-12.9.86          |                0          17 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-nvcc-dev_linux-64-12.9.86|                0        13.8 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-nvcc-impl-12.9.86     |                0          19 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-nvcc-tools-12.9.86    |                0        26.1 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-nvcc_linux-64-12.9.86 |                0          20 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-nvdisasm-12.9.88      |                1         5.3 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-nvml-dev-12.9.79      |                1         136 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-nvprof-12.9.79        |                0         2.5 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-nvprune-12.9.82       |                1          65 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-nvrtc-12.9.86         |                0        64.1 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-nvrtc-dev-12.9.86     |                0          31 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-nvtx-12.9.79          |                0          24 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-nvvm-dev_linux-64-12.9.86|                0          18 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-nvvm-impl-12.9.86     |                0        20.5 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-nvvm-tools-12.9.86    |                0        23.2 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-nvvp-12.9.79          |                1       112.4 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-opencl-12.9.19        |                0          25 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-opencl-dev-12.9.19    |                0          91 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-profiler-api-12.9.79  |                0          19 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-runtime-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-sanitizer-api-12.9.79 |                1         8.8 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-toolkit-12.9.1        |                0          17 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-tools-12.9.1          |                0          17 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-version-12.9          |                3          17 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     cuda-visual-tools-12.9.1   |                0          17 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     dbus-1.13.18               |       hb2f20db_0         504 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     expat-2.7.1                |       h6a678d5_0         182 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     fontconfig-2.14.1          |       h55d465d_3         281 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     freetype-2.13.3            |       h4a9f257_0         686 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     frozendict-2.4.2           |  py310h5eee18b_0          55 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     gcc_impl_linux-64-11.2.0   |       h1234567_1        22.2 MB
[36m(setup pid=2715, ip=10.102.30.60)[0m     gcc_linux-64-11.2.0        |       h5c386dc_0          25 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     gds-tools-1.14.1.1         |                4        37.7 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     glib-2.84.2                |       h6a678d5_0         526 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     glib-tools-2.84.2          |       h6a678d5_0         119 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     gmp-6.3.0                  |       h6a678d5_0         608 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     gxx_impl_linux-64-11.2.0   |       h1234567_1        10.6 MB
[36m(setup pid=2715, ip=10.102.30.60)[0m     gxx_linux-64-11.2.0        |       hc2dff05_0          24 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     kernel-headers_linux-64-3.10.0|      h57e8cba_10         952 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     libarchive-3.7.7           |       hfab0078_0         936 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     libcublas-12.9.1.4         |                0       446.3 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     libcublas-dev-12.9.1.4     |                0          86 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     libcufft-11.4.1.4          |                0       154.8 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     libcufft-dev-11.4.1.4      |                0          29 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     libcufile-1.14.1.1         |                4         946 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     libcufile-dev-1.14.1.1     |                4          30 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     libcurand-10.3.10.19       |                0        44.0 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     libcurand-dev-10.3.10.19   |                0         238 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     libcusolver-11.7.5.82      |                0       195.7 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     libcusolver-dev-11.7.5.82  |                0          57 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     libcusparse-12.5.10.65     |                0       199.3 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     libcusparse-dev-12.5.10.65 |                0          46 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     libgcc-7.2.0               |       h69d50b8_2         269 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     libgcc-devel_linux-64-11.2.0|       h1234567_1         2.5 MB
[36m(setup pid=2715, ip=10.102.30.60)[0m     libglib-2.84.2             |       h37c7471_0         1.7 MB
[36m(setup pid=2715, ip=10.102.30.60)[0m     libiconv-1.16              |       h5eee18b_3         759 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     libmamba-2.0.5             |       haf1ee3a_1         2.2 MB
[36m(setup pid=2715, ip=10.102.30.60)[0m     libmambapy-2.0.5           |  py310hdb19cb5_1         671 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     libnpp-12.4.1.87           |                0       167.6 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     libnpp-dev-12.4.1.87       |                0         442 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     libnvfatbin-12.9.82        |                0         799 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     libnvfatbin-dev-12.9.82    |                0          22 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     libnvjitlink-12.9.86       |                0        29.2 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     libnvjitlink-dev-12.9.86   |                0          22 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     libnvjpeg-12.4.0.76        |                0         3.4 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     libnvjpeg-dev-12.4.0.76    |                0          27 KB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     libpng-1.6.39              |       h5eee18b_0         304 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     libsolv-0.7.30             |       he621ea3_1         492 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     libstdcxx-devel_linux-64-11.2.0|       h1234567_1        14.6 MB
[36m(setup pid=2715, ip=10.102.30.60)[0m     libxcb-1.17.0              |       h9b100fa_0         430 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     libxkbcommon-1.9.1         |       h69220b7_0         732 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     libxml2-2.13.8             |       hfdd30dd_0         739 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     nlohmann_json-3.11.2       |       h6a678d5_0         124 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     nsight-compute-2025.2.1.3  |                0       319.3 MB  nvidia
[36m(setup pid=2715, ip=10.102.30.60)[0m     nspr-4.35                  |       h6a678d5_0         244 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     nss-3.89.1                 |       h6a678d5_0         2.1 MB
[36m(setup pid=2715, ip=10.102.30.60)[0m     ocl-icd-2.3.2              |       h5eee18b_1         136 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     openssl-3.0.17             |       h5eee18b_0         5.2 MB
[36m(setup pid=2715, ip=10.102.30.60)[0m     pthread-stubs-0.3          |       h0ce48e5_1           5 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     simdjson-3.10.1            |       hdb19cb5_0         258 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     spdlog-1.11.0              |       hdb19cb5_0         234 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     sysroot_linux-64-2.17      |      h57e8cba_10        32.6 MB
[36m(setup pid=2715, ip=10.102.30.60)[0m     xkeyboard-config-2.44      |       h5eee18b_0         411 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     xorg-libx11-1.8.12         |       h9b100fa_1         895 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     xorg-libxau-1.0.12         |       h9b100fa_0          13 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     xorg-libxdmcp-1.1.5        |       h9b100fa_0          19 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     xorg-xorgproto-2024.1      |       h5eee18b_1         580 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     xz-5.6.4                   |       h5eee18b_1         567 KB
[36m(setup pid=2715, ip=10.102.30.60)[0m     ------------------------------------------------------------
[36m(setup pid=2715, ip=10.102.30.60)[0m                                            Total:        2.06 GB
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=2715, ip=10.102.30.60)[0m The following NEW packages will be INSTALLED:
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=2715, ip=10.102.30.60)[0m   _sysroot_linux-64~ pkgs/main/noarch::_sysroot_linux-64_curr_repodata_hack-3-haa98f57_10 
[36m(setup pid=2715, ip=10.102.30.60)[0m   binutils_impl_lin~ pkgs/main/linux-64::binutils_impl_linux-64-2.38-h2a08ee3_1 
[36m(setup pid=2715, ip=10.102.30.60)[0m   binutils_linux-64  pkgs/main/linux-64::binutils_linux-64-2.38.0-hc2dff05_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cpp-expected       pkgs/main/linux-64::cpp-expected-1.1.0-hdb19cb5_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda               nvidia/linux-64::cuda-12.9.1-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-cccl_linux-64 nvidia/linux-64::cuda-cccl_linux-64-12.9.27-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-command-line~ nvidia/linux-64::cuda-command-line-tools-12.9.1-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-compiler      nvidia/linux-64::cuda-compiler-12.9.1-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-crt-dev_linu~ nvidia/noarch::cuda-crt-dev_linux-64-12.9.86-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-crt-tools     nvidia/linux-64::cuda-crt-tools-12.9.86-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-cudart        nvidia/linux-64::cuda-cudart-12.9.79-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-cudart-dev    nvidia/linux-64::cuda-cudart-dev-12.9.79-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-cudart-dev_l~ nvidia/noarch::cuda-cudart-dev_linux-64-12.9.79-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-cudart-static nvidia/linux-64::cuda-cudart-static-12.9.79-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-cudart-stati~ nvidia/noarch::cuda-cudart-static_linux-64-12.9.79-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-cudart_linux~ nvidia/noarch::cuda-cudart_linux-64-12.9.79-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-cuobjdump     nvidia/linux-64::cuda-cuobjdump-12.9.82-1 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-cupti         nvidia/linux-64::cuda-cupti-12.9.79-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-cupti-dev     nvidia/linux-64::cuda-cupti-dev-12.9.79-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-cuxxfilt      nvidia/linux-64::cuda-cuxxfilt-12.9.82-1 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-driver-dev    nvidia/linux-64::cuda-driver-dev-12.9.79-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-driver-dev_l~ nvidia/noarch::cuda-driver-dev_linux-64-12.9.79-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-gdb           nvidia/linux-64::cuda-gdb-12.9.79-1 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-libraries     nvidia/linux-64::cuda-libraries-12.9.1-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-libraries-dev nvidia/linux-64::cuda-libraries-dev-12.9.1-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-nsight        nvidia/linux-64::cuda-nsight-12.9.79-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-nvcc          nvidia/linux-64::cuda-nvcc-12.9.86-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-nvcc-dev_lin~ nvidia/noarch::cuda-nvcc-dev_linux-64-12.9.86-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-nvcc-impl     nvidia/linux-64::cuda-nvcc-impl-12.9.86-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-nvcc-tools    nvidia/linux-64::cuda-nvcc-tools-12.9.86-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-nvcc_linux-64 nvidia/linux-64::cuda-nvcc_linux-64-12.9.86-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-nvdisasm      nvidia/linux-64::cuda-nvdisasm-12.9.88-1 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-nvml-dev      nvidia/linux-64::cuda-nvml-dev-12.9.79-1 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-nvprof        nvidia/linux-64::cuda-nvprof-12.9.79-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-nvprune       nvidia/linux-64::cuda-nvprune-12.9.82-1 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-12.9.86-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-nvrtc-dev     nvidia/linux-64::cuda-nvrtc-dev-12.9.86-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-nvtx          nvidia/linux-64::cuda-nvtx-12.9.79-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-nvvm-dev_lin~ nvidia/noarch::cuda-nvvm-dev_linux-64-12.9.86-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-nvvm-impl     nvidia/linux-64::cuda-nvvm-impl-12.9.86-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-nvvm-tools    nvidia/linux-64::cuda-nvvm-tools-12.9.86-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-nvvp          nvidia/linux-64::cuda-nvvp-12.9.79-1 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-opencl        nvidia/linux-64::cuda-opencl-12.9.19-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-opencl-dev    nvidia/linux-64::cuda-opencl-dev-12.9.19-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-profiler-api  nvidia/linux-64::cuda-profiler-api-12.9.79-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-runtime       nvidia/linux-64::cuda-runtime-12.9.1-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-sanitizer-api nvidia/linux-64::cuda-sanitizer-api-12.9.79-1 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-toolkit       nvidia/linux-64::cuda-toolkit-12.9.1-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-tools         nvidia/linux-64::cuda-tools-12.9.1-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-version       nvidia/noarch::cuda-version-12.9-3 
[36m(setup pid=2715, ip=10.102.30.60)[0m   cuda-visual-tools  nvidia/linux-64::cuda-visual-tools-12.9.1-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   dbus               pkgs/main/linux-64::dbus-1.13.18-hb2f20db_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   fontconfig         pkgs/main/linux-64::fontconfig-2.14.1-h55d465d_3 
[36m(setup pid=2715, ip=10.102.30.60)[0m   freetype           pkgs/main/linux-64::freetype-2.13.3-h4a9f257_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   frozendict         pkgs/main/linux-64::frozendict-2.4.2-py310h5eee18b_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   gcc_impl_linux-64  pkgs/main/linux-64::gcc_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2715, ip=10.102.30.60)[0m   gcc_linux-64       pkgs/main/linux-64::gcc_linux-64-11.2.0-h5c386dc_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   gds-tools          nvidia/linux-64::gds-tools-1.14.1.1-4 
[36m(setup pid=2715, ip=10.102.30.60)[0m   glib               pkgs/main/linux-64::glib-2.84.2-h6a678d5_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   glib-tools         pkgs/main/linux-64::glib-tools-2.84.2-h6a678d5_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   gmp                pkgs/main/linux-64::gmp-6.3.0-h6a678d5_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   gxx_impl_linux-64  pkgs/main/linux-64::gxx_impl_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2715, ip=10.102.30.60)[0m   gxx_linux-64       pkgs/main/linux-64::gxx_linux-64-11.2.0-hc2dff05_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   kernel-headers_li~ pkgs/main/noarch::kernel-headers_linux-64-3.10.0-h57e8cba_10 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libcublas          nvidia/linux-64::libcublas-12.9.1.4-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libcublas-dev      nvidia/linux-64::libcublas-dev-12.9.1.4-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libcufft           nvidia/linux-64::libcufft-11.4.1.4-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libcufft-dev       nvidia/linux-64::libcufft-dev-11.4.1.4-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libcufile          nvidia/linux-64::libcufile-1.14.1.1-4 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libcufile-dev      nvidia/linux-64::libcufile-dev-1.14.1.1-4 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libcurand          nvidia/linux-64::libcurand-10.3.10.19-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libcurand-dev      nvidia/linux-64::libcurand-dev-10.3.10.19-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libcusolver        nvidia/linux-64::libcusolver-11.7.5.82-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libcusolver-dev    nvidia/linux-64::libcusolver-dev-11.7.5.82-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libcusparse        nvidia/linux-64::libcusparse-12.5.10.65-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libcusparse-dev    nvidia/linux-64::libcusparse-dev-12.5.10.65-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libgcc             pkgs/main/linux-64::libgcc-7.2.0-h69d50b8_2 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libgcc-devel_linu~ pkgs/main/linux-64::libgcc-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libglib            pkgs/main/linux-64::libglib-2.84.2-h37c7471_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libiconv           pkgs/main/linux-64::libiconv-1.16-h5eee18b_3 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libnpp             nvidia/linux-64::libnpp-12.4.1.87-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libnpp-dev         nvidia/linux-64::libnpp-dev-12.4.1.87-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libnvfatbin        nvidia/linux-64::libnvfatbin-12.9.82-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libnvfatbin-dev    nvidia/linux-64::libnvfatbin-dev-12.9.82-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libnvjitlink       nvidia/linux-64::libnvjitlink-12.9.86-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libnvjitlink-dev   nvidia/linux-64::libnvjitlink-dev-12.9.86-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libnvjpeg          nvidia/linux-64::libnvjpeg-12.4.0.76-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libnvjpeg-dev      nvidia/linux-64::libnvjpeg-dev-12.4.0.76-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libstdcxx-devel_l~ pkgs/main/linux-64::libstdcxx-devel_linux-64-11.2.0-h1234567_1 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libxkbcommon       pkgs/main/linux-64::libxkbcommon-1.9.1-h69220b7_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   nlohmann_json      pkgs/main/linux-64::nlohmann_json-3.11.2-h6a678d5_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   nsight-compute     nvidia/linux-64::nsight-compute-2025.2.1.3-0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   nspr               pkgs/main/linux-64::nspr-4.35-h6a678d5_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   nss                pkgs/main/linux-64::nss-3.89.1-h6a678d5_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   ocl-icd            pkgs/main/linux-64::ocl-icd-2.3.2-h5eee18b_1 
[36m(setup pid=2715, ip=10.102.30.60)[0m   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 
[36m(setup pid=2715, ip=10.102.30.60)[0m   simdjson           pkgs/main/linux-64::simdjson-3.10.1-hdb19cb5_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   spdlog             pkgs/main/linux-64::spdlog-1.11.0-hdb19cb5_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   sysroot_linux-64   pkgs/main/noarch::sysroot_linux-64-2.17-h57e8cba_10 
[36m(setup pid=2715, ip=10.102.30.60)[0m   xkeyboard-config   pkgs/main/linux-64::xkeyboard-config-2.44-h5eee18b_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 
[36m(setup pid=2715, ip=10.102.30.60)[0m   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=2715, ip=10.102.30.60)[0m The following packages will be UPDATED:
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=2715, ip=10.102.30.60)[0m   archspec                               0.2.1-pyhd3eb1b0_0 --> 0.2.3-pyhd3eb1b0_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   ca-certificates                     2023.12.12-h06a4308_0 --> 2025.2.25-h06a4308_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   certifi                        2023.11.17-py310h06a4308_0 --> 2025.7.14-py310h06a4308_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   conda                             23.11.0-py310h06a4308_0 --> 24.11.3-py310h06a4308_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libarchive                               3.6.2-h6ac8c49_2 --> 3.7.7-hfab0078_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libmamba                                 1.5.3-haf1ee3a_0 --> 2.0.5-haf1ee3a_1 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libmambapy                          1.5.3-py310h2dafd23_0 --> 2.0.5-py310hdb19cb5_1 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libsolv                                 0.7.24-he621ea3_0 --> 0.7.30-he621ea3_1 
[36m(setup pid=2715, ip=10.102.30.60)[0m   libxml2                                 2.10.4-hf1b16e4_1 --> 2.13.8-hfdd30dd_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   openssl                                 3.0.12-h7f8727e_0 --> 3.0.17-h5eee18b_0 
[36m(setup pid=2715, ip=10.102.30.60)[0m   xz                                       5.4.5-h5eee18b_0 --> 5.6.4-h5eee18b_1 
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=2715, ip=10.102.30.60)[0m Proceed ([y]/n)? 
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=3505)[0m Downloading and Extracting Packages: ...working... done
[36m(setup pid=3505)[0m Preparing transaction: ...working... done
[36m(setup pid=3505)[0m Verifying transaction: ...working... done
[36m(setup pid=3505)[0m Executing transaction: ...working... done
[36m(setup pid=3505)[0m Error while loading conda entry point: conda-libmamba-solver (module 'libmambapy' has no attribute 'QueryFormat')
[36m(setup pid=3505)[0m Using CPython 3.10.12 interpreter at: /usr/bin/python3.10
[36m(setup pid=3505)[0m Creating virtual environment with seed packages at: /root/training
[36m(setup pid=3505)[0m  + pip==25.2
[36m(setup pid=3505)[0m  + setuptools==80.9.0
[36m(setup pid=3505)[0m  + wheel==0.45.1
[36m(setup pid=3505)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3505)[0m Resolved 29 packages in 117ms
[36m(setup pid=3505)[0m Downloading nvidia-curand-cu12 (53.7MiB)
[36m(setup pid=3505)[0m Downloading nvidia-cuda-nvrtc-cu12 (22.6MiB)
[36m(setup pid=3505)[0m Downloading triton (148.4MiB)
[36m(setup pid=3505)[0m Downloading nvidia-cuda-cupti-cu12 (8.5MiB)
[36m(setup pid=3505)[0m Downloading nvidia-nccl-cu12 (192.0MiB)
[36m(setup pid=3505)[0m Downloading nvidia-nvjitlink-cu12 (18.8MiB)
[36m(setup pid=3505)[0m Downloading nvidia-cufile-cu12 (1.1MiB)
[36m(setup pid=3505)[0m Downloading sympy (6.0MiB)
[36m(setup pid=3505)[0m Downloading torchaudio (3.3MiB)
[36m(setup pid=3505)[0m Downloading nvidia-cusparse-cu12 (206.5MiB)
[36m(setup pid=3505)[0m Downloading nvidia-cublas-cu12 (374.9MiB)
[36m(setup pid=3505)[0m Downloading pillow (6.3MiB)
[36m(setup pid=3505)[0m Downloading torch (783.1MiB)
[36m(setup pid=3505)[0m Downloading nvidia-cudnn-cu12 (544.5MiB)
[36m(setup pid=3505)[0m Downloading nvidia-cusolver-cu12 (150.9MiB)
[36m(setup pid=3505)[0m Downloading nvidia-cufft-cu12 (190.9MiB)
[36m(setup pid=3505)[0m Downloading torchvision (7.1MiB)
[36m(setup pid=3505)[0m Downloading nvidia-cusparselt-cu12 (149.5MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading and Extracting Packages: ...working... done
[36m(setup pid=3505)[0m  Downloading nvidia-cufile-cu12
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing transaction: ...working... done
[36m(setup pid=3505)[0m  Downloading torchaudio
[36m(setup pid=3505)[0m  Downloading torchvision
[36m(setup pid=3505)[0m  Downloading pillow
[36m(setup pid=3505)[0m  Downloading nvidia-cuda-cupti-cu12
[36m(setup pid=2715, ip=10.102.30.60)[0m Verifying transaction: ...working... done
[36m(setup pid=3505)[0m  Downloading nvidia-nvjitlink-cu12
[36m(setup pid=3505)[0m  Downloading nvidia-cuda-nvrtc-cu12
[36m(setup pid=2715, ip=10.102.30.60)[0m Executing transaction: ...working... done
[36m(setup pid=2715, ip=10.102.30.60)[0m Error while loading conda entry point: conda-libmamba-solver (module 'libmambapy' has no attribute 'QueryFormat')
[36m(setup pid=2715, ip=10.102.30.60)[0m Using CPython 3.10.12 interpreter at: /usr/bin/python3.10
[36m(setup pid=2715, ip=10.102.30.60)[0m Creating virtual environment with seed packages at: /root/training
[36m(setup pid=2715, ip=10.102.30.60)[0m  + pip==25.2
[36m(setup pid=2715, ip=10.102.30.60)[0m  + setuptools==80.9.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + wheel==0.45.1
[36m(setup pid=2715, ip=10.102.30.60)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=2715, ip=10.102.30.60)[0m Resolved 29 packages in 89ms
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading nvidia-cudnn-cu12 (544.5MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading torch (783.1MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading sympy (6.0MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading nvidia-cusparse-cu12 (206.5MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading nvidia-cufile-cu12 (1.1MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading nvidia-curand-cu12 (53.7MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading nvidia-cublas-cu12 (374.9MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading nvidia-cuda-nvrtc-cu12 (22.6MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading nvidia-nccl-cu12 (192.0MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading nvidia-nvjitlink-cu12 (18.8MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading torchvision (7.1MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading nvidia-cusparselt-cu12 (149.5MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading pillow (6.3MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading triton (148.4MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading nvidia-cufft-cu12 (190.9MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading nvidia-cuda-cupti-cu12 (8.5MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading torchaudio (3.3MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading nvidia-cusolver-cu12 (150.9MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading nvidia-cufile-cu12
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading torchaudio
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading torchvision
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading pillow
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading nvidia-cuda-cupti-cu12
[36m(setup pid=3505)[0m  Downloading nvidia-curand-cu12
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading nvidia-nvjitlink-cu12
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading nvidia-cuda-nvrtc-cu12
[36m(setup pid=3505)[0m  Downloading sympy
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading nvidia-curand-cu12
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading sympy
[36m(setup pid=3505)[0m  Downloading nvidia-cusparselt-cu12
[36m(setup pid=3505)[0m  Downloading nvidia-cusolver-cu12
[36m(setup pid=3505)[0m  Downloading triton
[36m(setup pid=3505)[0m  Downloading nvidia-cufft-cu12
[36m(setup pid=3505)[0m  Downloading nvidia-nccl-cu12
[36m(setup pid=3505)[0m  Downloading nvidia-cusparse-cu12
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading nvidia-cusparselt-cu12
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading nvidia-cusolver-cu12
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading triton
[36m(setup pid=3505)[0m  Downloading nvidia-cublas-cu12
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading nvidia-cufft-cu12
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading nvidia-nccl-cu12
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading nvidia-cusparse-cu12
[36m(setup pid=3505)[0m  Downloading nvidia-cudnn-cu12
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading nvidia-cublas-cu12
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading nvidia-cudnn-cu12
[36m(setup pid=3505)[0m  Downloading torch
[36m(setup pid=3505)[0m Prepared 22 packages in 22.88s
[36m(setup pid=3505)[0m Installed 28 packages in 153ms
[36m(setup pid=3505)[0m  + filelock==3.18.0
[36m(setup pid=3505)[0m  + fsspec==2025.7.0
[36m(setup pid=3505)[0m  + jinja2==3.1.6
[36m(setup pid=3505)[0m  + markupsafe==3.0.2
[36m(setup pid=3505)[0m  + mpmath==1.3.0
[36m(setup pid=3505)[0m  + networkx==3.4.2
[36m(setup pid=3505)[0m  + numpy==2.2.6
[36m(setup pid=3505)[0m  + nvidia-cublas-cu12==12.6.4.1
[36m(setup pid=3505)[0m  + nvidia-cuda-cupti-cu12==12.6.80
[36m(setup pid=3505)[0m  + nvidia-cuda-nvrtc-cu12==12.6.77
[36m(setup pid=3505)[0m  + nvidia-cuda-runtime-cu12==12.6.77
[36m(setup pid=3505)[0m  + nvidia-cudnn-cu12==9.5.1.17
[36m(setup pid=3505)[0m  + nvidia-cufft-cu12==11.3.0.4
[36m(setup pid=3505)[0m  + nvidia-cufile-cu12==1.11.1.6
[36m(setup pid=3505)[0m  + nvidia-curand-cu12==10.3.7.77
[36m(setup pid=3505)[0m  + nvidia-cusolver-cu12==11.7.1.2
[36m(setup pid=3505)[0m  + nvidia-cusparse-cu12==12.5.4.2
[36m(setup pid=3505)[0m  + nvidia-cusparselt-cu12==0.6.3
[36m(setup pid=3505)[0m  + nvidia-nccl-cu12==2.26.2
[36m(setup pid=3505)[0m  + nvidia-nvjitlink-cu12==12.6.85
[36m(setup pid=3505)[0m  + nvidia-nvtx-cu12==12.6.77
[36m(setup pid=3505)[0m  + pillow==11.3.0
[36m(setup pid=3505)[0m  + sympy==1.14.0
[36m(setup pid=3505)[0m  + torch==2.7.1
[36m(setup pid=3505)[0m  + torchaudio==2.7.1
[36m(setup pid=3505)[0m  + torchvision==0.22.1
[36m(setup pid=3505)[0m  + triton==3.3.1
[36m(setup pid=3505)[0m  + typing-extensions==4.14.1
[36m(setup pid=3505)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3505)[0m Resolved 73 packages in 372ms
[36m(setup pid=3505)[0m    Building deepspeed==0.17.4
[36m(setup pid=3505)[0m Downloading tokenizers (3.0MiB)
[36m(setup pid=3505)[0m Downloading transformers (10.7MiB)
[36m(setup pid=3505)[0m Downloading hf-xet (3.0MiB)
[36m(setup pid=3505)[0m Downloading pyarrow (40.8MiB)
[36m(setup pid=3505)[0m  Downloading tokenizers
[36m(setup pid=3505)[0m  Downloading hf-xet
[36m(setup pid=3505)[0m  Downloading pyarrow
[36m(setup pid=3505)[0m  Downloading transformers
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading torch
[36m(setup pid=2715, ip=10.102.30.60)[0m Prepared 22 packages in 21.23s
[36m(setup pid=2715, ip=10.102.30.60)[0m Installed 28 packages in 152ms
[36m(setup pid=2715, ip=10.102.30.60)[0m  + filelock==3.18.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + fsspec==2025.7.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + jinja2==3.1.6
[36m(setup pid=2715, ip=10.102.30.60)[0m  + markupsafe==3.0.2
[36m(setup pid=2715, ip=10.102.30.60)[0m  + mpmath==1.3.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + networkx==3.4.2
[36m(setup pid=2715, ip=10.102.30.60)[0m  + numpy==2.2.6
[36m(setup pid=2715, ip=10.102.30.60)[0m  + nvidia-cublas-cu12==12.6.4.1
[36m(setup pid=2715, ip=10.102.30.60)[0m  + nvidia-cuda-cupti-cu12==12.6.80
[36m(setup pid=2715, ip=10.102.30.60)[0m  + nvidia-cuda-nvrtc-cu12==12.6.77
[36m(setup pid=2715, ip=10.102.30.60)[0m  + nvidia-cuda-runtime-cu12==12.6.77
[36m(setup pid=2715, ip=10.102.30.60)[0m  + nvidia-cudnn-cu12==9.5.1.17
[36m(setup pid=2715, ip=10.102.30.60)[0m  + nvidia-cufft-cu12==11.3.0.4
[36m(setup pid=2715, ip=10.102.30.60)[0m  + nvidia-cufile-cu12==1.11.1.6
[36m(setup pid=2715, ip=10.102.30.60)[0m  + nvidia-curand-cu12==10.3.7.77
[36m(setup pid=2715, ip=10.102.30.60)[0m  + nvidia-cusolver-cu12==11.7.1.2
[36m(setup pid=2715, ip=10.102.30.60)[0m  + nvidia-cusparse-cu12==12.5.4.2
[36m(setup pid=2715, ip=10.102.30.60)[0m  + nvidia-cusparselt-cu12==0.6.3
[36m(setup pid=2715, ip=10.102.30.60)[0m  + nvidia-nccl-cu12==2.26.2
[36m(setup pid=2715, ip=10.102.30.60)[0m  + nvidia-nvjitlink-cu12==12.6.85
[36m(setup pid=2715, ip=10.102.30.60)[0m  + nvidia-nvtx-cu12==12.6.77
[36m(setup pid=2715, ip=10.102.30.60)[0m  + pillow==11.3.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + sympy==1.14.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + torch==2.7.1
[36m(setup pid=2715, ip=10.102.30.60)[0m  + torchaudio==2.7.1
[36m(setup pid=2715, ip=10.102.30.60)[0m  + torchvision==0.22.1
[36m(setup pid=2715, ip=10.102.30.60)[0m  + triton==3.3.1
[36m(setup pid=2715, ip=10.102.30.60)[0m  + typing-extensions==4.14.1
[36m(setup pid=2715, ip=10.102.30.60)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=3505)[0m       Built deepspeed==0.17.4
[36m(setup pid=2715, ip=10.102.30.60)[0m Resolved 73 packages in 259ms
[36m(setup pid=2715, ip=10.102.30.60)[0m    Building deepspeed==0.17.4
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading hf-xet (3.0MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading tokenizers (3.0MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading pyarrow (40.8MiB)
[36m(setup pid=2715, ip=10.102.30.60)[0m Downloading transformers (10.7MiB)
[36m(setup pid=3505)[0m Prepared 21 packages in 1.63s
[36m(setup pid=3505)[0m Uninstalled 1 package in 0.93ms
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading tokenizers
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading hf-xet
[36m(setup pid=3505)[0m Installed 48 packages in 110ms
[36m(setup pid=3505)[0m  + accelerate==1.9.0
[36m(setup pid=3505)[0m  + aiohappyeyeballs==2.6.1
[36m(setup pid=3505)[0m  + aiohttp==3.12.15
[36m(setup pid=3505)[0m  + aiosignal==1.4.0
[36m(setup pid=3505)[0m  + annotated-types==0.7.0
[36m(setup pid=3505)[0m  + async-timeout==5.0.1
[36m(setup pid=3505)[0m  + attrs==25.3.0
[36m(setup pid=3505)[0m  + certifi==2025.7.14
[36m(setup pid=3505)[0m  + charset-normalizer==3.4.2
[36m(setup pid=3505)[0m  + datasets==4.0.0
[36m(setup pid=3505)[0m  + deepspeed==0.17.4
[36m(setup pid=3505)[0m  + dill==0.3.8
[36m(setup pid=3505)[0m  + einops==0.8.1
[36m(setup pid=3505)[0m  + frozenlist==1.7.0
[36m(setup pid=3505)[0m  - fsspec==2025.7.0
[36m(setup pid=3505)[0m  + fsspec==2025.3.0
[36m(setup pid=3505)[0m  + hf-xet==1.1.5
[36m(setup pid=3505)[0m  + hjson==3.1.0
[36m(setup pid=3505)[0m  + huggingface-hub==0.34.3
[36m(setup pid=3505)[0m  + idna==3.10
[36m(setup pid=3505)[0m  + liger-kernel==0.6.1
[36m(setup pid=3505)[0m  + msgpack==1.1.1
[36m(setup pid=3505)[0m  + multidict==6.6.3
[36m(setup pid=3505)[0m  + multiprocess==0.70.16
[36m(setup pid=3505)[0m  + ninja==1.11.1.4
[36m(setup pid=3505)[0m  + packaging==25.0
[36m(setup pid=3505)[0m  + pandas==2.3.1
[36m(setup pid=3505)[0m  + propcache==0.3.2
[36m(setup pid=3505)[0m  + psutil==7.0.0
[36m(setup pid=3505)[0m  + py-cpuinfo==9.0.0
[36m(setup pid=3505)[0m  + pyarrow==21.0.0
[36m(setup pid=3505)[0m  + pydantic==2.11.7
[36m(setup pid=3505)[0m  + pydantic-core==2.33.2
[36m(setup pid=3505)[0m  + python-dateutil==2.9.0.post0
[36m(setup pid=3505)[0m  + pytz==2025.2
[36m(setup pid=3505)[0m  + pyyaml==6.0.2
[36m(setup pid=3505)[0m  + regex==2025.7.34
[36m(setup pid=3505)[0m  + requests==2.32.4
[36m(setup pid=3505)[0m  + safetensors==0.5.3
[36m(setup pid=3505)[0m  + six==1.17.0
[36m(setup pid=3505)[0m  + tokenizers==0.21.4
[36m(setup pid=3505)[0m  + tqdm==4.67.1
[36m(setup pid=3505)[0m  + transformers==4.54.1
[36m(setup pid=3505)[0m  + trl==0.20.0
[36m(setup pid=3505)[0m  + typing-inspection==0.4.1
[36m(setup pid=3505)[0m  + tzdata==2025.2
[36m(setup pid=3505)[0m  + urllib3==2.5.0
[36m(setup pid=3505)[0m  + xxhash==3.5.0
[36m(setup pid=3505)[0m  + yarl==1.20.1
[36m(setup pid=3505)[0m 
[36m(setup pid=3505)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=3505)[0m 
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading pyarrow
[36m(setup pid=2715, ip=10.102.30.60)[0m  Downloading transformers
[36m(setup pid=3505)[0m Reading package lists...
[36m(setup pid=3505)[0m Building dependency tree...
[36m(setup pid=3505)[0m Reading state information...
[36m(setup pid=2715, ip=10.102.30.60)[0m       Built deepspeed==0.17.4
[36m(setup pid=3505)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=3505)[0m   libfuse2
[36m(setup pid=3505)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=3505)[0m The following additional packages will be installed:
[36m(setup pid=3505)[0m   vim-common vim-runtime
[36m(setup pid=3505)[0m Suggested packages:
[36m(setup pid=3505)[0m   ctags vim-doc vim-scripts
[36m(setup pid=3505)[0m The following NEW packages will be installed:
[36m(setup pid=3505)[0m   vmtouch
[36m(setup pid=3505)[0m The following packages will be upgraded:
[36m(setup pid=3505)[0m   vim vim-common vim-runtime
[36m(setup pid=2715, ip=10.102.30.60)[0m Prepared 21 packages in 1.40s
[36m(setup pid=2715, ip=10.102.30.60)[0m Uninstalled 1 package in 1ms
[36m(setup pid=2715, ip=10.102.30.60)[0m Installed 48 packages in 156ms
[36m(setup pid=2715, ip=10.102.30.60)[0m  + accelerate==1.9.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + aiohappyeyeballs==2.6.1
[36m(setup pid=2715, ip=10.102.30.60)[0m  + aiohttp==3.12.15
[36m(setup pid=2715, ip=10.102.30.60)[0m  + aiosignal==1.4.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + annotated-types==0.7.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + async-timeout==5.0.1
[36m(setup pid=2715, ip=10.102.30.60)[0m  + attrs==25.3.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + certifi==2025.7.14
[36m(setup pid=2715, ip=10.102.30.60)[0m  + charset-normalizer==3.4.2
[36m(setup pid=2715, ip=10.102.30.60)[0m  + datasets==4.0.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + deepspeed==0.17.4
[36m(setup pid=2715, ip=10.102.30.60)[0m  + dill==0.3.8
[36m(setup pid=2715, ip=10.102.30.60)[0m  + einops==0.8.1
[36m(setup pid=2715, ip=10.102.30.60)[0m  + frozenlist==1.7.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  - fsspec==2025.7.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + fsspec==2025.3.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + hf-xet==1.1.5
[36m(setup pid=2715, ip=10.102.30.60)[0m  + hjson==3.1.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + huggingface-hub==0.34.3
[36m(setup pid=2715, ip=10.102.30.60)[0m  + idna==3.10
[36m(setup pid=2715, ip=10.102.30.60)[0m  + liger-kernel==0.6.1
[36m(setup pid=2715, ip=10.102.30.60)[0m  + msgpack==1.1.1
[36m(setup pid=2715, ip=10.102.30.60)[0m  + multidict==6.6.3
[36m(setup pid=2715, ip=10.102.30.60)[0m  + multiprocess==0.70.16
[36m(setup pid=2715, ip=10.102.30.60)[0m  + ninja==1.11.1.4
[36m(setup pid=2715, ip=10.102.30.60)[0m  + packaging==25.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + pandas==2.3.1
[36m(setup pid=2715, ip=10.102.30.60)[0m  + propcache==0.3.2
[36m(setup pid=2715, ip=10.102.30.60)[0m  + psutil==7.0.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + py-cpuinfo==9.0.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + pyarrow==21.0.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + pydantic==2.11.7
[36m(setup pid=2715, ip=10.102.30.60)[0m  + pydantic-core==2.33.2
[36m(setup pid=2715, ip=10.102.30.60)[0m  + python-dateutil==2.9.0.post0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + pytz==2025.2
[36m(setup pid=2715, ip=10.102.30.60)[0m  + pyyaml==6.0.2
[36m(setup pid=2715, ip=10.102.30.60)[0m  + regex==2025.7.34
[36m(setup pid=2715, ip=10.102.30.60)[0m  + requests==2.32.4
[36m(setup pid=2715, ip=10.102.30.60)[0m  + safetensors==0.5.3
[36m(setup pid=2715, ip=10.102.30.60)[0m  + six==1.17.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + tokenizers==0.21.4
[36m(setup pid=2715, ip=10.102.30.60)[0m  + tqdm==4.67.1
[36m(setup pid=2715, ip=10.102.30.60)[0m  + transformers==4.54.1
[36m(setup pid=2715, ip=10.102.30.60)[0m  + trl==0.20.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + typing-inspection==0.4.1
[36m(setup pid=2715, ip=10.102.30.60)[0m  + tzdata==2025.2
[36m(setup pid=2715, ip=10.102.30.60)[0m  + urllib3==2.5.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + xxhash==3.5.0
[36m(setup pid=2715, ip=10.102.30.60)[0m  + yarl==1.20.1
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=2715, ip=10.102.30.60)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=3505)[0m 3 upgraded, 1 newly installed, 0 to remove and 84 not upgraded.
[36m(setup pid=3505)[0m Need to get 8664 kB of archives.
[36m(setup pid=3505)[0m After this operation, 68.6 kB of additional disk space will be used.
[36m(setup pid=3505)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 vmtouch amd64 1.3.1-2 [21.5 kB]
[36m(setup pid=3505)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim amd64 2:8.2.3995-1ubuntu2.24 [1728 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Reading package lists...
[36m(setup pid=3505)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-runtime all 2:8.2.3995-1ubuntu2.24 [6833 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Building dependency tree...
[36m(setup pid=2715, ip=10.102.30.60)[0m Reading state information...
[36m(setup pid=3505)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-common all 2:8.2.3995-1ubuntu2.24 [81.5 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2715, ip=10.102.30.60)[0m   libfuse2
[36m(setup pid=2715, ip=10.102.30.60)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=2715, ip=10.102.30.60)[0m The following additional packages will be installed:
[36m(setup pid=2715, ip=10.102.30.60)[0m   vim-common vim-runtime
[36m(setup pid=2715, ip=10.102.30.60)[0m Suggested packages:
[36m(setup pid=2715, ip=10.102.30.60)[0m   ctags vim-doc vim-scripts
[36m(setup pid=3505)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2715, ip=10.102.30.60)[0m The following NEW packages will be installed:
[36m(setup pid=2715, ip=10.102.30.60)[0m   vmtouch
[36m(setup pid=2715, ip=10.102.30.60)[0m The following packages will be upgraded:
[36m(setup pid=2715, ip=10.102.30.60)[0m   vim vim-common vim-runtime
[36m(setup pid=3505)[0m Fetched 8664 kB in 1s (6663 kB/s)
[36m(setup pid=3505)[0m Selecting previously unselected package vmtouch.
[36m(setup pid=3505)[0m (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 23408 files and directories currently installed.)
[36m(setup pid=3505)[0m Preparing to unpack .../vmtouch_1.3.1-2_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking vmtouch (1.3.1-2) ...
[36m(setup pid=3505)[0m Preparing to unpack .../vim_2%3a8.2.3995-1ubuntu2.24_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking vim (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3505)[0m Preparing to unpack .../vim-runtime_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=3505)[0m Unpacking vim-runtime (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m 3 upgraded, 1 newly installed, 0 to remove and 84 not upgraded.
[36m(setup pid=2715, ip=10.102.30.60)[0m Need to get 8664 kB of archives.
[36m(setup pid=2715, ip=10.102.30.60)[0m After this operation, 68.6 kB of additional disk space will be used.
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 vmtouch amd64 1.3.1-2 [21.5 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim amd64 2:8.2.3995-1ubuntu2.24 [1728 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-runtime all 2:8.2.3995-1ubuntu2.24 [6833 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 vim-common all 2:8.2.3995-1ubuntu2.24 [81.5 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2715, ip=10.102.30.60)[0m Fetched 8664 kB in 1s (6418 kB/s)
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package vmtouch.
[36m(setup pid=2715, ip=10.102.30.60)[0m (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 23408 files and directories currently installed.)
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../vmtouch_1.3.1-2_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking vmtouch (1.3.1-2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../vim_2%3a8.2.3995-1ubuntu2.24_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking vim (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../vim-runtime_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking vim-runtime (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3505)[0m Preparing to unpack .../vim-common_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=3505)[0m Unpacking vim-common (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3505)[0m Setting up vmtouch (1.3.1-2) ...
[36m(setup pid=3505)[0m invoke-rc.d: could not determine current runlevel
[36m(setup pid=3505)[0m invoke-rc.d: policy-rc.d denied execution of start.
[36m(setup pid=3505)[0m Setting up vim-common (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3505)[0m Setting up vim-runtime (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3505)[0m Setting up vim (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3505)[0m 
[36m(setup pid=3505)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=3505)[0m 
[36m(setup pid=3505)[0m Reading package lists...
[36m(setup pid=3505)[0m Building dependency tree...
[36m(setup pid=3505)[0m Reading state information...
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../vim-common_2%3a8.2.3995-1ubuntu2.24_all.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking vim-common (2:8.2.3995-1ubuntu2.24) over (2:8.2.3995-1ubuntu2.21) ...
[36m(setup pid=3505)[0m build-essential is already the newest version (12.9ubuntu3).
[36m(setup pid=3505)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=3505)[0m   libfuse2
[36m(setup pid=3505)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=3505)[0m The following additional packages will be installed:
[36m(setup pid=3505)[0m   javascript-common libexpat1 libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=3505)[0m   libjs-underscore libpython3-dev libpython3.10 libpython3.10-dev
[36m(setup pid=3505)[0m   libpython3.10-minimal libpython3.10-stdlib python3-distutils python3-lib2to3
[36m(setup pid=3505)[0m   python3.10 python3.10-minimal
[36m(setup pid=3505)[0m Suggested packages:
[36m(setup pid=3505)[0m   apache2 | lighttpd | httpd python3.10-venv python3.10-doc binfmt-support
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up vmtouch (1.3.1-2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m invoke-rc.d: could not determine current runlevel
[36m(setup pid=2715, ip=10.102.30.60)[0m invoke-rc.d: policy-rc.d denied execution of start.
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up vim-common (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up vim-runtime (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up vim (2:8.2.3995-1ubuntu2.24) ...
[36m(setup pid=3505)[0m The following NEW packages will be installed:
[36m(setup pid=3505)[0m   javascript-common libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=3505)[0m   libjs-underscore libpython3-dev libpython3.10-dev python3-dev
[36m(setup pid=3505)[0m   python3-distutils python3-lib2to3 python3.10-dev
[36m(setup pid=3505)[0m The following packages will be upgraded:
[36m(setup pid=3505)[0m   libexpat1 libpython3.10 libpython3.10-minimal libpython3.10-stdlib
[36m(setup pid=3505)[0m   python3.10 python3.10-minimal
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=2715, ip=10.102.30.60)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=3505)[0m 6 upgraded, 11 newly installed, 0 to remove and 78 not upgraded.
[36m(setup pid=3505)[0m Need to get 13.7 MB of archives.
[36m(setup pid=3505)[0m After this operation, 25.1 MB of additional disk space will be used.
[36m(setup pid=3505)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1 amd64 2.4.7-1ubuntu0.6 [92.1 kB]
[36m(setup pid=3505)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10 amd64 3.10.12-1~22.04.10 [1950 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Reading package lists...
[36m(setup pid=2715, ip=10.102.30.60)[0m Building dependency tree...
[36m(setup pid=2715, ip=10.102.30.60)[0m Reading state information...
[36m(setup pid=3505)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10 amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=3505)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-stdlib amd64 3.10.12-1~22.04.10 [1850 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m build-essential is already the newest version (12.9ubuntu3).
[36m(setup pid=2715, ip=10.102.30.60)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2715, ip=10.102.30.60)[0m   libfuse2
[36m(setup pid=2715, ip=10.102.30.60)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=2715, ip=10.102.30.60)[0m The following additional packages will be installed:
[36m(setup pid=2715, ip=10.102.30.60)[0m   javascript-common libexpat1 libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=2715, ip=10.102.30.60)[0m   libjs-underscore libpython3-dev libpython3.10 libpython3.10-dev
[36m(setup pid=2715, ip=10.102.30.60)[0m   libpython3.10-minimal libpython3.10-stdlib python3-distutils python3-lib2to3
[36m(setup pid=2715, ip=10.102.30.60)[0m   python3.10 python3.10-minimal
[36m(setup pid=2715, ip=10.102.30.60)[0m Suggested packages:
[36m(setup pid=2715, ip=10.102.30.60)[0m   apache2 | lighttpd | httpd python3.10-venv python3.10-doc binfmt-support
[36m(setup pid=3505)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-minimal amd64 3.10.12-1~22.04.10 [2277 kB]
[36m(setup pid=3505)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-minimal amd64 3.10.12-1~22.04.10 [815 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m The following NEW packages will be installed:
[36m(setup pid=2715, ip=10.102.30.60)[0m   javascript-common libexpat1-dev libjs-jquery libjs-sphinxdoc
[36m(setup pid=2715, ip=10.102.30.60)[0m   libjs-underscore libpython3-dev libpython3.10-dev python3-dev
[36m(setup pid=2715, ip=10.102.30.60)[0m   python3-distutils python3-lib2to3 python3.10-dev
[36m(setup pid=2715, ip=10.102.30.60)[0m The following packages will be upgraded:
[36m(setup pid=2715, ip=10.102.30.60)[0m   libexpat1 libpython3.10 libpython3.10-minimal libpython3.10-stdlib
[36m(setup pid=2715, ip=10.102.30.60)[0m   python3.10 python3.10-minimal
[36m(setup pid=3505)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 javascript-common all 11+nmu1 [5936 B]
[36m(setup pid=3505)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1-dev amd64 2.4.7-1ubuntu0.6 [148 kB]
[36m(setup pid=3505)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-jquery all 3.6.0+dfsg+~3.5.13-1 [321 kB]
[36m(setup pid=3505)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-underscore all 1.13.2~dfsg-2 [118 kB]
[36m(setup pid=3505)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-sphinxdoc all 4.3.2-1 [139 kB]
[36m(setup pid=3505)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-dev amd64 3.10.12-1~22.04.10 [4763 kB]
[36m(setup pid=3505)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3-dev amd64 3.10.6-1~22.04.1 [7064 B]
[36m(setup pid=3505)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-dev amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m 6 upgraded, 11 newly installed, 0 to remove and 78 not upgraded.
[36m(setup pid=2715, ip=10.102.30.60)[0m Need to get 13.7 MB of archives.
[36m(setup pid=2715, ip=10.102.30.60)[0m After this operation, 25.1 MB of additional disk space will be used.
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1 amd64 2.4.7-1ubuntu0.6 [92.1 kB]
[36m(setup pid=3505)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-lib2to3 all 3.10.8-1~22.04 [77.6 kB]
[36m(setup pid=3505)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-distutils all 3.10.8-1~22.04 [139 kB]
[36m(setup pid=3505)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-dev amd64 3.10.6-1~22.04.1 [26.0 kB]
[36m(setup pid=3505)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3505)[0m Fetched 13.7 MB in 2s (9046 kB/s)
[36m(setup pid=3505)[0m (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 23418 files and directories currently installed.)
[36m(setup pid=3505)[0m Preparing to unpack .../00-libexpat1_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libexpat1:amd64 (2.4.7-1ubuntu0.6) over (2.4.7-1ubuntu0.4) ...
[36m(setup pid=3505)[0m Preparing to unpack .../01-libpython3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libpython3.10:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3505)[0m Preparing to unpack .../02-python3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking python3.10 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3505)[0m Preparing to unpack .../03-libpython3.10-stdlib_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10 amd64 3.10.12-1~22.04.10 [1950 kB]
[36m(setup pid=3505)[0m Preparing to unpack .../04-python3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking python3.10-minimal (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3505)[0m Preparing to unpack .../05-libpython3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10 amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-stdlib amd64 3.10.12-1~22.04.10 [1850 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-minimal amd64 3.10.12-1~22.04.10 [2277 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-minimal amd64 3.10.12-1~22.04.10 [815 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 javascript-common all 11+nmu1 [5936 B]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libexpat1-dev amd64 2.4.7-1ubuntu0.6 [148 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-jquery all 3.6.0+dfsg+~3.5.13-1 [321 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-underscore all 1.13.2~dfsg-2 [118 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-sphinxdoc all 4.3.2-1 [139 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-dev amd64 3.10.12-1~22.04.10 [4763 kB]
[36m(setup pid=3505)[0m Selecting previously unselected package javascript-common.
[36m(setup pid=3505)[0m Preparing to unpack .../06-javascript-common_11+nmu1_all.deb ...
[36m(setup pid=3505)[0m Unpacking javascript-common (11+nmu1) ...
[36m(setup pid=3505)[0m Selecting previously unselected package libexpat1-dev:amd64.
[36m(setup pid=3505)[0m Preparing to unpack .../07-libexpat1-dev_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=3505)[0m Selecting previously unselected package libjs-jquery.
[36m(setup pid=3505)[0m Preparing to unpack .../08-libjs-jquery_3.6.0+dfsg+~3.5.13-1_all.deb ...
[36m(setup pid=3505)[0m Unpacking libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=3505)[0m Selecting previously unselected package libjs-underscore.
[36m(setup pid=3505)[0m Preparing to unpack .../09-libjs-underscore_1.13.2~dfsg-2_all.deb ...
[36m(setup pid=3505)[0m Unpacking libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=3505)[0m Selecting previously unselected package libjs-sphinxdoc.
[36m(setup pid=3505)[0m Preparing to unpack .../10-libjs-sphinxdoc_4.3.2-1_all.deb ...
[36m(setup pid=3505)[0m Unpacking libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=3505)[0m Selecting previously unselected package libpython3.10-dev:amd64.
[36m(setup pid=3505)[0m Preparing to unpack .../11-libpython3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3-dev amd64 3.10.6-1~22.04.1 [7064 B]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-dev amd64 3.10.12-1~22.04.10 [508 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-lib2to3 all 3.10.8-1~22.04 [77.6 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-distutils all 3.10.8-1~22.04 [139 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-dev amd64 3.10.6-1~22.04.1 [26.0 kB]
[36m(setup pid=3505)[0m Selecting previously unselected package libpython3-dev:amd64.
[36m(setup pid=3505)[0m Preparing to unpack .../12-libpython3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=3505)[0m Selecting previously unselected package python3.10-dev.
[36m(setup pid=3505)[0m Preparing to unpack .../13-python3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=3505)[0m Selecting previously unselected package python3-lib2to3.
[36m(setup pid=3505)[0m Preparing to unpack .../14-python3-lib2to3_3.10.8-1~22.04_all.deb ...
[36m(setup pid=3505)[0m Unpacking python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2715, ip=10.102.30.60)[0m Fetched 13.7 MB in 2s (9034 kB/s)
[36m(setup pid=3505)[0m Selecting previously unselected package python3-distutils.
[36m(setup pid=3505)[0m Preparing to unpack .../15-python3-distutils_3.10.8-1~22.04_all.deb ...
[36m(setup pid=3505)[0m Unpacking python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=3505)[0m Selecting previously unselected package python3-dev.
[36m(setup pid=3505)[0m Preparing to unpack .../16-python3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=3505)[0m Setting up libexpat1:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=3505)[0m Setting up javascript-common (11+nmu1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 23418 files and directories currently installed.)
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../00-libexpat1_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libexpat1:amd64 (2.4.7-1ubuntu0.6) over (2.4.7-1ubuntu0.4) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../01-libpython3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libpython3.10:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../02-python3.10_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=3505)[0m Setting up libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=3505)[0m Setting up libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3505)[0m Setting up libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=3505)[0m Setting up python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking python3.10 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../03-libpython3.10-stdlib_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3505)[0m Setting up libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=3505)[0m Setting up python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=3505)[0m Setting up python3.10-minimal (3.10.12-1~22.04.10) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../04-python3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking python3.10-minimal (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../05-libpython3.10-minimal_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) over (3.10.12-1~22.04.7) ...
[36m(setup pid=3505)[0m Setting up libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3505)[0m Setting up libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=3505)[0m Setting up libpython3.10:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3505)[0m Setting up python3.10 (3.10.12-1~22.04.10) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package javascript-common.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../06-javascript-common_11+nmu1_all.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking javascript-common (11+nmu1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libexpat1-dev:amd64.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../07-libexpat1-dev_2.4.7-1ubuntu0.6_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libjs-jquery.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../08-libjs-jquery_3.6.0+dfsg+~3.5.13-1_all.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libjs-underscore.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../09-libjs-underscore_1.13.2~dfsg-2_all.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libjs-sphinxdoc.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../10-libjs-sphinxdoc_4.3.2-1_all.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libpython3.10-dev:amd64.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../11-libpython3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libpython3-dev:amd64.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../12-libpython3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package python3.10-dev.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../13-python3.10-dev_3.10.12-1~22.04.10_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package python3-lib2to3.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../14-python3-lib2to3_3.10.8-1~22.04_all.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package python3-distutils.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../15-python3-distutils_3.10.8-1~22.04_all.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package python3-dev.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../16-python3-dev_3.10.6-1~22.04.1_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libexpat1:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up javascript-common (11+nmu1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libexpat1-dev:amd64 (2.4.7-1ubuntu0.6) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libpython3.10-minimal:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3505)[0m Setting up libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=3505)[0m Setting up python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=3505)[0m Setting up libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=3505)[0m Setting up python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=3505)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=3505)[0m 
[36m(setup pid=3505)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=3505)[0m 
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up python3-lib2to3 (3.10.8-1~22.04) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libjs-underscore (1.13.2~dfsg-2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up python3-distutils (3.10.8-1~22.04) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up python3.10-minimal (3.10.12-1~22.04.10) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libpython3.10-stdlib:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libjs-sphinxdoc (4.3.2-1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libpython3.10:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up python3.10 (3.10.12-1~22.04.10) ...
[36m(setup pid=3505)[0m Reading package lists...
[36m(setup pid=3505)[0m Building dependency tree...
[36m(setup pid=3505)[0m Reading state information...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libpython3.10-dev:amd64 (3.10.12-1~22.04.10) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up python3.10-dev (3.10.12-1~22.04.10) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libpython3-dev:amd64 (3.10.6-1~22.04.1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up python3-dev (3.10.6-1~22.04.1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=2715, ip=10.102.30.60)[0m WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=3505)[0m infiniband-diags is already the newest version (2410mlnx54-1.2410068).
[36m(setup pid=3505)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=3505)[0m   libfuse2
[36m(setup pid=3505)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=3505)[0m The following additional packages will be installed:
[36m(setup pid=3505)[0m   dbus dmsetup gir1.2-glib-2.0 libapparmor1 libargon2-1 libatm1 libbpf0
[36m(setup pid=3505)[0m   libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1 libgirepository-1.0-1
[36m(setup pid=3505)[0m   libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5 libmnl0 libnl-genl-3-200
[36m(setup pid=3505)[0m   libsensors-config libsensors5 libsystemd0 libxtables12 networkd-dispatcher
[36m(setup pid=3505)[0m   python3-dbus python3-gi shared-mime-info systemd systemd-timesyncd
[36m(setup pid=3505)[0m   xdg-user-dirs
[36m(setup pid=3505)[0m Suggested packages:
[36m(setup pid=3505)[0m   default-dbus-session-bus | dbus-session-bus lm-sensors lsof strace
[36m(setup pid=3505)[0m   iproute2-doc iw | wireless-tools python-dbus-doc isag systemd-container
[36m(setup pid=3505)[0m   libtss2-esys-3.0.2-0 libtss2-mu0 libtss2-rc0 policykit-1
[36m(setup pid=3505)[0m The following NEW packages will be installed:
[36m(setup pid=3505)[0m   dbus dmsetup gir1.2-glib-2.0 htop iproute2 libapparmor1 libargon2-1 libatm1
[36m(setup pid=3505)[0m   libbpf0 libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1
[36m(setup pid=3505)[0m   libgirepository-1.0-1 libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5
[36m(setup pid=3505)[0m   libmnl0 libnl-genl-3-200 libsensors-config libsensors5 libxtables12
[36m(setup pid=3505)[0m   networkd-dispatcher python3-dbus python3-gi shared-mime-info sysstat systemd
[36m(setup pid=3505)[0m   systemd-timesyncd xdg-user-dirs
[36m(setup pid=3505)[0m The following packages will be upgraded:
[36m(setup pid=3505)[0m   libsystemd0 net-tools
[36m(setup pid=3505)[0m 2 upgraded, 31 newly installed, 0 to remove and 76 not upgraded.
[36m(setup pid=3505)[0m Need to get 10.6 MB of archives.
[36m(setup pid=3505)[0m After this operation, 35.4 MB of additional disk space will be used.
[36m(setup pid=3505)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsystemd0 amd64 249.11-0ubuntu3.16 [317 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Reading package lists...
[36m(setup pid=3505)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libapparmor1 amd64 3.0.4-2ubuntu2.4 [39.7 kB]
[36m(setup pid=3505)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libargon2-1 amd64 0~20171227-0.3 [19.5 kB]
[36m(setup pid=3505)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdevmapper1.02.1 amd64 2:1.02.175-2.1ubuntu5 [139 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Building dependency tree...
[36m(setup pid=2715, ip=10.102.30.60)[0m Reading state information...
[36m(setup pid=3505)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libjson-c5 amd64 0.15-3~ubuntu1.22.04.2 [33.5 kB]
[36m(setup pid=3505)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcryptsetup12 amd64 2:2.4.3-1ubuntu1.3 [211 kB]
[36m(setup pid=3505)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libip4tc2 amd64 1.8.7-1ubuntu5.2 [19.9 kB]
[36m(setup pid=3505)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd amd64 249.11-0ubuntu3.16 [4581 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m infiniband-diags is already the newest version (2410mlnx54-1.2410068).
[36m(setup pid=2715, ip=10.102.30.60)[0m The following package was automatically installed and is no longer required:
[36m(setup pid=2715, ip=10.102.30.60)[0m   libfuse2
[36m(setup pid=2715, ip=10.102.30.60)[0m Use 'apt autoremove' to remove it.
[36m(setup pid=2715, ip=10.102.30.60)[0m The following additional packages will be installed:
[36m(setup pid=2715, ip=10.102.30.60)[0m   dbus dmsetup gir1.2-glib-2.0 libapparmor1 libargon2-1 libatm1 libbpf0
[36m(setup pid=2715, ip=10.102.30.60)[0m   libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1 libgirepository-1.0-1
[36m(setup pid=2715, ip=10.102.30.60)[0m   libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5 libmnl0 libnl-genl-3-200
[36m(setup pid=2715, ip=10.102.30.60)[0m   libsensors-config libsensors5 libsystemd0 libxtables12 networkd-dispatcher
[36m(setup pid=2715, ip=10.102.30.60)[0m   python3-dbus python3-gi shared-mime-info systemd systemd-timesyncd
[36m(setup pid=2715, ip=10.102.30.60)[0m   xdg-user-dirs
[36m(setup pid=2715, ip=10.102.30.60)[0m Suggested packages:
[36m(setup pid=2715, ip=10.102.30.60)[0m   default-dbus-session-bus | dbus-session-bus lm-sensors lsof strace
[36m(setup pid=2715, ip=10.102.30.60)[0m   iproute2-doc iw | wireless-tools python-dbus-doc isag systemd-container
[36m(setup pid=2715, ip=10.102.30.60)[0m   libtss2-esys-3.0.2-0 libtss2-mu0 libtss2-rc0 policykit-1
[36m(setup pid=2715, ip=10.102.30.60)[0m The following NEW packages will be installed:
[36m(setup pid=2715, ip=10.102.30.60)[0m   dbus dmsetup gir1.2-glib-2.0 htop iproute2 libapparmor1 libargon2-1 libatm1
[36m(setup pid=2715, ip=10.102.30.60)[0m   libbpf0 libcryptsetup12 libdbus-1-3 libdevmapper1.02.1 libelf1
[36m(setup pid=2715, ip=10.102.30.60)[0m   libgirepository-1.0-1 libglib2.0-0 libglib2.0-data libip4tc2 libjson-c5
[36m(setup pid=2715, ip=10.102.30.60)[0m   libmnl0 libnl-genl-3-200 libsensors-config libsensors5 libxtables12
[36m(setup pid=2715, ip=10.102.30.60)[0m   networkd-dispatcher python3-dbus python3-gi shared-mime-info sysstat systemd
[36m(setup pid=2715, ip=10.102.30.60)[0m   systemd-timesyncd xdg-user-dirs
[36m(setup pid=2715, ip=10.102.30.60)[0m The following packages will be upgraded:
[36m(setup pid=2715, ip=10.102.30.60)[0m   libsystemd0 net-tools
[36m(setup pid=3505)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdbus-1-3 amd64 1.12.20-2ubuntu4.1 [189 kB]
[36m(setup pid=3505)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dbus amd64 1.12.20-2ubuntu4.1 [158 kB]
[36m(setup pid=3505)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dmsetup amd64 2:1.02.175-2.1ubuntu5 [81.7 kB]
[36m(setup pid=3505)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-0 amd64 2.72.4-0ubuntu2.5 [1466 kB]
[36m(setup pid=3505)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgirepository-1.0-1 amd64 1.72.0-1 [55.6 kB]
[36m(setup pid=3505)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 gir1.2-glib-2.0 amd64 1.72.0-1 [164 kB]
[36m(setup pid=3505)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libelf1 amd64 0.186-1ubuntu0.1 [51.1 kB]
[36m(setup pid=3505)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libbpf0 amd64 1:0.5.0-1ubuntu22.04.1 [140 kB]
[36m(setup pid=3505)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmnl0 amd64 1.0.4-3build2 [13.2 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m 2 upgraded, 31 newly installed, 0 to remove and 76 not upgraded.
[36m(setup pid=2715, ip=10.102.30.60)[0m Need to get 10.6 MB of archives.
[36m(setup pid=2715, ip=10.102.30.60)[0m After this operation, 35.4 MB of additional disk space will be used.
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsystemd0 amd64 249.11-0ubuntu3.16 [317 kB]
[36m(setup pid=3505)[0m Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxtables12 amd64 1.8.7-1ubuntu5.2 [31.3 kB]
[36m(setup pid=3505)[0m Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 iproute2 amd64 5.15.0-1ubuntu2 [1070 kB]
[36m(setup pid=3505)[0m Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatm1 amd64 1:2.5.1-4build2 [22.8 kB]
[36m(setup pid=3505)[0m Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-data all 2.72.4-0ubuntu2.5 [4656 B]
[36m(setup pid=3505)[0m Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-dbus amd64 1.2.18-3build1 [99.5 kB]
[36m(setup pid=3505)[0m Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-gi amd64 3.42.1-0ubuntu1 [229 kB]
[36m(setup pid=3505)[0m Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 networkd-dispatcher all 2.1-2ubuntu0.22.04.2 [15.8 kB]
[36m(setup pid=3505)[0m Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 shared-mime-info amd64 2.1-2 [454 kB]
[36m(setup pid=3505)[0m Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-timesyncd amd64 249.11-0ubuntu3.16 [31.2 kB]
[36m(setup pid=3505)[0m Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 xdg-user-dirs amd64 0.17-2ubuntu4 [53.9 kB]
[36m(setup pid=3505)[0m Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-genl-3-200 amd64 3.5.0-0.1 [12.4 kB]
[36m(setup pid=3505)[0m Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 htop amd64 3.0.5-7build2 [128 kB]
[36m(setup pid=3505)[0m Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors-config all 1:3.6.0-7ubuntu1 [5274 B]
[36m(setup pid=3505)[0m Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors5 amd64 1:3.6.0-7ubuntu1 [26.3 kB]
[36m(setup pid=3505)[0m Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 net-tools amd64 1.60+git20181103.0eebece-1ubuntu5.4 [204 kB]
[36m(setup pid=3505)[0m Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 sysstat amd64 12.5.2-2ubuntu0.2 [487 kB]
[36m(setup pid=3505)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=3505)[0m Fetched 10.6 MB in 2s (6374 kB/s)
[36m(setup pid=3505)[0m (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=3505)[0m Preparing to unpack .../libsystemd0_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libsystemd0:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...
[36m(setup pid=3505)[0m Setting up libsystemd0:amd64 (249.11-0ubuntu3.16) ...
[36m(setup pid=3505)[0m Selecting previously unselected package libapparmor1:amd64.
[36m(setup pid=3505)[0m (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=3505)[0m Preparing to unpack .../00-libapparmor1_3.0.4-2ubuntu2.4_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=3505)[0m Selecting previously unselected package libargon2-1:amd64.
[36m(setup pid=3505)[0m Preparing to unpack .../01-libargon2-1_0~20171227-0.3_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=3505)[0m Selecting previously unselected package libdevmapper1.02.1:amd64.
[36m(setup pid=3505)[0m Preparing to unpack .../02-libdevmapper1.02.1_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3505)[0m Selecting previously unselected package libjson-c5:amd64.
[36m(setup pid=3505)[0m Preparing to unpack .../03-libjson-c5_0.15-3~ubuntu1.22.04.2_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libapparmor1 amd64 3.0.4-2ubuntu2.4 [39.7 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libargon2-1 amd64 0~20171227-0.3 [19.5 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdevmapper1.02.1 amd64 2:1.02.175-2.1ubuntu5 [139 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libjson-c5 amd64 0.15-3~ubuntu1.22.04.2 [33.5 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcryptsetup12 amd64 2:2.4.3-1ubuntu1.3 [211 kB]
[36m(setup pid=3505)[0m Selecting previously unselected package libcryptsetup12:amd64.
[36m(setup pid=3505)[0m Preparing to unpack .../04-libcryptsetup12_2%3a2.4.3-1ubuntu1.3_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=3505)[0m Selecting previously unselected package libip4tc2:amd64.
[36m(setup pid=3505)[0m Preparing to unpack .../05-libip4tc2_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3505)[0m Selecting previously unselected package systemd.
[36m(setup pid=3505)[0m Preparing to unpack .../06-systemd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libip4tc2 amd64 1.8.7-1ubuntu5.2 [19.9 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd amd64 249.11-0ubuntu3.16 [4581 kB]
[36m(setup pid=3505)[0m Selecting previously unselected package libdbus-1-3:amd64.
[36m(setup pid=3505)[0m Preparing to unpack .../07-libdbus-1-3_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3505)[0m Selecting previously unselected package dbus.
[36m(setup pid=3505)[0m Preparing to unpack .../08-dbus_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3505)[0m Selecting previously unselected package dmsetup.
[36m(setup pid=3505)[0m Preparing to unpack .../09-dmsetup_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3505)[0m Selecting previously unselected package libglib2.0-0:amd64.
[36m(setup pid=3505)[0m Preparing to unpack .../10-libglib2.0-0_2.72.4-0ubuntu2.5_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3505)[0m Selecting previously unselected package libgirepository-1.0-1:amd64.
[36m(setup pid=3505)[0m Preparing to unpack .../11-libgirepository-1.0-1_1.72.0-1_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=3505)[0m Selecting previously unselected package gir1.2-glib-2.0:amd64.
[36m(setup pid=3505)[0m Preparing to unpack .../12-gir1.2-glib-2.0_1.72.0-1_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=3505)[0m Selecting previously unselected package libelf1:amd64.
[36m(setup pid=3505)[0m Preparing to unpack .../13-libelf1_0.186-1ubuntu0.1_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=3505)[0m Selecting previously unselected package libbpf0:amd64.
[36m(setup pid=3505)[0m Preparing to unpack .../14-libbpf0_1%3a0.5.0-1ubuntu22.04.1_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=3505)[0m Selecting previously unselected package libmnl0:amd64.
[36m(setup pid=3505)[0m Preparing to unpack .../15-libmnl0_1.0.4-3build2_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdbus-1-3 amd64 1.12.20-2ubuntu4.1 [189 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dbus amd64 1.12.20-2ubuntu4.1 [158 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dmsetup amd64 2:1.02.175-2.1ubuntu5 [81.7 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-0 amd64 2.72.4-0ubuntu2.5 [1466 kB]
[36m(setup pid=3505)[0m Selecting previously unselected package libxtables12:amd64.
[36m(setup pid=3505)[0m Preparing to unpack .../16-libxtables12_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3505)[0m Selecting previously unselected package iproute2.
[36m(setup pid=3505)[0m Preparing to unpack .../17-iproute2_5.15.0-1ubuntu2_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=3505)[0m Selecting previously unselected package libatm1:amd64.
[36m(setup pid=3505)[0m Preparing to unpack .../18-libatm1_1%3a2.5.1-4build2_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=3505)[0m Selecting previously unselected package libglib2.0-data.
[36m(setup pid=3505)[0m Preparing to unpack .../19-libglib2.0-data_2.72.4-0ubuntu2.5_all.deb ...
[36m(setup pid=3505)[0m Unpacking libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3505)[0m Selecting previously unselected package python3-dbus.
[36m(setup pid=3505)[0m Preparing to unpack .../20-python3-dbus_1.2.18-3build1_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking python3-dbus (1.2.18-3build1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgirepository-1.0-1 amd64 1.72.0-1 [55.6 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 gir1.2-glib-2.0 amd64 1.72.0-1 [164 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libelf1 amd64 0.186-1ubuntu0.1 [51.1 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libbpf0 amd64 1:0.5.0-1ubuntu22.04.1 [140 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmnl0 amd64 1.0.4-3build2 [13.2 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxtables12 amd64 1.8.7-1ubuntu5.2 [31.3 kB]
[36m(setup pid=3505)[0m Selecting previously unselected package python3-gi.
[36m(setup pid=3505)[0m Preparing to unpack .../21-python3-gi_3.42.1-0ubuntu1_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=3505)[0m Selecting previously unselected package networkd-dispatcher.
[36m(setup pid=3505)[0m Preparing to unpack .../22-networkd-dispatcher_2.1-2ubuntu0.22.04.2_all.deb ...
[36m(setup pid=3505)[0m Unpacking networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=3505)[0m Selecting previously unselected package shared-mime-info.
[36m(setup pid=3505)[0m Preparing to unpack .../23-shared-mime-info_2.1-2_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking shared-mime-info (2.1-2) ...
[36m(setup pid=3505)[0m Selecting previously unselected package systemd-timesyncd.
[36m(setup pid=3505)[0m Preparing to unpack .../24-systemd-timesyncd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking systemd-timesyncd (249.11-0ubuntu3.16) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 iproute2 amd64 5.15.0-1ubuntu2 [1070 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatm1 amd64 1:2.5.1-4build2 [22.8 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-data all 2.72.4-0ubuntu2.5 [4656 B]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-dbus amd64 1.2.18-3build1 [99.5 kB]
[36m(setup pid=3505)[0m Selecting previously unselected package xdg-user-dirs.
[36m(setup pid=3505)[0m Preparing to unpack .../25-xdg-user-dirs_0.17-2ubuntu4_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=3505)[0m Selecting previously unselected package libnl-genl-3-200:amd64.
[36m(setup pid=3505)[0m Preparing to unpack .../26-libnl-genl-3-200_3.5.0-0.1_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=3505)[0m Selecting previously unselected package htop.
[36m(setup pid=3505)[0m Preparing to unpack .../27-htop_3.0.5-7build2_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking htop (3.0.5-7build2) ...
[36m(setup pid=3505)[0m Selecting previously unselected package libsensors-config.
[36m(setup pid=3505)[0m Preparing to unpack .../28-libsensors-config_1%3a3.6.0-7ubuntu1_all.deb ...
[36m(setup pid=3505)[0m Unpacking libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-gi amd64 3.42.1-0ubuntu1 [229 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 networkd-dispatcher all 2.1-2ubuntu0.22.04.2 [15.8 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 shared-mime-info amd64 2.1-2 [454 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-timesyncd amd64 249.11-0ubuntu3.16 [31.2 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 xdg-user-dirs amd64 0.17-2ubuntu4 [53.9 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-genl-3-200 amd64 3.5.0-0.1 [12.4 kB]
[36m(setup pid=3505)[0m Selecting previously unselected package libsensors5:amd64.
[36m(setup pid=3505)[0m Preparing to unpack .../29-libsensors5_1%3a3.6.0-7ubuntu1_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3505)[0m Preparing to unpack .../30-net-tools_1.60+git20181103.0eebece-1ubuntu5.4_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking net-tools (1.60+git20181103.0eebece-1ubuntu5.4) over (1.60+git20181103.0eebece-1ubuntu5) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 htop amd64 3.0.5-7build2 [128 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors-config all 1:3.6.0-7ubuntu1 [5274 B]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors5 amd64 1:3.6.0-7ubuntu1 [26.3 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 net-tools amd64 1.60+git20181103.0eebece-1ubuntu5.4 [204 kB]
[36m(setup pid=2715, ip=10.102.30.60)[0m Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 sysstat amd64 12.5.2-2ubuntu0.2 [487 kB]
[36m(setup pid=3505)[0m Selecting previously unselected package sysstat.
[36m(setup pid=3505)[0m Preparing to unpack .../31-sysstat_12.5.2-2ubuntu0.2_amd64.deb ...
[36m(setup pid=3505)[0m Unpacking sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=3505)[0m Setting up libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3505)[0m Setting up net-tools (1.60+git20181103.0eebece-1ubuntu5.4) ...
[36m(setup pid=3505)[0m Setting up libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=3505)[0m Setting up xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=3505)[0m Setting up libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3505)[0m No schema files found: doing nothing.
[36m(setup pid=3505)[0m Setting up libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=3505)[0m Setting up libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3505)[0m Setting up libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=3505)[0m Setting up libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=3505)[0m Setting up libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3505)[0m Setting up dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3505)[0m Setting up shared-mime-info (2.1-2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m debconf: delaying package configuration, since apt-utils is not installed
[36m(setup pid=2715, ip=10.102.30.60)[0m Fetched 10.6 MB in 2s (6224 kB/s)
[36m(setup pid=2715, ip=10.102.30.60)[0m (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../libsystemd0_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libsystemd0:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libsystemd0:amd64 (249.11-0ubuntu3.16) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libapparmor1:amd64.
[36m(setup pid=2715, ip=10.102.30.60)[0m (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 23994 files and directories currently installed.)
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../00-libapparmor1_3.0.4-2ubuntu2.4_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libargon2-1:amd64.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../01-libargon2-1_0~20171227-0.3_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libdevmapper1.02.1:amd64.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../02-libdevmapper1.02.1_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libjson-c5:amd64.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../03-libjson-c5_0.15-3~ubuntu1.22.04.2_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libcryptsetup12:amd64.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../04-libcryptsetup12_2%3a2.4.3-1ubuntu1.3_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libip4tc2:amd64.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../05-libip4tc2_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package systemd.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../06-systemd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libdbus-1-3:amd64.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../07-libdbus-1-3_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package dbus.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../08-dbus_1.12.20-2ubuntu4.1_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package dmsetup.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../09-dmsetup_2%3a1.02.175-2.1ubuntu5_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libglib2.0-0:amd64.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../10-libglib2.0-0_2.72.4-0ubuntu2.5_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libgirepository-1.0-1:amd64.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../11-libgirepository-1.0-1_1.72.0-1_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package gir1.2-glib-2.0:amd64.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../12-gir1.2-glib-2.0_1.72.0-1_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libelf1:amd64.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../13-libelf1_0.186-1ubuntu0.1_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libbpf0:amd64.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../14-libbpf0_1%3a0.5.0-1ubuntu22.04.1_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libmnl0:amd64.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../15-libmnl0_1.0.4-3build2_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libxtables12:amd64.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../16-libxtables12_1.8.7-1ubuntu5.2_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package iproute2.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../17-iproute2_5.15.0-1ubuntu2_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libatm1:amd64.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../18-libatm1_1%3a2.5.1-4build2_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libglib2.0-data.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../19-libglib2.0-data_2.72.4-0ubuntu2.5_all.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package python3-dbus.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../20-python3-dbus_1.2.18-3build1_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking python3-dbus (1.2.18-3build1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package python3-gi.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../21-python3-gi_3.42.1-0ubuntu1_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package networkd-dispatcher.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../22-networkd-dispatcher_2.1-2ubuntu0.22.04.2_all.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package shared-mime-info.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../23-shared-mime-info_2.1-2_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking shared-mime-info (2.1-2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package systemd-timesyncd.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../24-systemd-timesyncd_249.11-0ubuntu3.16_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking systemd-timesyncd (249.11-0ubuntu3.16) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package xdg-user-dirs.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../25-xdg-user-dirs_0.17-2ubuntu4_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libnl-genl-3-200:amd64.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../26-libnl-genl-3-200_3.5.0-0.1_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package htop.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../27-htop_3.0.5-7build2_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking htop (3.0.5-7build2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libsensors-config.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../28-libsensors-config_1%3a3.6.0-7ubuntu1_all.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package libsensors5:amd64.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../29-libsensors5_1%3a3.6.0-7ubuntu1_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3505)[0m Setting up libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=3505)[0m Setting up libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=3505)[0m Setting up libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=3505)[0m Setting up libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3505)[0m Setting up dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=3505)[0m Setting up libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=3505)[0m Setting up libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=3505)[0m Setting up libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=3505)[0m Setting up libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=3505)[0m Setting up sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../30-net-tools_1.60+git20181103.0eebece-1ubuntu5.4_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking net-tools (1.60+git20181103.0eebece-1ubuntu5.4) over (1.60+git20181103.0eebece-1ubuntu5) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Selecting previously unselected package sysstat.
[36m(setup pid=2715, ip=10.102.30.60)[0m Preparing to unpack .../31-sysstat_12.5.2-2ubuntu0.2_amd64.deb ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Unpacking sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libip4tc2:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up net-tools (1.60+git20181103.0eebece-1ubuntu5.4) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libapparmor1:amd64 (3.0.4-2ubuntu2.4) ...
[36m(setup pid=3505)[0m 
[36m(setup pid=3505)[0m Creating config file /etc/default/sysstat with new version
[36m(setup pid=3505)[0m update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode
[36m(setup pid=3505)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/sar.1.gz because associated file /usr/share/man/man1/sar.sysstat.1.gz (of link group sar) doesn't exist
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up xdg-user-dirs (0.17-2ubuntu4) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m No schema files found: doing nothing.
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libargon2-1:amd64 (0~20171227-0.3) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libsensors-config (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libatm1:amd64 (1:2.5.1-4build2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libglib2.0-data (2.72.4-0ubuntu2.5) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libdbus-1-3:amd64 (1.12.20-2ubuntu4.1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up dbus (1.12.20-2ubuntu4.1) ...
[36m(setup pid=3505)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer → /lib/systemd/system/sysstat-collect.timer.
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up shared-mime-info (2.1-2) ...
[36m(setup pid=3505)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer → /lib/systemd/system/sysstat-summary.timer.
[36m(setup pid=3505)[0m Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /lib/systemd/system/sysstat.service.
[36m(setup pid=3505)[0m Setting up python3-dbus (1.2.18-3build1) ...
[36m(setup pid=3505)[0m Setting up htop (3.0.5-7build2) ...
[36m(setup pid=3505)[0m Setting up gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=3505)[0m Setting up libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=3505)[0m Setting up libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=3505)[0m Setting up iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=3505)[0m Setting up systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=3505)[0m 
[36m(setup pid=3505)[0m Configuration file '/etc/systemd/system.conf'
[36m(setup pid=3505)[0m  ==> File on system created by you or by a script.
[36m(setup pid=3505)[0m  ==> File also in package provided by package maintainer.
[36m(setup pid=3505)[0m    What would you like to do about it ?  Your options are:
[36m(setup pid=3505)[0m     Y or I  : install the package maintainer's version
[36m(setup pid=3505)[0m     N or O  : keep your currently-installed version
[36m(setup pid=3505)[0m       D     : show the differences between the versions
[36m(setup pid=3505)[0m       Z     : start a shell to examine the situation
[36m(setup pid=3505)[0m  The default action is to keep your current version.
[36m(setup pid=3505)[0m *** system.conf (Y/I/N/O/D/Z) [default=N] ? dpkg: error processing package systemd (--configure):
[36m(setup pid=3505)[0m  end of file on stdin at conffile prompt
[36m(setup pid=3505)[0m Setting up python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=3505)[0m dpkg: dependency problems prevent configuration of systemd-timesyncd:
[36m(setup pid=3505)[0m  systemd-timesyncd depends on systemd (= 249.11-0ubuntu3.16); however:
[36m(setup pid=3505)[0m   Package systemd is not configured yet.
[36m(setup pid=3505)[0m 
[36m(setup pid=3505)[0m dpkg: error processing package systemd-timesyncd (--configure):
[36m(setup pid=3505)[0m  dependency problems - leaving unconfigured
[36m(setup pid=3505)[0m Setting up networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=3505)[0m Created symlink /etc/systemd/system/multi-user.target.wants/networkd-dispatcher.service → /lib/systemd/system/networkd-dispatcher.service.
[36m(setup pid=3505)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=3505)[0m Errors were encountered while processing:
[36m(setup pid=3505)[0m  systemd
[36m(setup pid=3505)[0m  systemd-timesyncd
[36m(setup pid=3505)[0m E: Sub-process /usr/bin/dpkg returned an error code (1)
[36m(setup pid=3505)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libmnl0:amd64 (1.0.4-3build2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libsensors5:amd64 (1:3.6.0-7ubuntu1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libxtables12:amd64 (1.8.7-1ubuntu5.2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libdevmapper1.02.1:amd64 (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up dmsetup (2:1.02.175-2.1ubuntu5) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libnl-genl-3-200:amd64 (3.5.0-0.1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libgirepository-1.0-1:amd64 (1.72.0-1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libelf1:amd64 (0.186-1ubuntu0.1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libjson-c5:amd64 (0.15-3~ubuntu1.22.04.2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up sysstat (12.5.2-2ubuntu0.2) ...
[36m(setup pid=3505)[0m Resolved 3 packages in 145ms
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=2715, ip=10.102.30.60)[0m Creating config file /etc/default/sysstat with new version
[36m(setup pid=3505)[0m Prepared 1 package in 10ms
[36m(setup pid=3505)[0m Installed 2 packages in 16ms
[36m(setup pid=3505)[0m  + nvidia-ml-py==12.575.51
[36m(setup pid=3505)[0m  + nvitop==1.5.2
[36m(setup pid=2715, ip=10.102.30.60)[0m update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode
[36m(setup pid=2715, ip=10.102.30.60)[0m update-alternatives: warning: skip creation of /usr/share/man/man1/sar.1.gz because associated file /usr/share/man/man1/sar.sysstat.1.gz (of link group sar) doesn't exist
[36m(setup pid=2715, ip=10.102.30.60)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer → /lib/systemd/system/sysstat-collect.timer.
[36m(setup pid=2715, ip=10.102.30.60)[0m Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer → /lib/systemd/system/sysstat-summary.timer.
[36m(setup pid=2715, ip=10.102.30.60)[0m Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /lib/systemd/system/sysstat.service.
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up python3-dbus (1.2.18-3build1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up htop (3.0.5-7build2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up gir1.2-glib-2.0:amd64 (1.72.0-1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libcryptsetup12:amd64 (2:2.4.3-1ubuntu1.3) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up libbpf0:amd64 (1:0.5.0-1ubuntu22.04.1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up iproute2 (5.15.0-1ubuntu2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up systemd (249.11-0ubuntu3.16) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=2715, ip=10.102.30.60)[0m Configuration file '/etc/systemd/system.conf'
[36m(setup pid=2715, ip=10.102.30.60)[0m  ==> File on system created by you or by a script.
[36m(setup pid=2715, ip=10.102.30.60)[0m  ==> File also in package provided by package maintainer.
[36m(setup pid=2715, ip=10.102.30.60)[0m    What would you like to do about it ?  Your options are:
[36m(setup pid=2715, ip=10.102.30.60)[0m     Y or I  : install the package maintainer's version
[36m(setup pid=2715, ip=10.102.30.60)[0m     N or O  : keep your currently-installed version
[36m(setup pid=2715, ip=10.102.30.60)[0m       D     : show the differences between the versions
[36m(setup pid=2715, ip=10.102.30.60)[0m       Z     : start a shell to examine the situation
[36m(setup pid=2715, ip=10.102.30.60)[0m  The default action is to keep your current version.
[36m(setup pid=2715, ip=10.102.30.60)[0m *** system.conf (Y/I/N/O/D/Z) [default=N] ? dpkg: error processing package systemd (--configure):
[36m(setup pid=2715, ip=10.102.30.60)[0m  end of file on stdin at conffile prompt
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up python3-gi (3.42.1-0ubuntu1) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m dpkg: dependency problems prevent configuration of systemd-timesyncd:
[36m(setup pid=2715, ip=10.102.30.60)[0m  systemd-timesyncd depends on systemd (= 249.11-0ubuntu3.16); however:
[36m(setup pid=2715, ip=10.102.30.60)[0m   Package systemd is not configured yet.
[36m(setup pid=2715, ip=10.102.30.60)[0m 
[36m(setup pid=2715, ip=10.102.30.60)[0m dpkg: error processing package systemd-timesyncd (--configure):
[36m(setup pid=2715, ip=10.102.30.60)[0m  dependency problems - leaving unconfigured
[36m(setup pid=2715, ip=10.102.30.60)[0m Setting up networkd-dispatcher (2.1-2ubuntu0.22.04.2) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Created symlink /etc/systemd/system/multi-user.target.wants/networkd-dispatcher.service → /lib/systemd/system/networkd-dispatcher.service.
[36m(setup pid=2715, ip=10.102.30.60)[0m Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
[36m(setup pid=2715, ip=10.102.30.60)[0m Errors were encountered while processing:
[36m(setup pid=2715, ip=10.102.30.60)[0m  systemd
[36m(setup pid=2715, ip=10.102.30.60)[0m  systemd-timesyncd
[36m(setup pid=2715, ip=10.102.30.60)[0m E: Sub-process /usr/bin/dpkg returned an error code (1)
[36m(setup pid=2715, ip=10.102.30.60)[0m Using Python 3.10.12 environment at: /root/training
[36m(setup pid=2715, ip=10.102.30.60)[0m Resolved 3 packages in 40ms
[36m(setup pid=2715, ip=10.102.30.60)[0m Prepared 1 package in 10ms
[36m(setup pid=2715, ip=10.102.30.60)[0m Installed 2 packages in 16ms
[36m(setup pid=2715, ip=10.102.30.60)[0m  + nvidia-ml-py==12.575.51
[36m(setup pid=2715, ip=10.102.30.60)[0m  + nvitop==1.5.2
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Processing directory 1/2: /tmp/checkpoint ===
[36m(head, rank=0, pid=3505)[0m Preserving existing cache directories...
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3505)[0m Downloading and caching dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Processing directory 1/2: /tmp/checkpoint ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Preserving existing cache directories...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Downloading and caching dataset...
[36m(head, rank=0, pid=3505)[0m Setting num_proc from 128 to 10 for the train split as it only contains 10 shards.
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Generating train split:   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3505)[0m Generating train split:   2%|▏         | 1000/47780 [00:00<00:24, 1944.70 examples/s]
[36m(head, rank=0, pid=3505)[0m Generating train split:  17%|█▋        | 8000/47780 [00:00<00:02, 15960.10 examples/s]
[36m(head, rank=0, pid=3505)[0m Generating train split:  25%|██▌       | 12000/47780 [00:00<00:01, 19743.57 examples/s]
[36m(head, rank=0, pid=3505)[0m Generating train split:  44%|████▍     | 21000/47780 [00:00<00:00, 30076.73 examples/s]
[36m(head, rank=0, pid=3505)[0m Generating train split:  63%|██████▎   | 30000/47780 [00:01<00:00, 38712.35 examples/s]
[36m(head, rank=0, pid=3505)[0m Generating train split:  87%|████████▋ | 41334/47780 [00:01<00:00, 54768.86 examples/s]Generating train split: 100%|██████████| 47780/47780 [00:01<00:00, 34700.61 examples/s]
[36m(head, rank=0, pid=3505)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(head, rank=0, pid=3505)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Setting num_proc from 128 to 10 for the train split as it only contains 10 shards.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Generating train split:   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Generating train split:   2%|▏         | 1000/47780 [00:00<00:24, 1943.98 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Generating train split:  19%|█▉        | 9000/47780 [00:00<00:02, 18159.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Generating train split:  29%|██▉       | 14000/47780 [00:00<00:01, 22614.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Generating train split:  44%|████▍     | 21000/47780 [00:00<00:00, 28163.48 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Generating train split:  63%|██████▎   | 30000/47780 [00:01<00:00, 38585.88 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Generating train split:  85%|████████▍ | 40556/47780 [00:01<00:00, 52879.96 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Generating train split: 100%|██████████| 47780/47780 [00:01<00:00, 57151.32 examples/s]Generating train split: 100%|██████████| 47780/47780 [00:01<00:00, 34708.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3505)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3505)[0m vmtouch output: Files: 14
[36m(head, rank=0, pid=3505)[0m      Directories: 5
[36m(head, rank=0, pid=3505)[0m    Evicted Pages: 1212952 (4G)
[36m(head, rank=0, pid=3505)[0m          Elapsed: 3.6649 seconds
[36m(head, rank=0, pid=3505)[0m Downloading and caching model...
[36m(head, rank=0, pid=3505)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m vmtouch output: Files: 14
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m      Directories: 5
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m    Evicted Pages: 1212952 (4G)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m          Elapsed: 3.6639 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Downloading and caching model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Fetching 5 files:  20%|██        | 1/5 [00:22<01:29, 22.37s/it]Fetching 5 files:  80%|████████  | 4/5 [00:22<00:04,  4.27s/it]Fetching 5 files: 100%|██████████| 5/5 [00:22<00:00,  4.50s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(head, rank=0, pid=3505)[0m Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3505)[0m Fetching 5 files:  20%|██        | 1/5 [00:26<01:44, 26.18s/it]Fetching 5 files:  80%|████████  | 4/5 [00:26<00:05,  5.03s/it]Fetching 5 files: 100%|██████████| 5/5 [00:26<00:00,  5.29s/it]
[36m(head, rank=0, pid=3505)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:03<00:15,  3.94s/it]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:04<00:16,  4.04s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:07<00:11,  3.87s/it]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:07<00:11,  3.88s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:11<00:07,  3.87s/it]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:11<00:07,  3.86s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:15<00:03,  3.87s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.77s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.82s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model downloaded and cached at: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Flushing filesystem cache for: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:15<00:03,  3.85s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.74s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.80s/it]
[36m(head, rank=0, pid=3505)[0m Model downloaded and cached at: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3505)[0m Flushing filesystem cache for: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3505)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3505)[0m vmtouch output: Files: 18
[36m(head, rank=0, pid=3505)[0m      Directories: 10
[36m(head, rank=0, pid=3505)[0m    Evicted Pages: 5950909 (22G)
[36m(head, rank=0, pid=3505)[0m          Elapsed: 18.962 seconds
[36m(head, rank=0, pid=3505)[0m Completed processing directory 1/2
[36m(head, rank=0, pid=3505)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache, /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3505)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3505)[0m vmtouch output: Files: 32
[36m(head, rank=0, pid=3505)[0m      Directories: 15
[36m(head, rank=0, pid=3505)[0m    Evicted Pages: 7163861 (27G)
[36m(head, rank=0, pid=3505)[0m          Elapsed: 0.003356 seconds
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Processing directory 2/2: /mnt/data ===
[36m(head, rank=0, pid=3505)[0m Preserving existing cache directories...
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3505)[0m Downloading and caching dataset...
[36m(head, rank=0, pid=3505)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(head, rank=0, pid=3505)[0m Flushing filesystem cache for: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3505)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3505)[0m vmtouch output: Files: 78
[36m(head, rank=0, pid=3505)[0m      Directories: 5
[36m(head, rank=0, pid=3505)[0m    Evicted Pages: 4617819 (17G)
[36m(head, rank=0, pid=3505)[0m          Elapsed: 0.30642 seconds
[36m(head, rank=0, pid=3505)[0m Downloading and caching model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m vmtouch output: Files: 18
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m      Directories: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m    Evicted Pages: 5950909 (22G)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m          Elapsed: 23.411 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed processing directory 1/2
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Flushing filesystem cache for: /tmp/checkpoint/dataset_cache, /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m vmtouch output: Files: 32
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m      Directories: 15
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m    Evicted Pages: 7163861 (27G)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m          Elapsed: 0.002739 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Processing directory 2/2: /mnt/data ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Preserving existing cache directories...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Downloading and caching dataset...
[36m(head, rank=0, pid=3505)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset downloaded successfully. Size: 47780 examples
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Flushing filesystem cache for: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m vmtouch output: Files: 78
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m      Directories: 5
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m    Evicted Pages: 4617819 (17G)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m          Elapsed: 0.3209 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Downloading and caching model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:22,  5.58s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:22,  5.50s/it]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:10<00:15,  5.28s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:10<00:15,  5.20s/it]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:15<00:10,  5.19s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:15<00:10,  5.06s/it]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:20<00:05,  5.14s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:25<00:00,  4.98s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:25<00:00,  5.10s/it]
[36m(head, rank=0, pid=3505)[0m Model downloaded and cached at: /mnt/data/model_cache
[36m(head, rank=0, pid=3505)[0m Flushing filesystem cache for: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:20<00:05,  5.00s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:24<00:00,  4.85s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:24<00:00,  4.98s/it]
[36m(head, rank=0, pid=3505)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3505)[0m vmtouch output: Files: 18
[36m(head, rank=0, pid=3505)[0m      Directories: 10
[36m(head, rank=0, pid=3505)[0m    Evicted Pages: 5950909 (22G)
[36m(head, rank=0, pid=3505)[0m          Elapsed: 1.021 seconds
[36m(head, rank=0, pid=3505)[0m Completed processing directory 2/2
[36m(head, rank=0, pid=3505)[0m Flushing filesystem cache for: /mnt/data/dataset_cache, /mnt/data/model_cache
[36m(head, rank=0, pid=3505)[0m Successfully flushed filesystem cache
[36m(head, rank=0, pid=3505)[0m vmtouch output: Files: 96
[36m(head, rank=0, pid=3505)[0m      Directories: 15
[36m(head, rank=0, pid=3505)[0m    Evicted Pages: 10568728 (40G)
[36m(head, rank=0, pid=3505)[0m          Elapsed: 0.10738 seconds
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Copying cached data to S3 directories ===
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Copying to S3 directory 1/2: /checkpoints_s3
[36m(head, rank=0, pid=3505)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model downloaded and cached at: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Flushing filesystem cache for: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m vmtouch output: Files: 18
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m      Directories: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m    Evicted Pages: 5950909 (22G)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m          Elapsed: 1.0074 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed processing directory 2/2
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Flushing filesystem cache for: /mnt/data/dataset_cache, /mnt/data/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Successfully flushed filesystem cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m vmtouch output: Files: 96
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m      Directories: 15
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m    Evicted Pages: 10568728 (40G)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m          Elapsed: 0.10532 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Copying cached data to S3 directories ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Copying to S3 directory 1/2: /checkpoints_s3
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3505)[0m Dataset cache copied successfully
[36m(head, rank=0, pid=3505)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache copied successfully
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3505)[0m Model cache copied successfully
[36m(head, rank=0, pid=3505)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3505)[0m Checkpoints copied successfully
[36m(head, rank=0, pid=3505)[0m Completed copying to S3 directory 1/2
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Copying to S3 directory 2/2: /checkpoints_s3_mount_cached
[36m(head, rank=0, pid=3505)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache copied successfully
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoints copied successfully
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed copying to S3 directory 1/2
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Copying to S3 directory 2/2: /checkpoints_s3_mount_cached
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Copying dataset cache from /tmp/checkpoint/dataset_cache to /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3505)[0m Dataset cache copied successfully
[36m(head, rank=0, pid=3505)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache copied successfully
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Copying model cache from /tmp/checkpoint/model_cache to /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3505)[0m Model cache copied successfully
[36m(head, rank=0, pid=3505)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3505)[0m Checkpoints copied successfully
[36m(head, rank=0, pid=3505)[0m Completed copying to S3 directory 2/2
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Download and caching completed ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache copied successfully
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Copying checkpoints from /tmp/checkpoint/checkpoints to /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoints copied successfully
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed copying to S3 directory 2/2
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Download and caching completed ===
[36m(head, rank=0, pid=3505)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /tmp/checkpoint/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /tmp/checkpoint/checkpoints
[36m(head, rank=0, pid=3505)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/tmp/checkpoint/checkpoints'
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/tmp/checkpoint/checkpoints'
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.08 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.08 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.13 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.14 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.12 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.13 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.14 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.14 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.15 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.24 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.22 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.25 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.26 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.32 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.36 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.36 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /tmp/checkpoint/model_cache
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 125.02it/s]
[36m(head, rank=0, pid=3505)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 128.29it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 128.35it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 126.76it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 130.41it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 123.45it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 0.96 seconds
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 129.13it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 131.02it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 127.72it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 126.32it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 127.45it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 136.31it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 1.05 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 0.95 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 0.96 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 0.97 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 0.99 seconds
[36m(head, rank=0, pid=3505)[0m Completed Load model in 1.05 seconds
[36m(head, rank=0, pid=3505)[0m Completed Load model in 1.05 seconds
[36m(head, rank=0, pid=3505)[0m Completed Load model in 1.05 seconds
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 0.98 seconds
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 133.35it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 0.98 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 128.06it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 1.03 seconds
[36m(head, rank=0, pid=3505)[0m Completed Load model in 1.02 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 1.17 seconds
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:04<00:17,  4.33s/it]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:04<00:17,  4.39s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:08<00:12,  4.20s/it]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:08<00:12,  4.26s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:12<00:08,  4.06s/it]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:12<00:08,  4.19s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:16<00:04,  4.01s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:20<00:00,  3.94s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:20<00:00,  4.02s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 20.93 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:16<00:04,  4.14s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:20<00:00,  4.01s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:20<00:00,  4.10s/it]
[36m(head, rank=0, pid=3505)[0m Completed Load model in 21.50 seconds
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:13<29:10:09,  2.20s/ examples]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   0%|          | 31/47780 [00:13<4:20:13,  3.06 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   0%|          | 56/47780 [00:13<2:02:30,  6.49 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   0%|          | 102/47780 [00:14<53:18, 14.91 examples/s] 
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   0%|          | 187/47780 [00:14<22:38, 35.02 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   1%|          | 256/47780 [00:14<14:43, 53.81 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   1%|          | 331/47780 [00:15<10:13, 77.40 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   1%|          | 429/47780 [00:15<06:57, 113.32 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   1%|          | 570/47780 [00:15<04:32, 173.07 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 735/47780 [00:16<03:13, 242.88 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 894/47780 [00:16<02:44, 284.47 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1077/47780 [00:16<02:16, 341.25 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1276/47780 [00:17<01:59, 388.23 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1526/47780 [00:17<01:41, 455.73 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1794/47780 [00:17<01:24, 542.62 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2034/47780 [00:18<01:16, 594.19 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2265/47780 [00:18<01:13, 615.60 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2528/47780 [00:18<01:07, 667.77 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2775/47780 [00:19<01:05, 686.44 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   6%|▋         | 3016/47780 [00:19<01:04, 694.38 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3299/47780 [00:19<01:00, 737.15 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3615/47780 [00:20<00:55, 796.01 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3893/47780 [00:20<00:54, 800.80 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4207/47780 [00:20<00:51, 839.91 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4594/47780 [00:21<00:46, 934.48 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4928/47780 [00:21<00:45, 931.94 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5283/47780 [00:22<00:45, 935.70 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5698/47780 [00:22<00:32, 1277.11 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5884/47780 [00:22<00:34, 1227.12 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6047/47780 [00:22<00:34, 1217.77 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6196/47780 [00:22<00:35, 1176.86 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6334/47780 [00:22<00:36, 1137.21 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6460/47780 [00:22<00:35, 1148.78 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6588/47780 [00:22<00:35, 1172.82 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6713/47780 [00:23<00:37, 1094.60 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6827/47780 [00:23<00:37, 1094.56 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 6955/47780 [00:23<00:35, 1138.82 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7074/47780 [00:23<00:36, 1127.62 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7205/47780 [00:23<00:34, 1168.68 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7338/47780 [00:23<00:33, 1193.38 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7459/47780 [00:23<00:33, 1197.19 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7580/47780 [00:23<00:34, 1150.85 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7697/47780 [00:23<00:34, 1145.52 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7813/47780 [00:24<00:35, 1135.42 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7936/47780 [00:24<00:34, 1157.30 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8053/47780 [00:24<00:36, 1102.59 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8170/47780 [00:24<00:35, 1115.49 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8287/47780 [00:24<00:35, 1118.69 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8400/47780 [00:24<00:35, 1095.84 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8510/47780 [00:24<00:36, 1063.82 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8617/47780 [00:24<00:37, 1051.81 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8739/47780 [00:24<00:35, 1096.02 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8850/47780 [00:25<00:37, 1038.32 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8955/47780 [00:25<00:38, 1014.32 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9072/47780 [00:25<00:36, 1055.20 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9181/47780 [00:25<00:36, 1059.22 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9294/47780 [00:25<00:35, 1071.18 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9426/47780 [00:25<00:33, 1141.15 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9543/47780 [00:25<00:34, 1124.50 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9656/47780 [00:25<00:34, 1106.09 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9768/47780 [00:25<00:34, 1109.60 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9893/47780 [00:25<00:33, 1137.23 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10007/47780 [00:26<00:33, 1127.24 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10120/47780 [00:26<00:34, 1078.26 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10244/47780 [00:26<00:33, 1116.95 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10357/47780 [00:26<00:34, 1080.78 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10466/47780 [00:26<00:34, 1074.52 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10574/47780 [00:26<00:35, 1039.57 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10682/47780 [00:26<00:36, 1026.70 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10791/47780 [00:26<00:35, 1038.55 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10919/47780 [00:26<00:33, 1106.48 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11045/47780 [00:27<00:32, 1123.90 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11171/47780 [00:27<00:32, 1133.79 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11289/47780 [00:27<00:32, 1136.13 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11403/47780 [00:27<00:32, 1128.70 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11524/47780 [00:27<00:31, 1142.85 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11641/47780 [00:27<00:31, 1144.69 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11758/47780 [00:27<00:31, 1144.29 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11883/47780 [00:27<00:30, 1161.01 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12022/47780 [00:27<00:29, 1213.61 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12154/47780 [00:27<00:28, 1243.36 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12282/47780 [00:28<00:29, 1212.13 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12405/47780 [00:28<00:29, 1196.54 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12526/47780 [00:28<00:29, 1182.76 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12645/47780 [00:28<00:30, 1168.22 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12773/47780 [00:28<00:29, 1190.10 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12896/47780 [00:28<00:29, 1184.92 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13015/47780 [00:28<00:30, 1121.79 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13129/47780 [00:28<00:31, 1107.86 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13242/47780 [00:28<00:32, 1053.08 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13357/47780 [00:29<00:31, 1076.52 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13472/47780 [00:29<00:31, 1096.81 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13590/47780 [00:29<00:30, 1115.94 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13708/47780 [00:29<00:30, 1128.39 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13822/47780 [00:29<00:31, 1062.94 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13938/47780 [00:29<00:32, 1051.67 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14057/47780 [00:29<00:30, 1090.22 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14210/47780 [00:29<00:28, 1191.76 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14331/47780 [00:29<00:28, 1164.15 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14461/47780 [00:29<00:28, 1187.03 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14582/47780 [00:30<00:28, 1170.96 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14700/47780 [00:30<00:28, 1160.07 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14817/47780 [00:30<00:29, 1114.27 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14929/47780 [00:30<00:30, 1093.62 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 15039/47780 [00:30<00:31, 1046.05 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15147/47780 [00:30<00:31, 1035.25 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15267/47780 [00:30<00:30, 1058.55 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15375/47780 [00:30<00:31, 1042.69 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15512/47780 [00:30<00:28, 1130.09 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15626/47780 [00:31<00:28, 1129.19 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15741/47780 [00:31<00:28, 1113.43 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15858/47780 [00:31<00:28, 1114.93 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15970/47780 [00:31<00:29, 1090.86 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16080/47780 [00:31<00:29, 1076.82 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16205/47780 [00:31<00:28, 1109.55 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16322/47780 [00:31<00:27, 1123.81 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16453/47780 [00:31<00:26, 1174.66 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16577/47780 [00:31<00:26, 1175.52 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16695/47780 [00:32<00:27, 1138.99 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16817/47780 [00:32<00:26, 1158.23 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16944/47780 [00:32<00:25, 1187.33 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17064/47780 [00:32<00:26, 1140.35 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17200/47780 [00:32<00:25, 1196.03 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17327/47780 [00:32<00:25, 1201.01 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17449/47780 [00:32<00:25, 1193.28 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17571/47780 [00:32<00:25, 1175.03 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17707/47780 [00:32<00:24, 1222.07 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17831/47780 [00:32<00:24, 1198.23 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17953/47780 [00:33<00:24, 1193.28 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18073/47780 [00:33<00:26, 1134.81 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18190/47780 [00:33<00:26, 1120.08 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18309/47780 [00:33<00:25, 1134.45 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18429/47780 [00:33<00:25, 1152.56 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18549/47780 [00:33<00:25, 1163.75 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18668/47780 [00:33<00:24, 1170.62 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18789/47780 [00:33<00:24, 1179.36 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18909/47780 [00:33<00:24, 1162.61 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19027/47780 [00:34<00:25, 1118.49 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19150/47780 [00:34<00:25, 1144.63 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19265/47780 [00:34<00:25, 1137.89 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19383/47780 [00:34<00:25, 1115.44 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19499/47780 [00:34<00:25, 1124.60 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19613/47780 [00:34<00:26, 1074.87 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19725/47780 [00:34<00:25, 1087.04 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19836/47780 [00:34<00:25, 1079.76 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19954/47780 [00:34<00:25, 1097.90 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20066/47780 [00:34<00:25, 1078.73 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20187/47780 [00:35<00:24, 1116.49 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20303/47780 [00:35<00:25, 1078.67 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20412/47780 [00:35<00:25, 1057.85 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20542/47780 [00:35<00:24, 1111.44 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20661/47780 [00:35<00:24, 1125.93 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20783/47780 [00:35<00:23, 1131.98 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20922/47780 [00:35<00:22, 1182.75 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21043/47780 [00:35<00:22, 1178.46 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21162/47780 [00:35<00:22, 1169.95 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21282/47780 [00:36<00:24, 1083.20 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21407/47780 [00:36<00:23, 1128.59 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21522/47780 [00:36<00:23, 1123.42 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21636/47780 [00:36<00:23, 1105.90 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21751/47780 [00:36<00:23, 1118.41 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21880/47780 [00:36<00:22, 1164.74 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22005/47780 [00:36<00:21, 1171.90 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22141/47780 [00:36<00:20, 1225.40 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22264/47780 [00:36<00:21, 1166.99 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22383/47780 [00:36<00:22, 1128.82 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22497/47780 [00:37<00:23, 1087.93 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22616/47780 [00:37<00:22, 1100.06 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22731/47780 [00:37<00:22, 1107.72 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22856/47780 [00:37<00:21, 1145.85 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22981/47780 [00:37<00:21, 1175.28 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23104/47780 [00:37<00:20, 1175.44 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23223/47780 [00:37<00:20, 1172.81 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23347/47780 [00:37<00:20, 1178.43 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23492/47780 [00:37<00:19, 1244.78 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23622/47780 [00:38<00:19, 1258.24 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23751/47780 [00:38<00:19, 1262.39 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23879/47780 [00:38<00:19, 1222.92 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24004/47780 [00:38<00:19, 1219.96 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24127/47780 [00:38<00:20, 1179.30 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24247/47780 [00:38<00:20, 1132.43 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24364/47780 [00:38<00:20, 1132.33 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24492/47780 [00:38<00:20, 1152.22 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24609/47780 [00:38<00:20, 1153.82 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24729/47780 [00:39<00:21, 1090.64 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24839/47780 [00:39<00:21, 1058.04 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24946/47780 [00:39<00:21, 1041.98 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25052/47780 [00:39<00:22, 1004.49 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25170/47780 [00:39<00:21, 1048.84 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25279/47780 [00:39<00:21, 1051.63 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25385/47780 [00:39<00:21, 1047.37 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25491/47780 [00:39<00:21, 1043.63 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25602/47780 [00:39<00:21, 1040.84 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25708/47780 [00:39<00:21, 1044.01 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25814/47780 [00:40<00:21, 1043.28 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25930/47780 [00:40<00:20, 1063.77 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26040/47780 [00:40<00:20, 1067.82 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26163/47780 [00:40<00:19, 1110.39 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26280/47780 [00:40<00:19, 1117.44 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26393/47780 [00:40<00:19, 1084.06 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26521/47780 [00:40<00:18, 1132.26 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26637/47780 [00:40<00:19, 1101.76 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26749/47780 [00:40<00:19, 1068.65 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26858/47780 [00:41<00:20, 1039.53 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26965/47780 [00:41<00:20, 1003.36 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27067/47780 [00:41<00:20, 996.38 examples/s] 
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27167/47780 [00:41<00:22, 901.77 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27260/47780 [00:41<00:23, 868.94 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27353/47780 [00:41<00:23, 884.58 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27446/47780 [00:41<00:23, 880.93 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27536/47780 [00:41<00:24, 833.75 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27622/47780 [00:41<00:24, 816.66 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27714/47780 [00:42<00:24, 832.93 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27799/47780 [00:42<00:24, 801.16 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27904/47780 [00:42<00:22, 865.33 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28004/47780 [00:42<00:22, 895.10 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28096/47780 [00:42<00:22, 889.64 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28189/47780 [00:42<00:21, 896.02 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28302/47780 [00:42<00:20, 960.06 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28401/47780 [00:42<00:20, 946.71 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28513/47780 [00:42<00:19, 983.21 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28655/47780 [00:42<00:17, 1104.45 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28771/47780 [00:43<00:17, 1072.22 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28888/47780 [00:43<00:17, 1098.99 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28999/47780 [00:43<00:17, 1085.64 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29127/47780 [00:43<00:16, 1133.14 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29246/47780 [00:43<00:16, 1148.53 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29363/47780 [00:43<00:16, 1131.94 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29486/47780 [00:43<00:15, 1143.69 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29613/47780 [00:43<00:15, 1168.33 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29750/47780 [00:43<00:14, 1224.63 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29873/47780 [00:44<00:15, 1189.35 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29994/47780 [00:44<00:14, 1189.82 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30117/47780 [00:44<00:14, 1182.04 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30240/47780 [00:44<00:14, 1194.90 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30360/47780 [00:44<00:15, 1151.43 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30476/47780 [00:44<00:15, 1127.17 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30610/47780 [00:44<00:14, 1175.70 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30742/47780 [00:44<00:14, 1215.10 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30865/47780 [00:44<00:14, 1206.76 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30987/47780 [00:44<00:14, 1167.39 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31106/47780 [00:45<00:14, 1128.77 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31221/47780 [00:45<00:15, 1095.54 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31341/47780 [00:45<00:14, 1113.49 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31461/47780 [00:45<00:14, 1134.33 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31575/47780 [00:45<00:14, 1093.27 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31687/47780 [00:45<00:14, 1077.58 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31796/47780 [00:45<00:15, 1048.07 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31913/47780 [00:45<00:14, 1068.07 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32022/47780 [00:45<00:15, 1032.98 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32126/47780 [00:46<00:15, 986.72 examples/s] 
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32239/47780 [00:46<00:15, 1019.98 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32342/47780 [00:46<00:15, 1012.50 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32460/47780 [00:46<00:14, 1058.50 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32588/47780 [00:46<00:13, 1121.78 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32701/47780 [00:46<00:14, 1049.17 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32810/47780 [00:46<00:14, 1030.66 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32964/47780 [00:46<00:13, 1135.70 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33085/47780 [00:46<00:12, 1150.35 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33211/47780 [00:47<00:12, 1180.18 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33330/47780 [00:47<00:12, 1175.37 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33448/47780 [00:47<00:12, 1149.66 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33564/47780 [00:47<00:12, 1132.96 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33685/47780 [00:47<00:12, 1154.77 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33801/47780 [00:47<00:12, 1137.12 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33915/47780 [00:47<00:12, 1133.33 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34049/47780 [00:47<00:11, 1172.51 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34168/47780 [00:47<00:11, 1151.63 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34285/47780 [00:47<00:11, 1151.19 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34401/47780 [00:48<00:11, 1129.23 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34514/47780 [00:48<00:12, 1094.11 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34624/47780 [00:48<00:12, 1070.95 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34732/47780 [00:48<00:12, 1031.80 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34839/47780 [00:48<00:13, 969.12 examples/s] 
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34946/47780 [00:48<00:12, 990.80 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35047/47780 [00:48<00:12, 979.78 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35147/47780 [00:48<00:13, 957.22 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35245/47780 [00:48<00:13, 918.87 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35341/47780 [00:49<00:14, 877.27 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35444/47780 [00:49<00:13, 912.74 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35537/47780 [00:49<00:13, 898.14 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35637/47780 [00:49<00:13, 915.64 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35735/47780 [00:49<00:12, 931.90 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35829/47780 [00:49<00:13, 886.20 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35924/47780 [00:49<00:13, 899.15 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36016/47780 [00:49<00:13, 860.84 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36113/47780 [00:49<00:13, 888.08 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36204/47780 [00:50<00:13, 879.37 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36296/47780 [00:50<00:12, 888.58 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36386/47780 [00:50<00:13, 862.59 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36478/47780 [00:50<00:12, 870.73 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36577/47780 [00:50<00:12, 902.26 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36674/47780 [00:50<00:12, 913.59 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36787/47780 [00:50<00:11, 969.42 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36886/47780 [00:50<00:11, 937.99 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36981/47780 [00:50<00:11, 929.29 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37075/47780 [00:51<00:11, 923.46 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37168/47780 [00:51<00:11, 897.92 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37262/47780 [00:51<00:11, 907.32 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37353/47780 [00:51<00:11, 890.05 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37444/47780 [00:51<00:11, 873.45 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37541/47780 [00:51<00:11, 895.27 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37632/47780 [00:51<00:11, 887.16 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37751/47780 [00:51<00:10, 965.26 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37848/47780 [00:51<00:10, 916.40 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37942/47780 [00:51<00:10, 915.61 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38034/47780 [00:52<00:10, 904.88 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38133/47780 [00:52<00:10, 927.91 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38241/47780 [00:52<00:10, 932.90 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38342/47780 [00:52<00:09, 948.70 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38441/47780 [00:52<00:09, 938.76 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38549/47780 [00:52<00:09, 979.19 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38650/47780 [00:52<00:09, 970.80 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38762/47780 [00:52<00:08, 1007.95 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38865/47780 [00:52<00:09, 980.99 examples/s] 
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38992/47780 [00:53<00:08, 1038.72 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39106/47780 [00:53<00:08, 1064.39 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39213/47780 [00:53<00:08, 1065.10 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39320/47780 [00:53<00:08, 1055.17 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39426/47780 [00:53<00:07, 1047.09 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39535/47780 [00:53<00:07, 1058.09 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39641/47780 [00:53<00:07, 1056.53 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39749/47780 [00:53<00:07, 1034.76 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39864/47780 [00:53<00:07, 1067.49 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39971/47780 [00:53<00:07, 1052.64 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40102/47780 [00:54<00:06, 1127.32 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40217/47780 [00:54<00:06, 1086.92 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40343/47780 [00:54<00:06, 1113.07 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40456/47780 [00:54<00:06, 1103.46 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40567/47780 [00:54<00:06, 1040.76 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40693/47780 [00:54<00:06, 1096.80 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40804/47780 [00:54<00:06, 1057.21 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40912/47780 [00:54<00:06, 1057.40 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41022/47780 [00:54<00:06, 1068.17 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41135/47780 [00:55<00:06, 1035.99 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41241/47780 [00:55<00:06, 1042.54 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41347/47780 [00:55<00:06, 987.58 examples/s] 
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41448/47780 [00:55<00:06, 978.99 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41549/47780 [00:55<00:06, 955.18 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41656/47780 [00:55<00:06, 973.36 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41754/47780 [00:55<00:06, 962.43 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41851/47780 [00:55<00:06, 944.80 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41946/47780 [00:55<00:06, 884.06 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42044/47780 [00:56<00:06, 902.50 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42135/47780 [00:56<00:06, 903.39 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42226/47780 [00:56<00:06, 883.72 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42315/47780 [00:56<00:06, 846.35 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42402/47780 [00:56<00:06, 811.32 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42484/47780 [00:56<00:06, 793.29 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42575/47780 [00:56<00:06, 812.67 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42657/47780 [00:56<00:06, 773.15 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42736/47780 [00:56<00:06, 754.17 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42813/47780 [00:57<00:06, 727.22 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42886/47780 [00:57<00:06, 723.87 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42965/47780 [00:57<00:06, 736.73 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43043/47780 [00:57<00:06, 747.83 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43120/47780 [00:57<00:06, 745.13 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43202/47780 [00:57<00:06, 760.83 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43289/47780 [00:57<00:05, 782.60 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43384/47780 [00:57<00:05, 816.49 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43467/47780 [00:57<00:05, 796.13 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43547/47780 [00:57<00:05, 766.62 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43624/47780 [00:58<00:05, 743.77 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43711/47780 [00:58<00:05, 774.51 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43798/47780 [00:58<00:04, 800.89 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43888/47780 [00:58<00:04, 822.92 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43972/47780 [00:58<00:04, 772.21 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44052/47780 [00:58<00:04, 761.59 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44130/47780 [00:58<00:04, 758.66 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44229/47780 [00:58<00:04, 779.73 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44309/47780 [00:58<00:04, 770.20 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44387/47780 [00:59<00:04, 736.21 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44461/47780 [00:59<00:04, 696.48 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44547/47780 [00:59<00:04, 737.36 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44622/47780 [00:59<00:04, 697.33 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44694/47780 [00:59<00:04, 689.70 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44767/47780 [00:59<00:04, 695.10 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44838/47780 [00:59<00:04, 661.41 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44914/47780 [00:59<00:04, 688.02 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44987/47780 [00:59<00:04, 697.65 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45059/47780 [01:00<00:03, 702.28 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45130/47780 [01:00<00:03, 700.54 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45201/47780 [01:00<00:03, 687.82 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45272/47780 [01:00<00:03, 672.45 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45341/47780 [01:00<00:03, 629.75 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45407/47780 [01:00<00:03, 611.87 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45472/47780 [01:00<00:03, 605.69 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45538/47780 [01:00<00:03, 600.38 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45600/47780 [01:00<00:03, 575.66 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45662/47780 [01:01<00:03, 587.59 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45722/47780 [01:01<00:03, 584.52 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45787/47780 [01:01<00:03, 601.01 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45848/47780 [01:01<00:03, 595.46 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45908/47780 [01:01<00:03, 584.48 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45974/47780 [01:01<00:02, 605.98 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46042/47780 [01:01<00:02, 623.49 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46107/47780 [01:01<00:02, 586.18 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46167/47780 [01:01<00:02, 582.01 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46228/47780 [01:02<00:02, 549.76 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46284/47780 [01:02<00:02, 550.04 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46342/47780 [01:02<00:02, 557.02 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46400/47780 [01:02<00:02, 508.96 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46455/47780 [01:02<00:02, 498.85 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46507/47780 [01:02<00:02, 458.21 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46555/47780 [01:02<00:02, 430.91 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46600/47780 [01:02<00:02, 415.47 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46647/47780 [01:02<00:02, 415.83 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46689/47780 [01:03<00:02, 413.02 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46732/47780 [01:03<00:02, 405.48 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46781/47780 [01:03<00:02, 400.23 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46826/47780 [01:03<00:02, 411.23 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46868/47780 [01:03<00:02, 408.13 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46916/47780 [01:03<00:02, 423.12 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46960/47780 [01:03<00:02, 409.40 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47002/47780 [01:03<00:02, 374.24 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47041/47780 [01:04<00:01, 371.24 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47080/47780 [01:04<00:01, 364.97 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47120/47780 [01:04<00:01, 362.96 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47158/47780 [01:04<00:01, 363.37 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47201/47780 [01:04<00:01, 380.59 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47240/47780 [01:04<00:01, 361.41 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47279/47780 [01:04<00:01, 349.74 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47315/47780 [01:04<00:01, 349.90 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47351/47780 [01:04<00:01, 351.56 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47388/47780 [01:04<00:01, 350.05 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47427/47780 [01:05<00:01, 309.81 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47461/47780 [01:05<00:01, 280.72 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47491/47780 [01:05<00:01, 273.53 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47522/47780 [01:05<00:00, 276.53 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47552/47780 [01:05<00:00, 249.23 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47578/47780 [01:05<00:00, 214.88 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47603/47780 [01:05<00:00, 211.60 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47625/47780 [01:06<00:00, 174.68 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47645/47780 [01:06<00:00, 148.91 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47662/47780 [01:06<00:00, 120.41 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47677/47780 [01:06<00:00, 109.18 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47690/47780 [01:06<00:00, 94.15 examples/s] 
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47702/47780 [01:07<00:00, 85.06 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47712/47780 [01:07<00:00, 74.42 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47722/47780 [01:07<00:00, 59.93 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47730/47780 [01:07<00:00, 61.34 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47738/47780 [01:07<00:00, 55.77 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47745/47780 [01:08<00:00, 54.38 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47751/47780 [01:08<00:00, 45.43 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47757/47780 [01:08<00:00, 40.26 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47763/47780 [01:08<00:00, 38.87 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47769/47780 [01:08<00:00, 39.12 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47776/47780 [01:09<00:00, 38.91 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [01:10<00:00, 12.79 examples/s]Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [01:11<00:00, 667.82 examples/s]
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:11<08:51, 88.04 examples/s]
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):  20%|█▉        | 9494/47780 [00:11<00:33, 1140.24 examples/s]
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):  40%|███▉      | 18961/47780 [00:11<00:10, 2764.72 examples/s]
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):  85%|████████▍ | 40385/47780 [00:11<00:00, 7888.28 examples/s]Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:17<00:00, 2656.88 examples/s]
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:29:42,461] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3505)[0m df: /root/.triton/autotune: No such file or directory
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:29:43,103] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:29:43,118] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:29:43,119] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:29:43,120] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:29:43,121] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:29:43,146] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:29:43,157] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:29:44,724] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:29:44,724] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:29:44,724] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:29:44,724] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:29:44,724] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:29:44,724] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:29:44,724] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:29:44,724] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 5/47780 [00:02<5:48:22,  2.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:12:22,  2.55 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:25:08,  2.45 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:32:33,  2.39 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 6/47780 [00:02<5:35:29,  2.37 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 18/47780 [00:02<1:31:15,  8.72 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 5/47780 [00:02<7:03:03,  1.88 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 22/47780 [00:02<1:20:08,  9.93 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 19/47780 [00:02<1:36:43,  8.23 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 19/47780 [00:02<1:39:19,  8.01 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 44/47780 [00:02<36:26, 21.83 examples/s]  
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 26/47780 [00:02<1:11:48, 11.08 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 5/47780 [00:03<8:06:44,  1.64 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 18/47780 [00:03<1:50:24,  7.21 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 47/47780 [00:03<36:45, 21.64 examples/s]  
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 45/47780 [00:03<38:56, 20.43 examples/s]  Tokenizing train dataset (num_proc=32):   0%|          | 42/47780 [00:03<43:05, 18.47 examples/s]  Tokenizing train dataset (num_proc=32):   0%|          | 83/47780 [00:03<19:18, 41.18 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 45/47780 [00:03<42:18, 18.80 examples/s]  Tokenizing train dataset (num_proc=32):   0%|          | 48/47780 [00:03<43:17, 18.37 examples/s] Tokenizing train dataset (num_proc=32):   0%|          | 55/47780 [00:03<32:48, 24.24 examples/s]  
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 76/47780 [00:03<23:20, 34.06 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 78/47780 [00:03<22:40, 35.07 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 145/47780 [00:03<11:00, 72.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 83/47780 [00:03<21:10, 37.55 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 85/47780 [00:03<24:43, 32.15 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 87/47780 [00:03<22:07, 35.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 92/47780 [00:03<19:53, 39.96 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 133/47780 [00:03<13:05, 60.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 136/47780 [00:04<12:35, 63.06 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 216/47780 [00:04<07:46, 101.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 163/47780 [00:04<10:24, 76.28 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 173/47780 [00:04<10:53, 72.86 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 199/47780 [00:04<08:59, 88.27 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 207/47780 [00:04<08:56, 88.68 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 164/47780 [00:04<11:51, 66.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 136/47780 [00:04<16:53, 46.99 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 276/47780 [00:04<05:23, 146.90 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 227/47780 [00:04<08:16, 95.78 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 294/47780 [00:04<06:50, 115.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   1%|          | 316/47780 [00:04<04:55, 160.54 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 244/47780 [00:04<08:28, 93.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   1%|          | 263/47780 [00:04<08:03, 98.25 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 267/47780 [00:04<08:22, 94.49 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   1%|          | 250/47780 [00:05<09:01, 87.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   1%|          | 352/47780 [00:05<06:04, 130.00 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 309/47780 [00:05<07:51, 100.62 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   1%|          | 404/47780 [00:05<05:41, 138.85 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   1%|          | 349/47780 [00:05<05:55, 133.49 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 375/47780 [00:05<06:08, 128.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   1%|          | 404/47780 [00:05<05:37, 140.32 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   1%|          | 361/47780 [00:05<06:48, 116.11 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 423/47780 [00:05<05:20, 147.71 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   1%|          | 439/47780 [00:05<05:49, 135.50 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   1%|          | 569/47780 [00:05<04:17, 183.51 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 456/47780 [00:06<05:50, 134.91 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   1%|          | 489/47780 [00:06<05:01, 156.61 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 510/47780 [00:06<04:57, 158.85 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 529/47780 [00:06<04:24, 178.75 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   1%|          | 559/47780 [00:06<04:23, 179.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 747/47780 [00:06<03:15, 240.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   1%|          | 568/47780 [00:06<04:50, 162.76 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 678/47780 [00:06<03:41, 212.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 655/47780 [00:06<03:50, 204.68 examples/s]Tokenizing train dataset (num_proc=32):   1%|▏         | 606/47780 [00:06<04:45, 165.09 examples/s]Tokenizing train dataset (num_proc=32):   1%|▏         | 673/47780 [00:06<04:03, 193.26 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 732/47780 [00:06<03:43, 210.95 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 874/47780 [00:06<03:25, 228.20 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 752/47780 [00:06<03:45, 208.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 801/47780 [00:07<03:23, 230.66 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 798/47780 [00:07<03:41, 211.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 766/47780 [00:07<03:51, 202.87 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 1031/47780 [00:07<02:58, 261.65 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 864/47780 [00:07<03:24, 229.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 889/47780 [00:07<03:27, 225.60 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 910/47780 [00:07<03:27, 225.36 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 921/47780 [00:07<03:26, 226.68 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 888/47780 [00:07<03:52, 201.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 954/47780 [00:07<03:32, 220.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1024/47780 [00:08<03:18, 235.00 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 1038/47780 [00:08<03:25, 227.12 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1023/47780 [00:08<03:41, 211.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1154/47780 [00:08<03:37, 214.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1092/47780 [00:08<03:13, 241.79 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1245/47780 [00:08<02:21, 328.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1046/47780 [00:08<03:27, 225.70 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1192/47780 [00:08<03:09, 246.18 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1105/47780 [00:08<03:36, 215.35 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1244/47780 [00:08<03:01, 256.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1199/47780 [00:08<03:21, 230.98 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1390/47780 [00:08<03:00, 256.44 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1371/47780 [00:08<02:18, 334.12 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1310/47780 [00:08<03:02, 255.02 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1452/47780 [00:09<02:12, 350.77 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1186/47780 [00:09<03:33, 217.80 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1371/47780 [00:09<02:23, 322.32 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1339/47780 [00:09<03:14, 238.45 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1427/47780 [00:09<02:56, 262.53 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1545/47780 [00:09<02:11, 351.27 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1315/47780 [00:09<03:20, 232.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1665/47780 [00:09<01:56, 396.95 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1439/47780 [00:09<03:02, 253.96 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1586/47780 [00:09<02:51, 268.65 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1551/47780 [00:09<02:08, 359.25 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1589/47780 [00:09<02:11, 350.11 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1528/47780 [00:09<03:00, 256.01 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1800/47780 [00:09<01:59, 384.65 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1661/47780 [00:09<02:11, 349.84 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1437/47780 [00:09<03:13, 239.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1755/47780 [00:10<02:29, 307.70 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1662/47780 [00:10<02:58, 258.38 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1734/47780 [00:10<02:33, 299.02 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1884/47780 [00:10<02:41, 284.98 examples/s]Tokenizing train dataset (num_proc=32):   4%|▎         | 1741/47780 [00:10<03:14, 237.00 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1634/47780 [00:10<03:10, 242.74 examples/s]Tokenizing train dataset (num_proc=32):   4%|▍         | 1970/47780 [00:10<01:50, 414.26 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1591/47780 [00:10<03:15, 235.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1674/47780 [00:10<02:46, 276.12 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1816/47780 [00:10<02:03, 373.64 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1794/47780 [00:10<03:41, 207.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2072/47780 [00:11<01:43, 442.49 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1618/47780 [00:11<04:51, 158.37 examples/s]Tokenizing train dataset (num_proc=32):   4%|▍         | 1977/47780 [00:11<03:38, 209.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1822/47780 [00:11<04:16, 179.20 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2097/47780 [00:11<02:02, 373.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2104/47780 [00:11<02:20, 324.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1696/47780 [00:11<04:50, 158.89 examples/s]Tokenizing train dataset (num_proc=32):   4%|▍         | 2077/47780 [00:11<03:18, 230.81 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1951/47780 [00:11<02:41, 283.11 examples/s]Tokenizing train dataset (num_proc=32):   5%|▍         | 2340/47780 [00:11<01:54, 397.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1891/47780 [00:11<03:40, 208.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2184/47780 [00:11<01:50, 411.32 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2048/47780 [00:12<04:29, 169.66 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2140/47780 [00:12<03:34, 213.23 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2188/47780 [00:12<03:09, 240.88 examples/s]Tokenizing train dataset (num_proc=32):   5%|▌         | 2509/47780 [00:12<01:41, 444.27 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2217/47780 [00:12<03:09, 240.35 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2439/47780 [00:12<02:05, 361.50 examples/s]Tokenizing train dataset (num_proc=32):   4%|▍         | 2057/47780 [00:12<03:22, 225.45 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2636/47780 [00:12<01:31, 491.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2395/47780 [00:12<01:47, 420.79 examples/s]Tokenizing train dataset (num_proc=32):   6%|▌         | 2781/47780 [00:13<01:44, 428.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2306/47780 [00:13<03:08, 240.70 examples/s]Tokenizing train dataset (num_proc=32):   5%|▌         | 2474/47780 [00:13<03:28, 217.66 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2191/47780 [00:13<05:47, 131.38 examples/s]Tokenizing train dataset (num_proc=32):   5%|▍         | 2275/47780 [00:13<03:31, 215.32 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2330/47780 [00:13<03:43, 203.71 examples/s]Tokenizing train dataset (num_proc=32):   5%|▌         | 2571/47780 [00:13<03:02, 248.21 examples/s]Tokenizing train dataset (num_proc=32):   6%|▌         | 2650/47780 [00:13<02:45, 272.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2551/47780 [00:13<02:18, 327.36 examples/s]Tokenizing train dataset (num_proc=32):   5%|▌         | 2402/47780 [00:13<03:03, 247.21 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2832/47780 [00:13<01:30, 498.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2752/47780 [00:13<02:27, 305.84 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2511/47780 [00:13<02:47, 270.93 examples/s]Tokenizing train dataset (num_proc=32):   5%|▌         | 2507/47780 [00:14<03:21, 225.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2892/47780 [00:14<02:53, 258.85 examples/s]Tokenizing train dataset (num_proc=32):   6%|▌         | 2761/47780 [00:14<02:07, 351.84 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3161/47780 [00:14<01:47, 416.62 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2972/47780 [00:14<01:34, 475.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2655/47780 [00:14<04:04, 184.93 examples/s]Tokenizing train dataset (num_proc=32):   5%|▌         | 2624/47780 [00:14<03:10, 237.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3210/47780 [00:14<01:28, 504.07 examples/s]Tokenizing train dataset (num_proc=32):   6%|▋         | 2988/47780 [00:14<01:39, 449.75 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   6%|▋         | 2995/47780 [00:14<02:13, 336.26 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2843/47780 [00:14<03:43, 201.43 examples/s]Tokenizing train dataset (num_proc=32):   5%|▌         | 2490/47780 [00:14<04:50, 155.75 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3231/47780 [00:14<01:45, 421.12 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2790/47780 [00:14<02:28, 303.12 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3389/47780 [00:14<01:35, 466.65 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3191/47780 [00:15<02:26, 303.74 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3298/47780 [00:15<02:07, 349.92 examples/s]Tokenizing train dataset (num_proc=32):   7%|▋         | 3284/47780 [00:15<03:05, 239.84 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3519/47780 [00:15<01:29, 496.59 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3373/47780 [00:15<02:43, 272.26 examples/s]Tokenizing train dataset (num_proc=32):   7%|▋         | 3195/47780 [00:15<02:22, 313.79 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3406/47780 [00:15<02:17, 322.36 examples/s]Tokenizing train dataset (num_proc=32):   7%|▋         | 3565/47780 [00:15<01:26, 512.59 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3723/47780 [00:15<01:31, 478.88 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2916/47780 [00:15<03:16, 227.88 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3246/47780 [00:15<01:50, 403.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3540/47780 [00:16<01:14, 594.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3477/47780 [00:16<03:15, 226.27 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3840/47780 [00:16<01:36, 457.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3747/47780 [00:16<01:54, 383.90 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3116/47780 [00:16<04:07, 180.38 examples/s]Tokenizing train dataset (num_proc=32):   8%|▊         | 3648/47780 [00:16<02:38, 277.69 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3234/47780 [00:16<03:21, 220.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3464/47780 [00:16<02:12, 333.95 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3659/47780 [00:16<01:37, 451.18 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3740/47780 [00:17<01:55, 379.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   9%|▊         | 4127/47780 [00:17<01:11, 607.74 examples/s]Tokenizing train dataset (num_proc=32):   8%|▊         | 3916/47780 [00:17<02:32, 288.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3989/47780 [00:17<02:18, 316.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4243/47780 [00:17<01:40, 432.51 examples/s]Tokenizing train dataset (num_proc=32):   7%|▋         | 3522/47780 [00:17<04:37, 159.60 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3952/47780 [00:17<02:25, 300.51 examples/s]Tokenizing train dataset (num_proc=32):   8%|▊         | 3975/47780 [00:17<02:15, 322.63 examples/s]Tokenizing train dataset (num_proc=32):   9%|▊         | 4180/47780 [00:17<01:47, 406.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3741/47780 [00:17<03:54, 187.52 examples/s]Tokenizing train dataset (num_proc=32):   9%|▉         | 4347/47780 [00:17<01:28, 493.31 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   9%|▊         | 4118/47780 [00:17<01:56, 373.99 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3816/47780 [00:18<02:35, 281.95 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4281/47780 [00:18<01:18, 557.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4317/47780 [00:18<02:15, 321.41 examples/s]Tokenizing train dataset (num_proc=32):   9%|▉         | 4533/47780 [00:18<01:38, 438.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 1/47780 [00:18<247:48:11, 18.67s/ examples]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 16/47780 [00:18<11:07:57,  1.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4431/47780 [00:19<02:45, 261.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4630/47780 [00:19<02:08, 336.99 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4330/47780 [00:19<02:37, 276.45 examples/s]Tokenizing train dataset (num_proc=32):  10%|▉         | 4715/47780 [00:19<01:38, 436.23 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4491/47780 [00:19<01:56, 370.30 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4836/47780 [00:19<01:17, 553.12 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4595/47780 [00:19<02:23, 301.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4936/47780 [00:19<01:37, 438.21 examples/s]Tokenizing train dataset (num_proc=32):  10%|█         | 4805/47780 [00:19<02:24, 298.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4280/47780 [00:19<03:41, 196.51 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4680/47780 [00:20<02:04, 346.70 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   9%|▊         | 4098/47780 [00:20<05:38, 129.12 examples/s]Tokenizing train dataset (num_proc=32):   9%|▉         | 4536/47780 [00:20<02:41, 268.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4667/47780 [00:20<03:10, 226.66 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5036/47780 [00:20<01:46, 400.59 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5028/47780 [00:20<02:13, 320.73 examples/s]Tokenizing train dataset (num_proc=32):  11%|█         | 5038/47780 [00:20<02:15, 315.96 examples/s]Tokenizing train dataset (num_proc=32):  11%|█         | 5359/47780 [00:20<01:33, 452.11 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 31/47780 [00:20<5:49:39,  2.28 examples/s] 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5330/47780 [00:21<01:34, 447.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 66/47780 [00:21<2:01:30,  6.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5160/47780 [00:21<02:23, 297.61 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5214/47780 [00:21<02:24, 293.75 examples/s]Tokenizing train dataset (num_proc=32):  10%|█         | 4918/47780 [00:21<03:50, 185.64 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5505/47780 [00:21<01:37, 434.00 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5290/47780 [00:21<02:07, 332.76 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4879/47780 [00:21<03:06, 230.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5300/47780 [00:21<01:49, 386.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4822/47780 [00:22<03:21, 212.66 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5167/47780 [00:22<02:11, 323.30 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5520/47780 [00:22<02:26, 288.49 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5879/47780 [00:22<01:33, 447.57 examples/s]Tokenizing train dataset (num_proc=32):  11%|█         | 5322/47780 [00:22<03:07, 226.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5600/47780 [00:22<02:22, 296.11 examples/s]Tokenizing train dataset (num_proc=32):  12%|█▏        | 5507/47780 [00:22<02:26, 288.81 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5751/47780 [00:22<02:03, 340.94 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 82/47780 [00:22<1:50:00,  7.23 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6200/47780 [00:22<01:12, 572.67 examples/s]Tokenizing train dataset (num_proc=32):   0%|          | 169/47780 [00:22<33:39, 23.57 examples/s] 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6506/47780 [00:22<00:54, 752.90 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  11%|█▏        | 5460/47780 [00:23<02:54, 242.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5663/47780 [00:23<02:10, 322.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6013/47780 [00:23<01:22, 509.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5673/47780 [00:23<02:10, 322.37 examples/s]Tokenizing train dataset (num_proc=32):  12%|█▏        | 5680/47780 [00:23<03:06, 226.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 5977/47780 [00:23<01:36, 434.61 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5970/47780 [00:23<02:03, 337.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6175/47780 [00:23<01:22, 507.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  11%|█▏        | 5427/47780 [00:23<02:52, 245.20 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5757/47780 [00:24<01:57, 356.99 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6093/47780 [00:24<01:22, 504.18 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6079/47780 [00:24<02:34, 270.20 examples/s]Tokenizing train dataset (num_proc=32):  14%|█▎        | 6464/47780 [00:24<01:37, 425.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5753/47780 [00:24<03:12, 218.64 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6014/47780 [00:24<02:13, 311.83 examples/s]Tokenizing train dataset (num_proc=32):  13%|█▎        | 6203/47780 [00:24<02:13, 311.39 examples/s]Tokenizing train dataset (num_proc=32):  14%|█▍        | 6754/47780 [00:24<01:49, 375.88 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6404/47780 [00:24<01:23, 495.84 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 6933/47780 [00:24<01:32, 443.16 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6354/47780 [00:24<02:01, 340.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   0%|          | 203/47780 [00:25<38:56, 20.36 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   1%|          | 331/47780 [00:25<15:58, 49.52 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6341/47780 [00:25<02:38, 260.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6713/47780 [00:25<01:33, 437.90 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6919/47780 [00:25<01:14, 548.64 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6635/47780 [00:25<02:01, 337.57 examples/s]Tokenizing train dataset (num_proc=32):  13%|█▎        | 6181/47780 [00:25<03:21, 206.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6856/47780 [00:25<01:33, 436.67 examples/s]Tokenizing train dataset (num_proc=32):  13%|█▎        | 6354/47780 [00:25<02:38, 261.42 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▍        | 7112/47780 [00:25<02:12, 307.25 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6325/47780 [00:25<02:19, 298.01 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▌        | 7354/47780 [00:26<01:36, 420.21 examples/s]Tokenizing train dataset (num_proc=32):  14%|█▍        | 6743/47780 [00:25<01:33, 437.66 examples/s]Tokenizing train dataset (num_proc=32):  14%|█▍        | 6661/47780 [00:26<01:35, 429.96 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6679/47780 [00:26<02:31, 272.14 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▍        | 6993/47780 [00:26<01:31, 443.66 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7655/47780 [00:26<01:07, 591.82 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7044/47780 [00:26<01:38, 411.85 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▍        | 7107/47780 [00:26<01:26, 471.96 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6606/47780 [00:26<02:20, 292.33 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6806/47780 [00:26<01:50, 370.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7835/47780 [00:26<01:14, 538.04 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7249/47780 [00:26<01:32, 436.64 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 7974/47780 [00:26<01:19, 499.62 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7260/47780 [00:26<01:49, 371.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7359/47780 [00:26<01:40, 403.62 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8083/47780 [00:27<01:24, 468.47 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 380/47780 [00:27<19:37, 40.26 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7445/47780 [00:27<01:46, 380.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   1%|          | 420/47780 [00:27<15:51, 49.75 examples/s]Tokenizing train dataset (num_proc=32):  14%|█▍        | 6879/47780 [00:27<02:12, 307.61 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8170/47780 [00:27<01:30, 437.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7514/47780 [00:27<01:49, 366.93 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7044/47780 [00:27<01:50, 367.02 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7572/47780 [00:27<01:50, 363.30 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8241/47780 [00:27<01:33, 421.06 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7623/47780 [00:27<01:53, 354.70 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8302/47780 [00:27<01:38, 400.61 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7668/47780 [00:27<01:53, 354.10 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▍        | 7103/47780 [00:27<03:19, 203.66 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8354/47780 [00:28<01:40, 391.12 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7233/47780 [00:28<02:40, 253.06 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7710/47780 [00:28<02:02, 327.36 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8401/47780 [00:28<01:41, 388.83 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7420/47780 [00:28<02:27, 273.33 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7501/47780 [00:28<01:40, 399.11 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 6940/47780 [00:28<03:00, 225.76 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7756/47780 [00:28<01:54, 348.76 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7696/47780 [00:28<01:42, 389.17 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8448/47780 [00:28<01:46, 369.19 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▋        | 7790/47780 [00:28<01:07, 596.12 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7239/47780 [00:28<02:02, 330.02 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▋        | 7796/47780 [00:28<01:55, 346.49 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▌        | 7198/47780 [00:28<02:16, 298.10 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8490/47780 [00:28<01:46, 370.56 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7536/47780 [00:28<01:26, 464.35 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▋        | 7836/47780 [00:28<01:52, 354.49 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▍        | 6965/47780 [00:28<03:23, 200.17 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7571/47780 [00:28<01:22, 488.41 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8533/47780 [00:28<01:44, 376.68 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▌        | 7221/47780 [00:28<02:20, 289.28 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▋        | 7874/47780 [00:28<01:55, 346.26 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8573/47780 [00:28<01:44, 374.21 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7521/47780 [00:28<01:34, 427.72 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 7913/47780 [00:28<01:52, 353.94 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8612/47780 [00:28<01:47, 364.98 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 7958/47780 [00:28<01:45, 378.27 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 7973/47780 [00:28<01:17, 511.13 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8655/47780 [00:28<01:42, 381.09 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 7998/47780 [00:28<01:44, 380.29 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▋        | 7860/47780 [00:28<01:54, 348.65 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8694/47780 [00:28<01:43, 378.99 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   1%|          | 451/47780 [00:28<20:36, 38.27 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8043/47780 [00:28<01:41, 390.86 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   1%|          | 523/47780 [00:29<12:50, 61.35 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8733/47780 [00:29<01:46, 366.68 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8083/47780 [00:29<01:45, 376.05 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7756/47780 [00:29<01:35, 420.70 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8780/47780 [00:29<01:42, 382.17 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8112/47780 [00:29<01:24, 468.64 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8133/47780 [00:29<01:37, 407.69 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8820/47780 [00:29<01:41, 382.38 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 7983/47780 [00:29<01:58, 337.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8175/47780 [00:29<01:36, 409.87 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8862/47780 [00:29<01:39, 392.79 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8217/47780 [00:29<01:45, 373.90 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8902/47780 [00:29<01:48, 358.06 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 7894/47780 [00:29<01:39, 402.06 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8256/47780 [00:29<01:47, 366.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8220/47780 [00:29<01:33, 421.09 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8078/47780 [00:29<01:59, 331.84 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8939/47780 [00:29<01:59, 326.11 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8294/47780 [00:29<01:59, 330.90 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7715/47780 [00:29<02:03, 323.41 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 8978/47780 [00:29<01:55, 336.27 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8328/47780 [00:29<02:00, 328.59 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8306/47780 [00:29<01:37, 403.98 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7752/47780 [00:29<02:10, 305.59 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9018/47780 [00:29<01:50, 349.50 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8154/47780 [00:29<02:01, 325.97 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8001/47780 [00:29<01:43, 383.01 examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 561/47780 [00:29<13:58, 56.33 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▋        | 7856/47780 [00:29<01:49, 364.67 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8363/47780 [00:29<02:03, 317.90 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8058/47780 [00:29<01:30, 439.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9055/47780 [00:29<01:50, 351.31 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8377/47780 [00:29<01:38, 398.87 examples/s]Tokenizing train dataset (num_proc=32):   1%|▏         | 609/47780 [00:29<10:28, 75.05 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8396/47780 [00:30<02:02, 320.83 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9093/47780 [00:30<01:48, 355.26 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8216/47780 [00:30<02:02, 323.77 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8086/47780 [00:30<01:44, 381.26 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8429/47780 [00:30<02:02, 322.13 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8438/47780 [00:30<01:39, 395.83 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9129/47780 [00:30<01:53, 339.48 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8463/47780 [00:30<02:01, 323.75 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8269/47780 [00:30<02:06, 312.28 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9164/47780 [00:30<01:54, 336.15 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8493/47780 [00:30<01:40, 391.01 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8157/47780 [00:30<01:45, 374.13 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8499/47780 [00:30<01:59, 328.46 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7977/47780 [00:30<01:57, 339.19 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9200/47780 [00:30<01:55, 333.99 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8533/47780 [00:30<02:02, 321.05 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8542/47780 [00:30<01:45, 373.37 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8314/47780 [00:30<02:15, 291.06 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9243/47780 [00:30<01:47, 359.02 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8217/47780 [00:30<01:50, 359.05 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8259/47780 [00:30<01:36, 409.33 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8579/47780 [00:30<01:48, 360.23 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8394/47780 [00:30<01:49, 358.72 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9283/47780 [00:30<01:43, 370.36 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8586/47780 [00:30<01:49, 357.67 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8268/47780 [00:30<01:48, 363.40 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8616/47780 [00:30<01:54, 343.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8070/47780 [00:30<02:00, 330.80 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9321/47780 [00:30<01:47, 356.94 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8446/47780 [00:30<01:50, 357.15 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8627/47780 [00:30<01:55, 338.71 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8315/47780 [00:30<01:48, 362.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8651/47780 [00:30<02:00, 323.42 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9357/47780 [00:30<01:48, 353.21 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8497/47780 [00:30<01:43, 378.54 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8686/47780 [00:30<01:41, 385.06 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8687/47780 [00:30<01:57, 333.17 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9393/47780 [00:30<01:49, 351.55 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8359/47780 [00:30<01:52, 349.15 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8144/47780 [00:30<02:04, 317.16 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8544/47780 [00:30<01:46, 367.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8729/47780 [00:30<01:50, 353.80 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8729/47780 [00:31<01:49, 357.93 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9431/47780 [00:31<01:46, 359.51 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8410/47780 [00:31<01:42, 383.05 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8400/47780 [00:31<01:55, 340.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8587/47780 [00:31<01:46, 368.51 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8770/47780 [00:31<01:46, 365.65 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8785/47780 [00:31<01:37, 400.09 examples/s]Tokenizing train dataset (num_proc=32):   1%|▏         | 640/47780 [00:31<14:10, 55.45 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9468/47780 [00:31<01:46, 358.78 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8205/47780 [00:31<02:07, 310.80 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8438/47780 [00:31<01:56, 337.41 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8807/47780 [00:31<01:48, 358.67 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8628/47780 [00:31<01:51, 352.39 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9512/47780 [00:31<01:40, 382.27 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8830/47780 [00:31<01:41, 382.64 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8845/47780 [00:31<01:47, 360.64 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8474/47780 [00:31<02:02, 319.94 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8525/47780 [00:31<01:42, 383.07 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8666/47780 [00:31<01:54, 342.98 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8873/47780 [00:31<01:38, 394.02 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8255/47780 [00:31<02:09, 306.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9551/47780 [00:31<01:45, 363.47 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8884/47780 [00:31<01:47, 360.71 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8705/47780 [00:31<01:52, 347.72 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8926/47780 [00:31<01:30, 428.42 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8508/47780 [00:31<02:09, 303.24 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9588/47780 [00:31<01:49, 349.18 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8299/47780 [00:31<02:10, 302.99 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8923/47780 [00:31<01:48, 356.82 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 8976/47780 [00:31<01:27, 443.26 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8541/47780 [00:31<02:07, 306.83 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8742/47780 [00:31<01:53, 343.00 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8617/47780 [00:31<01:45, 371.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9625/47780 [00:31<02:01, 313.29 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 8959/47780 [00:31<01:50, 349.99 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8575/47780 [00:31<02:04, 314.90 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8339/47780 [00:31<02:14, 293.25 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8781/47780 [00:31<01:53, 344.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9022/47780 [00:31<01:32, 420.06 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 8996/47780 [00:31<01:50, 351.75 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8608/47780 [00:31<02:05, 312.14 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8827/47780 [00:31<01:44, 373.66 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9066/47780 [00:31<01:34, 407.58 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8375/47780 [00:31<02:18, 284.32 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9658/47780 [00:31<02:28, 256.22 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9035/47780 [00:31<01:48, 358.42 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8644/47780 [00:31<02:00, 324.86 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8866/47780 [00:31<01:49, 355.56 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8692/47780 [00:31<01:53, 344.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8409/47780 [00:31<02:15, 289.91 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9108/47780 [00:31<01:44, 371.37 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9686/47780 [00:31<02:34, 246.47 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8677/47780 [00:31<02:06, 309.60 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9071/47780 [00:31<02:01, 318.05 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8903/47780 [00:31<01:52, 344.51 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8441/47780 [00:31<02:13, 294.82 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9773/47780 [00:32<01:36, 393.12 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9147/47780 [00:32<01:47, 357.80 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8716/47780 [00:32<02:00, 324.35 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9114/47780 [00:32<01:52, 344.88 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8752/47780 [00:32<01:56, 336.42 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8938/47780 [00:32<01:54, 339.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8473/47780 [00:32<02:16, 288.35 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9184/47780 [00:32<01:47, 360.23 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8758/47780 [00:32<01:52, 346.75 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9153/47780 [00:32<01:49, 353.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 8974/47780 [00:32<01:56, 334.12 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8504/47780 [00:32<02:19, 281.00 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8803/47780 [00:32<01:54, 339.03 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9221/47780 [00:32<01:50, 348.52 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9189/47780 [00:32<01:51, 347.48 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8794/47780 [00:32<02:01, 321.30 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9817/47780 [00:32<02:20, 270.93 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9008/47780 [00:32<02:00, 321.38 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8548/47780 [00:32<02:02, 319.15 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 732/47780 [00:32<12:22, 63.37 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8849/47780 [00:32<01:53, 342.43 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9257/47780 [00:32<01:56, 330.18 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9226/47780 [00:32<01:50, 349.72 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9928/47780 [00:32<01:27, 433.82 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8827/47780 [00:32<02:07, 304.94 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 881/47780 [00:32<06:10, 126.60 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8599/47780 [00:32<01:48, 360.68 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9041/47780 [00:32<02:04, 311.42 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9302/47780 [00:32<01:46, 361.74 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8893/47780 [00:32<01:52, 346.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9263/47780 [00:32<01:50, 349.31 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8637/47780 [00:32<01:49, 357.96 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9986/47780 [00:32<01:27, 431.68 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8858/47780 [00:32<02:14, 290.41 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9073/47780 [00:32<02:06, 306.06 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9357/47780 [00:32<01:33, 409.45 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9303/47780 [00:32<01:46, 362.13 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8934/47780 [00:32<01:54, 337.85 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8674/47780 [00:32<01:50, 353.62 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9111/47780 [00:32<02:01, 319.39 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10040/47780 [00:32<01:31, 412.39 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9399/47780 [00:32<01:41, 378.57 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9340/47780 [00:32<01:49, 352.45 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8888/47780 [00:32<02:39, 243.68 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 8972/47780 [00:32<01:56, 331.83 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9149/47780 [00:32<01:56, 332.52 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8711/47780 [00:32<01:53, 342.85 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9445/47780 [00:32<01:37, 392.02 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10089/47780 [00:32<01:33, 403.88 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9376/47780 [00:32<01:49, 351.69 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8939/47780 [00:32<02:07, 304.78 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9008/47780 [00:32<01:59, 324.56 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9187/47780 [00:32<01:52, 342.06 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8746/47780 [00:32<01:58, 330.40 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9414/47780 [00:32<01:49, 350.32 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 8972/47780 [00:32<02:06, 307.97 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9486/47780 [00:32<01:43, 368.41 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10135/47780 [00:32<01:37, 384.69 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9043/47780 [00:32<01:58, 327.00 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9234/47780 [00:32<01:42, 374.37 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8780/47780 [00:33<02:03, 316.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9451/47780 [00:33<01:48, 351.89 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9005/47780 [00:33<02:13, 289.48 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10177/47780 [00:33<01:37, 386.01 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9524/47780 [00:33<01:49, 348.98 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9272/47780 [00:33<01:45, 366.18 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9077/47780 [00:33<02:03, 312.38 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8815/47780 [00:33<02:02, 318.58 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9487/47780 [00:33<01:54, 334.39 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9563/47780 [00:33<01:48, 352.85 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9041/47780 [00:33<02:08, 301.30 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9309/47780 [00:33<01:45, 363.97 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9112/47780 [00:33<02:00, 321.55 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10219/47780 [00:33<01:46, 352.48 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8849/47780 [00:33<02:08, 302.63 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9521/47780 [00:33<01:57, 325.38 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9603/47780 [00:33<01:45, 361.69 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9348/47780 [00:33<01:44, 367.61 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9087/47780 [00:33<01:56, 332.82 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9145/47780 [00:33<02:01, 317.04 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10261/47780 [00:33<01:41, 368.39 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8901/47780 [00:33<01:48, 358.97 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9559/47780 [00:33<01:56, 328.17 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9643/47780 [00:33<01:43, 368.07 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9390/47780 [00:33<01:40, 382.42 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9122/47780 [00:33<01:55, 333.72 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9178/47780 [00:33<02:04, 310.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10300/47780 [00:33<01:48, 345.68 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8938/47780 [00:33<01:53, 342.75 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9687/47780 [00:33<01:39, 383.98 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9592/47780 [00:33<01:58, 322.58 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 935/47780 [00:33<08:05, 96.56 examples/s] Tokenizing train dataset (num_proc=32):  19%|█▉        | 9158/47780 [00:33<01:54, 337.31 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9430/47780 [00:33<01:41, 378.73 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9211/47780 [00:33<02:16, 281.75 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10343/47780 [00:33<01:43, 360.02 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 8998/47780 [00:33<01:35, 404.22 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 1013/47780 [00:33<05:54, 131.86 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9727/47780 [00:33<01:39, 384.20 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9197/47780 [00:33<01:50, 348.35 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9469/47780 [00:33<01:41, 378.01 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9625/47780 [00:33<02:05, 302.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10381/47780 [00:33<01:45, 354.17 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9047/47780 [00:33<01:32, 418.42 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9240/47780 [00:33<02:29, 257.64 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9233/47780 [00:33<01:49, 350.86 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9661/47780 [00:33<01:59, 318.28 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9509/47780 [00:33<01:46, 359.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9766/47780 [00:33<01:48, 349.79 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9094/47780 [00:33<01:31, 423.51 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9310/47780 [00:33<01:46, 361.61 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10418/47780 [00:33<01:56, 320.91 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9696/47780 [00:33<01:56, 325.93 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9270/47780 [00:33<01:56, 330.52 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9803/47780 [00:33<01:47, 354.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9546/47780 [00:33<01:50, 346.27 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9137/47780 [00:33<01:34, 410.57 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9352/47780 [00:33<01:43, 372.75 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9730/47780 [00:33<01:56, 326.23 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9310/47780 [00:33<01:50, 349.56 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10452/47780 [00:33<01:59, 312.78 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9839/47780 [00:33<01:51, 341.21 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9581/47780 [00:33<01:51, 341.15 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9763/47780 [00:34<02:00, 316.34 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9179/47780 [00:34<01:41, 380.22 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10484/47780 [00:34<01:59, 311.44 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9346/47780 [00:34<01:54, 337.02 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9616/47780 [00:34<01:51, 342.87 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9391/47780 [00:34<01:54, 336.31 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9874/47780 [00:34<01:55, 329.03 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9229/47780 [00:34<01:33, 411.87 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9798/47780 [00:34<01:58, 320.49 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10517/47780 [00:34<02:02, 303.68 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9381/47780 [00:34<01:56, 329.98 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9651/47780 [00:34<01:53, 336.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9908/47780 [00:34<01:56, 325.41 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9427/47780 [00:34<02:01, 314.76 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9273/47780 [00:34<01:33, 411.22 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10550/47780 [00:34<01:59, 310.73 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9686/47780 [00:34<01:53, 337.06 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9831/47780 [00:34<02:07, 297.70 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9415/47780 [00:34<01:59, 321.94 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9944/47780 [00:34<01:54, 331.16 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9460/47780 [00:34<02:03, 309.08 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9317/47780 [00:34<01:32, 414.23 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10583/47780 [00:34<01:57, 316.05 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9725/47780 [00:34<01:48, 351.90 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9452/47780 [00:34<01:54, 335.21 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9865/47780 [00:34<02:05, 301.62 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9978/47780 [00:34<01:54, 329.46 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9499/47780 [00:34<01:58, 323.49 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10615/47780 [00:34<02:06, 293.63 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9761/47780 [00:34<01:52, 338.51 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9359/47780 [00:34<01:40, 380.41 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10014/47780 [00:34<01:54, 331.13 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9486/47780 [00:34<02:00, 318.61 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9896/47780 [00:34<02:11, 288.91 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 1065/47780 [00:34<07:38, 101.91 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9533/47780 [00:34<02:10, 292.98 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10645/47780 [00:34<02:07, 292.21 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9800/47780 [00:34<01:49, 346.87 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10048/47780 [00:34<01:54, 330.14 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9399/47780 [00:34<01:42, 374.53 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9526/47780 [00:34<01:55, 331.90 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9931/47780 [00:34<02:06, 299.14 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 1133/47780 [00:34<05:46, 134.76 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9579/47780 [00:34<01:55, 330.05 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9835/47780 [00:34<01:50, 342.78 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10680/47780 [00:34<02:02, 301.77 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10083/47780 [00:34<01:53, 331.82 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9437/47780 [00:34<01:46, 359.69 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9560/47780 [00:34<02:01, 315.37 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9617/47780 [00:34<01:51, 342.41 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9962/47780 [00:34<02:28, 254.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10718/47780 [00:34<01:55, 320.16 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9474/47780 [00:34<01:46, 359.59 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9870/47780 [00:34<01:57, 321.88 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9595/47780 [00:34<01:57, 324.32 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10117/47780 [00:34<02:03, 305.96 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9655/47780 [00:34<01:54, 333.81 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9990/47780 [00:34<02:33, 245.48 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10752/47780 [00:34<01:56, 318.49 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9919/47780 [00:34<01:43, 365.08 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9628/47780 [00:34<01:57, 325.34 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9512/47780 [00:34<01:49, 349.26 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10148/47780 [00:34<02:19, 268.82 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9693/47780 [00:34<01:52, 339.12 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10061/47780 [00:35<01:44, 359.41 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10796/47780 [00:35<01:47, 345.19 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9956/47780 [00:35<01:44, 361.97 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9549/47780 [00:35<01:47, 354.87 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9667/47780 [00:35<01:53, 336.63 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10185/47780 [00:35<02:08, 291.72 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9730/47780 [00:35<01:49, 347.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10833/47780 [00:35<01:45, 351.85 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10101/47780 [00:35<01:47, 351.13 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10008/47780 [00:35<01:33, 402.92 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9586/47780 [00:35<01:48, 351.66 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9701/47780 [00:35<02:00, 316.65 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10223/47780 [00:35<02:00, 311.77 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9767/47780 [00:35<01:53, 335.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10869/47780 [00:35<01:46, 346.99 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10144/47780 [00:35<01:42, 367.99 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10049/47780 [00:35<01:34, 399.70 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9624/47780 [00:35<01:46, 359.68 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9734/47780 [00:35<02:06, 301.81 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10256/47780 [00:35<02:02, 306.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9801/47780 [00:35<01:55, 328.82 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10187/47780 [00:35<01:38, 381.12 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10905/47780 [00:35<01:48, 338.70 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10091/47780 [00:35<01:34, 400.11 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9663/47780 [00:35<01:49, 348.95 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9765/47780 [00:35<02:09, 292.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10291/47780 [00:35<01:58, 315.10 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10947/47780 [00:35<01:43, 357.32 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10227/47780 [00:35<01:38, 380.42 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10132/47780 [00:35<01:34, 399.74 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9835/47780 [00:35<02:06, 299.48 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9700/47780 [00:35<01:48, 350.38 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9795/47780 [00:35<02:08, 294.51 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10323/47780 [00:35<02:02, 305.91 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10983/47780 [00:35<01:46, 346.59 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10173/47780 [00:35<01:36, 389.20 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9870/47780 [00:35<02:01, 312.69 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10266/47780 [00:35<01:44, 360.51 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9738/47780 [00:35<01:48, 350.77 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9826/47780 [00:35<02:07, 298.64 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10358/47780 [00:35<01:57, 318.17 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11018/47780 [00:35<01:48, 339.88 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9902/47780 [00:35<02:03, 307.90 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9774/47780 [00:35<01:49, 345.61 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10303/47780 [00:35<01:49, 343.77 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10213/47780 [00:35<01:45, 355.74 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9859/47780 [00:35<02:07, 297.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10394/47780 [00:35<01:54, 326.66 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9942/47780 [00:35<01:54, 329.78 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11053/47780 [00:35<01:50, 331.45 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9809/47780 [00:35<01:51, 342.03 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10258/47780 [00:35<01:38, 381.14 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10338/47780 [00:35<01:53, 331.30 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9896/47780 [00:35<02:01, 311.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10429/47780 [00:35<01:55, 322.20 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11090/47780 [00:35<01:47, 342.30 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9850/47780 [00:35<01:45, 358.38 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10299/47780 [00:35<01:36, 388.90 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10378/47780 [00:35<01:47, 346.37 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9976/47780 [00:35<02:10, 290.24 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9929/47780 [00:35<02:05, 302.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10465/47780 [00:35<01:53, 329.28 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11125/47780 [00:36<01:54, 318.83 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10339/47780 [00:35<01:38, 379.35 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9887/47780 [00:36<01:50, 341.98 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10010/47780 [00:36<02:07, 296.76 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9964/47780 [00:36<02:01, 312.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10414/47780 [00:36<01:58, 314.81 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10503/47780 [00:36<01:53, 328.67 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11166/47780 [00:36<01:47, 340.20 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9922/47780 [00:36<01:51, 340.44 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10378/47780 [00:36<01:43, 361.60 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10045/47780 [00:36<02:01, 309.71 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9996/47780 [00:36<02:02, 307.70 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10471/47780 [00:36<01:38, 378.42 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10537/47780 [00:36<01:53, 328.05 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11201/47780 [00:36<01:49, 335.15 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9957/47780 [00:36<01:57, 321.35 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10415/47780 [00:36<01:45, 352.56 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10077/47780 [00:36<02:01, 310.18 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10028/47780 [00:36<02:02, 307.67 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10511/47780 [00:36<01:42, 364.61 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10570/47780 [00:36<02:00, 307.59 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11241/47780 [00:36<01:44, 349.75 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10116/47780 [00:36<01:54, 329.35 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9991/47780 [00:36<01:58, 319.36 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10062/47780 [00:36<02:00, 313.42 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10451/47780 [00:36<01:51, 335.89 examples/s]Tokenizing train dataset (num_proc=32):   2%|▏         | 1177/47780 [00:36<11:08, 69.71 examples/s] Tokenizing train dataset (num_proc=32):  22%|██▏       | 10557/47780 [00:36<01:35, 388.18 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10601/47780 [00:36<02:07, 292.43 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10166/47780 [00:36<01:40, 373.55 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10024/47780 [00:36<01:59, 315.27 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10101/47780 [00:36<01:53, 331.61 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10487/47780 [00:36<01:50, 338.96 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1344/47780 [00:36<05:23, 143.67 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11277/47780 [00:36<02:03, 295.60 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10597/47780 [00:36<01:44, 357.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10634/47780 [00:36<02:04, 299.37 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10056/47780 [00:36<02:04, 303.11 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10136/47780 [00:36<01:56, 322.18 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10522/47780 [00:36<01:54, 324.16 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10204/47780 [00:36<01:50, 340.39 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11321/47780 [00:36<01:50, 328.93 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10639/47780 [00:36<01:41, 366.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10665/47780 [00:36<02:05, 295.32 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10087/47780 [00:36<02:04, 303.03 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10174/47780 [00:36<01:51, 338.35 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10555/47780 [00:36<01:55, 322.03 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10684/47780 [00:36<01:37, 380.91 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11356/47780 [00:36<01:58, 308.16 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10240/47780 [00:36<02:01, 308.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10695/47780 [00:36<02:12, 279.56 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10118/47780 [00:36<02:06, 296.68 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10588/47780 [00:36<01:58, 313.79 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10209/47780 [00:36<01:57, 319.35 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11400/47780 [00:36<01:46, 341.61 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10273/47780 [00:36<01:59, 313.75 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10723/47780 [00:36<01:41, 366.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10726/47780 [00:36<02:09, 286.62 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10150/47780 [00:36<02:04, 303.13 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10624/47780 [00:36<01:55, 322.58 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11439/47780 [00:36<01:42, 353.19 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10306/47780 [00:36<01:58, 315.29 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10766/47780 [00:36<01:57, 314.93 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10761/47780 [00:36<01:45, 351.39 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10181/47780 [00:36<02:08, 292.12 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10242/47780 [00:37<02:29, 250.40 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11481/47780 [00:37<01:38, 370.03 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10344/47780 [00:37<01:53, 329.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10657/47780 [00:37<02:07, 292.25 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10216/47780 [00:37<02:01, 308.29 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10797/47780 [00:37<01:55, 319.24 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10270/47780 [00:37<02:33, 244.87 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10731/47780 [00:37<01:30, 411.29 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11519/47780 [00:37<01:42, 352.80 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10798/47780 [00:37<02:35, 238.12 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10249/47780 [00:37<02:02, 307.49 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10378/47780 [00:37<02:15, 276.11 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10342/47780 [00:37<01:44, 358.00 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10830/47780 [00:37<02:04, 297.76 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11558/47780 [00:37<01:39, 362.92 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10781/47780 [00:37<01:25, 431.02 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10872/47780 [00:37<01:43, 355.33 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10293/47780 [00:37<01:50, 337.79 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10453/47780 [00:37<01:37, 383.57 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10861/47780 [00:37<02:05, 294.86 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11595/47780 [00:37<01:42, 351.89 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10826/47780 [00:37<01:28, 419.76 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10382/47780 [00:37<01:51, 334.42 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10914/47780 [00:37<01:53, 325.78 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10494/47780 [00:37<01:39, 374.91 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10902/47780 [00:37<01:54, 321.73 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10327/47780 [00:37<02:00, 310.19 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10871/47780 [00:37<01:26, 425.88 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11631/47780 [00:37<01:46, 339.62 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10419/47780 [00:37<01:55, 323.92 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10951/47780 [00:37<01:52, 326.90 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10935/47780 [00:37<02:01, 304.20 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10534/47780 [00:37<01:46, 348.70 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10915/47780 [00:37<01:29, 410.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11666/47780 [00:37<01:48, 332.15 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10359/47780 [00:37<02:19, 267.53 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10455/47780 [00:37<01:57, 316.92 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10987/47780 [00:37<01:50, 331.61 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10976/47780 [00:37<01:51, 328.84 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10571/47780 [00:37<01:47, 347.21 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10958/47780 [00:37<01:28, 416.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11700/47780 [00:37<01:49, 330.12 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10427/47780 [00:37<01:42, 364.93 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10488/47780 [00:37<02:01, 307.75 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11027/47780 [00:37<01:45, 349.36 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1414/47780 [00:37<07:28, 103.31 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11014/47780 [00:37<01:48, 339.15 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11740/47780 [00:37<01:43, 349.78 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10607/47780 [00:37<01:50, 335.94 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11001/47780 [00:37<01:31, 401.47 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10520/47780 [00:37<02:01, 307.79 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10466/47780 [00:37<01:44, 356.36 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1525/47780 [00:37<05:03, 152.23 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11064/47780 [00:37<01:49, 336.68 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11051/47780 [00:37<01:47, 340.14 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11781/47780 [00:37<01:39, 363.43 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10642/47780 [00:37<01:56, 319.29 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10515/47780 [00:37<01:36, 387.90 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10552/47780 [00:37<02:00, 307.85 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11042/47780 [00:37<01:41, 362.79 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11100/47780 [00:37<01:47, 339.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11830/47780 [00:38<01:30, 395.39 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11086/47780 [00:38<01:54, 321.27 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10675/47780 [00:38<02:01, 305.05 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11080/47780 [00:38<01:41, 360.06 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10584/47780 [00:38<02:07, 291.73 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11135/47780 [00:38<01:47, 342.25 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10557/47780 [00:38<01:43, 361.34 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11870/47780 [00:38<01:32, 386.85 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11119/47780 [00:38<02:03, 297.61 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10709/47780 [00:38<01:59, 310.55 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10621/47780 [00:38<01:58, 312.77 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11117/47780 [00:38<01:51, 327.98 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11170/47780 [00:38<01:54, 319.44 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10595/47780 [00:38<01:50, 337.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11915/47780 [00:38<01:29, 401.20 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11151/47780 [00:38<02:01, 300.49 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10752/47780 [00:38<01:48, 341.37 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10654/47780 [00:38<01:59, 310.92 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11153/47780 [00:38<01:50, 332.84 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11210/47780 [00:38<01:48, 335.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 11958/47780 [00:38<01:28, 404.39 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10630/47780 [00:38<01:57, 314.98 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11182/47780 [00:38<02:00, 303.01 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10686/47780 [00:38<01:58, 313.32 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10790/47780 [00:38<01:56, 316.65 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11187/47780 [00:38<01:49, 334.14 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11248/47780 [00:38<01:45, 346.28 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12001/47780 [00:38<01:29, 398.48 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11213/47780 [00:38<02:00, 304.49 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10663/47780 [00:38<01:59, 309.61 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11224/47780 [00:38<01:46, 343.97 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10829/47780 [00:38<01:51, 332.51 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11284/47780 [00:38<01:45, 346.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10720/47780 [00:38<02:06, 293.88 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12043/47780 [00:38<01:29, 399.74 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10695/47780 [00:38<01:59, 309.28 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11244/47780 [00:38<02:07, 286.87 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11259/47780 [00:38<01:46, 341.73 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10863/47780 [00:38<01:52, 327.04 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10752/47780 [00:38<02:04, 298.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11320/47780 [00:38<01:46, 341.59 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10729/47780 [00:38<01:58, 313.97 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12085/47780 [00:38<01:34, 379.23 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11277/47780 [00:38<02:02, 298.53 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11360/47780 [00:38<01:42, 355.02 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10790/47780 [00:38<01:57, 313.74 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11295/47780 [00:38<01:53, 321.94 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12125/47780 [00:38<01:33, 380.90 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10897/47780 [00:38<02:12, 279.12 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11308/47780 [00:38<02:02, 298.45 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10761/47780 [00:38<02:03, 299.24 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11396/47780 [00:38<01:43, 352.09 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10823/47780 [00:38<01:57, 314.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11328/47780 [00:38<01:56, 313.58 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10931/47780 [00:38<02:05, 294.21 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12164/47780 [00:38<01:34, 375.07 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11340/47780 [00:38<02:00, 301.44 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10803/47780 [00:38<01:51, 331.06 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11432/47780 [00:38<01:42, 354.23 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10866/47780 [00:38<01:46, 346.88 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11371/47780 [00:38<01:47, 338.39 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10962/47780 [00:38<02:03, 297.97 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12202/47780 [00:38<01:35, 372.27 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11371/47780 [00:38<02:00, 302.72 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10837/47780 [00:38<01:57, 313.21 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10912/47780 [00:39<01:38, 375.88 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11468/47780 [00:39<01:51, 326.01 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11414/47780 [00:39<01:42, 355.90 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10993/47780 [00:39<02:03, 298.02 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12240/47780 [00:39<01:34, 374.19 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11410/47780 [00:39<01:51, 325.49 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10869/47780 [00:39<02:02, 302.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10963/47780 [00:39<01:30, 405.13 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11506/47780 [00:39<01:47, 337.07 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11459/47780 [00:39<01:36, 378.14 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11024/47780 [00:39<02:04, 295.11 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12281/47780 [00:39<01:34, 376.11 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11446/47780 [00:39<01:50, 327.86 examples/s]Tokenizing train dataset (num_proc=32):   3%|▎         | 1593/47780 [00:39<07:29, 102.79 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10900/47780 [00:39<02:07, 288.61 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11005/47780 [00:39<01:32, 395.76 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11507/47780 [00:39<01:29, 406.97 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11545/47780 [00:39<01:44, 347.95 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11054/47780 [00:39<02:03, 296.22 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11491/47780 [00:39<01:41, 359.08 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12319/47780 [00:39<01:41, 349.01 examples/s]Tokenizing train dataset (num_proc=32):   4%|▎         | 1683/47780 [00:39<05:31, 139.20 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10930/47780 [00:39<02:09, 285.08 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11582/47780 [00:39<01:43, 350.36 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11045/47780 [00:39<01:37, 375.07 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11550/47780 [00:39<01:30, 399.36 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11527/47780 [00:39<01:43, 350.94 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11085/47780 [00:39<02:09, 282.55 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12366/47780 [00:39<01:33, 378.31 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10962/47780 [00:39<02:07, 288.79 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11591/47780 [00:39<01:30, 398.31 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11085/47780 [00:39<01:37, 374.46 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11618/47780 [00:39<01:48, 334.00 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11123/47780 [00:39<02:00, 304.73 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12407/47780 [00:39<01:31, 387.11 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11564/47780 [00:39<01:49, 329.88 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10993/47780 [00:39<02:04, 294.48 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11655/47780 [00:39<01:46, 340.38 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11123/47780 [00:39<01:42, 359.13 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11632/47780 [00:39<01:38, 367.86 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11169/47780 [00:39<01:46, 344.80 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12447/47780 [00:39<01:30, 390.44 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11598/47780 [00:39<01:53, 318.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11030/47780 [00:39<01:58, 308.97 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11693/47780 [00:39<01:42, 351.52 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11160/47780 [00:39<01:46, 343.22 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12488/47780 [00:39<01:30, 392.02 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11671/47780 [00:39<01:46, 340.22 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11204/47780 [00:39<01:54, 320.35 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11631/47780 [00:39<01:56, 311.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11075/47780 [00:39<01:45, 348.81 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11730/47780 [00:39<01:42, 352.66 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12532/47780 [00:39<01:26, 405.55 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11195/47780 [00:39<01:54, 319.14 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11240/47780 [00:39<01:51, 327.52 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11666/47780 [00:39<01:53, 318.53 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11706/47780 [00:39<01:52, 319.25 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11111/47780 [00:39<01:45, 347.40 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11768/47780 [00:39<01:42, 352.46 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12573/47780 [00:39<01:31, 384.68 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11278/47780 [00:39<01:49, 334.66 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11228/47780 [00:39<01:59, 304.80 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11699/47780 [00:39<01:52, 320.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11148/47780 [00:39<01:44, 350.70 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11743/47780 [00:39<01:50, 325.97 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11805/47780 [00:40<01:49, 327.20 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12612/47780 [00:40<01:35, 368.92 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11264/47780 [00:40<01:56, 312.69 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11732/47780 [00:40<01:53, 316.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11786/47780 [00:40<01:41, 353.60 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11313/47780 [00:40<01:56, 314.07 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11184/47780 [00:40<01:49, 333.55 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11840/47780 [00:40<01:50, 326.28 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11296/47780 [00:40<01:59, 304.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11823/47780 [00:40<01:41, 354.30 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12650/47780 [00:40<01:41, 347.14 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11764/47780 [00:40<01:59, 300.73 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11224/47780 [00:40<01:45, 345.00 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11345/47780 [00:40<02:01, 299.79 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11875/47780 [00:40<01:48, 331.77 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11328/47780 [00:40<02:00, 302.40 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11796/47780 [00:40<01:58, 303.01 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12686/47780 [00:40<01:42, 341.15 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11263/47780 [00:40<01:43, 353.77 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11859/47780 [00:40<01:50, 326.49 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11376/47780 [00:40<02:05, 290.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11909/47780 [00:40<01:49, 327.95 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11369/47780 [00:40<01:50, 328.40 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12721/47780 [00:40<01:42, 343.40 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11827/47780 [00:40<02:03, 291.96 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11299/47780 [00:40<01:46, 342.64 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11893/47780 [00:40<01:53, 316.67 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11406/47780 [00:40<02:12, 274.96 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11943/47780 [00:40<01:48, 331.34 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11403/47780 [00:40<01:49, 331.33 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11860/47780 [00:40<01:58, 302.32 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11926/47780 [00:40<01:52, 318.83 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12756/47780 [00:40<01:49, 318.55 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11449/47780 [00:40<01:54, 316.04 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 11986/47780 [00:40<01:39, 359.61 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11334/47780 [00:40<01:57, 310.66 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11437/47780 [00:40<01:51, 326.08 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11899/47780 [00:40<01:53, 316.72 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12789/47780 [00:40<01:52, 309.90 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11489/47780 [00:40<01:48, 335.53 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 11959/47780 [00:40<01:56, 306.38 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11366/47780 [00:40<02:02, 297.81 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12023/47780 [00:40<01:46, 335.06 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   4%|▎         | 1737/47780 [00:40<08:22, 91.54 examples/s] Tokenizing train dataset (num_proc=32):  24%|██▍       | 11474/47780 [00:40<01:50, 327.87 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11933/47780 [00:40<01:53, 316.14 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12821/47780 [00:40<01:56, 299.55 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 11990/47780 [00:40<02:01, 294.27 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11410/47780 [00:40<01:48, 335.07 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12059/47780 [00:40<01:45, 338.64 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11524/47780 [00:40<01:56, 311.07 examples/s]Tokenizing train dataset (num_proc=32):   4%|▎         | 1777/47780 [00:40<07:17, 105.25 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11509/47780 [00:40<01:53, 319.63 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 11965/47780 [00:40<01:54, 313.70 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12020/47780 [00:40<02:02, 292.85 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11446/47780 [00:40<01:46, 341.40 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12094/47780 [00:40<01:44, 341.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11557/47780 [00:40<01:55, 313.32 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12852/47780 [00:40<02:06, 275.66 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11548/47780 [00:40<01:50, 328.33 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 11998/47780 [00:40<01:53, 314.65 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12054/47780 [00:40<01:59, 299.09 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12132/47780 [00:40<01:42, 348.98 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11486/47780 [00:40<01:43, 350.56 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11589/47780 [00:40<01:54, 315.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12888/47780 [00:40<01:58, 294.94 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11581/47780 [00:41<01:51, 325.26 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12031/47780 [00:41<01:53, 315.54 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11523/47780 [00:41<01:42, 352.07 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11630/47780 [00:41<01:48, 334.32 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12085/47780 [00:41<02:03, 288.87 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12919/47780 [00:41<01:56, 298.56 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12169/47780 [00:41<01:46, 335.53 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12063/47780 [00:41<01:54, 312.70 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11614/47780 [00:41<01:58, 305.98 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12117/47780 [00:41<02:01, 294.31 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11559/47780 [00:41<01:45, 342.67 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12955/47780 [00:41<01:51, 312.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11665/47780 [00:41<01:50, 327.65 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12203/47780 [00:41<01:58, 299.73 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12107/47780 [00:41<01:43, 346.19 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11653/47780 [00:41<01:51, 324.09 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12156/47780 [00:41<01:51, 318.16 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11599/47780 [00:41<01:41, 354.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11701/47780 [00:41<01:49, 329.43 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12987/47780 [00:41<02:00, 288.55 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12251/47780 [00:41<01:42, 347.06 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12142/47780 [00:41<01:43, 342.88 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12190/47780 [00:41<01:49, 324.36 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11636/47780 [00:41<01:43, 350.65 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11735/47780 [00:41<01:58, 304.91 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12287/47780 [00:41<01:42, 346.62 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13017/47780 [00:41<02:06, 273.93 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11686/47780 [00:41<02:17, 261.97 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12181/47780 [00:41<01:42, 348.78 examples/s]Tokenizing train dataset (num_proc=32):   4%|▍         | 1830/47780 [00:41<07:57, 96.30 examples/s] 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12226/47780 [00:41<01:49, 323.57 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11673/47780 [00:41<01:44, 344.65 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11766/47780 [00:41<02:00, 299.38 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13051/47780 [00:41<01:59, 291.27 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11743/47780 [00:41<01:47, 334.07 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12222/47780 [00:41<01:37, 366.18 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12323/47780 [00:41<01:48, 325.31 examples/s]Tokenizing train dataset (num_proc=32):   4%|▍         | 2041/47780 [00:41<03:26, 220.98 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12265/47780 [00:41<01:43, 342.38 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11709/47780 [00:41<01:43, 348.82 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13082/47780 [00:41<01:58, 293.63 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11809/47780 [00:41<01:49, 328.43 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12260/47780 [00:41<01:36, 368.28 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12357/47780 [00:41<01:50, 321.02 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11780/47780 [00:41<01:54, 314.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12305/47780 [00:41<01:41, 351.07 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11744/47780 [00:41<01:46, 337.68 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12297/47780 [00:41<01:36, 367.83 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11845/47780 [00:41<01:48, 329.81 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13113/47780 [00:41<02:02, 282.16 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12390/47780 [00:41<01:51, 317.31 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11816/47780 [00:41<01:53, 316.34 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12342/47780 [00:41<01:39, 356.26 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11787/47780 [00:41<01:39, 360.01 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11886/47780 [00:41<01:44, 344.59 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12335/47780 [00:41<01:40, 351.59 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13142/47780 [00:41<02:05, 275.56 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12423/47780 [00:41<01:53, 311.56 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11851/47780 [00:41<01:50, 325.01 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12378/47780 [00:41<01:46, 333.63 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11824/47780 [00:41<01:43, 347.00 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11923/47780 [00:41<01:41, 351.67 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13173/47780 [00:41<02:02, 281.81 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12371/47780 [00:42<01:46, 331.11 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12456/47780 [00:42<01:52, 312.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11888/47780 [00:42<01:52, 319.92 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12426/47780 [00:42<01:35, 371.02 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11861/47780 [00:42<01:43, 345.64 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 11960/47780 [00:42<01:43, 345.12 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13212/47780 [00:42<01:54, 301.94 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12489/47780 [00:42<01:53, 310.61 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11921/47780 [00:42<01:51, 322.34 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12405/47780 [00:42<01:54, 309.53 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12464/47780 [00:42<01:36, 364.14 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11897/47780 [00:42<01:46, 338.03 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 11997/47780 [00:42<01:43, 344.27 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13249/47780 [00:42<01:48, 317.47 examples/s]Tokenizing train dataset (num_proc=32):   4%|▍         | 2121/47780 [00:42<04:02, 188.37 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12526/47780 [00:42<01:50, 320.01 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12437/47780 [00:42<01:57, 301.22 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12501/47780 [00:42<01:46, 332.69 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12032/47780 [00:42<01:45, 337.64 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11931/47780 [00:42<01:56, 307.70 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13281/47780 [00:42<01:48, 317.79 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12562/47780 [00:42<01:47, 327.71 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2181/47780 [00:42<03:30, 216.12 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 11954/47780 [00:42<02:25, 245.95 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12468/47780 [00:42<01:57, 300.66 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12535/47780 [00:42<01:48, 324.42 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 11970/47780 [00:42<01:48, 329.43 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13313/47780 [00:42<01:50, 311.69 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12066/47780 [00:42<01:50, 324.19 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12595/47780 [00:42<01:48, 323.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12018/47780 [00:42<01:46, 336.52 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12499/47780 [00:42<02:02, 287.34 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12008/47780 [00:42<01:44, 343.25 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12568/47780 [00:42<01:51, 315.64 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12099/47780 [00:42<01:53, 315.37 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13345/47780 [00:42<01:58, 290.69 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12628/47780 [00:42<01:51, 314.78 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12057/47780 [00:42<01:48, 329.95 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12529/47780 [00:42<02:03, 284.42 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12043/47780 [00:42<01:43, 345.15 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12604/47780 [00:42<01:48, 324.26 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12136/47780 [00:42<01:47, 330.44 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13382/47780 [00:42<01:51, 309.00 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12660/47780 [00:42<01:52, 313.14 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12566/47780 [00:42<01:55, 304.79 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12094/47780 [00:42<01:56, 306.96 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12638/47780 [00:42<01:48, 324.96 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12078/47780 [00:42<01:47, 331.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12170/47780 [00:42<01:52, 317.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13414/47780 [00:42<01:51, 307.51 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12692/47780 [00:42<01:55, 304.67 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12598/47780 [00:42<01:53, 309.05 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12136/47780 [00:42<01:46, 334.00 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12112/47780 [00:42<01:49, 326.50 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12677/47780 [00:42<01:48, 324.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12205/47780 [00:42<01:49, 324.07 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12723/47780 [00:42<01:58, 296.19 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12639/47780 [00:42<01:46, 330.43 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13446/47780 [00:42<02:05, 273.77 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12174/47780 [00:42<01:47, 332.11 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12145/47780 [00:42<01:51, 320.41 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12714/47780 [00:42<01:45, 333.69 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12239/47780 [00:42<01:49, 324.94 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12754/47780 [00:42<01:57, 296.98 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12673/47780 [00:42<01:45, 332.88 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13493/47780 [00:43<01:46, 323.20 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12209/47780 [00:43<01:50, 323.03 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12748/47780 [00:43<01:45, 331.84 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12179/47780 [00:43<01:54, 312.20 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12272/47780 [00:43<01:51, 318.74 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12784/47780 [00:43<01:59, 292.94 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12713/47780 [00:43<01:40, 348.59 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13531/47780 [00:43<01:42, 334.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12243/47780 [00:43<01:51, 317.78 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12305/47780 [00:43<01:52, 315.05 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12212/47780 [00:43<01:57, 303.51 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12782/47780 [00:43<01:57, 297.12 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12818/47780 [00:43<01:57, 297.73 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12754/47780 [00:43<01:35, 366.33 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13566/47780 [00:43<01:42, 335.34 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12277/47780 [00:43<01:50, 320.27 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12253/47780 [00:43<01:47, 329.34 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12337/47780 [00:43<01:55, 306.13 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12823/47780 [00:43<01:46, 326.99 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12856/47780 [00:43<01:49, 317.56 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12792/47780 [00:43<01:34, 370.06 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13602/47780 [00:43<01:42, 334.79 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12292/47780 [00:43<01:42, 346.23 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12368/47780 [00:43<01:55, 306.82 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12310/47780 [00:43<01:57, 303.08 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12831/47780 [00:43<01:32, 375.87 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12889/47780 [00:43<01:50, 317.09 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12857/47780 [00:43<01:55, 303.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13646/47780 [00:43<01:35, 356.38 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12327/47780 [00:43<01:43, 343.42 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12345/47780 [00:43<01:52, 315.62 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12399/47780 [00:43<01:57, 301.36 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12921/47780 [00:43<01:52, 310.83 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12869/47780 [00:43<01:40, 348.24 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13686/47780 [00:43<01:32, 368.69 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12892/47780 [00:43<01:53, 306.41 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12367/47780 [00:43<01:38, 359.62 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12378/47780 [00:43<01:58, 299.43 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12430/47780 [00:43<02:03, 286.97 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12953/47780 [00:43<01:52, 310.21 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13735/47780 [00:43<01:27, 390.16 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12925/47780 [00:43<01:53, 306.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12905/47780 [00:43<01:48, 322.66 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12404/47780 [00:43<01:41, 349.84 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12465/47780 [00:43<01:58, 298.09 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12414/47780 [00:43<01:55, 306.08 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12986/47780 [00:43<01:59, 290.89 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12963/47780 [00:43<01:47, 322.70 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12939/47780 [00:43<01:48, 320.45 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13775/47780 [00:43<01:32, 367.58 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12446/47780 [00:43<01:39, 354.30 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12455/47780 [00:43<01:46, 332.16 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12495/47780 [00:43<02:04, 282.41 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12999/47780 [00:43<01:45, 329.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13016/47780 [00:43<02:01, 285.55 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12973/47780 [00:43<01:52, 308.63 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13813/47780 [00:43<01:38, 344.73 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12482/47780 [00:43<01:42, 344.32 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12489/47780 [00:43<01:48, 325.33 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13057/47780 [00:43<01:48, 319.90 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13038/47780 [00:43<01:40, 346.60 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12533/47780 [00:43<01:58, 296.51 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13006/47780 [00:43<01:53, 307.71 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13848/47780 [00:44<01:40, 338.52 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12520/47780 [00:44<01:40, 350.41 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13074/47780 [00:44<01:39, 350.37 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12566/47780 [00:44<01:57, 299.08 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12522/47780 [00:44<02:02, 288.06 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13090/47780 [00:44<01:58, 292.14 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13038/47780 [00:44<01:54, 304.28 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13883/47780 [00:44<01:47, 314.39 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13110/47780 [00:44<01:38, 352.17 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12557/47780 [00:44<01:50, 319.62 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12604/47780 [00:44<01:50, 318.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12554/47780 [00:44<02:00, 293.51 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13071/47780 [00:44<01:51, 310.27 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13121/47780 [00:44<02:01, 285.16 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13915/47780 [00:44<01:49, 309.58 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12592/47780 [00:44<01:47, 327.42 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13146/47780 [00:44<01:42, 339.33 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12636/47780 [00:44<01:52, 311.66 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12585/47780 [00:44<02:01, 289.38 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13155/47780 [00:44<01:55, 299.84 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13103/47780 [00:44<01:54, 303.93 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13950/47780 [00:44<01:47, 313.69 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13189/47780 [00:44<01:35, 361.40 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12668/47780 [00:44<01:53, 310.37 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12626/47780 [00:44<01:54, 306.86 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12624/47780 [00:44<01:51, 315.76 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13199/47780 [00:44<01:42, 338.71 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13991/47780 [00:44<01:39, 340.03 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13134/47780 [00:44<02:01, 284.02 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13229/47780 [00:44<01:33, 367.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12700/47780 [00:44<01:54, 305.76 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12659/47780 [00:44<01:59, 294.84 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12658/47780 [00:44<01:57, 299.22 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13168/47780 [00:44<01:55, 298.92 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14026/47780 [00:44<01:38, 342.42 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13266/47780 [00:44<01:36, 356.55 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13235/47780 [00:44<02:05, 275.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12740/47780 [00:44<01:48, 323.32 examples/s]Tokenizing train dataset (num_proc=32):   5%|▍         | 2238/47780 [00:44<09:21, 81.06 examples/s] Tokenizing train dataset (num_proc=32):  27%|██▋       | 12694/47780 [00:44<01:54, 306.14 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12703/47780 [00:44<01:45, 332.83 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13201/47780 [00:44<01:52, 307.60 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14066/47780 [00:44<01:34, 355.37 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13304/47780 [00:44<01:34, 363.00 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13277/47780 [00:44<01:51, 308.62 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12773/47780 [00:44<01:52, 310.01 examples/s]Tokenizing train dataset (num_proc=32):   5%|▌         | 2604/47780 [00:44<03:13, 233.20 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12749/47780 [00:44<01:36, 363.70 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13246/47780 [00:44<01:41, 340.50 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13311/47780 [00:44<01:51, 310.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14102/47780 [00:44<01:48, 309.76 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12805/47780 [00:44<01:53, 308.95 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13343/47780 [00:44<01:39, 344.47 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12726/47780 [00:44<02:27, 237.54 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12790/47780 [00:44<01:34, 368.44 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13283/47780 [00:44<01:39, 345.01 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14171/47780 [00:44<01:22, 406.18 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13381/47780 [00:44<01:37, 352.97 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13344/47780 [00:44<01:53, 302.78 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12791/47780 [00:44<01:45, 332.08 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12828/47780 [00:44<01:41, 344.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13318/47780 [00:44<01:52, 307.29 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13418/47780 [00:45<01:36, 357.50 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12836/47780 [00:45<02:29, 233.33 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13377/47780 [00:45<01:55, 297.29 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14217/47780 [00:45<01:26, 386.87 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12831/47780 [00:45<01:44, 335.36 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12864/47780 [00:45<01:41, 345.20 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12894/47780 [00:45<01:51, 312.08 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13454/47780 [00:45<01:42, 335.33 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13412/47780 [00:45<01:52, 304.82 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12870/47780 [00:45<01:40, 345.93 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14258/47780 [00:45<01:29, 373.62 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13350/47780 [00:45<02:24, 237.49 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12899/47780 [00:45<01:55, 302.88 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12938/47780 [00:45<01:43, 336.32 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13490/47780 [00:45<01:41, 337.47 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13451/47780 [00:45<01:45, 324.62 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12908/47780 [00:45<01:41, 344.09 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14297/47780 [00:45<01:35, 352.04 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13413/47780 [00:45<01:45, 326.01 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12938/47780 [00:45<01:47, 325.10 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12975/47780 [00:45<01:41, 341.26 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13533/47780 [00:45<01:36, 356.33 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13486/47780 [00:45<01:48, 317.14 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12949/47780 [00:45<01:37, 358.02 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14334/47780 [00:45<01:40, 332.36 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12972/47780 [00:45<01:48, 322.13 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13013/47780 [00:45<01:38, 351.57 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13576/47780 [00:45<01:30, 376.98 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13451/47780 [00:45<01:51, 307.75 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12987/47780 [00:45<01:35, 364.04 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13519/47780 [00:45<01:53, 300.80 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14368/47780 [00:45<01:46, 315.05 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13050/47780 [00:45<01:40, 345.14 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13005/47780 [00:45<01:54, 304.41 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13486/47780 [00:45<01:50, 311.58 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13614/47780 [00:45<01:35, 359.03 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13025/47780 [00:45<01:40, 345.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13550/47780 [00:45<01:59, 285.92 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14401/47780 [00:45<01:45, 315.51 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13090/47780 [00:45<01:38, 352.57 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13651/47780 [00:45<01:36, 353.90 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13037/47780 [00:45<01:58, 293.06 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13522/47780 [00:45<01:53, 301.02 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13062/47780 [00:45<01:45, 330.13 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13579/47780 [00:45<02:01, 281.07 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14437/47780 [00:45<01:45, 317.33 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13130/47780 [00:45<01:34, 365.71 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13069/47780 [00:45<01:56, 297.07 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13557/47780 [00:45<01:49, 313.25 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13687/47780 [00:45<01:41, 335.62 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13098/47780 [00:45<01:43, 336.11 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14478/47780 [00:45<01:38, 338.71 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13170/47780 [00:45<01:32, 374.43 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13100/47780 [00:45<01:56, 297.37 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13722/47780 [00:45<01:40, 339.46 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13590/47780 [00:45<01:49, 310.86 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13608/47780 [00:45<02:32, 224.16 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13133/47780 [00:45<01:44, 330.07 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14513/47780 [00:45<01:42, 323.36 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13142/47780 [00:45<01:44, 331.55 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13208/47780 [00:45<01:37, 353.33 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13628/47780 [00:46<01:45, 323.09 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13757/47780 [00:46<01:42, 331.32 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13675/47780 [00:46<01:46, 320.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13167/47780 [00:46<01:44, 330.29 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13249/47780 [00:46<01:33, 368.44 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13176/47780 [00:46<01:49, 315.60 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14546/47780 [00:46<01:52, 296.16 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13663/47780 [00:46<01:46, 319.70 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13791/47780 [00:46<01:45, 322.93 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13711/47780 [00:46<01:45, 323.17 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13201/47780 [00:46<01:47, 321.58 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13289/47780 [00:46<01:32, 373.22 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13211/47780 [00:46<01:47, 322.00 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13696/47780 [00:46<01:47, 315.82 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14578/47780 [00:46<01:52, 295.85 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13831/47780 [00:46<01:41, 333.29 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13236/47780 [00:46<01:45, 326.33 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13746/47780 [00:46<01:47, 315.46 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13329/47780 [00:46<01:37, 352.56 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13728/47780 [00:46<01:48, 313.08 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14611/47780 [00:46<01:51, 296.35 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13871/47780 [00:46<01:37, 348.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13244/47780 [00:46<01:56, 297.21 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13779/47780 [00:46<01:49, 311.10 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13269/47780 [00:46<01:52, 306.56 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13365/47780 [00:46<01:38, 350.82 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14641/47780 [00:46<01:51, 296.97 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13760/47780 [00:46<01:51, 305.34 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13275/47780 [00:46<01:54, 300.64 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13907/47780 [00:46<01:44, 325.55 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13812/47780 [00:46<01:48, 312.85 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13308/47780 [00:46<01:45, 326.00 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13413/47780 [00:46<01:28, 386.93 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13795/47780 [00:46<01:48, 314.28 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13306/47780 [00:46<01:54, 300.13 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14671/47780 [00:46<01:55, 287.81 examples/s]Tokenizing train dataset (num_proc=32):   6%|▌         | 2739/47780 [00:46<05:02, 148.74 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13944/47780 [00:46<01:40, 337.16 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13848/47780 [00:46<01:45, 322.70 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13341/47780 [00:46<01:52, 306.15 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13453/47780 [00:46<01:33, 365.77 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13839/47780 [00:46<01:38, 345.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13339/47780 [00:46<01:52, 305.06 examples/s]Tokenizing train dataset (num_proc=32):   6%|▋         | 3020/47780 [00:46<02:57, 252.46 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14700/47780 [00:46<02:02, 270.64 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13882/47780 [00:46<01:44, 323.85 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13983/47780 [00:46<01:39, 340.94 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13373/47780 [00:46<01:52, 307.05 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13387/47780 [00:46<01:38, 350.89 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13874/47780 [00:46<01:42, 331.91 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14729/47780 [00:46<02:00, 273.45 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13491/47780 [00:46<01:39, 346.02 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14018/47780 [00:46<01:41, 332.27 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13915/47780 [00:46<01:51, 304.71 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13411/47780 [00:46<01:45, 327.15 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13424/47780 [00:46<01:39, 344.51 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14761/47780 [00:46<01:57, 281.93 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13908/47780 [00:46<01:46, 317.68 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13527/47780 [00:46<01:43, 332.44 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14055/47780 [00:46<01:39, 339.00 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13955/47780 [00:46<01:44, 324.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13445/47780 [00:46<01:53, 303.25 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13466/47780 [00:46<01:34, 363.55 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14798/47780 [00:46<01:48, 304.74 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13988/47780 [00:47<01:43, 325.30 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13941/47780 [00:47<01:52, 299.78 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13562/47780 [00:46<01:46, 322.60 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14091/47780 [00:47<01:48, 309.91 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13476/47780 [00:47<01:55, 295.95 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13503/47780 [00:47<01:36, 355.60 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14830/47780 [00:47<01:47, 305.59 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13980/47780 [00:47<01:45, 320.77 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14021/47780 [00:47<01:45, 319.82 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13595/47780 [00:47<01:46, 321.49 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14128/47780 [00:47<01:43, 325.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13509/47780 [00:47<01:52, 304.78 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13539/47780 [00:47<01:35, 356.86 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14873/47780 [00:47<01:36, 341.25 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14014/47780 [00:47<01:43, 326.07 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13628/47780 [00:47<01:47, 317.22 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14054/47780 [00:47<01:47, 313.35 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14162/47780 [00:47<01:44, 322.78 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13540/47780 [00:47<01:59, 287.02 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14908/47780 [00:47<01:39, 331.68 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13575/47780 [00:47<01:44, 327.43 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14047/47780 [00:47<01:46, 316.18 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14094/47780 [00:47<01:42, 328.94 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13660/47780 [00:47<01:53, 300.84 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14198/47780 [00:47<01:44, 322.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13572/47780 [00:47<01:56, 292.64 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14942/47780 [00:47<01:39, 330.86 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13612/47780 [00:47<01:41, 335.48 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14084/47780 [00:47<01:45, 320.79 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13703/47780 [00:47<01:42, 332.88 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14127/47780 [00:47<01:46, 315.08 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14237/47780 [00:47<01:41, 330.20 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13602/47780 [00:47<01:58, 288.30 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14979/47780 [00:47<01:37, 337.98 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13646/47780 [00:47<01:42, 332.54 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14117/47780 [00:47<01:45, 319.79 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13737/47780 [00:47<01:43, 328.13 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14160/47780 [00:47<01:46, 315.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14271/47780 [00:47<01:45, 318.63 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13632/47780 [00:47<02:02, 279.13 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 15020/47780 [00:47<01:31, 358.66 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13681/47780 [00:47<01:44, 326.85 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14155/47780 [00:47<01:39, 336.59 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13783/47780 [00:47<01:34, 360.45 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14192/47780 [00:47<01:47, 313.08 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14304/47780 [00:47<01:46, 314.98 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13661/47780 [00:47<02:03, 276.29 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15057/47780 [00:47<01:31, 357.99 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13714/47780 [00:47<01:44, 326.67 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14191/47780 [00:47<01:38, 340.12 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13820/47780 [00:47<01:38, 343.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14225/47780 [00:47<01:52, 297.67 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14336/47780 [00:47<01:50, 302.75 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13695/47780 [00:47<01:59, 284.26 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13753/47780 [00:47<01:39, 341.76 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15093/47780 [00:47<01:40, 323.79 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14228/47780 [00:47<01:45, 318.85 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13863/47780 [00:47<01:33, 363.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14261/47780 [00:47<01:47, 311.60 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13725/47780 [00:47<01:58, 288.58 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14367/47780 [00:47<01:55, 288.57 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13791/47780 [00:47<01:36, 352.75 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15144/47780 [00:47<01:27, 371.60 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13903/47780 [00:47<01:30, 373.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14262/47780 [00:47<01:45, 317.52 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14297/47780 [00:47<01:45, 318.04 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13756/47780 [00:48<01:56, 291.41 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14401/47780 [00:48<01:53, 293.44 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15182/47780 [00:48<01:27, 373.45 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13827/47780 [00:48<01:44, 324.80 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14299/47780 [00:48<01:40, 331.93 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13941/47780 [00:48<01:32, 367.27 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14330/47780 [00:48<01:47, 310.59 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13786/47780 [00:48<01:57, 288.36 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14432/47780 [00:48<01:54, 291.08 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15225/47780 [00:48<01:24, 385.77 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13862/47780 [00:48<01:46, 316.99 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13980/47780 [00:48<01:31, 369.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14334/47780 [00:48<01:43, 323.42 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14367/47780 [00:48<01:43, 324.01 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13830/47780 [00:48<01:45, 323.21 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15267/47780 [00:48<01:22, 395.25 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14462/47780 [00:48<01:58, 281.60 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13895/47780 [00:48<01:55, 292.19 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14018/47780 [00:48<01:38, 341.08 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14367/47780 [00:48<01:50, 303.74 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13874/47780 [00:48<01:37, 348.51 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14400/47780 [00:48<01:54, 292.47 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14491/47780 [00:48<01:59, 277.61 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15308/47780 [00:48<01:25, 377.95 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3165/47780 [00:48<04:22, 170.16 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13928/47780 [00:48<01:54, 296.17 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14055/47780 [00:48<01:37, 345.38 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14405/47780 [00:48<01:44, 317.99 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14430/47780 [00:48<01:53, 294.44 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13911/47780 [00:48<01:37, 348.46 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14520/47780 [00:48<01:59, 278.33 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15347/47780 [00:48<01:25, 380.99 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3417/47780 [00:48<02:50, 260.71 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13963/47780 [00:48<01:48, 310.43 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14090/47780 [00:48<01:37, 343.99 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14461/47780 [00:48<01:52, 295.48 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14438/47780 [00:48<01:51, 297.97 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13947/47780 [00:48<01:39, 338.46 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14553/47780 [00:48<01:53, 292.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15386/47780 [00:48<01:30, 358.43 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13995/47780 [00:48<01:55, 293.74 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14125/47780 [00:48<01:42, 329.63 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14502/47780 [00:48<01:42, 324.06 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14586/47780 [00:48<01:49, 303.42 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13981/47780 [00:48<01:43, 327.98 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14469/47780 [00:48<01:56, 286.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15425/47780 [00:48<01:28, 363.82 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14539/47780 [00:48<01:38, 337.07 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14160/47780 [00:48<01:43, 326.13 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14619/47780 [00:48<01:47, 307.59 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14014/47780 [00:48<01:44, 324.08 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14501/47780 [00:48<01:55, 289.04 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15463/47780 [00:48<01:30, 356.31 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 14025/47780 [00:48<02:15, 249.54 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14193/47780 [00:48<01:49, 308.13 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14574/47780 [00:48<01:45, 315.22 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14060/47780 [00:48<01:37, 347.54 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14650/47780 [00:48<01:54, 288.13 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14071/47780 [00:48<01:51, 301.40 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14536/47780 [00:48<01:57, 283.99 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15499/47780 [00:48<01:31, 353.40 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14614/47780 [00:48<01:38, 335.02 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14097/47780 [00:48<01:36, 350.20 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14680/47780 [00:49<01:57, 281.90 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15537/47780 [00:49<01:29, 360.61 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14573/47780 [00:49<01:49, 303.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14225/47780 [00:49<01:59, 280.90 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14104/47780 [00:49<01:55, 290.60 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14134/47780 [00:49<01:35, 351.48 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14710/47780 [00:49<01:56, 283.91 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15574/47780 [00:49<01:29, 359.53 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14650/47780 [00:49<01:45, 313.70 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14269/47780 [00:49<01:45, 319.05 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14630/47780 [00:49<01:30, 368.12 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14135/47780 [00:49<02:09, 260.57 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14175/47780 [00:49<01:33, 359.88 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14740/47780 [00:49<01:55, 287.22 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14685/47780 [00:49<01:42, 322.00 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15611/47780 [00:49<01:30, 354.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14306/47780 [00:49<01:41, 329.18 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14668/47780 [00:49<01:35, 348.05 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14221/47780 [00:49<01:28, 379.86 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14770/47780 [00:49<01:55, 285.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15647/47780 [00:49<01:31, 351.90 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14341/47780 [00:49<01:43, 324.04 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14704/47780 [00:49<01:38, 337.12 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14167/47780 [00:49<02:26, 229.53 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14718/47780 [00:49<02:08, 257.32 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14259/47780 [00:49<01:30, 371.05 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14818/47780 [00:49<01:38, 333.62 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15685/47780 [00:49<01:30, 355.98 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14379/47780 [00:49<01:40, 332.33 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14236/47780 [00:49<01:41, 331.39 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14774/47780 [00:49<01:40, 329.47 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14739/47780 [00:49<01:49, 301.15 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14298/47780 [00:49<01:29, 372.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14857/47780 [00:49<01:36, 342.00 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14420/47780 [00:49<01:34, 353.69 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15721/47780 [00:49<01:34, 340.66 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14811/47780 [00:49<01:38, 335.77 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14770/47780 [00:49<01:50, 298.02 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14274/47780 [00:49<01:49, 304.66 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14902/47780 [00:49<01:29, 368.69 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14468/47780 [00:49<01:27, 381.29 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15764/47780 [00:49<01:28, 362.50 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14336/47780 [00:49<01:49, 304.95 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14804/47780 [00:49<01:47, 305.48 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14308/47780 [00:49<01:49, 304.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 14941/47780 [00:49<01:27, 374.64 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14848/47780 [00:49<01:46, 309.34 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14507/47780 [00:49<01:32, 358.71 examples/s]Tokenizing train dataset (num_proc=32):   7%|▋         | 3556/47780 [00:49<03:45, 196.03 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15801/47780 [00:49<01:40, 316.77 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14385/47780 [00:49<01:36, 347.52 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14839/47780 [00:49<01:44, 314.14 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14355/47780 [00:49<01:36, 345.31 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14979/47780 [00:49<01:34, 348.51 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14881/47780 [00:49<01:54, 288.48 examples/s]Tokenizing train dataset (num_proc=32):   8%|▊         | 3699/47780 [00:49<02:56, 249.63 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15839/47780 [00:49<01:36, 330.62 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14544/47780 [00:49<01:42, 325.79 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14423/47780 [00:49<01:35, 348.76 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14882/47780 [00:49<01:36, 342.46 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14393/47780 [00:49<01:35, 349.59 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 15015/47780 [00:49<01:36, 338.81 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14912/47780 [00:50<01:57, 279.75 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14581/47780 [00:50<01:39, 334.42 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15873/47780 [00:50<01:41, 315.88 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14460/47780 [00:50<01:38, 339.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14917/47780 [00:50<01:38, 333.31 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14430/47780 [00:50<01:37, 341.41 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 15050/47780 [00:50<01:38, 331.45 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14617/47780 [00:50<01:38, 337.52 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14942/47780 [00:50<01:58, 276.67 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15910/47780 [00:50<01:37, 326.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14495/47780 [00:50<01:39, 335.46 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14466/47780 [00:50<01:37, 342.56 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14951/47780 [00:50<01:43, 316.78 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15084/47780 [00:50<01:45, 310.28 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14654/47780 [00:50<01:40, 328.57 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14534/47780 [00:50<01:36, 342.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15944/47780 [00:50<01:41, 313.14 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 14971/47780 [00:50<02:05, 260.83 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14986/47780 [00:50<01:42, 319.48 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14502/47780 [00:50<01:45, 316.24 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15124/47780 [00:50<01:37, 334.21 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14695/47780 [00:50<01:34, 350.62 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15980/47780 [00:50<01:38, 322.70 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14571/47780 [00:50<01:36, 343.98 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 15019/47780 [00:50<01:42, 319.67 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14539/47780 [00:50<01:42, 323.56 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14998/47780 [00:50<02:21, 232.42 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15158/47780 [00:50<01:41, 321.19 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14731/47780 [00:50<01:34, 349.05 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14607/47780 [00:50<01:35, 347.35 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16013/47780 [00:50<01:47, 295.27 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15056/47780 [00:50<01:41, 322.17 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 15025/47780 [00:50<02:15, 241.46 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15193/47780 [00:50<01:41, 322.42 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14573/47780 [00:50<01:52, 295.80 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14767/47780 [00:50<01:33, 351.62 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15092/47780 [00:50<01:38, 332.54 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14643/47780 [00:50<01:43, 321.65 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16051/47780 [00:50<01:39, 317.65 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15062/47780 [00:50<02:01, 269.23 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15235/47780 [00:50<01:34, 345.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14604/47780 [00:50<01:51, 296.67 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14803/47780 [00:50<01:43, 318.26 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15126/47780 [00:50<01:38, 330.55 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14676/47780 [00:50<01:44, 316.48 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16092/47780 [00:50<01:35, 332.07 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15090/47780 [00:50<02:01, 268.93 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14638/47780 [00:50<01:48, 306.50 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15270/47780 [00:50<01:38, 331.66 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15173/47780 [00:50<01:29, 362.91 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16126/47780 [00:50<01:37, 323.15 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15119/47780 [00:50<02:02, 266.38 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14708/47780 [00:50<01:54, 289.25 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14836/47780 [00:50<01:56, 281.91 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14685/47780 [00:50<01:34, 349.85 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15309/47780 [00:50<01:34, 344.42 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15210/47780 [00:50<01:34, 345.21 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16159/47780 [00:50<01:40, 315.18 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14743/47780 [00:50<01:48, 303.63 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14873/47780 [00:50<01:49, 301.11 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14725/47780 [00:50<01:30, 363.91 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15147/47780 [00:50<02:16, 238.37 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15344/47780 [00:50<01:39, 327.23 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15252/47780 [00:51<01:29, 362.55 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14776/47780 [00:51<01:46, 309.30 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16191/47780 [00:51<01:43, 303.88 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14762/47780 [00:51<01:33, 353.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14906/47780 [00:51<01:52, 293.01 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15197/47780 [00:51<01:47, 302.93 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15378/47780 [00:51<01:43, 313.32 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15289/47780 [00:51<01:31, 356.07 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14810/47780 [00:51<01:44, 314.39 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14937/47780 [00:51<01:50, 296.15 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16222/47780 [00:51<01:51, 282.46 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14798/47780 [00:51<01:38, 335.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3809/47780 [00:51<04:09, 176.06 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15232/47780 [00:51<01:46, 305.69 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15412/47780 [00:51<01:41, 317.94 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15325/47780 [00:51<01:34, 344.99 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14968/47780 [00:51<01:50, 298.04 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16262/47780 [00:51<01:41, 310.10 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14839/47780 [00:51<01:33, 352.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14842/47780 [00:51<01:57, 280.65 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 4042/47780 [00:51<02:37, 277.58 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15446/47780 [00:51<01:42, 316.54 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15264/47780 [00:51<01:53, 287.54 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15360/47780 [00:51<01:38, 327.98 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 15000/47780 [00:51<01:47, 304.01 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16302/47780 [00:51<01:34, 332.13 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14892/47780 [00:51<01:37, 338.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14876/47780 [00:51<01:33, 353.75 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15487/47780 [00:51<01:35, 338.81 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15294/47780 [00:51<01:57, 276.44 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15393/47780 [00:51<01:41, 318.02 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16336/47780 [00:51<01:34, 333.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 15031/47780 [00:51<01:56, 280.50 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14928/47780 [00:51<01:41, 323.58 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14912/47780 [00:51<01:37, 336.31 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15534/47780 [00:51<01:26, 371.95 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15326/47780 [00:51<01:53, 284.92 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16372/47780 [00:51<01:32, 337.86 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15425/47780 [00:51<01:44, 308.88 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14966/47780 [00:51<01:38, 331.57 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14946/47780 [00:51<01:43, 316.01 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15572/47780 [00:51<01:29, 361.74 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15355/47780 [00:51<01:56, 277.31 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15060/47780 [00:51<02:15, 241.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15460/47780 [00:51<01:40, 320.08 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16408/47780 [00:51<01:38, 318.61 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 15001/47780 [00:51<01:39, 329.29 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 14980/47780 [00:51<01:44, 312.69 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15612/47780 [00:51<01:28, 364.34 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15385/47780 [00:51<01:55, 280.42 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15102/47780 [00:51<01:55, 282.74 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15495/47780 [00:51<01:43, 311.69 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16447/47780 [00:51<01:33, 334.71 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15655/47780 [00:51<01:24, 380.24 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 15035/47780 [00:51<01:45, 311.46 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 15013/47780 [00:51<01:46, 307.38 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15417/47780 [00:51<01:51, 291.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15132/47780 [00:51<01:55, 283.67 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15527/47780 [00:51<01:46, 302.51 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16501/47780 [00:51<01:21, 383.45 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15696/47780 [00:51<01:23, 382.56 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15067/47780 [00:51<01:46, 307.41 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15452/47780 [00:51<01:46, 304.75 examples/s]Tokenizing train dataset (num_proc=32):  31%|███▏      | 15044/47780 [00:51<01:48, 301.52 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15163/47780 [00:51<02:01, 267.58 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16540/47780 [00:52<01:25, 364.84 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15735/47780 [00:52<01:23, 384.52 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15081/47780 [00:52<01:43, 316.89 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15485/47780 [00:52<01:44, 307.99 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15099/47780 [00:52<01:50, 294.82 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15558/47780 [00:52<02:07, 251.88 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15202/47780 [00:52<01:50, 294.37 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16577/47780 [00:52<01:27, 355.95 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15774/47780 [00:52<01:25, 373.29 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15516/47780 [00:52<01:45, 305.34 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15134/47780 [00:52<01:46, 306.27 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15113/47780 [00:52<01:48, 300.61 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15596/47780 [00:52<01:55, 278.34 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15234/47780 [00:52<01:55, 281.91 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16615/47780 [00:52<01:27, 357.10 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15812/47780 [00:52<01:26, 371.14 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15555/47780 [00:52<01:38, 326.11 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15176/47780 [00:52<01:38, 330.41 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15628/47780 [00:52<01:52, 285.48 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15280/47780 [00:52<01:42, 316.80 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16651/47780 [00:52<01:27, 353.93 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15588/47780 [00:52<01:42, 315.45 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15850/47780 [00:52<01:31, 349.47 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15144/47780 [00:52<02:19, 233.93 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15210/47780 [00:52<01:41, 322.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15663/47780 [00:52<01:46, 300.49 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15313/47780 [00:52<01:41, 320.20 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16693/47780 [00:52<01:23, 372.01 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15620/47780 [00:52<01:42, 313.85 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15893/47780 [00:52<01:25, 371.46 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15214/47780 [00:52<01:35, 342.26 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15249/47780 [00:52<01:35, 341.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15697/47780 [00:52<01:43, 310.83 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15346/47780 [00:52<01:49, 296.94 examples/s]Tokenizing train dataset (num_proc=32):   9%|▊         | 4167/47780 [00:52<03:45, 193.37 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16731/47780 [00:52<01:28, 350.39 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15254/47780 [00:52<01:31, 356.49 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15730/47780 [00:52<01:41, 315.38 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15284/47780 [00:52<01:38, 328.46 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15652/47780 [00:52<01:50, 291.38 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15931/47780 [00:52<01:34, 335.78 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15377/47780 [00:52<01:47, 300.20 examples/s]Tokenizing train dataset (num_proc=32):   9%|▉         | 4375/47780 [00:52<02:32, 285.30 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16767/47780 [00:52<01:29, 345.71 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15294/47780 [00:52<01:31, 356.05 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15690/47780 [00:52<01:42, 313.18 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15320/47780 [00:52<01:39, 326.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15763/47780 [00:52<01:46, 299.94 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15970/47780 [00:52<01:31, 346.82 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15408/47780 [00:52<01:48, 299.69 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16802/47780 [00:52<01:29, 344.34 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15334/47780 [00:52<01:31, 353.09 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15729/47780 [00:52<01:36, 331.12 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15801/47780 [00:52<01:39, 322.04 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 16006/47780 [00:52<01:32, 343.11 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15353/47780 [00:52<01:44, 310.22 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15439/47780 [00:52<01:47, 301.44 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16839/47780 [00:52<01:34, 327.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15766/47780 [00:52<01:35, 334.52 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15834/47780 [00:52<01:40, 317.22 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15392/47780 [00:52<01:37, 332.02 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15373/47780 [00:52<01:33, 347.92 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16042/47780 [00:52<01:34, 336.63 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15478/47780 [00:52<01:39, 324.27 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16873/47780 [00:53<01:34, 325.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15802/47780 [00:53<01:33, 341.70 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15876/47780 [00:53<01:33, 342.25 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15412/47780 [00:53<01:31, 352.38 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15426/47780 [00:53<01:39, 325.71 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16076/47780 [00:53<01:34, 334.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15511/47780 [00:53<01:41, 318.16 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15837/47780 [00:53<01:36, 332.59 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16906/47780 [00:53<01:40, 308.23 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15462/47780 [00:53<01:37, 332.95 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15449/47780 [00:53<01:35, 338.87 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16110/47780 [00:53<01:36, 327.52 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15911/47780 [00:53<01:46, 299.68 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15543/47780 [00:53<01:42, 314.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16949/47780 [00:53<01:30, 341.14 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15503/47780 [00:53<01:31, 350.97 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16147/47780 [00:53<01:34, 336.27 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15484/47780 [00:53<01:37, 330.52 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15871/47780 [00:53<01:47, 296.97 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15956/47780 [00:53<01:33, 338.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15575/47780 [00:53<01:48, 296.43 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 16984/47780 [00:53<01:35, 322.60 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15539/47780 [00:53<01:33, 345.52 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16186/47780 [00:53<01:29, 351.23 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15923/47780 [00:53<01:31, 349.32 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15518/47780 [00:53<01:43, 313.08 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15993/47780 [00:53<01:39, 320.01 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15609/47780 [00:53<01:47, 298.07 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15574/47780 [00:53<01:33, 343.34 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17019/47780 [00:53<01:34, 326.59 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16236/47780 [00:53<01:21, 385.69 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15550/47780 [00:53<01:43, 311.55 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15959/47780 [00:53<01:37, 324.95 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16027/47780 [00:53<01:39, 318.60 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15646/47780 [00:53<01:42, 313.91 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17056/47780 [00:53<01:32, 333.74 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16280/47780 [00:53<01:20, 392.21 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15610/47780 [00:53<01:39, 324.86 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15582/47780 [00:53<01:44, 309.22 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16060/47780 [00:53<01:39, 318.36 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15993/47780 [00:53<01:39, 320.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15683/47780 [00:53<01:38, 327.23 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17092/47780 [00:53<01:30, 338.51 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15645/47780 [00:53<01:37, 328.75 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15624/47780 [00:53<01:37, 329.51 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16323/47780 [00:53<01:27, 361.20 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16097/47780 [00:53<01:36, 328.83 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15716/47780 [00:53<01:38, 324.30 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16026/47780 [00:53<01:42, 309.66 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17129/47780 [00:53<01:29, 343.52 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15679/47780 [00:53<01:38, 324.53 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15660/47780 [00:53<01:35, 335.23 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16360/47780 [00:53<01:30, 348.55 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16131/47780 [00:53<01:36, 327.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15754/47780 [00:53<01:34, 339.30 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16062/47780 [00:53<01:41, 313.92 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17164/47780 [00:53<01:28, 345.06 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15713/47780 [00:53<01:37, 328.80 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15703/47780 [00:53<01:28, 361.97 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16399/47780 [00:53<01:29, 348.85 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15793/47780 [00:53<01:33, 342.94 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16094/47780 [00:53<01:43, 306.36 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16165/47780 [00:53<01:44, 303.87 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17201/47780 [00:54<01:27, 348.59 examples/s]Tokenizing train dataset (num_proc=32):   9%|▉         | 4499/47780 [00:53<03:44, 192.58 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15747/47780 [00:54<01:40, 317.29 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15740/47780 [00:54<01:28, 360.02 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16440/47780 [00:54<01:26, 361.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15831/47780 [00:54<01:30, 353.46 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16125/47780 [00:54<01:45, 299.41 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17240/47780 [00:54<01:25, 356.50 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16196/47780 [00:54<01:51, 283.93 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15784/47780 [00:54<01:37, 328.67 examples/s]Tokenizing train dataset (num_proc=32):  10%|▉         | 4702/47780 [00:54<02:33, 280.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15867/47780 [00:54<01:30, 351.54 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16478/47780 [00:54<01:30, 345.66 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15777/47780 [00:54<01:43, 309.59 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16156/47780 [00:54<01:46, 295.99 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17279/47780 [00:54<01:24, 362.13 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16230/47780 [00:54<01:46, 296.04 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15821/47780 [00:54<01:36, 332.85 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16513/47780 [00:54<01:30, 344.85 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15903/47780 [00:54<01:37, 328.19 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15810/47780 [00:54<01:43, 307.93 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16187/47780 [00:54<01:46, 296.29 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17316/47780 [00:54<01:26, 351.98 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16261/47780 [00:54<01:52, 281.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15866/47780 [00:54<01:27, 365.94 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15942/47780 [00:54<01:34, 337.00 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16222/47780 [00:54<01:44, 301.99 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16548/47780 [00:54<01:39, 314.95 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17354/47780 [00:54<01:26, 352.06 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16291/47780 [00:54<01:49, 286.35 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15842/47780 [00:54<01:56, 273.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15903/47780 [00:54<01:30, 351.21 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15977/47780 [00:54<01:34, 336.73 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16584/47780 [00:54<01:35, 326.78 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17390/47780 [00:54<01:26, 349.66 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16253/47780 [00:54<01:48, 291.23 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16320/47780 [00:54<01:53, 278.20 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15874/47780 [00:54<01:54, 279.74 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15939/47780 [00:54<01:35, 334.53 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16012/47780 [00:54<01:35, 332.75 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16637/47780 [00:54<01:21, 382.34 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17426/47780 [00:54<01:28, 341.44 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16352/47780 [00:54<01:49, 286.49 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16283/47780 [00:54<01:54, 274.64 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15903/47780 [00:54<01:53, 281.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15973/47780 [00:54<01:34, 335.79 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16684/47780 [00:54<01:17, 402.82 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16322/47780 [00:54<01:43, 303.45 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16046/47780 [00:54<01:46, 297.77 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17461/47780 [00:54<01:34, 321.94 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15944/47780 [00:54<01:41, 313.74 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16382/47780 [00:54<01:55, 272.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16007/47780 [00:54<01:37, 326.27 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16725/47780 [00:54<01:21, 382.52 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15977/47780 [00:54<01:39, 318.13 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16353/47780 [00:54<01:45, 298.11 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16077/47780 [00:54<01:48, 291.61 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16427/47780 [00:54<01:40, 313.50 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17495/47780 [00:54<01:39, 305.33 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16040/47780 [00:54<01:41, 313.27 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16393/47780 [00:54<01:36, 323.81 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16019/47780 [00:54<01:32, 343.10 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16765/47780 [00:54<01:26, 359.90 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16107/47780 [00:54<01:53, 279.25 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16459/47780 [00:55<01:42, 305.17 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17526/47780 [00:55<01:42, 293.89 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16081/47780 [00:55<01:35, 332.80 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16426/47780 [00:55<01:36, 324.72 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16054/47780 [00:55<01:32, 341.34 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16142/47780 [00:55<01:47, 295.00 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16802/47780 [00:55<01:31, 337.13 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16497/47780 [00:55<01:38, 318.84 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17570/47780 [00:55<01:33, 324.14 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16115/47780 [00:55<01:36, 327.47 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16475/47780 [00:55<01:24, 368.50 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16184/47780 [00:55<01:37, 325.65 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16841/47780 [00:55<01:28, 350.67 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16089/47780 [00:55<01:40, 313.88 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17603/47780 [00:55<01:33, 321.13 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16530/47780 [00:55<01:42, 304.52 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16148/47780 [00:55<01:42, 307.33 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16515/47780 [00:55<01:23, 373.32 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16218/47780 [00:55<01:35, 328.98 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16879/47780 [00:55<01:27, 351.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17637/47780 [00:55<01:33, 324.04 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16568/47780 [00:55<01:37, 318.69 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16126/47780 [00:55<01:43, 306.21 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16188/47780 [00:55<01:35, 329.28 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16562/47780 [00:55<01:18, 396.74 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16915/47780 [00:55<01:27, 350.77 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16261/47780 [00:55<01:31, 342.70 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17677/47780 [00:55<01:28, 341.58 examples/s]Tokenizing train dataset (num_proc=32):  10%|█         | 4818/47780 [00:55<03:46, 189.96 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16606/47780 [00:55<01:33, 331.97 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16158/47780 [00:55<01:50, 285.56 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16616/47780 [00:55<01:11, 433.05 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16222/47780 [00:55<01:45, 298.20 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17713/47780 [00:55<01:26, 346.14 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16296/47780 [00:55<01:36, 326.50 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16951/47780 [00:55<01:32, 333.80 examples/s]Tokenizing train dataset (num_proc=32):  11%|█         | 5037/47780 [00:55<02:28, 288.28 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16193/47780 [00:55<01:46, 295.73 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16640/47780 [00:55<01:45, 296.54 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16262/47780 [00:55<01:37, 324.91 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16661/47780 [00:55<01:15, 414.16 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17751/47780 [00:55<01:25, 352.50 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 16987/47780 [00:55<01:31, 337.29 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16330/47780 [00:55<01:36, 326.61 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16226/47780 [00:55<01:43, 304.03 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16672/47780 [00:55<01:43, 300.38 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16703/47780 [00:55<01:15, 411.00 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16297/47780 [00:55<01:43, 302.88 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17792/47780 [00:55<01:24, 354.10 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17021/47780 [00:55<01:31, 336.65 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16363/47780 [00:55<01:47, 291.72 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16258/47780 [00:55<01:43, 303.38 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16704/47780 [00:55<01:46, 293.08 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16329/47780 [00:55<01:43, 304.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16745/47780 [00:55<01:19, 391.03 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17057/47780 [00:55<01:30, 340.95 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17836/47780 [00:55<01:20, 372.90 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16292/47780 [00:55<01:42, 308.46 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16394/47780 [00:55<01:48, 290.34 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16734/47780 [00:55<01:48, 286.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16361/47780 [00:55<01:42, 306.81 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16785/47780 [00:55<01:23, 373.16 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17092/47780 [00:55<01:34, 324.52 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16324/47780 [00:55<01:41, 310.08 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17874/47780 [00:56<01:28, 336.27 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16424/47780 [00:56<01:55, 272.51 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16763/47780 [00:56<01:54, 271.75 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16823/47780 [00:56<01:24, 366.71 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16393/47780 [00:56<01:50, 283.65 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17125/47780 [00:56<01:36, 319.28 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16357/47780 [00:56<01:40, 312.16 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17909/47780 [00:56<01:30, 331.52 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16460/47780 [00:56<01:46, 295.38 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16791/47780 [00:56<01:53, 273.95 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16865/47780 [00:56<01:21, 377.61 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16430/47780 [00:56<01:43, 303.36 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17158/47780 [00:56<01:41, 301.52 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16392/47780 [00:56<01:38, 319.35 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17943/47780 [00:56<01:36, 310.10 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16827/47780 [00:56<01:45, 294.64 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16491/47780 [00:56<01:51, 280.87 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16461/47780 [00:56<01:50, 283.57 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16428/47780 [00:56<01:36, 323.64 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17189/47780 [00:56<01:44, 291.55 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17980/47780 [00:56<01:33, 319.77 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16903/47780 [00:56<01:39, 311.61 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16857/47780 [00:56<01:45, 292.92 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16520/47780 [00:56<01:53, 274.67 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16469/47780 [00:56<01:29, 348.22 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17228/47780 [00:56<01:35, 318.27 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16490/47780 [00:56<01:56, 268.13 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16960/47780 [00:56<01:22, 375.77 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18017/47780 [00:56<01:30, 327.39 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16895/47780 [00:56<01:37, 317.61 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16549/47780 [00:56<01:55, 270.10 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16527/47780 [00:56<01:47, 291.89 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17261/47780 [00:56<01:39, 307.43 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16504/47780 [00:56<01:36, 322.71 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18055/47780 [00:56<01:27, 341.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16928/47780 [00:56<01:39, 310.52 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17002/47780 [00:56<01:26, 357.53 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16577/47780 [00:56<01:55, 269.65 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16561/47780 [00:56<01:43, 301.71 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17296/47780 [00:56<01:36, 316.00 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16543/47780 [00:56<01:32, 337.62 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18090/47780 [00:56<01:27, 340.40 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16961/47780 [00:56<01:41, 302.20 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16610/47780 [00:56<01:48, 286.32 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17042/47780 [00:56<01:24, 364.90 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17329/47780 [00:56<01:36, 315.81 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16578/47780 [00:56<01:32, 337.64 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16592/47780 [00:56<01:48, 286.45 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18130/47780 [00:56<01:24, 349.36 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17081/47780 [00:56<01:22, 369.89 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16639/47780 [00:56<01:51, 279.40 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 16992/47780 [00:56<01:49, 282.40 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17361/47780 [00:56<01:36, 314.10 examples/s]Tokenizing train dataset (num_proc=32):  11%|█         | 5157/47780 [00:56<03:39, 194.02 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16631/47780 [00:56<01:39, 312.88 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16614/47780 [00:56<01:38, 314.99 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16668/47780 [00:56<01:51, 278.01 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18166/47780 [00:56<01:34, 313.26 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17022/47780 [00:56<01:48, 283.92 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17120/47780 [00:56<01:29, 342.74 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17396/47780 [00:56<01:33, 324.32 examples/s]Tokenizing train dataset (num_proc=32):  11%|█▏        | 5392/47780 [00:56<02:20, 301.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16663/47780 [00:56<01:38, 314.63 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16651/47780 [00:56<01:35, 327.55 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16703/47780 [00:56<01:46, 291.73 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17055/47780 [00:57<01:44, 293.45 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18200/47780 [00:57<01:35, 310.33 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17157/47780 [00:57<01:32, 332.61 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17431/47780 [00:57<01:35, 316.72 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16696/47780 [00:57<01:38, 315.58 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16685/47780 [00:57<01:37, 319.14 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16737/47780 [00:57<01:41, 305.12 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17087/47780 [00:57<01:42, 300.55 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18232/47780 [00:57<01:35, 309.67 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17193/47780 [00:57<01:33, 325.63 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17469/47780 [00:57<01:31, 331.18 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16728/47780 [00:57<01:38, 315.20 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16720/47780 [00:57<01:36, 320.54 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17120/47780 [00:57<01:40, 305.89 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16768/47780 [00:57<01:45, 293.13 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18264/47780 [00:57<01:34, 312.47 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17503/47780 [00:57<01:31, 329.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17228/47780 [00:57<01:36, 315.75 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16764/47780 [00:57<01:40, 308.37 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17152/47780 [00:57<01:38, 309.92 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16807/47780 [00:57<01:37, 317.35 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16753/47780 [00:57<01:42, 303.06 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18296/47780 [00:57<01:36, 304.13 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17263/47780 [00:57<01:34, 321.37 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17537/47780 [00:57<01:35, 315.89 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16798/47780 [00:57<01:40, 306.87 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17188/47780 [00:57<01:34, 324.14 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16787/47780 [00:57<01:39, 313.03 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18329/47780 [00:57<01:34, 311.29 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16839/47780 [00:57<01:42, 300.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17303/47780 [00:57<01:29, 339.19 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17570/47780 [00:57<01:35, 315.36 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16829/47780 [00:57<01:42, 301.87 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17227/47780 [00:57<01:28, 343.41 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18363/47780 [00:57<01:33, 316.21 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16875/47780 [00:57<01:38, 313.97 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16819/47780 [00:57<01:47, 289.11 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17338/47780 [00:57<01:30, 338.16 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16862/47780 [00:57<01:41, 305.56 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17602/47780 [00:57<01:40, 299.66 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17268/47780 [00:57<01:25, 355.05 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18402/47780 [00:57<01:28, 333.57 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16907/47780 [00:57<01:42, 301.75 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16849/47780 [00:57<01:49, 282.57 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17374/47780 [00:57<01:32, 329.68 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17637/47780 [00:57<01:37, 309.87 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16899/47780 [00:57<01:37, 316.74 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17304/47780 [00:57<01:28, 344.55 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16940/47780 [00:57<01:41, 303.15 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18436/47780 [00:57<01:34, 309.94 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16878/47780 [00:57<01:50, 278.71 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17408/47780 [00:57<01:32, 329.08 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17671/47780 [00:57<01:35, 315.14 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17342/47780 [00:57<01:25, 354.48 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16931/47780 [00:57<01:42, 300.57 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18478/47780 [00:57<01:27, 333.49 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16911/47780 [00:57<01:48, 283.61 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 16971/47780 [00:57<01:47, 285.76 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17442/47780 [00:57<01:36, 314.14 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17703/47780 [00:57<01:38, 305.65 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 16963/47780 [00:57<01:40, 305.75 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17378/47780 [00:57<01:31, 333.12 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18515/47780 [00:57<01:26, 339.88 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16943/47780 [00:57<01:45, 293.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17000/47780 [00:57<01:47, 286.17 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17478/47780 [00:58<01:35, 317.21 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17744/47780 [00:58<01:30, 331.85 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 16994/47780 [00:58<01:43, 296.74 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17412/47780 [00:58<01:31, 331.37 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 16975/47780 [00:58<01:43, 297.75 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17034/47780 [00:58<01:42, 298.69 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18550/47780 [00:58<01:29, 327.39 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17785/47780 [00:58<01:24, 354.00 examples/s]Tokenizing train dataset (num_proc=32):  12%|█▏        | 5522/47780 [00:58<03:18, 212.42 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17455/47780 [00:58<01:26, 351.48 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17024/47780 [00:58<01:49, 281.70 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17069/47780 [00:58<01:39, 309.92 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17510/47780 [00:58<01:53, 267.13 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18584/47780 [00:58<01:30, 324.18 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17006/47780 [00:58<01:49, 281.80 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17822/47780 [00:58<01:23, 358.04 examples/s]Tokenizing train dataset (num_proc=32):  12%|█▏        | 5712/47780 [00:58<02:20, 299.73 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17053/47780 [00:58<01:52, 272.04 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17491/47780 [00:58<01:31, 330.70 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17101/47780 [00:58<01:38, 312.78 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18618/47780 [00:58<01:28, 328.59 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17573/47780 [00:58<01:25, 353.92 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17041/47780 [00:58<01:43, 297.68 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17858/47780 [00:58<01:30, 331.53 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17082/47780 [00:58<01:54, 268.38 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18653/47780 [00:58<01:27, 334.41 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17525/47780 [00:58<01:34, 320.77 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17614/47780 [00:58<01:23, 361.01 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17133/47780 [00:58<01:44, 294.05 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17072/47780 [00:58<01:47, 286.34 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17892/47780 [00:58<01:34, 316.93 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17116/47780 [00:58<01:47, 285.06 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17560/47780 [00:58<01:32, 327.27 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17655/47780 [00:58<01:20, 374.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18688/47780 [00:58<01:29, 324.26 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17163/47780 [00:58<01:45, 289.22 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17107/47780 [00:58<01:41, 302.46 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17926/47780 [00:58<01:32, 323.14 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17146/47780 [00:58<01:45, 289.21 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17703/47780 [00:58<01:15, 398.32 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17593/47780 [00:58<01:37, 311.14 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17199/47780 [00:58<01:38, 309.01 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18721/47780 [00:58<01:34, 308.27 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17138/47780 [00:58<01:41, 301.19 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17959/47780 [00:58<01:33, 317.95 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17179/47780 [00:58<01:41, 300.70 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17625/47780 [00:58<01:36, 312.73 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18753/47780 [00:58<01:34, 307.94 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17744/47780 [00:58<01:21, 369.14 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17231/47780 [00:58<01:44, 292.26 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17169/47780 [00:58<01:48, 281.27 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17994/47780 [00:58<01:33, 319.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17210/47780 [00:58<01:40, 303.29 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17657/47780 [00:58<01:37, 308.16 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18784/47780 [00:58<01:37, 298.30 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17265/47780 [00:58<01:42, 299.00 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17782/47780 [00:58<01:25, 352.77 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17206/47780 [00:58<01:40, 305.34 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17244/47780 [00:58<01:37, 314.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18032/47780 [00:58<01:29, 332.94 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18815/47780 [00:58<01:36, 298.79 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17688/47780 [00:58<01:44, 289.31 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17300/47780 [00:58<01:37, 312.41 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17821/47780 [00:58<01:22, 362.70 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17238/47780 [00:58<01:39, 306.08 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18067/47780 [00:59<01:29, 330.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17276/47780 [00:59<01:44, 291.47 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18849/47780 [00:59<01:34, 306.80 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17332/47780 [00:59<01:37, 311.60 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17721/47780 [00:59<01:43, 290.93 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17275/47780 [00:59<01:35, 320.69 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17858/47780 [00:59<01:25, 349.32 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18101/47780 [00:59<01:35, 311.55 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17306/47780 [00:59<01:47, 284.65 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17368/47780 [00:59<01:34, 322.16 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18881/47780 [00:59<01:35, 303.69 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17320/47780 [00:59<01:26, 353.78 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17896/47780 [00:59<01:24, 354.00 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17751/47780 [00:59<01:47, 278.20 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17342/47780 [00:59<01:40, 302.46 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18133/47780 [00:59<01:37, 303.73 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18917/47780 [00:59<01:30, 319.54 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17401/47780 [00:59<01:33, 323.94 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17932/47780 [00:59<01:25, 350.31 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17356/47780 [00:59<01:29, 339.91 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17783/47780 [00:59<01:45, 283.36 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17374/47780 [00:59<01:38, 307.37 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18165/47780 [00:59<01:36, 308.14 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17435/47780 [00:59<01:32, 328.51 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18950/47780 [00:59<01:35, 301.79 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17815/47780 [00:59<01:42, 293.41 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17391/47780 [00:59<01:31, 331.26 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17968/47780 [00:59<01:31, 325.26 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18196/47780 [00:59<01:36, 305.39 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17405/47780 [00:59<01:43, 294.64 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17474/47780 [00:59<01:29, 339.24 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18982/47780 [00:59<01:34, 303.51 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17855/47780 [00:59<01:33, 319.93 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17432/47780 [00:59<01:26, 349.70 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18228/47780 [00:59<01:39, 296.40 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18001/47780 [00:59<01:44, 286.26 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17435/47780 [00:59<01:50, 274.43 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17508/47780 [00:59<01:32, 327.53 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19020/47780 [00:59<01:29, 321.48 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17889/47780 [00:59<01:33, 318.41 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17468/47780 [00:59<01:30, 333.65 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18258/47780 [00:59<01:40, 294.01 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18045/47780 [00:59<01:33, 318.74 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17466/47780 [00:59<01:46, 283.90 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17546/47780 [00:59<01:28, 340.51 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19053/47780 [00:59<01:32, 309.83 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17921/47780 [00:59<01:40, 298.39 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17502/47780 [00:59<01:31, 331.75 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17496/47780 [00:59<01:45, 286.76 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18290/47780 [00:59<01:44, 282.13 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17584/47780 [00:59<01:26, 350.44 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18078/47780 [00:59<01:34, 314.64 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19095/47780 [00:59<01:26, 333.15 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17952/47780 [00:59<01:39, 298.34 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17538/47780 [00:59<01:30, 335.06 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18322/47780 [00:59<01:41, 289.31 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17538/47780 [00:59<01:35, 315.91 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18111/47780 [00:59<01:35, 311.97 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17620/47780 [00:59<01:27, 343.73 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19129/47780 [00:59<01:26, 331.00 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17572/47780 [00:59<01:31, 331.84 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17983/47780 [00:59<01:47, 276.79 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18148/47780 [01:00<01:31, 324.79 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17573/47780 [01:00<01:34, 318.41 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18365/47780 [01:00<01:32, 318.05 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19165/47780 [01:00<01:25, 335.89 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17656/47780 [01:00<01:38, 306.96 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17616/47780 [01:00<01:24, 356.50 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18012/47780 [01:00<01:51, 266.09 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18181/47780 [01:00<01:32, 318.73 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18397/47780 [01:00<01:34, 311.22 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17605/47780 [01:00<01:37, 310.84 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19200/47780 [01:00<01:25, 336.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17705/47780 [01:00<01:24, 355.69 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17652/47780 [01:00<01:30, 334.48 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18039/47780 [01:00<01:52, 263.94 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18216/47780 [01:00<01:31, 324.23 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17641/47780 [01:00<01:34, 318.54 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18429/47780 [01:00<01:38, 297.50 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17742/47780 [01:00<01:28, 340.72 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19234/47780 [01:00<01:34, 302.09 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17689/47780 [01:00<01:27, 344.05 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18072/47780 [01:00<01:46, 279.33 examples/s]Tokenizing train dataset (num_proc=32):  12%|█▏        | 5834/47780 [01:00<04:31, 154.53 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18249/47780 [01:00<01:34, 311.71 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18471/47780 [01:00<01:30, 323.96 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17673/47780 [01:00<01:40, 298.36 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19265/47780 [01:00<01:34, 301.21 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17727/47780 [01:00<01:26, 346.71 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17777/47780 [01:00<01:33, 322.13 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18111/47780 [01:00<01:36, 307.38 examples/s]Tokenizing train dataset (num_proc=32):  13%|█▎        | 6061/47780 [01:00<02:54, 239.20 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18282/47780 [01:00<01:33, 316.68 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17704/47780 [01:00<01:41, 294.88 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18505/47780 [01:00<01:34, 310.75 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19296/47780 [01:00<01:36, 293.69 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17762/47780 [01:00<01:30, 331.91 examples/s]Tokenizing train dataset (num_proc=32):  13%|█▎        | 6276/47780 [01:00<02:01, 342.87 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17811/47780 [01:00<01:36, 310.55 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18143/47780 [01:00<01:44, 284.26 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18315/47780 [01:00<01:34, 313.40 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17734/47780 [01:00<01:43, 290.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18537/47780 [01:00<01:34, 310.58 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19328/47780 [01:00<01:36, 294.47 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17801/47780 [01:00<01:26, 345.05 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17843/47780 [01:00<01:40, 297.37 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18176/47780 [01:00<01:40, 293.90 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18355/47780 [01:00<01:28, 334.27 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17768/47780 [01:00<01:40, 297.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18569/47780 [01:00<01:34, 309.30 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17845/47780 [01:00<01:20, 371.76 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19360/47780 [01:00<01:36, 295.18 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17877/47780 [01:00<01:36, 308.42 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18209/47780 [01:00<01:37, 303.82 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18394/47780 [01:00<01:25, 342.48 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18601/47780 [01:00<01:35, 305.17 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17808/47780 [01:00<01:34, 315.71 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19393/47780 [01:00<01:34, 301.51 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17915/47780 [01:00<01:31, 324.97 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17883/47780 [01:00<01:30, 331.37 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18240/47780 [01:00<01:39, 298.36 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18429/47780 [01:00<01:26, 340.66 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18632/47780 [01:00<01:36, 303.62 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17851/47780 [01:00<01:27, 343.80 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19428/47780 [01:00<01:30, 311.87 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18272/47780 [01:00<01:36, 304.47 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17918/47780 [01:00<01:29, 333.63 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17950/47780 [01:00<01:36, 307.93 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18464/47780 [01:00<01:34, 311.23 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18663/47780 [01:00<01:38, 294.95 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17886/47780 [01:00<01:29, 334.27 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19471/47780 [01:01<01:22, 341.77 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18312/47780 [01:01<01:29, 328.77 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17984/47780 [01:01<01:35, 313.30 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17953/47780 [01:01<01:36, 307.66 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18496/47780 [01:01<01:34, 309.75 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18695/47780 [01:01<01:36, 301.85 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17935/47780 [01:01<01:18, 378.07 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19509/47780 [01:01<01:21, 348.66 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18346/47780 [01:01<01:32, 318.10 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18016/47780 [01:01<01:34, 314.35 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17985/47780 [01:01<01:35, 310.70 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18729/47780 [01:01<01:33, 309.78 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18528/47780 [01:01<01:36, 303.04 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19546/47780 [01:01<01:19, 354.69 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17974/47780 [01:01<01:30, 328.77 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18049/47780 [01:01<01:34, 315.82 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18379/47780 [01:01<01:34, 311.37 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18018/47780 [01:01<01:36, 309.38 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18763/47780 [01:01<01:33, 311.52 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18570/47780 [01:01<01:28, 331.70 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19582/47780 [01:01<01:26, 325.95 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18009/47780 [01:01<01:31, 324.11 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18411/47780 [01:01<01:37, 302.31 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18081/47780 [01:01<01:41, 293.51 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18051/47780 [01:01<01:34, 314.85 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18797/47780 [01:01<01:31, 315.79 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18604/47780 [01:01<01:29, 326.60 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19618/47780 [01:01<01:27, 321.67 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18043/47780 [01:01<01:35, 311.48 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18087/47780 [01:01<01:30, 327.57 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18442/47780 [01:01<01:40, 291.33 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18126/47780 [01:01<01:30, 329.22 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18831/47780 [01:01<01:29, 322.59 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18637/47780 [01:01<01:32, 313.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19656/47780 [01:01<01:23, 337.18 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18478/47780 [01:01<01:35, 306.93 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18125/47780 [01:01<01:30, 327.85 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18075/47780 [01:01<01:41, 292.06 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18870/47780 [01:01<01:26, 334.71 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18160/47780 [01:01<01:32, 320.98 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18675/47780 [01:01<01:27, 331.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19691/47780 [01:01<01:29, 315.42 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18107/47780 [01:01<01:40, 296.59 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18159/47780 [01:01<01:30, 327.41 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18906/47780 [01:01<01:25, 338.19 examples/s]Tokenizing train dataset (num_proc=32):  13%|█▎        | 6428/47780 [01:01<02:54, 237.37 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18509/47780 [01:01<01:40, 291.63 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18193/47780 [01:01<01:36, 306.62 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18709/47780 [01:01<01:30, 319.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19724/47780 [01:01<01:28, 316.46 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18139/47780 [01:01<01:38, 299.58 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18947/47780 [01:01<01:21, 355.04 examples/s]Tokenizing train dataset (num_proc=32):  14%|█▍        | 6609/47780 [01:01<02:08, 321.13 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18539/47780 [01:01<01:40, 290.65 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18192/47780 [01:01<01:37, 303.71 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18227/47780 [01:01<01:36, 306.10 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18742/47780 [01:01<01:35, 305.49 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19757/47780 [01:01<01:31, 306.68 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18575/47780 [01:01<01:37, 299.85 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18170/47780 [01:01<01:44, 283.64 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18983/47780 [01:01<01:25, 336.76 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18266/47780 [01:01<01:30, 325.56 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18223/47780 [01:01<01:39, 295.79 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18777/47780 [01:01<01:31, 317.59 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19791/47780 [01:02<01:29, 312.28 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18200/47780 [01:02<01:42, 287.81 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19017/47780 [01:02<01:27, 330.23 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18614/47780 [01:02<01:32, 314.66 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18302/47780 [01:02<01:30, 327.49 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18253/47780 [01:02<01:42, 287.62 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18811/47780 [01:02<01:40, 287.93 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19823/47780 [01:02<01:33, 298.97 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18234/47780 [01:02<01:39, 296.03 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19051/47780 [01:02<01:29, 322.23 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18648/47780 [01:02<01:32, 314.65 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18341/47780 [01:02<01:26, 341.64 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18283/47780 [01:02<01:42, 287.99 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18855/47780 [01:02<01:28, 325.02 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19866/47780 [01:02<01:24, 330.01 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18264/47780 [01:02<01:40, 293.79 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18681/47780 [01:02<01:32, 315.26 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18312/47780 [01:02<01:42, 288.14 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18379/47780 [01:02<01:26, 340.94 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19085/47780 [01:02<01:33, 306.47 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18889/47780 [01:02<01:33, 308.83 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19900/47780 [01:02<01:25, 325.21 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18300/47780 [01:02<01:35, 310.22 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18720/47780 [01:02<01:27, 332.84 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18342/47780 [01:02<01:42, 288.28 examples/s]Tokenizing train dataset (num_proc=32):  14%|█▍        | 6737/47780 [01:02<02:19, 294.61 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18418/47780 [01:02<01:24, 346.76 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19116/47780 [01:02<01:35, 300.73 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18928/47780 [01:02<01:28, 327.03 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19938/47780 [01:02<01:23, 333.50 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18333/47780 [01:02<01:35, 307.74 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18372/47780 [01:02<01:43, 285.40 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18459/47780 [01:02<01:21, 360.68 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18754/47780 [01:02<01:34, 306.66 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19147/47780 [01:02<01:43, 277.93 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18967/47780 [01:02<01:25, 338.71 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18364/47780 [01:02<01:36, 305.02 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19972/47780 [01:02<01:25, 323.96 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18406/47780 [01:02<01:37, 300.84 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18787/47780 [01:02<01:33, 311.02 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18496/47780 [01:02<01:26, 339.78 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19190/47780 [01:02<01:30, 316.42 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19010/47780 [01:02<01:19, 362.21 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18395/47780 [01:02<01:38, 299.45 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20005/47780 [01:02<01:28, 315.26 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18437/47780 [01:02<01:37, 300.33 examples/s]Tokenizing train dataset (num_proc=32):  14%|█▍        | 6834/47780 [01:02<02:18, 295.39 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18819/47780 [01:02<01:39, 292.37 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18531/47780 [01:02<01:31, 318.54 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19223/47780 [01:02<01:37, 293.88 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19047/47780 [01:02<01:23, 344.89 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18428/47780 [01:02<01:38, 298.03 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18469/47780 [01:02<01:36, 302.51 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20037/47780 [01:02<01:31, 303.23 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18853/47780 [01:02<01:35, 302.38 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18565/47780 [01:02<01:33, 313.55 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19082/47780 [01:02<01:23, 342.48 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19259/47780 [01:02<01:35, 298.69 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18471/47780 [01:02<01:27, 335.41 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18503/47780 [01:02<01:34, 309.69 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18884/47780 [01:02<01:36, 300.84 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20068/47780 [01:02<01:42, 269.28 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18601/47780 [01:02<01:30, 322.00 examples/s]Tokenizing train dataset (num_proc=32):  14%|█▍        | 6912/47780 [01:02<02:17, 297.22 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18509/47780 [01:03<01:25, 344.21 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19290/47780 [01:02<01:38, 289.20 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18540/47780 [01:03<01:32, 316.22 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19117/47780 [01:03<01:31, 312.60 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18916/47780 [01:03<01:34, 306.20 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20098/47780 [01:03<01:41, 272.68 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18635/47780 [01:03<01:30, 320.97 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19325/47780 [01:03<01:34, 302.63 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19149/47780 [01:03<01:34, 301.72 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18572/47780 [01:03<01:37, 299.44 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18545/47780 [01:03<01:32, 315.98 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18949/47780 [01:03<01:33, 309.91 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20128/47780 [01:03<01:40, 275.96 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▍        | 6975/47780 [01:03<02:16, 299.15 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18669/47780 [01:03<01:34, 309.06 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19364/47780 [01:03<01:27, 326.42 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19186/47780 [01:03<01:29, 317.94 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18630/47780 [01:03<01:17, 374.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18982/47780 [01:03<01:32, 312.13 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20156/47780 [01:03<01:39, 276.70 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18701/47780 [01:03<01:33, 311.49 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19398/47780 [01:03<01:30, 315.23 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18578/47780 [01:03<01:52, 258.96 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19219/47780 [01:03<01:30, 316.27 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18668/47780 [01:03<01:19, 367.38 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19016/47780 [01:03<01:33, 309.01 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20188/47780 [01:03<01:36, 287.20 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▍        | 7030/47780 [01:03<02:22, 286.50 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18733/47780 [01:03<01:37, 297.37 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19438/47780 [01:03<01:25, 332.20 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19258/47780 [01:03<01:25, 333.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18606/47780 [01:03<02:02, 239.00 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19047/47780 [01:03<01:33, 306.21 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20218/47780 [01:03<01:35, 289.68 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18706/47780 [01:03<01:32, 314.39 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18763/47780 [01:03<01:38, 295.13 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▍        | 7075/47780 [01:03<02:16, 299.28 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19472/47780 [01:03<01:28, 319.44 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19292/47780 [01:03<01:30, 314.05 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19078/47780 [01:03<01:33, 307.13 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18669/47780 [01:03<01:28, 329.12 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20249/47780 [01:03<01:35, 288.82 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18749/47780 [01:03<01:25, 340.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18793/47780 [01:03<01:41, 286.64 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19328/47780 [01:03<01:28, 322.96 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19505/47780 [01:03<01:35, 296.59 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19109/47780 [01:03<01:35, 300.74 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▍        | 7118/47780 [01:03<02:18, 292.69 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20279/47780 [01:03<01:37, 282.34 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18706/47780 [01:03<01:30, 320.76 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18785/47780 [01:03<01:24, 341.56 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18822/47780 [01:03<01:43, 278.50 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19365/47780 [01:03<01:25, 332.58 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19140/47780 [01:03<01:36, 296.60 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20312/47780 [01:03<01:33, 292.56 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▍        | 7156/47780 [01:03<02:16, 298.56 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18741/47780 [01:03<01:29, 324.92 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19536/47780 [01:03<01:41, 279.28 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18821/47780 [01:03<01:29, 322.32 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18850/47780 [01:03<01:51, 258.67 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19180/47780 [01:03<01:28, 322.91 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18780/47780 [01:03<01:24, 342.08 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20352/47780 [01:03<01:25, 321.34 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19399/47780 [01:03<01:32, 306.79 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19566/47780 [01:03<01:41, 279.04 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▌        | 7193/47780 [01:03<02:16, 296.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18855/47780 [01:03<01:31, 316.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18877/47780 [01:03<01:55, 250.93 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18816/47780 [01:04<01:24, 343.02 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19220/47780 [01:04<01:26, 329.91 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19431/47780 [01:04<01:36, 294.52 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▌        | 7229/47780 [01:04<02:14, 302.27 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19595/47780 [01:04<01:47, 262.07 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20385/47780 [01:04<01:39, 275.29 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18897/47780 [01:04<01:23, 344.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18903/47780 [01:04<01:54, 252.63 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19261/47780 [01:04<01:21, 348.71 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▌        | 7269/47780 [01:04<02:05, 322.47 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19461/47780 [01:04<01:39, 283.87 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19627/47780 [01:04<01:42, 274.70 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20446/47780 [01:04<01:15, 361.56 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18933/47780 [01:04<01:26, 333.95 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18852/47780 [01:04<01:41, 284.63 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18937/47780 [01:04<01:46, 271.59 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19303/47780 [01:04<01:17, 369.04 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19495/47780 [01:04<01:34, 298.86 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19655/47780 [01:04<01:42, 273.12 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▌        | 7305/47780 [01:04<02:09, 311.91 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20486/47780 [01:04<01:16, 358.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18900/47780 [01:04<01:27, 329.27 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18965/47780 [01:04<01:48, 264.64 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18967/47780 [01:04<01:36, 299.78 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19341/47780 [01:04<01:19, 359.64 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19526/47780 [01:04<01:34, 299.46 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19692/47780 [01:04<01:34, 296.65 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▌        | 7339/47780 [01:04<02:07, 318.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20524/47780 [01:04<01:16, 354.46 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18993/47780 [01:04<01:48, 266.48 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18936/47780 [01:04<01:30, 319.85 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18998/47780 [01:04<01:36, 298.87 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19378/47780 [01:04<01:24, 335.95 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19722/47780 [01:04<01:34, 297.28 examples/s]Tokenizing train dataset (num_proc=32):  15%|█▌        | 7377/47780 [01:04<02:00, 334.05 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19557/47780 [01:04<01:43, 273.88 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20563/47780 [01:04<01:18, 348.79 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19020/47780 [01:04<01:52, 255.87 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19040/47780 [01:04<01:26, 331.32 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18970/47780 [01:04<01:32, 312.43 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19417/47780 [01:04<01:21, 346.78 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7415/47780 [01:04<01:56, 346.24 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19752/47780 [01:04<01:38, 285.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19587/47780 [01:04<01:40, 280.63 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20599/47780 [01:04<01:19, 340.68 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19007/47780 [01:04<01:28, 324.77 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19050/47780 [01:04<01:49, 263.39 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19074/47780 [01:04<01:30, 315.88 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19453/47780 [01:04<01:23, 338.43 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19781/47780 [01:04<01:41, 275.65 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19621/47780 [01:04<01:34, 296.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7451/47780 [01:04<02:05, 321.87 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19077/47780 [01:04<01:49, 261.25 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20634/47780 [01:04<01:25, 315.77 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19121/47780 [01:04<01:20, 357.78 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19041/47780 [01:04<01:33, 308.71 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19809/47780 [01:04<01:41, 275.51 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19653/47780 [01:04<01:34, 297.13 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7485/47780 [01:04<02:09, 310.40 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19108/47780 [01:04<01:45, 272.02 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19489/47780 [01:04<01:40, 282.33 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19073/47780 [01:04<01:32, 311.37 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20669/47780 [01:04<01:27, 308.35 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19159/47780 [01:04<01:23, 341.90 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19845/47780 [01:04<01:34, 296.13 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19684/47780 [01:04<01:34, 297.37 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19136/47780 [01:04<01:45, 271.22 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19536/47780 [01:04<01:26, 325.20 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7517/47780 [01:04<02:20, 285.74 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 19108/47780 [01:04<01:30, 315.40 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19206/47780 [01:04<01:15, 376.62 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20702/47780 [01:04<01:29, 304.06 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19719/47780 [01:05<01:31, 305.40 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19875/47780 [01:05<01:47, 258.48 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19168/47780 [01:05<01:41, 282.00 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19140/47780 [01:05<01:32, 309.86 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7559/47780 [01:05<02:12, 304.53 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19245/47780 [01:05<01:15, 376.21 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20734/47780 [01:05<01:28, 305.51 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19571/47780 [01:05<01:32, 306.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19750/47780 [01:05<01:32, 303.27 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19931/47780 [01:05<01:22, 337.55 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19209/47780 [01:05<01:30, 316.76 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19175/47780 [01:05<01:30, 317.55 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7591/47780 [01:05<02:14, 299.18 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19785/47780 [01:05<01:28, 316.64 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20765/47780 [01:05<01:37, 278.44 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19604/47780 [01:05<01:38, 286.19 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19284/47780 [01:05<01:29, 318.89 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19967/47780 [01:05<01:22, 336.53 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19242/47780 [01:05<01:29, 318.61 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19210/47780 [01:05<01:29, 319.63 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7625/47780 [01:05<02:10, 306.77 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19836/47780 [01:05<01:15, 368.63 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19637/47780 [01:05<01:35, 294.14 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20805/47780 [01:05<01:28, 304.67 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19329/47780 [01:05<01:20, 352.16 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19279/47780 [01:05<01:26, 330.35 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20003/47780 [01:05<01:26, 321.93 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19245/47780 [01:05<01:28, 320.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7657/47780 [01:05<02:19, 288.40 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19873/47780 [01:05<01:17, 360.70 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20840/47780 [01:05<01:25, 316.69 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19367/47780 [01:05<01:19, 355.74 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19668/47780 [01:05<01:39, 283.29 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19316/47780 [01:05<01:24, 337.99 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19278/47780 [01:05<01:31, 312.82 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20037/47780 [01:05<01:33, 297.84 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19910/47780 [01:05<01:16, 362.58 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20876/47780 [01:05<01:23, 321.69 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7687/47780 [01:05<02:24, 276.84 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19404/47780 [01:05<01:18, 359.60 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19697/47780 [01:05<01:42, 273.83 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19350/47780 [01:05<01:28, 319.86 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19310/47780 [01:05<01:36, 294.63 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20910/47780 [01:05<01:23, 323.29 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20068/47780 [01:05<01:37, 283.23 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19444/47780 [01:05<01:16, 370.29 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19947/47780 [01:05<01:22, 337.59 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19731/47780 [01:05<01:37, 286.76 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7716/47780 [01:05<02:38, 253.37 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19386/47780 [01:05<01:26, 327.51 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20957/47780 [01:05<01:13, 362.71 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20097/47780 [01:05<01:37, 284.27 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19340/47780 [01:05<01:40, 283.65 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19985/47780 [01:05<01:21, 342.11 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19765/47780 [01:05<01:33, 299.61 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▌        | 7754/47780 [01:05<02:23, 279.31 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19483/47780 [01:05<01:24, 336.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19419/47780 [01:05<01:30, 313.86 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19369/47780 [01:05<01:42, 276.50 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20126/47780 [01:05<01:41, 271.38 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19796/47780 [01:05<01:32, 301.66 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20994/47780 [01:05<01:23, 322.14 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▋        | 7783/47780 [01:05<02:25, 275.39 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20020/47780 [01:05<01:29, 309.49 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19452/47780 [01:05<01:29, 318.11 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19518/47780 [01:05<01:28, 317.80 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19403/47780 [01:05<01:39, 284.75 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20159/47780 [01:05<01:38, 281.68 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19827/47780 [01:05<01:37, 288.14 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21046/47780 [01:05<01:12, 370.98 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20053/47780 [01:06<01:28, 311.76 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▋        | 7811/47780 [01:05<02:28, 269.29 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19484/47780 [01:06<01:34, 297.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19551/47780 [01:06<01:32, 305.81 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19434/47780 [01:06<01:37, 291.57 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20188/47780 [01:06<01:37, 283.49 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19865/47780 [01:06<01:30, 307.10 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21085/47780 [01:06<01:12, 367.14 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20086/47780 [01:06<01:28, 313.32 examples/s]Tokenizing train dataset (num_proc=32):  16%|█▋        | 7839/47780 [01:06<02:29, 266.79 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19583/47780 [01:06<01:32, 306.41 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19515/47780 [01:06<01:44, 271.78 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19464/47780 [01:06<01:36, 293.85 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20217/47780 [01:06<01:43, 267.57 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20118/47780 [01:06<01:27, 314.90 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21132/47780 [01:06<01:10, 379.88 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19896/47780 [01:06<01:34, 294.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7866/47780 [01:06<02:29, 267.06 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19615/47780 [01:06<01:37, 289.80 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19545/47780 [01:06<01:44, 270.54 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19494/47780 [01:06<01:41, 279.71 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20245/47780 [01:06<01:42, 267.43 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20153/47780 [01:06<01:26, 319.70 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21171/47780 [01:06<01:10, 378.20 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19926/47780 [01:06<01:36, 289.93 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7897/47780 [01:06<02:28, 268.64 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19585/47780 [01:06<01:34, 298.73 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19645/47780 [01:06<01:45, 267.18 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20278/47780 [01:06<01:38, 279.47 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19523/47780 [01:06<01:45, 267.61 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19956/47780 [01:06<01:36, 289.15 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21210/47780 [01:06<01:11, 369.43 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20186/47780 [01:06<01:29, 306.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7927/47780 [01:06<02:25, 273.34 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19616/47780 [01:06<01:34, 298.23 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19673/47780 [01:06<01:48, 259.78 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20307/47780 [01:06<01:41, 271.97 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19550/47780 [01:06<01:49, 256.71 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21248/47780 [01:06<01:12, 368.21 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19990/47780 [01:06<01:33, 297.08 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 7955/47780 [01:06<02:27, 269.31 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20217/47780 [01:06<01:31, 301.04 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19647/47780 [01:06<01:39, 282.00 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20338/47780 [01:06<01:37, 280.75 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19576/47780 [01:06<01:53, 249.32 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20022/47780 [01:06<01:32, 299.01 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 7982/47780 [01:06<02:28, 268.15 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20258/47780 [01:06<01:25, 320.79 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19700/47780 [01:06<02:04, 224.93 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21286/47780 [01:06<01:20, 330.64 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19682/47780 [01:06<01:35, 295.11 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19604/47780 [01:06<01:50, 255.30 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20052/47780 [01:06<01:33, 297.26 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8021/47780 [01:06<02:12, 301.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20367/47780 [01:06<01:48, 251.68 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20291/47780 [01:06<01:27, 312.92 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21320/47780 [01:06<01:23, 315.05 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19725/47780 [01:06<02:09, 216.07 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19636/47780 [01:06<01:45, 267.23 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20089/47780 [01:06<01:30, 307.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8054/47780 [01:06<02:11, 302.32 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20393/47780 [01:06<01:48, 251.52 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20328/47780 [01:06<01:24, 325.35 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19712/47780 [01:06<01:51, 252.15 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21367/47780 [01:06<01:14, 353.38 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19782/47780 [01:06<01:33, 299.96 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19667/47780 [01:06<01:40, 279.20 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20129/47780 [01:06<01:23, 329.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8085/47780 [01:06<02:12, 300.59 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20426/47780 [01:06<01:40, 272.89 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20362/47780 [01:06<01:24, 325.39 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19815/47780 [01:07<01:31, 304.59 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21404/47780 [01:07<01:16, 343.07 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19696/47780 [01:07<01:43, 270.13 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19739/47780 [01:07<02:10, 215.37 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20459/47780 [01:07<01:34, 288.77 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8116/47780 [01:07<02:15, 293.76 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20395/47780 [01:07<01:25, 319.68 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20163/47780 [01:07<01:29, 308.19 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19847/47780 [01:07<01:39, 281.67 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21439/47780 [01:07<01:24, 311.99 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19724/47780 [01:07<01:42, 272.73 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19814/47780 [01:07<01:23, 335.98 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20489/47780 [01:07<01:34, 290.11 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8147/47780 [01:07<02:12, 298.27 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20200/47780 [01:07<01:24, 325.14 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20428/47780 [01:07<01:28, 308.53 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21471/47780 [01:07<01:24, 310.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19754/47780 [01:07<01:40, 277.57 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8183/47780 [01:07<02:06, 312.59 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20533/47780 [01:07<01:23, 328.04 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19878/47780 [01:07<01:45, 264.39 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20235/47780 [01:07<01:22, 332.08 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19852/47780 [01:07<01:26, 321.18 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20467/47780 [01:07<01:23, 327.45 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21505/47780 [01:07<01:23, 314.75 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19782/47780 [01:07<01:41, 275.06 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8222/47780 [01:07<02:00, 327.55 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19907/47780 [01:07<01:44, 265.50 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20269/47780 [01:07<01:24, 326.41 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20504/47780 [01:07<01:21, 335.99 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19893/47780 [01:07<01:23, 333.53 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20567/47780 [01:07<01:38, 277.28 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19813/47780 [01:07<01:39, 281.96 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21537/47780 [01:07<01:24, 309.39 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8255/47780 [01:07<02:05, 313.72 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19936/47780 [01:07<01:44, 266.33 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20302/47780 [01:07<01:26, 316.73 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20538/47780 [01:07<01:21, 333.00 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19929/47780 [01:07<01:24, 330.20 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20628/47780 [01:07<01:15, 359.78 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21569/47780 [01:07<01:25, 305.17 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19842/47780 [01:07<01:45, 265.78 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8297/47780 [01:07<01:56, 339.73 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20340/47780 [01:07<01:22, 331.34 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20572/47780 [01:07<01:22, 328.33 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19964/47780 [01:07<01:22, 335.16 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19965/47780 [01:07<01:52, 246.32 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20667/47780 [01:07<01:20, 337.71 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21607/47780 [01:07<01:21, 322.83 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19873/47780 [01:07<01:40, 277.91 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20376/47780 [01:07<01:21, 335.53 examples/s]Tokenizing train dataset (num_proc=32):  17%|█▋        | 8332/47780 [01:07<02:00, 327.67 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19999/47780 [01:07<01:28, 315.52 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19996/47780 [01:07<01:47, 257.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20605/47780 [01:07<01:36, 281.76 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19902/47780 [01:07<01:41, 274.74 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20703/47780 [01:07<01:26, 311.42 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20410/47780 [01:07<01:23, 328.91 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21640/47780 [01:07<01:29, 291.44 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8365/47780 [01:07<02:08, 307.68 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20034/47780 [01:07<01:25, 324.65 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20023/47780 [01:07<01:52, 247.81 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20643/47780 [01:07<01:30, 300.02 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20739/47780 [01:07<01:24, 320.41 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20450/47780 [01:07<01:19, 345.80 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19930/47780 [01:07<01:47, 259.21 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21670/47780 [01:07<01:32, 281.86 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8397/47780 [01:07<02:09, 304.54 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20060/47780 [01:07<01:39, 277.46 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20680/47780 [01:07<01:25, 317.77 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20485/47780 [01:08<01:19, 342.97 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20774/47780 [01:08<01:24, 318.11 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19957/47780 [01:08<01:52, 248.37 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8440/47780 [01:08<01:56, 339.14 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20069/47780 [01:08<01:49, 252.72 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21699/47780 [01:08<01:38, 264.60 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20091/47780 [01:08<01:36, 285.95 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20713/47780 [01:08<01:29, 300.78 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20811/47780 [01:08<01:22, 328.49 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20521/47780 [01:08<01:20, 339.67 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19985/47780 [01:08<01:48, 256.83 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8476/47780 [01:08<01:57, 333.48 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20140/47780 [01:08<01:18, 353.78 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21729/47780 [01:08<01:36, 271.00 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20121/47780 [01:08<01:37, 283.16 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20748/47780 [01:08<01:26, 311.24 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20845/47780 [01:08<01:21, 331.62 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20019/47780 [01:08<01:39, 279.50 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8510/47780 [01:08<01:59, 328.20 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21761/47780 [01:08<01:31, 283.08 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20180/47780 [01:08<01:17, 358.00 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20150/47780 [01:08<01:36, 285.01 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20556/47780 [01:08<01:35, 284.08 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20781/47780 [01:08<01:29, 302.95 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20879/47780 [01:08<01:22, 324.91 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20049/47780 [01:08<01:45, 262.14 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8544/47780 [01:08<02:03, 316.93 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20179/47780 [01:08<01:41, 271.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20220/47780 [01:08<01:20, 343.21 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21790/47780 [01:08<01:38, 262.76 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20610/47780 [01:08<01:18, 345.69 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20813/47780 [01:08<01:28, 304.24 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20915/47780 [01:08<01:20, 332.85 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8579/47780 [01:08<02:00, 326.09 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20088/47780 [01:08<01:35, 290.54 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20224/47780 [01:08<01:25, 320.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21832/47780 [01:08<01:25, 304.84 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20257/47780 [01:08<01:20, 342.07 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20847/47780 [01:08<01:26, 310.81 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20647/47780 [01:08<01:24, 319.52 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20955/47780 [01:08<01:17, 348.13 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20125/47780 [01:08<01:30, 305.81 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8612/47780 [01:08<02:06, 309.62 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21866/47780 [01:08<01:22, 312.43 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20257/47780 [01:08<01:30, 303.21 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20293/47780 [01:08<01:24, 326.76 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20881/47780 [01:08<01:25, 315.53 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20681/47780 [01:08<01:27, 311.01 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20991/47780 [01:08<01:19, 336.11 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20164/47780 [01:08<01:23, 329.20 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8644/47780 [01:08<02:08, 303.88 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21898/47780 [01:08<01:24, 307.65 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20288/47780 [01:08<01:30, 304.49 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20915/47780 [01:08<01:26, 311.78 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20714/47780 [01:08<01:30, 300.17 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21025/47780 [01:08<01:27, 305.75 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8690/47780 [01:08<01:52, 345.98 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20323/47780 [01:08<01:29, 307.22 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21931/47780 [01:08<01:28, 292.64 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20198/47780 [01:08<01:34, 292.47 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20957/47780 [01:08<01:19, 338.62 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20327/47780 [01:08<01:50, 247.94 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21057/47780 [01:08<01:28, 303.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8727/47780 [01:08<01:50, 352.69 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20745/47780 [01:08<01:37, 276.97 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20358/47780 [01:08<01:26, 315.67 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20237/47780 [01:08<01:26, 318.08 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21964/47780 [01:08<01:26, 299.75 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20992/47780 [01:08<01:23, 319.52 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20356/47780 [01:08<01:53, 241.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8766/47780 [01:08<01:48, 359.44 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21088/47780 [01:09<01:30, 294.01 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20779/47780 [01:09<01:34, 287.09 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20391/47780 [01:09<01:27, 314.26 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22009/47780 [01:09<01:16, 336.90 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20270/47780 [01:09<01:28, 310.86 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21033/47780 [01:09<01:18, 341.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20430/47780 [01:09<01:19, 343.21 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21125/47780 [01:09<01:25, 313.11 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8803/47780 [01:09<01:50, 353.99 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20809/47780 [01:09<01:35, 281.33 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20424/47780 [01:09<01:26, 316.91 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20302/47780 [01:09<01:28, 310.26 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22044/47780 [01:09<01:18, 326.92 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21071/47780 [01:09<01:18, 340.51 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20468/47780 [01:09<01:18, 348.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21157/47780 [01:09<01:24, 314.46 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20845/47780 [01:09<01:30, 296.35 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20460/47780 [01:09<01:24, 322.17 examples/s]Tokenizing train dataset (num_proc=32):  18%|█▊        | 8839/47780 [01:09<01:58, 329.48 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20335/47780 [01:09<01:28, 308.59 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22079/47780 [01:09<01:19, 322.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21106/47780 [01:09<01:21, 328.23 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21192/47780 [01:09<01:22, 321.51 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20506/47780 [01:09<01:25, 318.19 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20493/47780 [01:09<01:25, 320.79 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8874/47780 [01:09<01:57, 331.47 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20369/47780 [01:09<01:28, 310.71 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20876/47780 [01:09<01:37, 275.52 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22112/47780 [01:09<01:21, 313.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21141/47780 [01:09<01:21, 327.14 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21228/47780 [01:09<01:20, 328.71 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20526/47780 [01:09<01:27, 312.31 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8908/47780 [01:09<02:03, 315.69 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20540/47780 [01:09<01:29, 304.46 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22145/47780 [01:09<01:21, 315.26 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20930/47780 [01:09<01:19, 338.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20401/47780 [01:09<01:32, 296.61 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21262/47780 [01:09<01:20, 331.47 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21177/47780 [01:09<01:25, 312.82 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20559/47780 [01:09<01:25, 317.26 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20431/47780 [01:09<01:31, 297.54 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20967/47780 [01:09<01:18, 343.31 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20578/47780 [01:09<01:27, 310.08 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▊        | 8940/47780 [01:09<02:12, 294.23 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22177/47780 [01:09<01:30, 284.01 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21296/47780 [01:09<01:22, 319.59 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21214/47780 [01:09<01:23, 318.17 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21004/47780 [01:09<01:16, 350.30 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20591/47780 [01:09<01:32, 294.22 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20611/47780 [01:09<01:26, 313.53 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20464/47780 [01:09<01:32, 296.60 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 8971/47780 [01:09<02:11, 295.72 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21332/47780 [01:09<01:20, 327.33 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22206/47780 [01:09<01:36, 266.15 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21247/47780 [01:09<01:23, 317.00 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20622/47780 [01:09<01:32, 292.48 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21042/47780 [01:09<01:17, 347.15 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20494/47780 [01:09<01:32, 294.11 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20644/47780 [01:09<01:28, 308.15 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9002/47780 [01:09<02:12, 292.86 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21371/47780 [01:09<01:17, 341.37 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22239/47780 [01:09<01:32, 277.05 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21280/47780 [01:09<01:23, 317.83 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20653/47780 [01:09<01:33, 290.89 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9037/47780 [01:09<02:06, 305.58 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21079/47780 [01:09<01:19, 335.70 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20524/47780 [01:09<01:36, 282.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20676/47780 [01:09<01:29, 301.20 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21406/47780 [01:09<01:17, 339.86 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21312/47780 [01:09<01:23, 317.66 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22268/47780 [01:09<01:32, 277.23 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20683/47780 [01:10<01:33, 289.81 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20709/47780 [01:10<01:28, 306.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9075/47780 [01:10<02:01, 319.38 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20553/47780 [01:10<01:40, 269.61 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21113/47780 [01:10<01:25, 310.66 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21351/47780 [01:10<01:18, 338.28 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21441/47780 [01:10<01:20, 329.22 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22297/47780 [01:10<01:32, 275.06 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20719/47780 [01:10<01:28, 306.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20740/47780 [01:10<01:29, 301.11 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20582/47780 [01:10<01:39, 272.56 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9108/47780 [01:10<02:08, 301.94 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21153/47780 [01:10<01:20, 332.55 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21483/47780 [01:10<01:15, 349.56 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21385/47780 [01:10<01:22, 321.16 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22325/47780 [01:10<01:42, 248.94 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20756/47780 [01:10<01:25, 317.51 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20771/47780 [01:10<01:34, 286.62 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20611/47780 [01:10<01:40, 270.13 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9148/47780 [01:10<02:00, 320.63 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21187/47780 [01:10<01:25, 310.67 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21418/47780 [01:10<01:21, 322.80 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21519/47780 [01:10<01:20, 326.12 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22366/47780 [01:10<01:27, 291.18 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20800/47780 [01:10<01:34, 285.15 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20646/47780 [01:10<01:34, 287.44 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20788/47780 [01:10<01:33, 287.45 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9182/47780 [01:10<02:04, 310.03 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21451/47780 [01:10<01:22, 320.60 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21219/47780 [01:10<01:27, 303.55 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22399/47780 [01:10<01:25, 298.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21552/47780 [01:10<01:22, 316.36 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20831/47780 [01:10<01:33, 288.75 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20680/47780 [01:10<01:29, 301.93 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20819/47780 [01:10<01:35, 283.14 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9216/47780 [01:10<02:02, 314.71 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21484/47780 [01:10<01:24, 312.83 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21250/47780 [01:10<01:28, 300.95 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22430/47780 [01:10<01:29, 284.09 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21584/47780 [01:10<01:32, 283.80 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20864/47780 [01:10<01:31, 293.76 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20711/47780 [01:10<01:32, 291.11 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20849/47780 [01:10<01:34, 286.44 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9264/47780 [01:10<01:46, 360.60 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21516/47780 [01:10<01:25, 307.68 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21282/47780 [01:10<01:30, 293.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22464/47780 [01:10<01:25, 294.86 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21616/47780 [01:10<01:30, 290.04 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20899/47780 [01:10<01:28, 302.90 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20892/47780 [01:10<01:23, 323.29 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20757/47780 [01:10<01:23, 324.25 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21552/47780 [01:10<01:21, 320.79 examples/s]Tokenizing train dataset (num_proc=32):  19%|█▉        | 9301/47780 [01:10<01:54, 336.23 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21321/47780 [01:10<01:24, 314.45 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22494/47780 [01:10<01:26, 292.99 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21647/47780 [01:10<01:29, 292.25 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20937/47780 [01:10<01:23, 320.98 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20795/47780 [01:10<01:20, 336.04 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20926/47780 [01:10<01:25, 313.92 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21369/47780 [01:10<01:14, 355.61 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9336/47780 [01:10<02:02, 313.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22524/47780 [01:10<01:28, 285.08 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20980/47780 [01:10<01:16, 348.28 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21677/47780 [01:10<01:37, 267.37 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20829/47780 [01:10<01:24, 318.77 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21585/47780 [01:10<01:47, 243.85 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20959/47780 [01:10<01:29, 298.45 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21405/47780 [01:10<01:15, 349.05 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9369/47780 [01:10<02:06, 304.35 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22553/47780 [01:11<01:35, 264.05 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21015/47780 [01:10<01:21, 329.38 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21705/47780 [01:11<01:37, 268.07 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21647/47780 [01:11<01:18, 332.74 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20866/47780 [01:11<01:22, 326.10 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20991/47780 [01:11<01:31, 293.04 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21445/47780 [01:11<01:13, 359.30 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22583/47780 [01:11<01:32, 272.65 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9400/47780 [01:11<02:20, 273.86 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21051/47780 [01:11<01:19, 334.65 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21733/47780 [01:11<01:40, 260.39 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21685/47780 [01:11<01:18, 331.02 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21021/47780 [01:11<01:32, 290.30 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21482/47780 [01:11<01:13, 357.85 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20899/47780 [01:11<01:27, 306.71 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22619/47780 [01:11<01:25, 293.57 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9429/47780 [01:11<02:22, 268.22 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21086/47780 [01:11<01:20, 331.45 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21760/47780 [01:11<01:39, 262.48 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21727/47780 [01:11<01:14, 350.60 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21051/47780 [01:11<01:33, 286.68 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21518/47780 [01:11<01:18, 335.61 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20930/47780 [01:11<01:33, 288.70 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21124/47780 [01:11<01:17, 345.20 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9457/47780 [01:11<02:23, 266.52 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21789/47780 [01:11<01:38, 264.73 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22649/47780 [01:11<01:35, 262.94 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21080/47780 [01:11<01:33, 284.49 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21765/47780 [01:11<01:16, 340.32 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21557/47780 [01:11<01:14, 350.60 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20961/47780 [01:11<01:32, 291.36 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21166/47780 [01:11<01:13, 362.87 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9487/47780 [01:11<02:20, 272.66 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21823/47780 [01:11<01:30, 285.83 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22678/47780 [01:11<01:33, 267.11 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21112/47780 [01:11<01:31, 291.18 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20991/47780 [01:11<01:31, 292.85 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21801/47780 [01:11<01:20, 324.45 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21593/47780 [01:11<01:20, 323.60 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21203/47780 [01:11<01:14, 356.42 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21852/47780 [01:11<01:30, 286.48 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9515/47780 [01:11<02:27, 260.12 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21142/47780 [01:11<01:30, 293.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22706/47780 [01:11<01:36, 259.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21022/47780 [01:11<01:31, 292.07 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21839/47780 [01:11<01:17, 335.97 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21626/47780 [01:11<01:22, 317.80 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21887/47780 [01:11<01:26, 298.61 examples/s]Tokenizing train dataset (num_proc=32):  20%|█▉        | 9554/47780 [01:11<02:10, 293.22 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21239/47780 [01:11<01:18, 337.07 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21183/47780 [01:11<01:22, 323.76 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22733/47780 [01:11<01:35, 262.09 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21053/47780 [01:11<01:32, 290.12 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21874/47780 [01:11<01:21, 318.92 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21917/47780 [01:11<01:26, 298.99 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9584/47780 [01:11<02:09, 295.00 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21659/47780 [01:11<01:30, 287.21 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22760/47780 [01:11<01:34, 264.25 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21226/47780 [01:11<01:15, 352.51 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21273/47780 [01:11<01:24, 314.17 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21083/47780 [01:11<01:32, 289.89 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21908/47780 [01:11<01:19, 324.54 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21952/47780 [01:11<01:23, 310.25 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9619/47780 [01:11<02:04, 307.16 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22787/47780 [01:11<01:35, 263.07 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21689/47780 [01:11<01:35, 273.45 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21262/47780 [01:11<01:19, 332.79 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21305/47780 [01:11<01:26, 305.85 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21116/47780 [01:11<01:31, 291.45 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21951/47780 [01:11<01:16, 338.64 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21984/47780 [01:11<01:26, 298.79 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22814/47780 [01:11<01:34, 264.89 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9650/47780 [01:11<02:12, 288.16 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21730/47780 [01:11<01:26, 302.86 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21339/47780 [01:11<01:23, 315.02 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21296/47780 [01:12<01:21, 324.37 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21146/47780 [01:12<01:33, 284.23 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21990/47780 [01:12<01:14, 345.20 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22841/47780 [01:12<01:34, 263.66 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22015/47780 [01:12<01:28, 292.31 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21761/47780 [01:12<01:25, 304.37 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21373/47780 [01:12<01:24, 311.73 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9680/47780 [01:12<02:20, 270.36 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21329/47780 [01:12<01:23, 318.48 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21176/47780 [01:12<01:32, 288.65 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22025/47780 [01:12<01:20, 318.28 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22869/47780 [01:12<01:32, 268.00 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22048/47780 [01:12<01:26, 296.30 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21405/47780 [01:12<01:24, 312.20 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9712/47780 [01:12<02:14, 283.62 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21362/47780 [01:12<01:22, 318.50 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21205/47780 [01:12<01:32, 288.79 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21792/47780 [01:12<01:34, 275.59 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22896/47780 [01:12<01:33, 265.86 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22083/47780 [01:12<01:23, 308.01 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22058/47780 [01:12<01:25, 302.14 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9744/47780 [01:12<02:10, 290.89 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21437/47780 [01:12<01:26, 305.96 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21398/47780 [01:12<01:22, 319.53 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21822/47780 [01:12<01:33, 277.08 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21234/47780 [01:12<01:42, 259.29 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22114/47780 [01:12<01:23, 307.70 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22932/47780 [01:12<01:28, 280.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22092/47780 [01:12<01:24, 302.53 examples/s]Tokenizing train dataset (num_proc=32):  20%|██        | 9775/47780 [01:12<02:08, 296.05 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21476/47780 [01:12<01:19, 329.49 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21858/47780 [01:12<01:27, 295.61 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21431/47780 [01:12<01:24, 311.81 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21261/47780 [01:12<01:46, 248.93 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22963/47780 [01:12<01:26, 288.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22145/47780 [01:12<01:23, 305.55 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22126/47780 [01:12<01:22, 309.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9807/47780 [01:12<02:05, 302.91 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21511/47780 [01:12<01:20, 328.09 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21466/47780 [01:12<01:21, 322.33 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21889/47780 [01:12<01:30, 287.04 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22183/47780 [01:12<01:19, 323.59 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22999/47780 [01:12<01:21, 302.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9839/47780 [01:12<02:03, 307.84 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21287/47780 [01:12<01:53, 233.12 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22172/47780 [01:12<01:13, 348.51 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21552/47780 [01:12<01:16, 343.53 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21499/47780 [01:12<01:23, 313.56 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21923/47780 [01:12<01:26, 297.32 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22219/47780 [01:12<01:16, 334.14 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23038/47780 [01:12<01:15, 327.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21331/47780 [01:12<01:32, 284.73 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22208/47780 [01:12<01:13, 345.74 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9871/47780 [01:12<02:04, 303.49 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21590/47780 [01:12<01:14, 350.08 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21533/47780 [01:12<01:23, 314.34 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21954/47780 [01:12<01:29, 288.96 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22253/47780 [01:12<01:18, 324.57 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23071/47780 [01:12<01:17, 320.52 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21374/47780 [01:12<01:22, 321.58 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9910/47780 [01:12<01:56, 325.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22244/47780 [01:12<01:13, 346.23 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21626/47780 [01:12<01:16, 340.53 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21565/47780 [01:12<01:24, 311.97 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21984/47780 [01:12<01:32, 279.38 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23105/47780 [01:12<01:15, 326.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22303/47780 [01:12<01:08, 370.69 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9943/47780 [01:12<01:57, 323.12 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21408/47780 [01:12<01:28, 296.87 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22279/47780 [01:12<01:20, 314.95 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21602/47780 [01:12<01:20, 325.19 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21661/47780 [01:12<01:19, 327.05 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22013/47780 [01:13<01:34, 273.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22347/47780 [01:13<01:06, 381.96 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23138/47780 [01:13<01:20, 306.24 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 9977/47780 [01:13<01:58, 318.59 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21446/47780 [01:13<01:23, 315.71 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21636/47780 [01:13<01:20, 325.79 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22314/47780 [01:13<01:20, 317.52 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21694/47780 [01:13<01:28, 296.12 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22041/47780 [01:13<01:37, 263.75 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23171/47780 [01:13<01:20, 306.01 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10009/47780 [01:13<02:00, 313.91 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22386/47780 [01:13<01:10, 358.91 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21480/47780 [01:13<01:22, 318.78 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21672/47780 [01:13<01:19, 328.11 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21725/47780 [01:13<01:29, 290.86 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22347/47780 [01:13<01:30, 280.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22070/47780 [01:13<01:38, 262.29 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10041/47780 [01:13<02:01, 311.84 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22423/47780 [01:13<01:13, 347.17 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23202/47780 [01:13<01:24, 290.44 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21516/47780 [01:13<01:19, 330.21 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21710/47780 [01:13<01:16, 339.14 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22103/47780 [01:13<01:33, 274.74 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21762/47780 [01:13<01:28, 295.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22377/47780 [01:13<01:33, 272.16 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10073/47780 [01:13<02:01, 310.85 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21554/47780 [01:13<01:16, 340.61 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23235/47780 [01:13<01:21, 301.30 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21753/47780 [01:13<01:11, 365.11 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22458/47780 [01:13<01:20, 316.52 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22132/47780 [01:13<01:32, 276.33 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21792/47780 [01:13<01:28, 293.96 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22410/47780 [01:13<01:29, 283.99 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10105/47780 [01:13<02:01, 309.23 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23269/47780 [01:13<01:20, 305.77 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22496/47780 [01:13<01:15, 333.20 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21790/47780 [01:13<01:14, 347.81 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21589/47780 [01:13<01:23, 314.13 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22162/47780 [01:13<01:31, 279.51 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21825/47780 [01:13<01:27, 297.60 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22440/47780 [01:13<01:31, 276.18 examples/s]Tokenizing train dataset (num_proc=32):  21%|██        | 10151/47780 [01:13<01:48, 345.66 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23300/47780 [01:13<01:21, 300.04 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21622/47780 [01:13<01:22, 316.95 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21826/47780 [01:13<01:15, 342.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22201/47780 [01:13<01:22, 310.78 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22530/47780 [01:13<01:27, 288.00 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22469/47780 [01:13<01:32, 274.31 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10186/47780 [01:13<01:49, 342.27 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23331/47780 [01:13<01:22, 295.64 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21856/47780 [01:13<01:35, 270.80 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21656/47780 [01:13<01:22, 318.11 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21871/47780 [01:13<01:11, 364.50 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22574/47780 [01:13<01:17, 324.81 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22519/47780 [01:13<01:16, 332.26 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23363/47780 [01:13<01:21, 299.80 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22233/47780 [01:13<01:32, 275.17 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10221/47780 [01:13<01:56, 321.74 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21900/47780 [01:13<01:23, 310.27 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21689/47780 [01:13<01:22, 314.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21908/47780 [01:13<01:16, 339.06 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22618/47780 [01:13<01:11, 350.44 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22553/47780 [01:13<01:17, 326.90 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21933/47780 [01:13<01:22, 314.38 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23394/47780 [01:13<01:22, 295.91 examples/s]Tokenizing train dataset (num_proc=32):  21%|██▏       | 10258/47780 [01:13<01:54, 328.94 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22263/47780 [01:13<01:32, 276.06 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21724/47780 [01:13<01:21, 320.78 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21943/47780 [01:13<01:15, 341.94 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22656/47780 [01:13<01:13, 342.44 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22595/47780 [01:13<01:12, 349.31 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23424/47780 [01:14<01:22, 296.83 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21965/47780 [01:14<01:26, 298.92 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22292/47780 [01:14<01:35, 267.86 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10292/47780 [01:13<01:58, 317.69 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21757/47780 [01:14<01:23, 312.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21978/47780 [01:14<01:15, 340.33 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22701/47780 [01:14<01:07, 371.40 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22631/47780 [01:14<01:13, 344.47 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23454/47780 [01:14<01:25, 284.78 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21999/47780 [01:14<01:23, 307.12 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22324/47780 [01:14<01:33, 273.29 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10324/47780 [01:14<02:02, 306.80 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21796/47780 [01:14<01:18, 330.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22013/47780 [01:14<01:15, 342.70 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22668/47780 [01:14<01:12, 347.88 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22740/47780 [01:14<01:11, 349.35 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23483/47780 [01:14<01:25, 282.77 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22352/47780 [01:14<01:33, 272.27 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10356/47780 [01:14<02:02, 306.46 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21830/47780 [01:14<01:19, 325.93 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22031/47780 [01:14<01:29, 288.06 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22048/47780 [01:14<01:22, 312.96 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22703/47780 [01:14<01:12, 345.17 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23514/47780 [01:14<01:23, 290.51 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22776/47780 [01:14<01:15, 330.82 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22381/47780 [01:14<01:33, 271.13 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10388/47780 [01:14<02:03, 301.80 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21863/47780 [01:14<01:19, 326.61 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22062/47780 [01:14<01:28, 291.13 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22081/47780 [01:14<01:20, 317.59 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22738/47780 [01:14<01:12, 345.87 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23545/47780 [01:14<01:22, 294.29 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22810/47780 [01:14<01:16, 326.36 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22412/47780 [01:14<01:30, 279.06 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21896/47780 [01:14<01:22, 312.46 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22092/47780 [01:14<01:30, 284.09 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10419/47780 [01:14<02:16, 273.74 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22117/47780 [01:14<01:18, 325.71 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22773/47780 [01:14<01:14, 335.15 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23579/47780 [01:14<01:19, 302.84 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22844/47780 [01:14<01:16, 327.22 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22441/47780 [01:14<01:31, 276.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22121/47780 [01:14<01:29, 285.51 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21928/47780 [01:14<01:27, 295.86 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10451/47780 [01:14<02:11, 283.04 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22150/47780 [01:14<01:21, 312.65 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22807/47780 [01:14<01:16, 325.23 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23617/47780 [01:14<01:15, 321.60 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22884/47780 [01:14<01:12, 341.45 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22470/47780 [01:14<01:30, 279.95 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22152/47780 [01:14<01:30, 283.08 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10483/47780 [01:14<02:07, 292.62 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21958/47780 [01:14<01:34, 274.08 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22182/47780 [01:14<01:25, 297.78 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23654/47780 [01:14<01:11, 335.49 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22840/47780 [01:14<01:21, 306.01 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22919/47780 [01:14<01:14, 334.05 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22499/47780 [01:14<01:35, 264.30 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10513/47780 [01:14<02:09, 288.28 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22182/47780 [01:14<01:40, 253.54 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21986/47780 [01:14<01:40, 257.67 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23688/47780 [01:14<01:14, 324.69 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22213/47780 [01:14<01:30, 282.93 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22876/47780 [01:14<01:18, 317.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22953/47780 [01:14<01:13, 335.60 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22526/47780 [01:14<01:36, 262.42 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22226/47780 [01:14<01:24, 302.26 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10543/47780 [01:14<02:23, 259.75 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23727/47780 [01:14<01:10, 342.07 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22017/47780 [01:14<01:37, 263.47 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22251/47780 [01:14<01:24, 302.38 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22908/47780 [01:14<01:20, 307.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22987/47780 [01:14<01:17, 318.71 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22553/47780 [01:14<01:38, 256.62 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22258/47780 [01:15<01:26, 295.58 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23766/47780 [01:15<01:07, 354.32 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10570/47780 [01:15<02:23, 258.75 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22283/47780 [01:15<01:23, 304.75 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22939/47780 [01:15<01:21, 304.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 22044/47780 [01:15<01:41, 252.86 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23020/47780 [01:15<01:21, 304.77 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22579/47780 [01:15<01:41, 249.12 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22289/47780 [01:15<01:30, 282.90 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22317/47780 [01:15<01:22, 310.34 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10597/47780 [01:15<02:32, 244.16 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23802/47780 [01:15<01:13, 328.37 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22073/47780 [01:15<01:40, 256.14 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22970/47780 [01:15<01:25, 289.87 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22606/47780 [01:15<01:39, 252.25 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23051/47780 [01:15<01:33, 263.21 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22320/47780 [01:15<01:28, 287.22 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22354/47780 [01:15<01:17, 327.00 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10629/47780 [01:15<02:22, 261.59 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23839/47780 [01:15<01:11, 333.20 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22105/47780 [01:15<01:34, 270.51 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23008/47780 [01:15<01:21, 304.90 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22635/47780 [01:15<01:37, 257.08 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22355/47780 [01:15<01:24, 300.98 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22387/47780 [01:15<01:19, 320.85 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10660/47780 [01:15<02:16, 271.78 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23873/47780 [01:15<01:14, 320.77 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23079/47780 [01:15<01:45, 234.28 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22670/47780 [01:15<01:28, 283.20 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23041/47780 [01:15<01:23, 295.49 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22133/47780 [01:15<01:44, 245.74 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10698/47780 [01:15<02:04, 298.60 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22386/47780 [01:15<01:28, 287.15 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23909/47780 [01:15<01:13, 324.48 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22420/47780 [01:15<01:27, 289.79 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22707/47780 [01:15<01:22, 304.81 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23076/47780 [01:15<01:20, 307.07 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22159/47780 [01:15<01:43, 247.10 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23156/47780 [01:15<01:10, 349.11 examples/s]Tokenizing train dataset (num_proc=32):  22%|██▏       | 10730/47780 [01:15<02:01, 304.56 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22420/47780 [01:15<01:24, 298.78 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23947/47780 [01:15<01:10, 336.15 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22457/47780 [01:15<01:22, 308.39 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23108/47780 [01:15<01:19, 310.61 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22738/47780 [01:15<01:24, 296.03 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22185/47780 [01:15<01:43, 247.68 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23194/47780 [01:15<01:09, 353.35 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10761/47780 [01:15<02:03, 298.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22451/47780 [01:15<01:25, 294.80 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23986/47780 [01:15<01:10, 339.87 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22491/47780 [01:15<01:22, 307.57 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23141/47780 [01:15<01:18, 312.62 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22768/47780 [01:15<01:27, 287.01 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22211/47780 [01:15<01:48, 235.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23231/47780 [01:15<01:15, 324.07 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10792/47780 [01:15<02:08, 288.56 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22483/47780 [01:15<01:26, 292.59 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24022/47780 [01:15<01:09, 340.94 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22523/47780 [01:15<01:22, 307.03 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22797/47780 [01:15<01:27, 285.14 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23173/47780 [01:15<01:23, 294.46 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22236/47780 [01:15<01:47, 237.01 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23265/47780 [01:15<01:19, 308.97 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22521/47780 [01:15<01:19, 317.00 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10822/47780 [01:15<02:09, 285.45 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24065/47780 [01:15<01:05, 364.44 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23205/47780 [01:15<01:22, 298.28 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22555/47780 [01:15<01:29, 282.15 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22827/47780 [01:15<01:31, 272.02 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22269/47780 [01:15<01:40, 254.26 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23305/47780 [01:16<01:14, 329.19 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10852/47780 [01:15<02:08, 286.89 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24102/47780 [01:16<01:04, 364.51 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22553/47780 [01:16<01:25, 296.53 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23236/47780 [01:16<01:25, 288.01 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22298/47780 [01:16<01:37, 261.21 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22585/47780 [01:16<01:31, 275.16 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22855/47780 [01:16<01:33, 266.75 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23339/47780 [01:16<01:15, 324.83 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10887/47780 [01:16<02:03, 298.15 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24140/47780 [01:16<01:04, 364.78 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22585/47780 [01:16<01:23, 300.66 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23265/47780 [01:16<01:26, 282.87 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22890/47780 [01:16<01:26, 287.02 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22613/47780 [01:16<01:31, 273.56 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22327/47780 [01:16<01:42, 247.23 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10928/47780 [01:16<01:54, 322.58 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23373/47780 [01:16<01:20, 302.61 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24177/47780 [01:16<01:08, 345.13 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22616/47780 [01:16<01:28, 284.15 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23297/47780 [01:16<01:23, 293.17 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22641/47780 [01:16<01:33, 269.66 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22919/47780 [01:16<01:31, 272.14 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 10966/47780 [01:16<01:49, 335.19 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23404/47780 [01:16<01:21, 300.16 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24212/47780 [01:16<01:11, 329.15 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22645/47780 [01:16<01:31, 273.78 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23328/47780 [01:16<01:22, 297.65 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22352/47780 [01:16<02:03, 205.84 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22670/47780 [01:16<01:31, 275.14 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22962/47780 [01:16<01:18, 315.42 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11000/47780 [01:16<01:51, 329.09 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23435/47780 [01:16<01:23, 292.04 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24246/47780 [01:16<01:13, 321.36 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22413/47780 [01:16<01:24, 300.66 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22678/47780 [01:16<01:29, 279.98 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23358/47780 [01:16<01:24, 288.31 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22703/47780 [01:16<01:26, 290.59 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22996/47780 [01:16<01:19, 312.55 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11035/47780 [01:16<01:50, 331.20 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23465/47780 [01:16<01:24, 287.53 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24282/47780 [01:16<01:10, 331.86 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22718/47780 [01:16<01:20, 312.77 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23390/47780 [01:16<01:23, 291.04 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22446/47780 [01:16<01:27, 290.40 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22737/47780 [01:16<01:25, 291.46 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23040/47780 [01:16<01:11, 344.68 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11075/47780 [01:16<01:47, 342.77 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23495/47780 [01:16<01:24, 288.15 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22751/47780 [01:16<01:18, 317.51 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24316/47780 [01:16<01:14, 316.52 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23420/47780 [01:16<01:27, 279.86 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22768/47780 [01:16<01:29, 280.76 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23075/47780 [01:16<01:14, 330.94 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22477/47780 [01:16<01:32, 272.80 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23524/47780 [01:16<01:24, 285.53 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11110/47780 [01:16<01:53, 323.07 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22785/47780 [01:16<01:18, 316.84 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24352/47780 [01:16<01:11, 328.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22799/47780 [01:16<01:26, 288.38 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23449/47780 [01:16<01:32, 263.00 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22511/47780 [01:16<01:27, 287.15 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23109/47780 [01:16<01:16, 322.66 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11149/47780 [01:16<01:47, 341.57 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23559/47780 [01:16<01:21, 297.44 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22817/47780 [01:16<01:18, 317.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24386/47780 [01:16<01:11, 327.92 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23476/47780 [01:16<01:32, 262.08 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23147/47780 [01:16<01:13, 334.99 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22829/47780 [01:16<01:33, 267.73 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23590/47780 [01:16<01:20, 300.72 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11189/47780 [01:16<01:45, 346.25 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22543/47780 [01:17<01:37, 257.87 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22856/47780 [01:16<01:14, 334.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24420/47780 [01:17<01:13, 316.98 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23511/47780 [01:17<01:24, 286.43 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23185/47780 [01:17<01:13, 332.66 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22857/47780 [01:17<01:32, 268.00 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22577/47780 [01:17<01:30, 278.13 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23621/47780 [01:17<01:23, 289.19 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22891/47780 [01:17<01:14, 335.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24452/47780 [01:17<01:15, 310.80 examples/s]Tokenizing train dataset (num_proc=32):  23%|██▎       | 11224/47780 [01:17<02:00, 302.50 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23540/47780 [01:17<01:25, 282.81 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22885/47780 [01:17<01:33, 265.69 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23219/47780 [01:17<01:16, 319.92 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23655/47780 [01:17<01:20, 300.95 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22607/47780 [01:17<01:31, 274.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22925/47780 [01:17<01:16, 325.54 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11257/47780 [01:17<01:58, 306.93 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24484/47780 [01:17<01:19, 293.57 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23575/47780 [01:17<01:21, 297.99 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22916/47780 [01:17<01:29, 277.91 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23252/47780 [01:17<01:16, 319.14 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23689/47780 [01:17<01:17, 312.08 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22636/47780 [01:17<01:33, 267.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22958/47780 [01:17<01:21, 304.58 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24519/47780 [01:17<01:16, 302.38 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11289/47780 [01:17<02:02, 297.73 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23611/47780 [01:17<01:20, 300.73 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22946/47780 [01:17<01:34, 263.40 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23721/47780 [01:17<01:17, 308.70 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23285/47780 [01:17<01:25, 286.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22989/47780 [01:17<01:21, 303.53 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22665/47780 [01:17<01:38, 254.65 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24552/47780 [01:17<01:15, 306.23 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23651/47780 [01:17<01:14, 322.62 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▎       | 11322/47780 [01:17<02:06, 287.74 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22975/47780 [01:17<01:32, 267.67 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23752/47780 [01:17<01:19, 300.52 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23316/47780 [01:17<01:24, 290.02 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22693/47780 [01:17<01:37, 258.54 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24590/47780 [01:17<01:12, 319.90 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23694/47780 [01:17<01:09, 347.46 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11352/47780 [01:17<02:05, 290.83 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23003/47780 [01:17<01:34, 262.31 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23787/47780 [01:17<01:17, 311.22 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23020/47780 [01:17<01:39, 249.59 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23348/47780 [01:17<01:24, 289.04 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22720/47780 [01:17<01:35, 261.48 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24627/47780 [01:17<01:11, 323.24 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23729/47780 [01:17<01:10, 339.78 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11387/47780 [01:17<02:01, 300.64 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23036/47780 [01:17<01:28, 279.15 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23065/47780 [01:17<01:23, 296.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23819/47780 [01:17<01:23, 287.42 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23378/47780 [01:17<01:26, 281.28 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22747/47780 [01:17<01:39, 252.53 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11419/47780 [01:17<02:00, 302.74 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24660/47780 [01:17<01:16, 301.65 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23077/47780 [01:17<01:18, 315.07 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23765/47780 [01:17<01:14, 320.75 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23101/47780 [01:17<01:18, 312.64 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23853/47780 [01:17<01:20, 298.54 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22779/47780 [01:17<01:33, 268.46 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23407/47780 [01:17<01:31, 267.57 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11455/47780 [01:17<01:55, 315.36 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23808/47780 [01:17<01:08, 350.45 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24691/47780 [01:17<01:18, 294.06 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23138/47780 [01:17<01:15, 324.74 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23110/47780 [01:17<01:19, 308.38 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23885/47780 [01:17<01:22, 289.62 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23448/47780 [01:17<01:20, 302.70 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22807/47780 [01:17<01:33, 265.68 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11487/47780 [01:17<01:57, 309.61 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23844/47780 [01:18<01:08, 349.44 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24734/47780 [01:18<01:10, 328.03 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23142/47780 [01:18<01:19, 311.48 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23173/47780 [01:18<01:15, 327.97 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23915/47780 [01:18<01:23, 286.59 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23479/47780 [01:18<01:23, 291.83 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11522/47780 [01:18<01:53, 319.98 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23181/47780 [01:18<01:15, 327.14 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23207/47780 [01:18<01:16, 323.18 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24768/47780 [01:18<01:14, 310.46 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23882/47780 [01:18<01:12, 331.32 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22835/47780 [01:18<01:53, 219.81 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23516/47780 [01:18<01:17, 313.04 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23955/47780 [01:18<01:19, 299.60 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23216/47780 [01:18<01:15, 326.13 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11555/47780 [01:18<02:03, 293.38 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23240/47780 [01:18<01:16, 321.52 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23916/47780 [01:18<01:11, 333.25 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24801/47780 [01:18<01:15, 305.76 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22878/47780 [01:18<01:36, 259.34 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23990/47780 [01:18<01:16, 311.34 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23549/47780 [01:18<01:18, 307.64 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11587/47780 [01:18<02:00, 300.62 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23273/47780 [01:18<01:17, 317.68 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23249/47780 [01:18<01:16, 319.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23950/47780 [01:18<01:11, 331.86 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24832/47780 [01:18<01:19, 288.12 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22909/47780 [01:18<01:31, 271.02 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24022/47780 [01:18<01:16, 312.24 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23586/47780 [01:18<01:14, 324.87 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11625/47780 [01:18<01:52, 322.71 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23285/47780 [01:18<01:14, 327.72 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23984/47780 [01:18<01:13, 322.99 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23306/47780 [01:18<01:24, 288.34 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22940/47780 [01:18<01:29, 276.65 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24862/47780 [01:18<01:21, 282.13 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23625/47780 [01:18<01:11, 339.84 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24054/47780 [01:18<01:19, 297.29 examples/s]Tokenizing train dataset (num_proc=32):  24%|██▍       | 11665/47780 [01:18<01:44, 344.78 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23318/47780 [01:18<01:17, 316.38 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24017/47780 [01:18<01:17, 308.19 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23336/47780 [01:18<01:29, 273.77 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23661/47780 [01:18<01:10, 341.63 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24892/47780 [01:18<01:24, 272.26 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24091/47780 [01:18<01:15, 314.33 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22971/47780 [01:18<01:39, 248.18 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11701/47780 [01:18<01:45, 342.75 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23350/47780 [01:18<01:19, 307.47 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23371/47780 [01:18<01:23, 293.70 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23696/47780 [01:18<01:11, 335.74 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24920/47780 [01:18<01:27, 260.42 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24049/47780 [01:18<01:27, 269.80 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24123/47780 [01:18<01:16, 309.00 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11752/47780 [01:18<01:32, 389.72 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23381/47780 [01:18<01:24, 288.91 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22997/47780 [01:18<01:58, 209.11 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23734/47780 [01:18<01:10, 341.24 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23402/47780 [01:18<01:25, 285.58 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24952/47780 [01:18<01:23, 273.41 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24100/47780 [01:18<01:11, 330.89 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24157/47780 [01:18<01:16, 310.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11792/47780 [01:18<01:34, 381.12 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23412/47780 [01:18<01:24, 288.46 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23439/47780 [01:18<01:19, 305.52 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23062/47780 [01:18<01:21, 304.82 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23769/47780 [01:18<01:13, 326.15 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24136/47780 [01:18<01:12, 328.10 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24195/47780 [01:18<01:12, 326.57 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24980/47780 [01:18<01:28, 257.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11831/47780 [01:18<01:37, 369.06 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23441/47780 [01:19<01:25, 285.56 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23473/47780 [01:19<01:17, 314.92 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24173/47780 [01:19<01:10, 334.14 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24228/47780 [01:19<01:13, 320.09 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23096/47780 [01:19<01:23, 295.76 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23802/47780 [01:19<01:17, 308.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25009/47780 [01:19<01:27, 261.16 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11869/47780 [01:19<01:43, 348.36 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23477/47780 [01:19<01:21, 299.96 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23511/47780 [01:19<01:13, 328.44 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24209/47780 [01:19<01:10, 333.34 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25042/47780 [01:19<01:22, 277.06 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23128/47780 [01:19<01:24, 290.59 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24261/47780 [01:19<01:16, 305.71 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23835/47780 [01:19<01:17, 307.72 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11905/47780 [01:19<01:52, 319.94 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23508/47780 [01:19<01:24, 286.77 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24250/47780 [01:19<01:06, 353.04 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23545/47780 [01:19<01:20, 302.20 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25076/47780 [01:19<01:17, 291.27 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24296/47780 [01:19<01:14, 314.52 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23160/47780 [01:19<01:24, 291.83 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23866/47780 [01:19<01:24, 283.51 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23537/47780 [01:19<01:27, 278.37 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25106/47780 [01:19<01:18, 290.49 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24328/47780 [01:19<01:15, 309.11 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24286/47780 [01:19<01:11, 329.08 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23576/47780 [01:19<01:25, 283.22 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23191/47780 [01:19<01:27, 282.23 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23896/47780 [01:19<01:22, 287.88 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▍       | 11938/47780 [01:19<02:28, 241.48 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23576/47780 [01:19<01:20, 302.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24363/47780 [01:19<01:13, 320.62 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25136/47780 [01:19<01:22, 274.15 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23221/47780 [01:19<01:26, 283.31 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24320/47780 [01:19<01:14, 314.56 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23926/47780 [01:19<01:23, 284.27 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23605/47780 [01:19<01:29, 268.68 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12001/47780 [01:19<01:49, 326.66 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23607/47780 [01:19<01:23, 288.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24402/47780 [01:19<01:08, 340.17 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23255/47780 [01:19<01:22, 296.04 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25164/47780 [01:19<01:22, 272.97 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23634/47780 [01:19<01:28, 274.16 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23955/47780 [01:19<01:25, 278.46 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24352/47780 [01:19<01:15, 309.25 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24439/47780 [01:19<01:06, 348.77 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12039/47780 [01:19<01:53, 315.35 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23636/47780 [01:19<01:28, 274.04 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25192/47780 [01:19<01:24, 265.82 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23667/47780 [01:19<01:23, 288.27 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23288/47780 [01:19<01:23, 292.20 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24384/47780 [01:19<01:15, 308.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23995/47780 [01:19<01:16, 310.98 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23668/47780 [01:19<01:26, 280.27 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12075/47780 [01:19<01:54, 310.56 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23700/47780 [01:19<01:20, 299.88 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24417/47780 [01:19<01:14, 314.65 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25225/47780 [01:19<01:19, 283.43 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24475/47780 [01:19<01:14, 312.35 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23327/47780 [01:19<01:18, 312.46 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24031/47780 [01:19<01:14, 317.56 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23697/47780 [01:19<01:25, 282.55 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23734/47780 [01:19<01:18, 307.80 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24450/47780 [01:19<01:13, 315.94 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24508/47780 [01:19<01:13, 317.05 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23362/47780 [01:19<01:15, 322.87 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25254/47780 [01:19<01:22, 273.22 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12109/47780 [01:19<01:58, 300.14 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24063/47780 [01:19<01:19, 297.27 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23728/47780 [01:20<01:23, 287.57 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23409/47780 [01:20<01:06, 364.39 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25284/47780 [01:20<01:20, 280.64 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12143/47780 [01:20<01:54, 310.04 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24482/47780 [01:20<01:16, 302.78 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24545/47780 [01:20<01:13, 317.60 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23767/47780 [01:20<01:22, 291.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24094/47780 [01:20<01:19, 298.26 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23449/47780 [01:20<01:07, 362.41 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23757/47780 [01:20<01:30, 264.10 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24519/47780 [01:20<01:13, 318.51 examples/s]Tokenizing train dataset (num_proc=32):  25%|██▌       | 12177/47780 [01:20<01:56, 305.14 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24582/47780 [01:20<01:10, 331.02 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23800/47780 [01:20<01:19, 301.25 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24125/47780 [01:20<01:20, 294.93 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25313/47780 [01:20<01:30, 249.37 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23786/47780 [01:20<01:29, 268.26 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12211/47780 [01:20<01:54, 311.54 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23487/47780 [01:20<01:08, 355.04 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24616/47780 [01:20<01:14, 309.65 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23831/47780 [01:20<01:23, 285.97 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24159/47780 [01:20<01:19, 297.59 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25339/47780 [01:20<01:29, 249.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24554/47780 [01:20<01:20, 290.29 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23814/47780 [01:20<01:30, 265.67 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23523/47780 [01:20<01:13, 330.07 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24194/47780 [01:20<01:16, 308.80 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23860/47780 [01:20<01:27, 272.15 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25367/47780 [01:20<01:29, 249.69 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24648/47780 [01:20<01:18, 296.06 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24584/47780 [01:20<01:21, 284.60 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12243/47780 [01:20<02:15, 262.58 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23845/47780 [01:20<01:27, 274.98 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24228/47780 [01:20<01:14, 317.57 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24685/47780 [01:20<01:13, 313.37 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23888/47780 [01:20<01:28, 270.23 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25393/47780 [01:20<01:29, 249.58 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23557/47780 [01:20<01:17, 312.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24613/47780 [01:20<01:25, 272.26 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12285/47780 [01:20<01:59, 298.18 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23873/47780 [01:20<01:29, 267.07 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24263/47780 [01:20<01:13, 321.34 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25424/47780 [01:20<01:24, 263.60 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23593/47780 [01:20<01:17, 312.16 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24717/47780 [01:20<01:18, 295.06 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24648/47780 [01:20<01:20, 289.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23916/47780 [01:20<01:33, 254.14 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12317/47780 [01:20<02:03, 287.96 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23900/47780 [01:20<01:34, 253.87 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24296/47780 [01:20<01:12, 321.81 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23631/47780 [01:20<01:13, 326.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25451/47780 [01:20<01:28, 251.26 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24747/47780 [01:20<01:19, 290.74 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23954/47780 [01:20<01:23, 285.54 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12349/47780 [01:20<02:01, 291.14 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23933/47780 [01:20<01:28, 268.93 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24329/47780 [01:20<01:17, 303.11 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24779/47780 [01:20<01:17, 298.65 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25477/47780 [01:20<01:28, 250.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24678/47780 [01:20<01:42, 225.22 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23987/47780 [01:20<01:21, 292.46 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23667/47780 [01:20<01:17, 311.88 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12382/47780 [01:20<02:01, 292.08 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23961/47780 [01:20<01:31, 260.46 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24360/47780 [01:20<01:18, 298.44 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25505/47780 [01:20<01:26, 256.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24732/47780 [01:20<01:17, 295.66 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23703/47780 [01:20<01:14, 324.54 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24022/47780 [01:20<01:20, 294.79 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24810/47780 [01:20<01:25, 268.69 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12422/47780 [01:20<01:51, 317.82 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23988/47780 [01:21<01:34, 251.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25532/47780 [01:21<01:26, 257.34 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24391/47780 [01:21<01:22, 282.85 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24765/47780 [01:21<01:17, 295.13 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24058/47780 [01:21<01:16, 311.35 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23741/47780 [01:21<01:11, 336.40 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12461/47780 [01:21<01:44, 337.54 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24847/47780 [01:21<01:20, 286.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24016/47780 [01:21<01:34, 251.46 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25572/47780 [01:21<01:16, 291.30 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24424/47780 [01:21<01:18, 295.66 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24797/47780 [01:21<01:17, 295.75 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23776/47780 [01:21<01:12, 328.86 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24090/47780 [01:21<01:20, 295.76 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▌       | 12496/47780 [01:21<01:50, 319.70 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24877/47780 [01:21<01:25, 266.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24056/47780 [01:21<01:21, 292.16 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24462/47780 [01:21<01:13, 318.27 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25602/47780 [01:21<01:16, 290.53 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24829/47780 [01:21<01:19, 289.88 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23814/47780 [01:21<01:10, 339.54 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24120/47780 [01:21<01:19, 296.64 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24905/47780 [01:21<01:28, 257.13 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24086/47780 [01:21<01:21, 289.91 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12529/47780 [01:21<02:04, 282.29 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24497/47780 [01:21<01:13, 317.53 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25632/47780 [01:21<01:18, 283.56 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23850/47780 [01:21<01:09, 344.77 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24152/47780 [01:21<01:18, 300.19 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24861/47780 [01:21<01:18, 291.55 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24932/47780 [01:21<01:28, 257.77 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24118/47780 [01:21<01:19, 296.35 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12583/47780 [01:21<01:42, 344.54 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25665/47780 [01:21<01:14, 296.74 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24901/47780 [01:21<01:12, 317.72 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24529/47780 [01:21<01:18, 294.47 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23886/47780 [01:21<01:14, 322.41 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24183/47780 [01:21<01:23, 283.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12620/47780 [01:21<01:40, 350.00 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24148/47780 [01:21<01:22, 287.50 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25702/47780 [01:21<01:11, 310.66 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24559/47780 [01:21<01:19, 293.22 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24934/47780 [01:21<01:12, 313.74 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24959/47780 [01:21<01:41, 224.78 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23920/47780 [01:21<01:13, 325.06 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24214/47780 [01:21<01:21, 287.70 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25734/47780 [01:21<01:12, 305.98 examples/s]Tokenizing train dataset (num_proc=32):  26%|██▋       | 12657/47780 [01:21<01:46, 331.33 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24177/47780 [01:21<01:29, 263.94 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23956/47780 [01:21<01:11, 331.06 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24966/47780 [01:21<01:17, 296.05 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24243/47780 [01:21<01:22, 285.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24589/47780 [01:21<01:25, 270.92 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24983/47780 [01:21<01:57, 193.83 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25765/47780 [01:21<01:14, 296.98 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24208/47780 [01:21<01:26, 273.72 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12692/47780 [01:21<01:50, 318.95 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23990/47780 [01:21<01:12, 329.97 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24272/47780 [01:21<01:23, 280.03 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25011/47780 [01:21<01:08, 330.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24617/47780 [01:21<01:27, 265.25 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25010/47780 [01:21<01:48, 209.55 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25797/47780 [01:21<01:13, 297.82 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12725/47780 [01:21<01:53, 309.09 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24030/47780 [01:21<01:08, 345.99 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24236/47780 [01:21<01:31, 258.30 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24302/47780 [01:21<01:25, 273.51 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24645/47780 [01:21<01:27, 265.90 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25045/47780 [01:21<01:11, 318.63 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25074/47780 [01:21<01:11, 315.85 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25829/47780 [01:22<01:13, 299.76 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12758/47780 [01:22<01:51, 314.29 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24069/47780 [01:22<01:08, 346.71 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24263/47780 [01:22<01:33, 250.43 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25078/47780 [01:22<01:11, 318.03 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24672/47780 [01:22<01:28, 261.34 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24330/47780 [01:22<01:29, 263.08 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25871/47780 [01:22<01:06, 331.62 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25109/47780 [01:22<01:17, 291.91 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12790/47780 [01:22<01:55, 302.84 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24110/47780 [01:22<01:05, 360.63 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24291/47780 [01:22<01:32, 253.07 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24704/47780 [01:22<01:25, 268.65 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25113/47780 [01:22<01:12, 313.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24359/47780 [01:22<01:30, 259.50 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25906/47780 [01:22<01:06, 329.15 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25141/47780 [01:22<01:17, 292.42 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24318/47780 [01:22<01:31, 257.68 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12821/47780 [01:22<01:59, 292.00 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25145/47780 [01:22<01:11, 315.34 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24147/47780 [01:22<01:11, 332.79 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24735/47780 [01:22<01:23, 277.18 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24386/47780 [01:22<01:33, 251.37 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25178/47780 [01:22<01:13, 309.26 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25940/47780 [01:22<01:10, 309.56 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12859/47780 [01:22<01:50, 315.91 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24767/47780 [01:22<01:21, 282.72 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25177/47780 [01:22<01:13, 306.42 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24345/47780 [01:22<01:37, 239.35 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24412/47780 [01:22<01:34, 247.53 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24181/47780 [01:22<01:20, 293.18 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25218/47780 [01:22<01:07, 333.48 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25974/47780 [01:22<01:08, 317.30 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12891/47780 [01:22<01:52, 309.11 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25212/47780 [01:22<01:10, 318.61 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24796/47780 [01:22<01:22, 277.10 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24374/47780 [01:22<01:35, 245.39 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24441/47780 [01:22<01:32, 251.68 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25259/47780 [01:22<01:04, 351.08 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24212/47780 [01:22<01:26, 272.49 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26010/47780 [01:22<01:08, 316.31 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24827/47780 [01:22<01:20, 284.81 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12923/47780 [01:22<02:02, 284.52 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25245/47780 [01:22<01:14, 304.51 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24399/47780 [01:22<01:38, 238.46 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24476/47780 [01:22<01:23, 278.59 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24247/47780 [01:22<01:20, 291.83 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25297/47780 [01:22<01:06, 339.02 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26043/47780 [01:22<01:09, 313.14 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24857/47780 [01:22<01:20, 285.92 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 12975/47780 [01:22<01:40, 347.42 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25284/47780 [01:22<01:09, 324.76 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24427/47780 [01:22<01:34, 247.44 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24507/47780 [01:22<01:22, 281.37 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24280/47780 [01:22<01:17, 301.74 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25334/47780 [01:22<01:05, 344.64 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26076/47780 [01:22<01:09, 314.44 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13017/47780 [01:22<01:34, 367.19 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25318/47780 [01:22<01:09, 321.38 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24462/47780 [01:22<01:25, 273.04 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24886/47780 [01:22<01:25, 267.73 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24541/47780 [01:22<01:22, 281.99 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24311/47780 [01:22<01:20, 291.52 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26108/47780 [01:22<01:09, 312.38 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25370/47780 [01:22<01:07, 334.13 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13059/47780 [01:22<01:31, 378.27 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25354/47780 [01:22<01:07, 332.30 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24493/47780 [01:22<01:23, 280.36 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24926/47780 [01:22<01:16, 298.59 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24574/47780 [01:22<01:20, 288.93 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26140/47780 [01:22<01:08, 314.15 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24346/47780 [01:22<01:17, 300.64 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25389/47780 [01:23<01:07, 330.15 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13100/47780 [01:23<01:33, 370.23 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24525/47780 [01:23<01:19, 291.44 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25406/47780 [01:23<01:13, 304.28 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24958/47780 [01:23<01:14, 304.56 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24603/47780 [01:23<01:22, 279.69 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26172/47780 [01:23<01:10, 305.64 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24377/47780 [01:23<01:18, 299.83 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25426/47780 [01:23<01:06, 337.74 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24557/47780 [01:23<01:19, 292.88 examples/s]Tokenizing train dataset (num_proc=32):  27%|██▋       | 13138/47780 [01:23<01:35, 364.38 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24989/47780 [01:23<01:16, 297.10 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24634/47780 [01:23<01:20, 288.10 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26203/47780 [01:23<01:10, 305.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25438/47780 [01:23<01:24, 263.88 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24408/47780 [01:23<01:20, 289.91 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25460/47780 [01:23<01:06, 334.58 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13175/47780 [01:23<01:40, 343.42 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24587/47780 [01:23<01:24, 275.83 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24663/47780 [01:23<01:22, 279.06 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25019/47780 [01:23<01:24, 269.44 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26239/47780 [01:23<01:07, 320.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25508/47780 [01:23<01:00, 366.24 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24438/47780 [01:23<01:26, 268.88 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13216/47780 [01:23<01:36, 357.62 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24619/47780 [01:23<01:21, 285.31 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25494/47780 [01:23<01:15, 295.28 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24694/47780 [01:23<01:21, 284.86 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25047/47780 [01:23<01:23, 272.16 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26272/47780 [01:23<01:07, 317.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25548/47780 [01:23<01:00, 367.42 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24469/47780 [01:23<01:24, 276.92 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24648/47780 [01:23<01:20, 286.46 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24725/47780 [01:23<01:19, 288.67 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25075/47780 [01:23<01:26, 262.75 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13253/47780 [01:23<01:45, 328.02 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26313/47780 [01:23<01:02, 344.37 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25587/47780 [01:23<01:01, 361.93 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24498/47780 [01:23<01:26, 268.39 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25526/47780 [01:23<01:32, 240.38 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24677/47780 [01:23<01:27, 263.34 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24759/47780 [01:23<01:17, 296.78 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25102/47780 [01:23<01:26, 261.85 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13287/47780 [01:23<01:45, 327.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26350/47780 [01:23<01:00, 351.55 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25625/47780 [01:23<01:07, 328.12 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24527/47780 [01:23<01:25, 271.29 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25607/47780 [01:23<00:59, 372.77 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24803/47780 [01:23<01:08, 337.76 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25132/47780 [01:23<01:24, 269.41 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13326/47780 [01:23<01:44, 329.99 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26386/47780 [01:23<01:04, 330.50 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24559/47780 [01:23<01:21, 284.61 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24704/47780 [01:23<01:44, 221.15 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25660/47780 [01:23<01:07, 326.49 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24845/47780 [01:23<01:04, 357.24 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26427/47780 [01:23<01:00, 352.86 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25650/47780 [01:23<01:06, 333.71 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25160/47780 [01:23<01:31, 246.72 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13360/47780 [01:23<01:57, 293.89 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24592/47780 [01:23<01:18, 294.79 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24741/47780 [01:23<01:30, 253.20 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25697/47780 [01:23<01:05, 334.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24881/47780 [01:23<01:06, 342.30 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26464/47780 [01:23<01:00, 354.57 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25191/47780 [01:23<01:26, 261.43 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25688/47780 [01:23<01:07, 325.93 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24623/47780 [01:23<01:17, 298.93 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13391/47780 [01:23<01:56, 295.13 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25735/47780 [01:23<01:03, 346.91 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24768/47780 [01:24<01:33, 244.85 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24916/47780 [01:24<01:10, 322.53 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26500/47780 [01:24<01:01, 348.28 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25218/47780 [01:24<01:28, 255.30 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24658/47780 [01:24<01:14, 310.00 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25724/47780 [01:24<01:09, 318.73 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25771/47780 [01:24<01:04, 339.01 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13422/47780 [01:24<02:04, 276.31 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24794/47780 [01:24<01:36, 238.84 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24949/47780 [01:24<01:13, 310.81 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26536/47780 [01:24<01:04, 331.85 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25246/47780 [01:24<01:26, 259.35 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24691/47780 [01:24<01:13, 312.64 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25806/47780 [01:24<01:04, 338.11 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13451/47780 [01:24<02:06, 271.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24823/47780 [01:24<01:33, 246.35 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24983/47780 [01:24<01:13, 311.97 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25276/47780 [01:24<01:24, 267.70 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26574/47780 [01:24<01:04, 331.19 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24726/47780 [01:24<01:11, 323.46 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25759/47780 [01:24<01:28, 250.16 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25841/47780 [01:24<01:09, 317.11 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13488/47780 [01:24<01:57, 291.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24849/47780 [01:24<01:33, 245.34 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25015/47780 [01:24<01:13, 310.74 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25303/47780 [01:24<01:26, 259.36 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24759/47780 [01:24<01:11, 321.47 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26609/47780 [01:24<01:04, 328.71 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25812/47780 [01:24<01:11, 307.15 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25874/47780 [01:24<01:09, 317.13 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24876/47780 [01:24<01:31, 249.80 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13518/47780 [01:24<02:05, 273.03 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25047/47780 [01:24<01:14, 303.21 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25341/47780 [01:24<01:17, 290.31 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24795/47780 [01:24<01:09, 332.71 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26645/47780 [01:24<01:08, 309.85 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25849/47780 [01:24<01:09, 315.73 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24902/47780 [01:24<01:31, 249.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25907/47780 [01:24<01:09, 313.80 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13560/47780 [01:24<01:49, 311.55 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25080/47780 [01:24<01:13, 310.63 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25380/47780 [01:24<01:10, 318.63 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24831/47780 [01:24<01:09, 328.74 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26677/47780 [01:24<01:09, 303.13 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25893/47780 [01:24<01:04, 339.72 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24930/47780 [01:24<01:28, 257.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25948/47780 [01:24<01:04, 336.90 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25115/47780 [01:24<01:10, 321.79 examples/s]Tokenizing train dataset (num_proc=32):  28%|██▊       | 13592/47780 [01:24<01:58, 288.86 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24868/47780 [01:24<01:07, 337.44 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25414/47780 [01:24<01:15, 296.89 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26708/47780 [01:24<01:09, 301.56 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25932/47780 [01:24<01:02, 348.85 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25987/47780 [01:24<01:02, 349.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24961/47780 [01:24<01:25, 267.33 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25156/47780 [01:24<01:05, 346.12 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13622/47780 [01:24<02:02, 279.17 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24902/47780 [01:24<01:10, 326.36 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25447/47780 [01:24<01:14, 299.81 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26739/47780 [01:24<01:09, 300.80 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25970/47780 [01:24<01:01, 353.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24992/47780 [01:24<01:21, 279.36 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26023/47780 [01:24<01:07, 321.36 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25191/47780 [01:24<01:07, 332.66 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24936/47780 [01:24<01:10, 323.18 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25480/47780 [01:24<01:13, 304.82 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13651/47780 [01:24<02:14, 253.30 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26008/47780 [01:24<01:01, 356.21 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25023/47780 [01:24<01:19, 285.28 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26770/47780 [01:24<01:13, 286.54 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26059/47780 [01:24<01:05, 331.29 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25227/47780 [01:24<01:06, 336.98 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24969/47780 [01:25<01:10, 321.39 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25518/47780 [01:25<01:10, 316.60 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▊       | 13687/47780 [01:25<02:01, 280.25 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25052/47780 [01:25<01:21, 279.85 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26799/47780 [01:25<01:13, 284.95 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26045/47780 [01:25<01:06, 324.43 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26093/47780 [01:25<01:10, 307.25 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25261/47780 [01:25<01:08, 326.57 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25002/47780 [01:25<01:11, 316.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13716/47780 [01:25<02:01, 279.88 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26838/47780 [01:25<01:07, 310.98 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25550/47780 [01:25<01:18, 284.31 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25081/47780 [01:25<01:26, 261.91 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26125/47780 [01:25<01:09, 310.49 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25297/47780 [01:25<01:07, 332.22 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26079/47780 [01:25<01:12, 299.94 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25034/47780 [01:25<01:12, 313.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13745/47780 [01:25<02:01, 279.59 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26870/47780 [01:25<01:06, 312.71 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25111/47780 [01:25<01:23, 272.31 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25580/47780 [01:25<01:19, 279.66 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26167/47780 [01:25<01:04, 337.22 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25331/47780 [01:25<01:09, 323.39 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26111/47780 [01:25<01:13, 293.32 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25066/47780 [01:25<01:14, 305.06 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13774/47780 [01:25<02:01, 279.51 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26902/47780 [01:25<01:09, 301.04 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25141/47780 [01:25<01:20, 280.08 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25612/47780 [01:25<01:16, 289.73 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26202/47780 [01:25<01:08, 316.02 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25365/47780 [01:25<01:12, 307.21 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25097/47780 [01:25<01:14, 302.82 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13804/47780 [01:25<01:59, 284.68 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26934/47780 [01:25<01:08, 303.00 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26142/47780 [01:25<01:24, 257.47 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25648/47780 [01:25<01:12, 305.10 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25170/47780 [01:25<01:26, 262.02 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26253/47780 [01:25<00:58, 368.55 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13837/47780 [01:25<01:55, 294.91 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25128/47780 [01:25<01:17, 292.01 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25396/47780 [01:25<01:17, 288.59 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26174/47780 [01:25<01:20, 269.93 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26965/47780 [01:25<01:12, 288.54 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25679/47780 [01:25<01:13, 300.20 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25210/47780 [01:25<01:16, 293.57 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26291/47780 [01:25<00:59, 359.12 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25164/47780 [01:25<01:12, 310.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13867/47780 [01:25<01:58, 286.45 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25426/47780 [01:25<01:19, 280.03 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26206/47780 [01:25<01:17, 279.90 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25710/47780 [01:25<01:13, 300.80 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25241/47780 [01:25<01:16, 294.78 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26995/47780 [01:25<01:15, 273.96 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26328/47780 [01:25<01:00, 351.86 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25196/47780 [01:25<01:14, 304.46 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13898/47780 [01:25<01:58, 286.21 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25460/47780 [01:25<01:15, 296.06 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25741/47780 [01:25<01:12, 303.35 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26235/47780 [01:25<01:18, 273.62 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25271/47780 [01:25<01:16, 295.11 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27028/47780 [01:25<01:12, 286.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25229/47780 [01:25<01:12, 310.51 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13932/47780 [01:25<01:54, 295.27 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26364/47780 [01:25<01:09, 307.40 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26263/47780 [01:25<01:20, 267.16 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25772/47780 [01:25<01:18, 282.03 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25302/47780 [01:25<01:19, 284.20 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25490/47780 [01:25<01:25, 259.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27061/47780 [01:25<01:11, 288.71 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13962/47780 [01:25<01:55, 292.86 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25261/47780 [01:25<01:15, 299.07 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25801/47780 [01:26<01:18, 281.52 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25331/47780 [01:26<01:18, 285.62 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26396/47780 [01:26<01:13, 290.69 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26291/47780 [01:26<01:23, 257.02 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25534/47780 [01:26<01:13, 303.00 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27092/47780 [01:26<01:12, 285.10 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 13995/47780 [01:26<01:54, 293.80 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25837/47780 [01:26<01:12, 303.59 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26434/47780 [01:26<01:08, 310.69 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26317/47780 [01:26<01:23, 256.90 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25368/47780 [01:26<01:13, 303.04 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25571/47780 [01:26<01:09, 317.35 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25293/47780 [01:26<01:26, 261.20 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27130/47780 [01:26<01:07, 304.69 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14026/47780 [01:26<01:55, 292.62 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25874/47780 [01:26<01:08, 318.97 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26347/47780 [01:26<01:20, 266.32 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25404/47780 [01:26<01:10, 315.54 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25604/47780 [01:26<01:11, 310.55 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26466/47780 [01:26<01:11, 300.02 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27161/47780 [01:26<01:11, 286.99 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14056/47780 [01:26<01:57, 287.33 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25321/47780 [01:26<01:44, 215.22 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25916/47780 [01:26<01:03, 344.13 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25440/47780 [01:26<01:08, 324.93 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26378/47780 [01:26<01:20, 266.60 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25637/47780 [01:26<01:10, 312.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26497/47780 [01:26<01:13, 287.72 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27190/47780 [01:26<01:15, 272.90 examples/s]Tokenizing train dataset (num_proc=32):  29%|██▉       | 14085/47780 [01:26<02:03, 272.56 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25403/47780 [01:26<01:03, 353.38 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25672/47780 [01:26<01:09, 319.65 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25951/47780 [01:26<01:08, 318.18 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26409/47780 [01:26<01:18, 272.74 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25473/47780 [01:26<01:13, 305.16 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26527/47780 [01:26<01:13, 287.89 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27218/47780 [01:26<01:18, 263.34 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14113/47780 [01:26<02:06, 265.81 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26438/47780 [01:26<01:17, 274.42 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25984/47780 [01:26<01:08, 316.28 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25705/47780 [01:26<01:10, 312.05 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25507/47780 [01:26<01:11, 311.26 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26562/47780 [01:26<01:10, 301.60 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25444/47780 [01:26<01:07, 329.95 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14140/47780 [01:26<02:07, 263.87 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27245/47780 [01:26<01:25, 239.44 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25737/47780 [01:26<01:11, 308.97 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25544/47780 [01:26<01:08, 324.19 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26593/47780 [01:26<01:10, 300.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26016/47780 [01:26<01:11, 306.44 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25482/47780 [01:26<01:07, 331.28 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26466/47780 [01:26<01:28, 240.54 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14170/47780 [01:26<02:03, 271.29 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27270/47780 [01:26<01:27, 234.80 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26051/47780 [01:26<01:08, 318.52 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26624/47780 [01:26<01:11, 296.45 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25579/47780 [01:26<01:10, 317.08 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25769/47780 [01:26<01:14, 293.62 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26491/47780 [01:26<01:28, 239.84 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25518/47780 [01:26<01:12, 307.07 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14199/47780 [01:26<02:01, 276.48 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27297/47780 [01:26<01:23, 243.98 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26658/47780 [01:26<01:09, 305.38 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25612/47780 [01:26<01:10, 313.55 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25807/47780 [01:26<01:10, 311.52 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26084/47780 [01:26<01:14, 291.56 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26516/47780 [01:26<01:30, 235.61 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14228/47780 [01:26<02:01, 277.14 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27323/47780 [01:26<01:24, 243.25 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25551/47780 [01:27<01:22, 270.57 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26689/47780 [01:27<01:10, 299.24 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25840/47780 [01:27<01:11, 305.73 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26121/47780 [01:27<01:09, 310.06 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26542/47780 [01:27<01:28, 240.00 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25647/47780 [01:27<01:15, 293.73 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14257/47780 [01:27<02:02, 274.61 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27348/47780 [01:27<01:25, 239.89 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25592/47780 [01:27<01:14, 297.52 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25872/47780 [01:27<01:13, 299.68 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26154/47780 [01:27<01:10, 308.56 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26720/47780 [01:27<01:17, 271.66 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26567/47780 [01:27<01:30, 234.60 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14285/47780 [01:27<02:04, 269.95 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25679/47780 [01:27<01:22, 269.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27379/47780 [01:27<01:22, 248.27 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25624/47780 [01:27<01:13, 300.15 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25907/47780 [01:27<01:10, 310.09 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26199/47780 [01:27<01:04, 337.09 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26748/47780 [01:27<01:17, 271.29 examples/s]Tokenizing train dataset (num_proc=32):  30%|██▉       | 14313/47780 [01:27<02:02, 272.80 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25731/47780 [01:27<01:07, 326.69 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26591/47780 [01:27<01:40, 210.51 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27413/47780 [01:27<01:14, 273.53 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25662/47780 [01:27<01:09, 317.40 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25942/47780 [01:27<01:08, 317.89 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26776/47780 [01:27<01:17, 270.78 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26234/47780 [01:27<01:04, 331.53 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14341/47780 [01:27<02:09, 257.91 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27444/47780 [01:27<01:12, 280.79 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26623/47780 [01:27<01:29, 236.56 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25765/47780 [01:27<01:08, 320.05 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25703/47780 [01:27<01:04, 341.84 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25975/47780 [01:27<01:08, 317.68 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26268/47780 [01:27<01:09, 310.77 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26804/47780 [01:27<01:23, 250.62 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14369/47780 [01:27<02:06, 264.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26649/47780 [01:27<01:29, 235.29 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27473/47780 [01:27<01:15, 270.46 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25798/47780 [01:27<01:11, 309.46 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25739/47780 [01:27<01:05, 337.77 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26007/47780 [01:27<01:13, 297.66 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14397/47780 [01:27<02:06, 264.63 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26300/47780 [01:27<01:13, 291.69 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26677/47780 [01:27<01:25, 247.35 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27506/47780 [01:27<01:11, 284.45 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26830/47780 [01:27<01:30, 230.72 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25774/47780 [01:27<01:07, 328.41 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25830/47780 [01:27<01:14, 296.36 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26042/47780 [01:27<01:11, 305.57 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14424/47780 [01:27<02:14, 248.79 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26704/47780 [01:27<01:29, 235.28 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27535/47780 [01:27<01:14, 270.50 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25862/47780 [01:27<01:13, 299.73 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26330/47780 [01:27<01:20, 265.72 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25808/47780 [01:27<01:09, 317.61 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26855/47780 [01:27<01:37, 213.61 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26073/47780 [01:27<01:11, 303.49 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26731/47780 [01:27<01:26, 242.15 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14450/47780 [01:27<02:25, 229.32 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26358/47780 [01:27<01:21, 263.76 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25894/47780 [01:27<01:14, 292.48 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25843/47780 [01:27<01:07, 326.26 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26881/47780 [01:27<01:34, 221.21 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27563/47780 [01:27<01:21, 247.98 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26104/47780 [01:27<01:17, 279.76 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26756/47780 [01:27<01:28, 238.64 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26386/47780 [01:27<01:20, 265.57 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14480/47780 [01:27<02:15, 244.89 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25877/47780 [01:27<01:10, 312.32 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27589/47780 [01:28<01:21, 249.11 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25924/47780 [01:28<01:19, 273.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26133/47780 [01:28<01:18, 276.78 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26904/47780 [01:28<01:49, 189.88 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26787/47780 [01:28<01:22, 254.00 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26415/47780 [01:28<01:18, 272.01 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14506/47780 [01:28<02:14, 246.65 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27621/47780 [01:28<01:15, 265.47 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25952/47780 [01:28<01:19, 275.00 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25909/47780 [01:28<01:14, 295.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26161/47780 [01:28<01:17, 277.61 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26817/47780 [01:28<01:19, 264.81 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26446/47780 [01:28<01:16, 279.61 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14534/47780 [01:28<02:10, 255.32 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27649/47780 [01:28<01:16, 263.40 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25980/47780 [01:28<01:20, 270.36 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25949/47780 [01:28<01:07, 323.45 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26924/47780 [01:28<02:10, 160.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26193/47780 [01:28<01:14, 289.35 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26853/47780 [01:28<01:12, 290.11 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26476/47780 [01:28<01:15, 282.21 examples/s]Tokenizing train dataset (num_proc=32):  30%|███       | 14565/47780 [01:28<02:04, 266.39 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27680/47780 [01:28<01:13, 273.70 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25983/47780 [01:28<01:09, 314.22 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26008/47780 [01:28<01:24, 256.36 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26224/47780 [01:28<01:13, 295.13 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26986/47780 [01:28<01:20, 257.53 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26883/47780 [01:28<01:12, 286.38 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14594/47780 [01:28<02:01, 272.17 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26505/47780 [01:28<01:17, 274.83 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27712/47780 [01:28<01:10, 283.62 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26022/47780 [01:28<01:05, 331.53 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26039/47780 [01:28<01:21, 265.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26255/47780 [01:28<01:15, 283.40 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27016/47780 [01:28<01:22, 253.07 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14622/47780 [01:28<02:05, 264.65 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26533/47780 [01:28<01:18, 270.38 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26912/47780 [01:28<01:15, 274.76 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27741/47780 [01:28<01:14, 270.12 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26056/47780 [01:28<01:06, 326.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26071/47780 [01:28<01:17, 279.94 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26289/47780 [01:28<01:14, 289.45 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27048/47780 [01:28<01:18, 264.31 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26943/47780 [01:28<01:13, 284.60 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26563/47780 [01:28<01:16, 278.74 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14649/47780 [01:28<02:05, 263.25 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26089/47780 [01:28<01:06, 323.84 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27769/47780 [01:28<01:16, 260.91 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26100/47780 [01:28<01:19, 273.79 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26330/47780 [01:28<01:07, 316.12 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27077/47780 [01:28<01:21, 252.91 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26591/47780 [01:28<01:16, 275.51 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26972/47780 [01:28<01:14, 279.55 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14676/47780 [01:28<02:15, 243.57 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26128/47780 [01:28<01:20, 269.43 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26122/47780 [01:28<01:11, 304.89 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27796/47780 [01:28<01:20, 247.14 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26362/47780 [01:28<01:12, 296.88 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27104/47780 [01:28<01:22, 251.95 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26619/47780 [01:28<01:21, 259.06 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27002/47780 [01:28<01:17, 267.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14701/47780 [01:28<02:23, 230.11 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26158/47780 [01:28<01:18, 275.42 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26161/47780 [01:28<01:07, 322.03 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27821/47780 [01:28<01:23, 237.81 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26395/47780 [01:28<01:10, 303.09 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27131/47780 [01:28<01:23, 246.55 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26649/47780 [01:28<01:20, 261.90 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27033/47780 [01:28<01:15, 273.02 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14738/47780 [01:28<02:07, 259.23 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26196/47780 [01:28<01:05, 328.83 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26186/47780 [01:28<01:20, 266.78 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26428/47780 [01:28<01:08, 310.57 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27845/47780 [01:29<01:30, 220.61 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27161/47780 [01:29<01:19, 257.99 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26680/47780 [01:29<01:17, 272.30 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27072/47780 [01:29<01:09, 299.14 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26231/47780 [01:29<01:04, 333.69 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14765/47780 [01:29<02:09, 253.99 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26215/47780 [01:29<01:20, 267.71 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26464/47780 [01:29<01:06, 320.94 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27869/47780 [01:29<01:29, 222.05 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27188/47780 [01:29<01:18, 260.81 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26710/47780 [01:29<01:15, 279.95 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27119/47780 [01:29<00:59, 346.58 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26268/47780 [01:29<01:03, 337.69 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14791/47780 [01:29<02:14, 246.07 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26246/47780 [01:29<01:21, 264.66 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26497/47780 [01:29<01:09, 305.72 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27902/47780 [01:29<01:19, 248.58 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27216/47780 [01:29<01:18, 260.64 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27156/47780 [01:29<00:58, 353.26 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26739/47780 [01:29<01:18, 267.46 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26309/47780 [01:29<01:00, 354.44 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14816/47780 [01:29<02:16, 240.74 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26273/47780 [01:29<01:23, 257.55 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26528/47780 [01:29<01:11, 296.80 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27192/47780 [01:29<00:59, 347.57 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27244/47780 [01:29<01:21, 251.96 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27928/47780 [01:29<01:26, 228.94 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26766/47780 [01:29<01:19, 265.35 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26345/47780 [01:29<01:00, 351.90 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14842/47780 [01:29<02:15, 243.32 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26299/47780 [01:29<01:23, 258.22 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26562/47780 [01:29<01:10, 302.57 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27228/47780 [01:29<01:00, 339.45 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27270/47780 [01:29<01:23, 244.85 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26793/47780 [01:29<01:19, 263.36 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27957/47780 [01:29<01:25, 232.79 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26381/47780 [01:29<01:01, 350.23 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14882/47780 [01:29<01:55, 284.03 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26325/47780 [01:29<01:23, 258.21 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26832/47780 [01:29<01:11, 293.22 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27263/47780 [01:29<01:04, 320.13 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26593/47780 [01:29<01:19, 265.36 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26420/47780 [01:29<00:59, 357.63 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27981/47780 [01:29<01:28, 222.97 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26352/47780 [01:29<01:22, 259.25 examples/s]Tokenizing train dataset (num_proc=32):  31%|███       | 14911/47780 [01:29<01:57, 279.36 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27295/47780 [01:29<01:34, 216.21 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26866/47780 [01:29<01:08, 306.54 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27298/47780 [01:29<01:03, 321.76 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26456/47780 [01:29<01:00, 350.17 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28004/47780 [01:29<01:29, 219.82 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26379/47780 [01:29<01:21, 262.25 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26621/47780 [01:29<01:24, 249.06 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27318/47780 [01:29<01:35, 213.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 14941/47780 [01:29<02:04, 264.23 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26897/47780 [01:29<01:11, 293.20 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27332/47780 [01:29<01:06, 309.05 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28028/47780 [01:29<01:29, 220.84 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26408/47780 [01:29<01:19, 267.30 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27340/47780 [01:29<01:39, 206.28 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26647/47780 [01:29<01:29, 237.28 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26492/47780 [01:29<01:08, 310.13 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 14975/47780 [01:29<01:58, 275.92 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26931/47780 [01:29<01:10, 293.87 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28056/47780 [01:29<01:24, 234.50 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27365/47780 [01:29<01:05, 311.98 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26441/47780 [01:29<01:17, 275.83 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26673/47780 [01:29<01:27, 240.64 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27362/47780 [01:29<01:39, 205.70 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26524/47780 [01:29<01:08, 309.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 15003/47780 [01:29<02:06, 259.18 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26963/47780 [01:30<01:10, 294.50 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26473/47780 [01:30<01:14, 286.68 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28089/47780 [01:30<01:18, 249.92 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27398/47780 [01:30<01:08, 296.81 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27384/47780 [01:30<01:37, 209.53 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26701/47780 [01:30<01:26, 243.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26556/47780 [01:30<01:09, 305.23 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 15038/47780 [01:30<01:57, 278.34 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27001/47780 [01:30<01:05, 318.40 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26507/47780 [01:30<01:10, 300.72 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27430/47780 [01:30<01:08, 296.85 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28117/47780 [01:30<01:20, 244.74 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27415/47780 [01:30<01:27, 232.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26587/47780 [01:30<01:09, 303.12 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15068/47780 [01:30<01:56, 281.25 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26727/47780 [01:30<01:31, 230.46 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27034/47780 [01:30<01:08, 301.26 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27463/47780 [01:30<01:07, 302.67 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28151/47780 [01:30<01:12, 269.28 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27445/47780 [01:30<01:20, 251.35 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26538/47780 [01:30<01:15, 280.57 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26751/47780 [01:30<01:33, 225.87 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15097/47780 [01:30<01:59, 273.81 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26618/47780 [01:30<01:17, 274.50 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27065/47780 [01:30<01:08, 303.67 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27507/47780 [01:30<01:00, 337.30 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27477/47780 [01:30<01:14, 270.97 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28179/47780 [01:30<01:15, 258.94 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26567/47780 [01:30<01:18, 271.02 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26774/47780 [01:30<01:33, 224.57 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26649/47780 [01:30<01:16, 275.50 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27096/47780 [01:30<01:08, 301.78 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15125/47780 [01:30<02:18, 236.27 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27542/47780 [01:30<01:00, 337.14 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27506/47780 [01:30<01:15, 267.02 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28207/47780 [01:30<01:14, 262.21 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26595/47780 [01:30<01:20, 261.74 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26797/47780 [01:30<01:33, 224.47 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26679/47780 [01:30<01:17, 272.89 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27135/47780 [01:30<01:03, 323.60 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15169/47780 [01:30<01:54, 285.64 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27576/47780 [01:30<01:00, 333.60 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28234/47780 [01:30<01:14, 261.16 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27533/47780 [01:30<01:19, 253.60 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26624/47780 [01:30<01:19, 266.85 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26820/47780 [01:30<01:33, 224.91 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26709/47780 [01:30<01:18, 267.65 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27172/47780 [01:30<01:03, 325.65 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27614/47780 [01:30<00:58, 343.45 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15206/47780 [01:30<01:46, 304.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27561/47780 [01:30<01:17, 259.23 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26652/47780 [01:30<01:21, 258.99 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28261/47780 [01:30<01:21, 239.53 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26846/47780 [01:30<01:32, 227.34 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26736/47780 [01:30<01:20, 260.92 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27205/47780 [01:30<01:05, 312.74 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27649/47780 [01:30<00:58, 341.48 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15238/47780 [01:30<01:47, 302.33 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27591/47780 [01:30<01:16, 265.24 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26682/47780 [01:30<01:18, 270.28 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28288/47780 [01:30<01:18, 247.67 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26875/47780 [01:30<01:25, 245.04 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26767/47780 [01:30<01:17, 271.31 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27237/47780 [01:30<01:08, 301.15 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15278/47780 [01:30<01:44, 311.94 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27684/47780 [01:30<01:03, 318.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27618/47780 [01:30<01:16, 261.95 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26902/47780 [01:30<01:23, 250.92 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26710/47780 [01:30<01:20, 260.71 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28314/47780 [01:30<01:22, 235.49 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26795/47780 [01:30<01:16, 273.53 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27645/47780 [01:31<01:17, 261.30 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27268/47780 [01:31<01:11, 285.61 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27718/47780 [01:31<01:05, 307.08 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15310/47780 [01:31<01:51, 292.11 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26738/47780 [01:31<01:19, 263.67 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26928/47780 [01:31<01:24, 246.27 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28338/47780 [01:31<01:23, 234.20 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26828/47780 [01:31<01:13, 286.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27299/47780 [01:31<01:10, 292.06 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15343/47780 [01:31<01:47, 302.08 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26954/47780 [01:31<01:23, 250.20 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26770/47780 [01:31<01:16, 273.32 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27749/47780 [01:31<01:08, 291.64 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27672/47780 [01:31<01:23, 239.41 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28372/47780 [01:31<01:14, 260.59 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26861/47780 [01:31<01:10, 295.62 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27329/47780 [01:31<01:11, 284.63 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26980/47780 [01:31<01:25, 244.39 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27780/47780 [01:31<01:08, 293.81 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28406/47780 [01:31<01:08, 282.90 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27697/47780 [01:31<01:24, 238.85 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26798/47780 [01:31<01:19, 265.53 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15374/47780 [01:31<01:58, 272.70 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26900/47780 [01:31<01:06, 315.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27364/47780 [01:31<01:08, 298.84 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27811/47780 [01:31<01:07, 294.89 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27009/47780 [01:31<01:22, 251.84 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28443/47780 [01:31<01:03, 303.77 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26829/47780 [01:31<01:15, 275.74 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27722/47780 [01:31<01:27, 229.69 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15403/47780 [01:31<02:00, 267.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26932/47780 [01:31<01:09, 301.70 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27395/47780 [01:31<01:08, 298.64 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28477/47780 [01:31<01:02, 311.14 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27842/47780 [01:31<01:08, 292.47 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26857/47780 [01:31<01:16, 273.80 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27036/47780 [01:31<01:25, 243.17 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15431/47780 [01:31<02:00, 267.72 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27746/47780 [01:31<01:30, 222.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26964/47780 [01:31<01:09, 298.10 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27427/47780 [01:31<01:07, 301.35 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27874/47780 [01:31<01:06, 300.04 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26885/47780 [01:31<01:17, 269.32 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28509/47780 [01:31<01:05, 293.28 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27061/47780 [01:31<01:26, 239.31 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15465/47780 [01:31<01:53, 284.51 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27769/47780 [01:31<01:34, 211.12 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 26996/47780 [01:31<01:12, 284.91 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27462/47780 [01:31<01:04, 315.25 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27905/47780 [01:31<01:07, 292.71 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26913/47780 [01:31<01:16, 271.03 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27088/47780 [01:31<01:24, 245.61 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28546/47780 [01:31<01:02, 307.83 examples/s]Tokenizing train dataset (num_proc=32):  32%|███▏      | 15494/47780 [01:31<01:55, 279.85 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27791/47780 [01:31<01:38, 202.66 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27495/47780 [01:31<01:05, 311.98 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27025/47780 [01:31<01:16, 272.72 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26942/47780 [01:31<01:16, 271.68 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27113/47780 [01:31<01:26, 239.41 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28582/47780 [01:31<01:00, 315.33 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27935/47780 [01:31<01:12, 273.12 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15532/47780 [01:31<01:45, 304.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27822/47780 [01:31<01:27, 228.68 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27058/47780 [01:31<01:12, 286.99 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27531/47780 [01:31<01:03, 318.79 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26970/47780 [01:31<01:15, 274.02 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27143/47780 [01:31<01:21, 252.86 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28614/47780 [01:31<01:01, 313.21 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27969/47780 [01:31<01:09, 285.33 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15563/47780 [01:31<01:51, 289.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27849/47780 [01:31<01:23, 239.94 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27563/47780 [01:31<01:03, 318.87 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27087/47780 [01:31<01:13, 281.72 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28647/47780 [01:32<01:00, 316.73 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27170/47780 [01:32<01:21, 252.00 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 26998/47780 [01:32<01:23, 249.59 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27998/47780 [01:32<01:10, 280.61 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15596/47780 [01:32<01:48, 297.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27883/47780 [01:32<01:15, 265.11 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27124/47780 [01:32<01:08, 302.84 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27595/47780 [01:32<01:09, 288.86 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28679/47780 [01:32<01:00, 315.38 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28033/47780 [01:32<01:07, 293.43 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27198/47780 [01:32<01:21, 251.34 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27024/47780 [01:32<01:25, 244.00 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15630/47780 [01:32<01:46, 302.41 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27910/47780 [01:32<01:18, 251.86 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27155/47780 [01:32<01:10, 291.67 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27625/47780 [01:32<01:09, 289.11 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28712/47780 [01:32<01:01, 312.02 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27229/47780 [01:32<01:17, 264.17 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27064/47780 [01:32<01:13, 281.12 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28063/47780 [01:32<01:10, 279.03 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15661/47780 [01:32<01:52, 285.11 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27936/47780 [01:32<01:21, 243.72 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27185/47780 [01:32<01:11, 287.55 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27659/47780 [01:32<01:07, 299.89 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28744/47780 [01:32<01:01, 310.96 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28095/47780 [01:32<01:08, 287.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27256/47780 [01:32<01:21, 252.21 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27093/47780 [01:32<01:20, 257.87 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15692/47780 [01:32<01:53, 282.95 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27215/47780 [01:32<01:10, 290.88 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27961/47780 [01:32<01:24, 235.03 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27696/47780 [01:32<01:03, 316.26 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28782/47780 [01:32<00:57, 330.64 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28130/47780 [01:32<01:04, 305.08 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15724/47780 [01:32<01:50, 290.17 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27282/47780 [01:32<01:26, 236.13 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27120/47780 [01:32<01:22, 250.16 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27985/47780 [01:32<01:27, 226.40 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27728/47780 [01:32<01:06, 302.88 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27245/47780 [01:32<01:16, 268.46 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28816/47780 [01:32<00:58, 321.67 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28161/47780 [01:32<01:06, 292.97 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27307/47780 [01:32<01:26, 237.07 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15754/47780 [01:32<01:53, 282.94 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27150/47780 [01:32<01:19, 258.22 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28014/47780 [01:32<01:23, 238.00 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27275/47780 [01:32<01:14, 275.83 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27759/47780 [01:32<01:07, 298.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28851/47780 [01:32<00:57, 326.57 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28192/47780 [01:32<01:06, 292.98 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27335/47780 [01:32<01:23, 246.31 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15786/47780 [01:32<01:50, 290.34 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27177/47780 [01:32<01:21, 253.06 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28044/47780 [01:32<01:18, 252.39 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27310/47780 [01:32<01:09, 295.19 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27789/47780 [01:32<01:09, 286.27 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28884/47780 [01:32<00:59, 316.03 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15819/47780 [01:32<01:46, 301.30 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27367/47780 [01:32<01:20, 253.65 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27216/47780 [01:32<01:10, 290.42 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28073/47780 [01:32<01:15, 262.56 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27340/47780 [01:32<01:12, 280.65 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27818/47780 [01:32<01:11, 280.85 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28916/47780 [01:32<01:01, 307.35 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28223/47780 [01:32<01:22, 236.84 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15850/47780 [01:32<01:46, 300.42 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27396/47780 [01:32<01:17, 262.78 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27247/47780 [01:32<01:10, 289.57 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28100/47780 [01:32<01:18, 249.82 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27374/47780 [01:32<01:10, 290.71 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27847/47780 [01:32<01:11, 277.35 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28266/47780 [01:32<01:09, 281.83 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28947/47780 [01:33<01:06, 283.43 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15885/47780 [01:32<01:41, 314.52 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27277/47780 [01:33<01:10, 289.07 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27423/47780 [01:33<01:21, 250.37 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27405/47780 [01:33<01:08, 296.07 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27875/47780 [01:33<01:17, 255.22 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28981/47780 [01:33<01:03, 294.67 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28297/47780 [01:33<01:14, 261.90 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28127/47780 [01:33<01:30, 215.98 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15918/47780 [01:33<01:44, 305.41 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27315/47780 [01:33<01:04, 314.93 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27449/47780 [01:33<01:21, 250.34 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27435/47780 [01:33<01:17, 263.99 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27912/47780 [01:33<01:10, 282.92 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29013/47780 [01:33<01:02, 298.36 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28159/47780 [01:33<01:21, 239.58 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28325/47780 [01:33<01:15, 258.90 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27348/47780 [01:33<01:04, 315.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27475/47780 [01:33<01:22, 247.34 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27941/47780 [01:33<01:09, 284.79 examples/s]Tokenizing train dataset (num_proc=32):  33%|███▎      | 15950/47780 [01:33<02:07, 249.29 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27465/47780 [01:33<01:15, 270.78 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27380/47780 [01:33<01:05, 313.48 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28184/47780 [01:33<01:25, 230.28 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28353/47780 [01:33<01:16, 253.87 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29044/47780 [01:33<01:11, 262.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27500/47780 [01:33<01:28, 230.30 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16008/47780 [01:33<01:36, 330.94 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27970/47780 [01:33<01:10, 280.21 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27502/47780 [01:33<01:09, 291.38 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27412/47780 [01:33<01:04, 314.31 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28208/47780 [01:33<01:24, 232.60 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28381/47780 [01:33<01:16, 252.78 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29072/47780 [01:33<01:12, 259.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27528/47780 [01:33<01:24, 238.65 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27533/47780 [01:33<01:08, 296.10 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27999/47780 [01:33<01:12, 273.65 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28234/47780 [01:33<01:22, 237.74 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16045/47780 [01:33<01:51, 285.19 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27445/47780 [01:33<01:12, 280.06 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27554/47780 [01:33<01:24, 239.22 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28407/47780 [01:33<01:23, 232.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29099/47780 [01:33<01:15, 246.70 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27563/47780 [01:33<01:08, 293.96 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28036/47780 [01:33<01:07, 294.18 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28259/47780 [01:33<01:24, 230.83 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▎      | 16085/47780 [01:33<01:41, 312.28 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27488/47780 [01:33<01:03, 317.27 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27586/47780 [01:33<01:18, 258.88 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29125/47780 [01:33<01:15, 247.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28431/47780 [01:33<01:25, 227.40 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28066/47780 [01:33<01:09, 283.05 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27593/47780 [01:33<01:13, 274.20 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28286/47780 [01:33<01:22, 236.41 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16120/47780 [01:33<01:44, 303.00 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28455/47780 [01:33<01:25, 225.82 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27614/47780 [01:33<01:21, 246.80 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29151/47780 [01:33<01:19, 235.40 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27522/47780 [01:33<01:09, 290.68 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27621/47780 [01:33<01:14, 269.94 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28096/47780 [01:33<01:12, 269.72 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28314/47780 [01:33<01:19, 245.86 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28483/47780 [01:33<01:21, 238.11 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29189/47780 [01:33<01:08, 271.27 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27645/47780 [01:33<01:19, 254.20 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27553/47780 [01:33<01:08, 293.27 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16153/47780 [01:33<01:51, 284.35 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28126/47780 [01:33<01:11, 275.62 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28340/47780 [01:33<01:18, 247.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27649/47780 [01:33<01:23, 240.66 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29217/47780 [01:34<01:07, 273.54 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27673/47780 [01:34<01:17, 260.96 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16190/47780 [01:34<01:43, 305.56 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28508/47780 [01:34<01:27, 219.23 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27588/47780 [01:34<01:08, 295.52 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28365/47780 [01:34<01:21, 239.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28154/47780 [01:34<01:14, 264.16 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27674/47780 [01:34<01:27, 228.75 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29251/47780 [01:34<01:04, 289.23 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27703/47780 [01:34<01:14, 269.23 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27623/47780 [01:34<01:05, 307.58 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28543/47780 [01:34<01:16, 251.38 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16223/47780 [01:34<01:50, 284.81 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28192/47780 [01:34<01:06, 295.95 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28394/47780 [01:34<01:21, 237.90 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27705/47780 [01:34<01:22, 244.80 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27746/47780 [01:34<01:03, 313.50 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29282/47780 [01:34<01:04, 288.37 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28573/47780 [01:34<01:14, 258.95 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27655/47780 [01:34<01:06, 301.00 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16254/47780 [01:34<01:53, 277.92 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28223/47780 [01:34<01:05, 297.37 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28421/47780 [01:34<01:19, 244.04 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29316/47780 [01:34<01:01, 300.93 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27730/47780 [01:34<01:26, 231.26 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28603/47780 [01:34<01:11, 267.35 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27686/47780 [01:34<01:08, 293.57 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27778/47780 [01:34<01:12, 275.38 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28254/47780 [01:34<01:07, 287.48 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28449/47780 [01:34<01:16, 253.79 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16284/47780 [01:34<01:59, 264.13 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29347/47780 [01:34<01:01, 301.90 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27763/47780 [01:34<01:18, 255.49 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28638/47780 [01:34<01:05, 290.49 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27716/47780 [01:34<01:11, 282.53 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27814/47780 [01:34<01:08, 291.56 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28284/47780 [01:34<01:07, 287.52 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28475/47780 [01:34<01:18, 246.70 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29378/47780 [01:34<01:00, 301.96 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27792/47780 [01:34<01:15, 264.03 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28676/47780 [01:34<01:00, 315.76 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16312/47780 [01:34<02:15, 231.92 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27844/47780 [01:34<01:09, 287.74 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27746/47780 [01:34<01:11, 278.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28314/47780 [01:34<01:10, 275.65 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28503/47780 [01:34<01:17, 248.05 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29410/47780 [01:34<01:00, 302.55 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27820/47780 [01:34<01:14, 268.45 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28710/47780 [01:34<00:59, 319.29 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27875/47780 [01:34<01:07, 293.79 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16370/47780 [01:34<01:45, 298.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27777/47780 [01:34<01:11, 278.05 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28534/47780 [01:34<01:12, 264.11 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29443/47780 [01:34<00:59, 307.30 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28746/47780 [01:34<00:57, 330.89 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28342/47780 [01:34<01:21, 239.74 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27848/47780 [01:34<01:19, 251.34 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16405/47780 [01:34<01:42, 305.49 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27907/47780 [01:34<01:09, 285.39 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27805/47780 [01:34<01:14, 269.62 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29476/47780 [01:34<00:59, 310.20 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28780/47780 [01:34<00:56, 333.55 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28388/47780 [01:34<01:05, 295.81 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27874/47780 [01:34<01:19, 251.28 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27938/47780 [01:34<01:07, 291.92 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28561/47780 [01:34<01:29, 213.69 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27836/47780 [01:34<01:11, 277.78 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16437/47780 [01:34<01:48, 288.51 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29509/47780 [01:34<00:58, 312.49 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28424/47780 [01:34<01:02, 309.72 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28814/47780 [01:34<01:01, 309.84 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27907/47780 [01:35<01:15, 261.60 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28598/47780 [01:35<01:16, 252.19 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27864/47780 [01:35<01:17, 255.48 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29547/47780 [01:35<00:56, 324.48 examples/s]Tokenizing train dataset (num_proc=32):  34%|███▍      | 16467/47780 [01:35<01:55, 271.06 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28459/47780 [01:35<01:00, 320.53 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27968/47780 [01:35<01:21, 244.08 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28854/47780 [01:35<00:57, 328.11 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27934/47780 [01:35<01:16, 257.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28626/47780 [01:35<01:16, 251.18 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27900/47780 [01:35<01:10, 280.49 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29586/47780 [01:35<00:54, 335.73 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16500/47780 [01:35<01:51, 281.30 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28493/47780 [01:35<00:59, 322.62 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27994/47780 [01:35<01:22, 238.96 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28888/47780 [01:35<01:00, 311.81 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27964/47780 [01:35<01:15, 264.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28655/47780 [01:35<01:13, 259.17 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27935/47780 [01:35<01:07, 293.19 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16529/47780 [01:35<01:51, 280.34 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28538/47780 [01:35<00:53, 358.56 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28019/47780 [01:35<01:22, 238.97 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29620/47780 [01:35<01:00, 299.14 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28920/47780 [01:35<01:01, 309.06 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28000/47780 [01:35<01:10, 281.52 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28682/47780 [01:35<01:14, 256.52 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27969/47780 [01:35<01:05, 302.92 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16563/47780 [01:35<01:45, 296.44 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28575/47780 [01:35<00:53, 358.06 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28046/47780 [01:35<01:21, 242.14 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29652/47780 [01:35<01:00, 301.32 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28035/47780 [01:35<01:05, 300.48 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28952/47780 [01:35<01:01, 308.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28709/47780 [01:35<01:14, 257.30 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28000/47780 [01:35<01:06, 295.66 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16594/47780 [01:35<01:49, 284.70 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28071/47780 [01:35<01:21, 242.64 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29694/47780 [01:35<00:54, 333.62 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28992/47780 [01:35<00:56, 330.88 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28612/47780 [01:35<00:58, 326.66 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28066/47780 [01:35<01:07, 293.34 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28736/47780 [01:35<01:14, 255.27 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28030/47780 [01:35<01:09, 285.74 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16627/47780 [01:35<01:46, 293.57 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28103/47780 [01:35<01:15, 260.36 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29728/47780 [01:35<00:55, 324.56 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28648/47780 [01:35<00:58, 329.11 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29026/47780 [01:35<00:59, 315.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28765/47780 [01:35<01:12, 262.01 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28096/47780 [01:35<01:15, 262.45 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16657/47780 [01:35<01:50, 280.48 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28059/47780 [01:35<01:13, 266.83 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28130/47780 [01:35<01:15, 260.16 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29761/47780 [01:35<00:56, 316.80 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28682/47780 [01:35<00:59, 318.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29058/47780 [01:35<01:03, 297.08 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28793/47780 [01:35<01:15, 252.74 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28132/47780 [01:35<01:08, 285.18 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16691/47780 [01:35<01:46, 293.17 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28161/47780 [01:35<01:13, 268.23 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29798/47780 [01:35<00:54, 330.59 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28086/47780 [01:35<01:18, 251.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28727/47780 [01:35<00:53, 354.28 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29089/47780 [01:35<01:02, 297.44 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28820/47780 [01:35<01:17, 243.98 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28162/47780 [01:35<01:09, 281.04 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▍      | 16721/47780 [01:35<01:47, 288.67 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28191/47780 [01:35<01:10, 277.21 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28114/47780 [01:35<01:18, 251.18 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29832/47780 [01:35<00:58, 308.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28764/47780 [01:35<00:55, 342.79 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29119/47780 [01:35<01:04, 289.02 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28848/47780 [01:36<01:14, 253.76 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28191/47780 [01:36<01:16, 257.42 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28222/47780 [01:36<01:09, 280.30 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16751/47780 [01:36<01:54, 270.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28147/47780 [01:36<01:15, 260.97 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28801/47780 [01:36<00:56, 335.80 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29864/47780 [01:36<01:00, 295.70 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28876/47780 [01:36<01:13, 258.26 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29149/47780 [01:36<01:10, 264.99 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28223/47780 [01:36<01:11, 273.70 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28255/47780 [01:36<01:08, 285.65 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16793/47780 [01:36<01:40, 307.82 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28181/47780 [01:36<01:09, 282.11 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29908/47780 [01:36<00:53, 334.65 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28835/47780 [01:36<00:58, 322.85 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28910/47780 [01:36<01:08, 275.23 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29176/47780 [01:36<01:10, 263.63 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28252/47780 [01:36<01:16, 255.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28210/47780 [01:36<01:10, 278.17 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16825/47780 [01:36<01:48, 285.69 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29946/47780 [01:36<00:52, 339.41 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28946/47780 [01:36<01:02, 299.11 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28868/47780 [01:36<01:03, 298.57 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29203/47780 [01:36<01:13, 251.61 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28284/47780 [01:36<01:27, 222.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28283/47780 [01:36<01:12, 267.38 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28240/47780 [01:36<01:09, 280.08 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29983/47780 [01:36<00:52, 340.55 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28980/47780 [01:36<01:00, 309.97 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16855/47780 [01:36<01:53, 271.47 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28899/47780 [01:36<01:05, 286.45 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28324/47780 [01:36<01:14, 262.71 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29237/47780 [01:36<01:09, 266.76 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28315/47780 [01:36<01:10, 275.49 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28273/47780 [01:36<01:07, 288.99 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30018/47780 [01:36<00:54, 324.96 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29012/47780 [01:36<01:04, 290.08 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16883/47780 [01:36<02:02, 251.99 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28928/47780 [01:36<01:05, 287.28 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29271/47780 [01:36<01:05, 280.65 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28345/47780 [01:36<01:09, 279.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28353/47780 [01:36<01:18, 247.17 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28304/47780 [01:36<01:09, 282.16 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30051/47780 [01:36<00:56, 315.56 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29043/47780 [01:36<01:04, 289.46 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16910/47780 [01:36<02:02, 252.92 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28966/47780 [01:36<01:01, 306.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29302/47780 [01:36<01:06, 279.41 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28374/47780 [01:36<01:11, 270.21 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28380/47780 [01:36<01:17, 250.15 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28336/47780 [01:36<01:07, 285.99 examples/s]Tokenizing train dataset (num_proc=32):  35%|███▌      | 16940/47780 [01:36<01:56, 265.39 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30083/47780 [01:36<00:58, 300.43 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29073/47780 [01:36<01:06, 282.67 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28998/47780 [01:36<01:00, 309.74 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29333/47780 [01:36<01:04, 284.78 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28402/47780 [01:36<01:18, 245.70 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28366/47780 [01:36<01:12, 269.11 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28408/47780 [01:36<01:25, 227.33 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30131/47780 [01:36<00:51, 345.67 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 16975/47780 [01:36<01:47, 285.38 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29030/47780 [01:36<01:00, 311.92 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29103/47780 [01:36<01:06, 281.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29364/47780 [01:36<01:04, 285.47 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28429/47780 [01:36<01:17, 249.47 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28432/47780 [01:36<01:24, 228.27 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28399/47780 [01:36<01:10, 276.47 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17006/47780 [01:36<01:47, 285.95 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30167/47780 [01:36<00:52, 338.32 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29132/47780 [01:36<01:07, 277.22 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29065/47780 [01:36<01:00, 309.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29395/47780 [01:37<01:03, 289.09 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28456/47780 [01:37<01:15, 255.00 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28456/47780 [01:37<01:24, 229.04 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17038/47780 [01:37<01:44, 295.31 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28427/47780 [01:37<01:13, 263.25 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30206/47780 [01:37<00:50, 348.84 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29097/47780 [01:37<01:01, 305.34 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29160/47780 [01:37<01:10, 263.69 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29426/47780 [01:37<01:02, 291.61 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28482/47780 [01:37<01:16, 253.27 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28481/47780 [01:37<01:22, 232.73 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30242/47780 [01:37<00:50, 347.64 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28460/47780 [01:37<01:10, 275.30 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29131/47780 [01:37<00:59, 311.97 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29189/47780 [01:37<01:08, 270.77 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17068/47780 [01:37<01:50, 277.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29459/47780 [01:37<01:01, 299.38 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28514/47780 [01:37<01:12, 266.40 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28515/47780 [01:37<01:13, 261.48 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30278/47780 [01:37<00:50, 347.66 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28491/47780 [01:37<01:08, 283.60 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29217/47780 [01:37<01:08, 270.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29163/47780 [01:37<01:01, 300.43 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29489/47780 [01:37<01:03, 288.93 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17097/47780 [01:37<02:01, 253.18 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28549/47780 [01:37<01:07, 286.80 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28544/47780 [01:37<01:11, 269.44 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30313/47780 [01:37<00:50, 344.41 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28520/47780 [01:37<01:10, 271.33 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29197/47780 [01:37<00:59, 311.14 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29245/47780 [01:37<01:11, 258.47 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29522/47780 [01:37<01:01, 297.65 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17123/47780 [01:37<02:01, 251.96 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28572/47780 [01:37<01:15, 254.80 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28578/47780 [01:37<01:13, 260.93 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29276/47780 [01:37<01:09, 266.78 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30348/47780 [01:37<00:56, 310.17 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29229/47780 [01:37<01:05, 284.90 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17151/47780 [01:37<01:59, 257.25 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28548/47780 [01:37<01:17, 249.08 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29552/47780 [01:37<01:06, 273.36 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28598/47780 [01:37<01:18, 245.49 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28612/47780 [01:37<01:10, 270.48 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30380/47780 [01:37<00:57, 303.15 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28576/47780 [01:37<01:14, 257.20 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29304/47780 [01:37<01:11, 258.94 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17178/47780 [01:37<01:58, 257.55 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29588/47780 [01:37<01:03, 287.40 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29258/47780 [01:37<01:09, 267.35 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28625/47780 [01:37<01:16, 249.04 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28640/47780 [01:37<01:13, 261.00 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28603/47780 [01:37<01:14, 257.60 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17210/47780 [01:37<01:51, 275.08 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30411/47780 [01:37<00:57, 301.18 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29331/47780 [01:37<01:13, 251.85 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29618/47780 [01:37<01:03, 284.96 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29301/47780 [01:37<01:00, 305.61 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28655/47780 [01:37<01:14, 255.10 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28667/47780 [01:37<01:13, 261.32 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17242/47780 [01:37<01:47, 285.10 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28633/47780 [01:37<01:11, 266.67 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30442/47780 [01:37<00:59, 291.08 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29364/47780 [01:37<01:09, 266.53 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29654/47780 [01:37<00:59, 304.81 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29333/47780 [01:37<01:03, 290.60 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28685/47780 [01:37<01:12, 264.77 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28695/47780 [01:37<01:13, 258.01 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17271/47780 [01:37<01:47, 283.25 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28660/47780 [01:37<01:14, 256.05 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30476/47780 [01:37<00:58, 298.03 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29391/47780 [01:37<01:09, 263.32 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29688/47780 [01:37<00:59, 305.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29363/47780 [01:38<01:03, 290.07 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28725/47780 [01:38<01:11, 266.80 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▌      | 17303/47780 [01:38<01:46, 287.27 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30509/47780 [01:38<00:56, 306.90 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28690/47780 [01:38<01:13, 260.37 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29428/47780 [01:38<01:03, 288.11 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28712/47780 [01:38<01:23, 227.41 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29727/47780 [01:38<00:57, 314.94 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29394/47780 [01:38<01:02, 292.27 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28755/47780 [01:38<01:09, 273.05 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17334/47780 [01:38<01:43, 293.80 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30549/47780 [01:38<00:51, 333.34 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29468/47780 [01:38<00:57, 318.37 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28721/47780 [01:38<01:11, 267.49 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29762/47780 [01:38<00:56, 321.17 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29430/47780 [01:38<00:59, 310.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28736/47780 [01:38<01:30, 209.36 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28783/47780 [01:38<01:10, 268.99 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17364/47780 [01:38<01:47, 282.45 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29507/47780 [01:38<00:54, 336.50 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28753/47780 [01:38<01:08, 278.97 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30584/47780 [01:38<00:55, 309.64 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29796/47780 [01:38<00:55, 326.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29464/47780 [01:38<00:57, 315.92 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28763/47780 [01:38<01:28, 215.86 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28810/47780 [01:38<01:11, 266.17 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29541/47780 [01:38<00:54, 333.65 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17393/47780 [01:38<01:49, 278.06 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28783/47780 [01:38<01:07, 281.39 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30621/47780 [01:38<00:53, 322.55 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29837/47780 [01:38<00:51, 346.43 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29496/47780 [01:38<00:59, 306.55 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28793/47780 [01:38<01:20, 237.24 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28837/47780 [01:38<01:12, 259.71 examples/s]Tokenizing train dataset (num_proc=32):  36%|███▋      | 17421/47780 [01:38<01:53, 266.74 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29878/47780 [01:38<00:49, 364.42 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29575/47780 [01:38<00:58, 309.90 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28812/47780 [01:38<01:12, 261.29 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29538/47780 [01:38<00:55, 331.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30654/47780 [01:38<00:58, 295.16 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28818/47780 [01:38<01:24, 223.64 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28865/47780 [01:38<01:13, 259.02 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17456/47780 [01:38<01:44, 289.98 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29918/47780 [01:38<00:49, 362.63 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28856/47780 [01:38<01:01, 305.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29607/47780 [01:38<01:01, 293.63 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30689/47780 [01:38<00:55, 306.22 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29572/47780 [01:38<00:58, 312.45 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28842/47780 [01:38<01:23, 226.01 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28891/47780 [01:38<01:15, 250.00 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17486/47780 [01:38<01:45, 286.25 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29955/47780 [01:38<00:50, 356.46 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28888/47780 [01:38<01:01, 306.24 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29604/47780 [01:38<00:57, 314.23 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30721/47780 [01:38<00:56, 302.62 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28872/47780 [01:38<01:18, 240.33 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29638/47780 [01:38<01:10, 258.90 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28919/47780 [01:38<01:13, 255.60 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17516/47780 [01:38<01:44, 289.99 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29991/47780 [01:38<00:49, 357.05 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28922/47780 [01:38<01:01, 308.75 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29639/47780 [01:38<00:56, 321.78 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30752/47780 [01:38<00:56, 301.73 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28897/47780 [01:38<01:18, 240.55 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29669/47780 [01:38<01:07, 268.88 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28946/47780 [01:38<01:14, 253.95 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17554/47780 [01:38<01:35, 315.87 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30027/47780 [01:38<00:50, 350.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28959/47780 [01:38<00:58, 322.57 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30784/47780 [01:38<00:57, 294.27 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29672/47780 [01:38<00:58, 309.13 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28922/47780 [01:38<01:21, 230.34 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29697/47780 [01:39<01:08, 265.66 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17586/47780 [01:39<01:38, 306.22 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28972/47780 [01:39<01:16, 246.69 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30063/47780 [01:39<00:52, 338.92 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29705/47780 [01:39<01:01, 291.69 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28948/47780 [01:39<01:20, 235.17 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28992/47780 [01:39<01:09, 270.95 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29726/47780 [01:39<01:08, 264.22 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17622/47780 [01:39<01:34, 318.58 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29003/47780 [01:39<01:14, 253.44 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30814/47780 [01:39<01:09, 243.52 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30097/47780 [01:39<00:52, 338.66 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28986/47780 [01:39<01:08, 273.72 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29737/47780 [01:39<01:02, 287.98 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29038/47780 [01:39<00:59, 316.86 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29762/47780 [01:39<01:02, 290.03 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17655/47780 [01:39<01:34, 317.18 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29033/47780 [01:39<01:11, 263.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30861/47780 [01:39<00:57, 294.35 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30131/47780 [01:39<00:55, 317.38 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29014/47780 [01:39<01:08, 272.28 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29767/47780 [01:39<01:02, 287.19 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29792/47780 [01:39<01:02, 287.01 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17690/47780 [01:39<01:32, 323.84 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29060/47780 [01:39<01:12, 259.69 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30893/47780 [01:39<00:56, 297.51 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29074/47780 [01:39<01:05, 285.97 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30163/47780 [01:39<00:57, 307.92 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29046/47780 [01:39<01:05, 285.54 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29796/47780 [01:39<01:03, 282.00 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29822/47780 [01:39<01:06, 271.94 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29088/47780 [01:39<01:11, 262.33 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29115/47780 [01:39<00:58, 316.68 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17723/47780 [01:39<01:45, 285.65 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30925/47780 [01:39<01:00, 279.22 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30194/47780 [01:39<00:59, 295.39 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29825/47780 [01:39<01:03, 284.14 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29075/47780 [01:39<01:11, 260.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29119/47780 [01:39<01:08, 272.98 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17753/47780 [01:39<01:44, 286.62 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30966/47780 [01:39<00:54, 307.67 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29149/47780 [01:39<01:02, 300.30 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29850/47780 [01:39<01:15, 237.91 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30227/47780 [01:39<01:00, 291.99 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29854/47780 [01:39<01:03, 282.53 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29114/47780 [01:39<01:03, 295.31 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29147/47780 [01:39<01:08, 271.32 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17786/47780 [01:39<01:41, 295.30 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29898/47780 [01:39<00:59, 298.99 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30998/47780 [01:39<00:56, 298.25 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30264/47780 [01:39<00:56, 310.55 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29884/47780 [01:39<01:02, 287.43 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29182/47780 [01:39<01:05, 281.99 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29147/47780 [01:39<01:04, 289.04 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29175/47780 [01:39<01:14, 251.06 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17817/47780 [01:39<01:43, 289.31 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31032/47780 [01:39<00:54, 306.15 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29916/47780 [01:39<01:00, 293.78 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30296/47780 [01:39<00:59, 296.21 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29930/47780 [01:39<01:05, 272.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29212/47780 [01:39<01:09, 267.68 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29177/47780 [01:39<01:09, 268.34 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17851/47780 [01:39<01:40, 297.98 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29201/47780 [01:39<01:18, 237.82 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31065/47780 [01:39<00:54, 305.53 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29959/47780 [01:39<01:04, 277.14 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29946/47780 [01:39<01:03, 282.34 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30331/47780 [01:39<00:58, 297.71 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29240/47780 [01:39<01:08, 270.70 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29213/47780 [01:39<01:03, 292.52 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17883/47780 [01:39<01:39, 300.04 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31096/47780 [01:40<00:55, 302.73 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29226/47780 [01:40<01:22, 224.22 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29991/47780 [01:40<00:54, 326.35 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29988/47780 [01:40<01:04, 274.43 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30365/47780 [01:40<00:56, 309.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29271/47780 [01:40<01:06, 278.32 examples/s]Tokenizing train dataset (num_proc=32):  37%|███▋      | 17914/47780 [01:40<01:38, 302.39 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29243/47780 [01:40<01:07, 273.84 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31130/47780 [01:40<00:53, 310.87 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29249/47780 [01:40<01:23, 221.20 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30017/47780 [01:40<01:05, 272.97 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30032/47780 [01:40<00:52, 338.69 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29300/47780 [01:40<01:07, 272.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30397/47780 [01:40<01:00, 289.22 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17946/47780 [01:40<01:38, 304.24 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29274/47780 [01:40<01:05, 280.47 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31162/47780 [01:40<00:54, 303.08 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29276/47780 [01:40<01:18, 234.25 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30047/47780 [01:40<01:03, 277.37 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30066/47780 [01:40<00:52, 338.45 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29328/47780 [01:40<01:07, 274.32 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 17977/47780 [01:40<01:38, 302.18 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30427/47780 [01:40<01:05, 263.72 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29307/47780 [01:40<01:04, 287.76 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31193/47780 [01:40<00:54, 304.83 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29301/47780 [01:40<01:19, 231.02 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30100/47780 [01:40<00:53, 331.60 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30084/47780 [01:40<00:59, 296.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29366/47780 [01:40<01:02, 294.48 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18009/47780 [01:40<01:36, 307.22 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29344/47780 [01:40<01:00, 307.09 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30454/47780 [01:40<01:09, 247.70 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31226/47780 [01:40<00:54, 305.26 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29332/47780 [01:40<01:13, 250.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30117/47780 [01:40<00:59, 299.13 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30134/47780 [01:40<00:57, 309.49 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29396/47780 [01:40<01:05, 282.46 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18040/47780 [01:40<01:38, 301.56 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30482/47780 [01:40<01:07, 255.93 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31260/47780 [01:40<00:52, 314.42 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29376/47780 [01:40<01:03, 291.11 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29358/47780 [01:40<01:12, 252.75 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30156/47780 [01:40<00:56, 310.93 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29426/47780 [01:40<01:05, 278.70 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30167/47780 [01:40<00:59, 298.23 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18071/47780 [01:40<01:43, 286.89 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30510/47780 [01:40<01:06, 259.68 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31293/47780 [01:40<00:52, 316.04 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29384/47780 [01:40<01:14, 246.47 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29406/47780 [01:40<01:08, 267.32 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30190/47780 [01:40<00:56, 312.00 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29454/47780 [01:40<01:07, 270.16 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30200/47780 [01:40<00:59, 294.45 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18100/47780 [01:40<01:48, 272.54 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30537/47780 [01:40<01:09, 248.54 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31325/47780 [01:40<00:55, 298.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29409/47780 [01:40<01:16, 239.24 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30222/47780 [01:40<00:57, 303.19 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29434/47780 [01:40<01:12, 254.62 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29483/47780 [01:40<01:07, 269.60 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30234/47780 [01:40<00:57, 303.42 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18128/47780 [01:40<01:49, 271.51 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30571/47780 [01:40<01:03, 270.64 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31357/47780 [01:40<00:54, 302.70 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29439/47780 [01:40<01:11, 256.21 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30258/47780 [01:40<00:55, 316.40 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29460/47780 [01:40<01:11, 256.02 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30265/47780 [01:40<00:57, 305.01 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29516/47780 [01:40<01:05, 277.92 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30599/47780 [01:40<01:03, 270.19 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18156/47780 [01:40<01:54, 258.96 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29469/47780 [01:41<01:08, 266.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31388/47780 [01:41<00:55, 293.94 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30290/47780 [01:41<00:57, 302.13 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29547/47780 [01:41<01:03, 286.37 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30296/47780 [01:41<00:58, 299.69 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29486/47780 [01:41<01:21, 225.31 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30633/47780 [01:41<01:00, 283.47 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18183/47780 [01:41<01:55, 257.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31419/47780 [01:41<00:56, 288.58 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30324/47780 [01:41<00:57, 304.16 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30328/47780 [01:41<00:57, 305.34 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29577/47780 [01:41<01:04, 281.95 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29571/47780 [01:41<00:47, 383.55 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29496/47780 [01:41<01:25, 214.91 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30662/47780 [01:41<01:00, 282.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18209/47780 [01:41<01:58, 250.56 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31448/47780 [01:41<01:00, 269.05 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30363/47780 [01:41<00:55, 314.88 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30355/47780 [01:41<00:58, 298.57 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29607/47780 [01:41<01:06, 273.27 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29540/47780 [01:41<01:08, 265.76 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29613/47780 [01:41<00:48, 376.79 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18240/47780 [01:41<01:51, 266.04 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30691/47780 [01:41<01:02, 275.03 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31480/47780 [01:41<00:57, 282.54 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30397/47780 [01:41<00:53, 321.91 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30385/47780 [01:41<01:00, 289.80 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29635/47780 [01:41<01:06, 272.16 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29569/47780 [01:41<01:07, 269.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30719/47780 [01:41<01:01, 276.39 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18281/47780 [01:41<01:38, 299.96 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31518/47780 [01:41<00:53, 306.32 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29655/47780 [01:41<00:53, 341.38 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30434/47780 [01:41<00:52, 332.52 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30416/47780 [01:41<01:00, 285.75 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29598/47780 [01:41<01:06, 274.59 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30754/47780 [01:41<00:57, 294.17 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29663/47780 [01:41<01:12, 251.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18314/47780 [01:41<01:36, 305.18 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30472/47780 [01:41<00:50, 346.11 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31550/47780 [01:41<00:57, 283.37 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29692/47780 [01:41<00:55, 325.63 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30446/47780 [01:41<00:59, 289.60 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29627/47780 [01:41<01:10, 259.09 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29689/47780 [01:41<01:12, 251.17 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30784/47780 [01:41<00:58, 289.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18345/47780 [01:41<01:37, 302.76 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30508/47780 [01:41<00:52, 330.96 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31579/47780 [01:41<00:59, 273.72 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29727/47780 [01:41<00:58, 306.62 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29720/47780 [01:41<01:07, 267.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29654/47780 [01:41<01:09, 258.99 examples/s]Tokenizing train dataset (num_proc=32):  38%|███▊      | 18385/47780 [01:41<01:30, 323.59 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30476/47780 [01:41<01:07, 255.15 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30813/47780 [01:41<01:04, 265.01 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30545/47780 [01:41<00:52, 330.70 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31607/47780 [01:41<01:01, 264.61 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29750/47780 [01:41<01:06, 270.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29759/47780 [01:41<01:00, 295.56 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29681/47780 [01:41<01:11, 253.77 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30507/47780 [01:41<01:04, 266.57 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18418/47780 [01:41<01:34, 311.10 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30844/47780 [01:41<01:01, 274.35 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30579/47780 [01:41<00:51, 333.13 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31635/47780 [01:41<01:00, 265.95 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29781/47780 [01:41<01:04, 278.52 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29716/47780 [01:41<01:05, 277.17 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30537/47780 [01:41<01:03, 272.57 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18451/47780 [01:41<01:33, 312.54 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29790/47780 [01:41<01:05, 274.42 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30872/47780 [01:41<01:06, 255.94 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30615/47780 [01:42<00:50, 337.33 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31666/47780 [01:42<00:57, 278.12 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29811/47780 [01:42<01:04, 278.38 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29745/47780 [01:42<01:06, 271.66 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▊      | 18493/47780 [01:42<01:26, 339.63 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29820/47780 [01:42<01:03, 280.76 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30565/47780 [01:42<01:06, 257.47 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30898/47780 [01:42<01:06, 254.00 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30650/47780 [01:42<00:50, 340.98 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31699/47780 [01:42<00:54, 292.78 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29839/47780 [01:42<01:04, 278.68 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18528/47780 [01:42<01:26, 338.78 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29851/47780 [01:42<01:02, 288.36 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29773/47780 [01:42<01:08, 262.33 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30592/47780 [01:42<01:08, 250.05 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30928/47780 [01:42<01:03, 264.10 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30686/47780 [01:42<00:49, 342.48 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31729/47780 [01:42<00:56, 285.05 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29867/47780 [01:42<01:09, 258.03 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29800/47780 [01:42<01:08, 261.53 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18562/47780 [01:42<01:30, 323.57 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30619/47780 [01:42<01:07, 254.46 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30961/47780 [01:42<00:59, 280.44 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30721/47780 [01:42<00:49, 343.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31758/47780 [01:42<00:58, 273.98 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29833/47780 [01:42<01:03, 280.51 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29894/47780 [01:42<01:10, 254.83 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30647/47780 [01:42<01:05, 259.90 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29881/47780 [01:42<01:24, 212.77 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30992/47780 [01:42<00:58, 284.59 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30758/47780 [01:42<00:49, 344.35 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18595/47780 [01:42<01:36, 301.70 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31786/47780 [01:42<00:58, 272.41 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29867/47780 [01:42<01:00, 297.53 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29921/47780 [01:42<01:09, 256.72 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30681/47780 [01:42<01:01, 279.49 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29936/47780 [01:42<01:02, 284.90 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18632/47780 [01:42<01:31, 320.27 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31031/47780 [01:42<00:55, 300.91 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30794/47780 [01:42<00:51, 330.00 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31814/47780 [01:42<01:02, 257.26 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29902/47780 [01:42<00:57, 310.41 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30710/47780 [01:42<01:01, 279.11 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29969/47780 [01:42<01:00, 292.70 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18665/47780 [01:42<01:31, 319.65 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29947/47780 [01:42<01:15, 236.78 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31071/47780 [01:42<00:50, 328.56 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30828/47780 [01:42<00:51, 332.37 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29934/47780 [01:42<00:57, 308.21 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31840/47780 [01:42<01:06, 239.29 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30739/47780 [01:42<01:02, 273.59 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30007/47780 [01:42<00:57, 311.72 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18699/47780 [01:42<01:30, 321.99 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29977/47780 [01:42<01:11, 248.62 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31109/47780 [01:42<00:48, 343.27 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30868/47780 [01:42<00:48, 347.97 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29965/47780 [01:42<00:59, 301.73 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30776/47780 [01:42<00:56, 300.26 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31876/47780 [01:42<01:01, 258.90 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18739/47780 [01:42<01:25, 340.42 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31144/47780 [01:42<00:48, 341.60 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30004/47780 [01:42<01:10, 251.50 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30903/47780 [01:42<00:50, 336.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30041/47780 [01:42<01:03, 280.56 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29996/47780 [01:42<01:02, 284.50 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30807/47780 [01:42<00:58, 289.30 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30031/47780 [01:42<01:09, 255.14 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31179/47780 [01:42<00:48, 340.02 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31903/47780 [01:42<01:06, 240.52 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18774/47780 [01:42<01:31, 316.18 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30939/47780 [01:42<00:49, 343.44 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31218/47780 [01:43<00:46, 354.24 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30072/47780 [01:43<01:12, 243.85 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30066/47780 [01:43<01:05, 271.66 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30837/47780 [01:43<01:00, 279.41 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30026/47780 [01:43<01:07, 262.74 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31933/47780 [01:43<01:03, 250.84 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30974/47780 [01:43<00:49, 337.49 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18807/47780 [01:43<01:38, 295.14 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30102/47780 [01:43<00:59, 296.30 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30107/47780 [01:43<01:06, 266.21 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31254/47780 [01:43<00:48, 340.33 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30053/47780 [01:43<01:06, 264.61 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31970/47780 [01:43<00:55, 282.46 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31011/47780 [01:43<00:49, 339.13 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30866/47780 [01:43<01:03, 267.88 examples/s]Tokenizing train dataset (num_proc=32):  39%|███▉      | 18838/47780 [01:43<01:41, 284.19 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30141/47780 [01:43<01:02, 281.99 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30135/47780 [01:43<00:58, 302.65 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31999/47780 [01:43<00:56, 280.64 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31289/47780 [01:43<00:50, 327.75 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30895/47780 [01:43<01:01, 273.79 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30080/47780 [01:43<01:10, 252.37 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31048/47780 [01:43<00:49, 337.76 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18874/47780 [01:43<01:35, 304.22 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30166/47780 [01:43<00:59, 298.01 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30171/47780 [01:43<01:03, 278.02 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30931/47780 [01:43<00:57, 295.13 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32031/47780 [01:43<00:55, 286.05 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30106/47780 [01:43<01:10, 249.06 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31322/47780 [01:43<00:52, 310.78 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31083/47780 [01:43<00:50, 328.70 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18906/47780 [01:43<01:34, 305.25 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32064/47780 [01:43<00:53, 295.03 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30196/47780 [01:43<01:01, 285.18 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30201/47780 [01:43<01:04, 273.02 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30140/47780 [01:43<01:06, 265.23 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30961/47780 [01:43<01:00, 277.04 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31354/47780 [01:43<00:53, 306.61 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18937/47780 [01:43<01:37, 296.21 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31116/47780 [01:43<00:59, 281.31 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32094/47780 [01:43<00:52, 296.05 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30230/47780 [01:43<01:04, 271.05 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30172/47780 [01:43<01:02, 280.18 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30225/47780 [01:43<01:05, 270.04 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30991/47780 [01:43<00:59, 280.78 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31385/47780 [01:43<00:53, 304.21 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18967/47780 [01:43<01:37, 294.43 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30261/47780 [01:43<01:02, 281.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31146/47780 [01:43<01:03, 261.33 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30208/47780 [01:43<00:58, 302.02 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32124/47780 [01:43<00:57, 273.84 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30253/47780 [01:43<01:08, 257.32 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31020/47780 [01:43<01:03, 265.60 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31416/47780 [01:43<00:59, 275.07 examples/s]Tokenizing train dataset (num_proc=32):  40%|███▉      | 18997/47780 [01:43<01:40, 286.24 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30299/47780 [01:43<00:56, 308.94 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31176/47780 [01:43<01:01, 269.29 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30239/47780 [01:43<00:58, 298.29 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32152/47780 [01:43<00:57, 274.04 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30279/47780 [01:43<01:09, 252.52 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31047/47780 [01:43<01:03, 263.82 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31447/47780 [01:43<00:58, 278.27 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19026/47780 [01:43<01:43, 277.02 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31206/47780 [01:43<01:02, 266.00 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32183/47780 [01:43<00:55, 281.12 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30277/47780 [01:43<00:55, 314.56 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30331/47780 [01:43<01:02, 280.30 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30309/47780 [01:43<01:05, 265.53 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31074/47780 [01:43<01:06, 251.55 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31476/47780 [01:43<00:59, 273.49 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19054/47780 [01:43<01:45, 271.63 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30314/47780 [01:44<00:52, 330.39 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31236/47780 [01:44<01:01, 269.44 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32212/47780 [01:44<00:55, 280.18 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30336/47780 [01:44<01:06, 261.70 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30364/47780 [01:44<01:02, 278.57 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31101/47780 [01:44<01:06, 250.72 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31507/47780 [01:44<00:58, 279.66 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 19084/47780 [01:44<01:44, 274.69 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30353/47780 [01:44<00:50, 343.80 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32247/47780 [01:44<00:52, 298.10 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31264/47780 [01:44<01:03, 261.02 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30368/47780 [01:44<01:02, 277.40 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30395/47780 [01:44<01:01, 280.99 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31129/47780 [01:44<01:04, 256.35 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19122/47780 [01:44<01:34, 304.26 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31536/47780 [01:44<01:01, 262.18 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32277/47780 [01:44<00:52, 293.63 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31291/47780 [01:44<01:02, 263.40 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30388/47780 [01:44<00:53, 326.59 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30401/47780 [01:44<01:00, 289.20 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30424/47780 [01:44<01:01, 280.42 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31165/47780 [01:44<01:00, 276.18 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19153/47780 [01:44<01:40, 286.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31570/47780 [01:44<00:58, 277.12 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32313/47780 [01:44<00:49, 309.84 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31321/47780 [01:44<01:00, 270.61 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30432/47780 [01:44<01:00, 288.59 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30422/47780 [01:44<00:54, 319.21 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30453/47780 [01:44<01:02, 276.35 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31193/47780 [01:44<01:01, 268.28 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19192/47780 [01:44<01:31, 311.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31604/47780 [01:44<00:55, 291.14 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32347/47780 [01:44<00:48, 318.49 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31353/47780 [01:44<00:58, 281.52 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30455/47780 [01:44<00:56, 308.53 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30461/47780 [01:44<01:04, 270.39 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30481/47780 [01:44<01:04, 268.73 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19224/47780 [01:44<01:33, 307.01 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31225/47780 [01:44<01:03, 262.34 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31634/47780 [01:44<00:56, 283.89 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32379/47780 [01:44<00:49, 311.56 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31382/47780 [01:44<00:58, 280.34 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30490/47780 [01:44<01:02, 275.69 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30490/47780 [01:44<00:55, 313.32 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30512/47780 [01:44<01:03, 273.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31257/47780 [01:44<01:00, 274.91 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31663/47780 [01:44<00:57, 279.67 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19255/47780 [01:44<01:38, 288.13 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32418/47780 [01:44<00:46, 330.63 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31415/47780 [01:44<00:55, 294.58 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30532/47780 [01:44<00:50, 339.16 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30519/47780 [01:44<01:02, 276.16 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30545/47780 [01:44<01:00, 283.90 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31291/47780 [01:44<00:56, 292.73 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31692/47780 [01:44<00:56, 282.41 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19285/47780 [01:44<01:43, 276.51 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32452/47780 [01:44<00:47, 321.41 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31446/47780 [01:44<00:59, 273.90 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30573/47780 [01:44<00:47, 358.93 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30577/47780 [01:44<00:58, 294.04 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30547/47780 [01:44<01:07, 257.01 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31323/47780 [01:44<00:54, 300.10 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31727/47780 [01:44<00:55, 291.69 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32485/47780 [01:44<00:48, 317.35 examples/s]Tokenizing train dataset (num_proc=32):  40%|████      | 19313/47780 [01:44<01:45, 268.65 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30610/47780 [01:44<00:47, 357.94 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30608/47780 [01:44<00:58, 295.24 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31474/47780 [01:44<01:03, 258.39 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31358/47780 [01:44<00:52, 311.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30574/47780 [01:44<01:09, 247.23 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31761/47780 [01:44<00:53, 298.70 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19354/47780 [01:44<01:33, 303.90 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32518/47780 [01:44<00:48, 317.21 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30646/47780 [01:44<00:49, 347.13 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31394/47780 [01:45<00:50, 321.62 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30607/47780 [01:45<01:04, 266.65 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30638/47780 [01:45<01:02, 274.12 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31501/47780 [01:45<01:10, 229.43 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31791/47780 [01:45<00:56, 282.97 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32557/47780 [01:45<00:45, 337.86 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19385/47780 [01:45<01:36, 295.52 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30682/47780 [01:45<00:49, 347.22 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31431/47780 [01:45<00:50, 320.78 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30634/47780 [01:45<01:07, 253.57 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31529/47780 [01:45<01:07, 239.82 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30666/47780 [01:45<01:07, 253.70 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32596/47780 [01:45<00:43, 347.74 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19419/47780 [01:45<01:32, 307.72 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31820/47780 [01:45<00:59, 270.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30717/47780 [01:45<00:49, 344.97 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31465/47780 [01:45<00:50, 322.54 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30660/47780 [01:45<01:08, 249.48 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31554/47780 [01:45<01:08, 237.43 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30704/47780 [01:45<01:00, 284.26 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32640/47780 [01:45<00:40, 372.09 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19451/47780 [01:45<01:33, 304.28 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30753/47780 [01:45<00:49, 343.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31848/47780 [01:45<01:03, 250.60 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31498/47780 [01:45<00:52, 310.48 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30688/47780 [01:45<01:07, 252.68 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31583/47780 [01:45<01:04, 251.55 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32681/47780 [01:45<00:39, 382.99 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30734/47780 [01:45<01:03, 268.12 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30793/47780 [01:45<00:47, 357.51 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19482/47780 [01:45<01:38, 286.79 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31875/47780 [01:45<01:04, 248.12 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31611/47780 [01:45<01:02, 256.67 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30719/47780 [01:45<01:04, 265.68 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31535/47780 [01:45<00:52, 311.37 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32722/47780 [01:45<00:39, 377.62 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30763/47780 [01:45<01:02, 273.73 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19517/47780 [01:45<01:35, 295.52 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30830/47780 [01:45<00:49, 343.48 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31904/47780 [01:45<01:01, 259.24 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31640/47780 [01:45<01:01, 263.16 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30747/47780 [01:45<01:03, 266.75 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31567/47780 [01:45<00:53, 302.16 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32760/47780 [01:45<00:42, 353.11 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30791/47780 [01:45<01:05, 261.24 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30871/47780 [01:45<00:47, 354.44 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19547/47780 [01:45<01:38, 285.74 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31931/47780 [01:45<01:01, 257.66 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31671/47780 [01:45<00:58, 276.35 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31600/47780 [01:45<00:52, 309.61 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30774/47780 [01:45<01:09, 245.41 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32805/47780 [01:45<00:39, 376.64 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30825/47780 [01:45<01:01, 276.59 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19581/47780 [01:45<01:33, 300.50 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31958/47780 [01:45<01:00, 260.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30908/47780 [01:45<00:48, 347.07 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31700/47780 [01:45<00:58, 277.22 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31635/47780 [01:45<00:51, 310.71 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32846/47780 [01:45<00:39, 381.59 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30799/47780 [01:45<01:14, 229.18 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30858/47780 [01:45<00:59, 282.04 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19612/47780 [01:45<01:34, 297.14 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31987/47780 [01:45<01:00, 262.49 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30944/47780 [01:45<00:48, 346.89 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31728/47780 [01:45<00:59, 268.66 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31667/47780 [01:45<00:54, 296.56 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30887/47780 [01:45<00:59, 283.11 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32885/47780 [01:45<00:41, 362.82 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30834/47780 [01:45<01:05, 258.50 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19642/47780 [01:45<01:35, 294.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32020/47780 [01:45<00:56, 278.63 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30980/47780 [01:45<00:51, 324.75 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31756/47780 [01:46<01:03, 252.13 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30863/47780 [01:46<01:03, 267.00 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31697/47780 [01:46<00:55, 287.97 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30916/47780 [01:46<01:00, 276.92 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32939/47780 [01:46<00:36, 403.79 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19672/47780 [01:46<01:36, 290.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32048/47780 [01:46<00:57, 272.78 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31016/47780 [01:46<00:50, 330.72 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31785/47780 [01:46<01:04, 248.46 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30892/47780 [01:46<01:03, 267.45 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30953/47780 [01:46<00:55, 303.02 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32981/47780 [01:46<00:37, 393.72 examples/s]Tokenizing train dataset (num_proc=32):  41%|████      | 19702/47780 [01:46<01:38, 285.86 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32080/47780 [01:46<00:55, 283.15 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31726/47780 [01:46<01:01, 259.99 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31050/47780 [01:46<00:53, 312.45 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31812/47780 [01:46<01:02, 254.18 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30924/47780 [01:46<01:01, 272.97 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30984/47780 [01:46<00:57, 294.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32110/47780 [01:46<00:54, 287.87 examples/s]Tokenizing train dataset (num_proc=32):  41%|████▏     | 19731/47780 [01:46<01:39, 280.63 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31759/47780 [01:46<00:58, 272.62 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33021/47780 [01:46<00:40, 367.82 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31083/47780 [01:46<00:53, 310.40 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31838/47780 [01:46<01:05, 244.98 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30953/47780 [01:46<01:01, 274.86 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31014/47780 [01:46<00:57, 293.13 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32140/47780 [01:46<00:54, 288.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19773/47780 [01:46<01:27, 320.04 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31790/47780 [01:46<00:57, 279.69 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33071/47780 [01:46<00:36, 399.41 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31115/47780 [01:46<00:57, 290.66 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31872/47780 [01:46<00:58, 271.12 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32177/47780 [01:46<00:50, 311.82 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30981/47780 [01:46<01:02, 269.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19806/47780 [01:46<01:26, 321.58 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31044/47780 [01:46<01:00, 276.20 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33114/47780 [01:46<00:36, 403.46 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31819/47780 [01:46<00:57, 276.00 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31900/47780 [01:46<00:58, 273.43 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31145/47780 [01:46<00:59, 278.41 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32210/47780 [01:46<00:49, 317.10 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31072/47780 [01:46<01:00, 277.21 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31009/47780 [01:46<01:04, 260.99 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19839/47780 [01:46<01:32, 300.98 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31848/47780 [01:46<00:57, 277.00 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33155/47780 [01:46<00:38, 379.69 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31928/47780 [01:46<00:59, 266.51 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31186/47780 [01:46<00:53, 309.88 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32245/47780 [01:46<00:48, 319.37 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31101/47780 [01:46<01:00, 275.26 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31036/47780 [01:46<01:04, 257.92 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19871/47780 [01:46<01:34, 296.25 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31877/47780 [01:46<00:57, 274.40 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33194/47780 [01:46<00:39, 370.42 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31220/47780 [01:46<00:53, 311.53 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32283/47780 [01:46<00:45, 336.91 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31955/47780 [01:46<01:01, 258.42 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31134/47780 [01:46<00:58, 287.00 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31062/47780 [01:46<01:06, 252.84 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31912/47780 [01:46<00:53, 295.68 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19902/47780 [01:46<01:33, 296.91 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33233/47780 [01:46<00:39, 367.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31255/47780 [01:46<00:51, 322.01 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31985/47780 [01:46<00:59, 264.41 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32317/47780 [01:46<00:48, 318.78 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31176/47780 [01:46<00:51, 321.12 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31089/47780 [01:46<01:04, 257.66 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31946/47780 [01:46<00:52, 301.82 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19932/47780 [01:46<01:37, 284.56 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33270/47780 [01:46<00:40, 360.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31289/47780 [01:46<00:50, 327.08 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32019/47780 [01:46<00:56, 279.37 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32350/47780 [01:47<00:48, 315.30 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31209/47780 [01:46<00:51, 319.62 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31979/47780 [01:47<00:51, 306.45 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31115/47780 [01:47<01:09, 241.21 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19964/47780 [01:47<01:35, 291.68 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33310/47780 [01:47<00:39, 369.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31325/47780 [01:47<00:48, 336.11 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31248/47780 [01:47<00:48, 339.90 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32382/47780 [01:47<00:49, 309.54 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32053/47780 [01:47<00:56, 277.71 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32011/47780 [01:47<00:51, 306.81 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31141/47780 [01:47<01:11, 234.03 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 19994/47780 [01:47<01:43, 269.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31364/47780 [01:47<00:47, 344.30 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33348/47780 [01:47<00:43, 332.17 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32414/47780 [01:47<00:50, 302.73 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31283/47780 [01:47<00:50, 327.25 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32042/47780 [01:47<00:51, 304.26 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31178/47780 [01:47<01:02, 265.25 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20025/47780 [01:47<01:38, 280.52 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31399/47780 [01:47<00:47, 345.15 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32081/47780 [01:47<01:06, 234.65 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33384/47780 [01:47<00:43, 329.50 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32445/47780 [01:47<00:52, 294.44 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32073/47780 [01:47<00:52, 301.89 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31316/47780 [01:47<00:51, 317.24 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31206/47780 [01:47<01:01, 268.85 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20057/47780 [01:47<01:36, 288.21 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32125/47780 [01:47<00:54, 285.62 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33418/47780 [01:47<00:45, 318.37 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31434/47780 [01:47<00:53, 304.61 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31349/47780 [01:47<00:51, 320.83 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32106/47780 [01:47<00:50, 309.79 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32482/47780 [01:47<00:49, 311.96 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31236/47780 [01:47<01:00, 275.00 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20092/47780 [01:47<01:31, 302.16 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32156/47780 [01:47<00:56, 274.71 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33453/47780 [01:47<00:44, 323.26 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31470/47780 [01:47<00:51, 319.00 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31384/47780 [01:47<00:50, 326.31 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32514/47780 [01:47<00:50, 303.64 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32138/47780 [01:47<00:52, 295.96 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31270/47780 [01:47<00:56, 290.31 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20129/47780 [01:47<01:28, 311.00 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32191/47780 [01:47<00:55, 282.55 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31419/47780 [01:47<00:49, 329.27 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33486/47780 [01:47<00:47, 299.23 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32550/47780 [01:47<00:48, 312.73 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31303/47780 [01:47<00:54, 301.69 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32174/47780 [01:47<00:50, 307.40 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31503/47780 [01:47<00:56, 290.36 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20161/47780 [01:47<01:28, 313.34 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32226/47780 [01:47<00:52, 297.13 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31453/47780 [01:47<00:50, 320.98 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33517/47780 [01:47<00:47, 302.02 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32582/47780 [01:47<00:48, 310.62 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32214/47780 [01:47<00:47, 330.23 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31533/47780 [01:47<00:55, 292.15 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31334/47780 [01:47<00:57, 287.06 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20195/47780 [01:47<01:26, 319.42 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32257/47780 [01:47<00:53, 290.79 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31486/47780 [01:47<00:52, 313.34 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32614/47780 [01:47<00:49, 306.78 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32248/47780 [01:47<00:47, 324.65 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31563/47780 [01:47<00:56, 288.34 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33548/47780 [01:47<00:50, 279.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20230/47780 [01:47<01:25, 322.61 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31363/47780 [01:47<01:01, 266.78 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32287/47780 [01:47<00:54, 284.41 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31524/47780 [01:47<00:49, 329.03 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32647/47780 [01:47<00:48, 313.26 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31598/47780 [01:47<00:53, 300.58 examples/s]Tokenizing train dataset (num_proc=32):  42%|████▏     | 20273/47780 [01:47<01:18, 352.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33577/47780 [01:48<00:52, 270.94 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31391/47780 [01:48<01:01, 267.98 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32281/47780 [01:48<00:53, 290.30 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32325/47780 [01:48<00:49, 310.37 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32686/47780 [01:48<00:45, 335.35 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31629/47780 [01:48<00:54, 298.88 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31558/47780 [01:48<00:53, 303.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20309/47780 [01:48<01:20, 339.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31419/47780 [01:48<01:00, 271.15 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32319/47780 [01:48<00:49, 312.09 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33605/47780 [01:48<00:54, 259.46 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32360/47780 [01:48<00:49, 314.49 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32720/47780 [01:48<00:47, 314.68 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20353/47780 [01:48<01:15, 365.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31590/47780 [01:48<00:53, 301.49 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31451/47780 [01:48<00:58, 278.56 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33644/47780 [01:48<00:48, 291.10 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32351/47780 [01:48<00:52, 293.77 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32394/47780 [01:48<00:48, 318.30 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31660/47780 [01:48<01:06, 241.02 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32755/47780 [01:48<00:46, 321.37 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31480/47780 [01:48<00:58, 278.32 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33680/47780 [01:48<00:45, 306.58 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20390/47780 [01:48<01:20, 342.20 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32386/47780 [01:48<00:50, 305.64 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31621/47780 [01:48<00:59, 271.00 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32428/47780 [01:48<00:47, 320.87 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31700/47780 [01:48<00:58, 275.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32788/47780 [01:48<00:47, 316.25 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20425/47780 [01:48<01:20, 340.56 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31508/47780 [01:48<01:00, 267.04 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33712/47780 [01:48<00:47, 293.44 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32418/47780 [01:48<00:49, 307.97 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31654/47780 [01:48<00:58, 277.60 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32461/47780 [01:48<00:47, 323.46 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31742/47780 [01:48<00:51, 312.04 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32821/47780 [01:48<00:47, 317.82 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31535/47780 [01:48<01:02, 261.96 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32450/47780 [01:48<00:50, 302.88 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33748/47780 [01:48<00:46, 302.33 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31698/47780 [01:48<00:50, 317.33 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32495/47780 [01:48<00:48, 317.27 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20460/47780 [01:48<01:29, 305.42 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31778/47780 [01:48<00:49, 321.36 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32853/47780 [01:48<00:47, 313.83 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31563/47780 [01:48<01:00, 266.61 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33780/47780 [01:48<00:46, 303.69 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32486/47780 [01:48<00:48, 315.14 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32531/47780 [01:48<00:46, 326.56 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31731/47780 [01:48<00:51, 310.54 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31820/47780 [01:48<00:46, 344.63 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20492/47780 [01:48<01:31, 297.76 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32885/47780 [01:48<00:49, 302.25 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31591/47780 [01:48<01:02, 258.97 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33811/47780 [01:48<00:46, 300.02 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32525/47780 [01:48<00:46, 328.89 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32564/47780 [01:48<00:48, 315.81 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20524/47780 [01:48<01:30, 302.54 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31856/47780 [01:48<00:49, 323.50 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31763/47780 [01:48<00:57, 279.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32916/47780 [01:48<00:48, 304.02 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31622/47780 [01:48<00:59, 270.31 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33842/47780 [01:48<00:46, 301.57 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32560/47780 [01:48<00:45, 334.68 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20555/47780 [01:48<01:32, 294.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32597/47780 [01:48<00:50, 298.55 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31792/47780 [01:48<00:59, 268.39 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32947/47780 [01:48<00:50, 292.03 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31890/47780 [01:48<00:54, 290.55 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31651/47780 [01:48<01:01, 260.63 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32594/47780 [01:48<00:47, 321.67 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32629/47780 [01:49<00:50, 302.04 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33874/47780 [01:49<00:52, 265.74 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32979/47780 [01:49<00:49, 299.80 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20585/47780 [01:49<01:42, 264.46 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31820/47780 [01:49<01:04, 248.11 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32628/47780 [01:49<00:47, 319.52 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31921/47780 [01:49<00:57, 278.10 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31679/47780 [01:49<01:03, 252.48 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33906/47780 [01:49<00:49, 278.51 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32660/47780 [01:49<00:51, 291.17 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33015/47780 [01:49<00:47, 313.97 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31846/47780 [01:49<01:03, 250.72 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20613/47780 [01:49<01:48, 250.24 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31705/47780 [01:49<01:05, 246.02 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32662/47780 [01:49<00:50, 301.91 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31950/47780 [01:49<01:02, 252.66 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32693/47780 [01:49<00:50, 298.57 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33050/47780 [01:49<00:45, 323.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33935/47780 [01:49<00:52, 262.53 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20646/47780 [01:49<01:40, 270.58 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31876/47780 [01:49<01:01, 259.61 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32694/47780 [01:49<00:49, 302.83 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31731/47780 [01:49<01:06, 239.71 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32725/47780 [01:49<00:49, 301.26 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31977/47780 [01:49<01:03, 247.49 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33962/47780 [01:49<00:52, 263.77 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33084/47780 [01:49<00:47, 307.58 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31903/47780 [01:49<01:00, 261.61 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20676/47780 [01:49<01:44, 258.91 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32731/47780 [01:49<00:47, 318.37 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31756/47780 [01:49<01:06, 239.42 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32762/47780 [01:49<00:47, 317.14 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33990/47780 [01:49<00:51, 266.16 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33129/47780 [01:49<00:42, 341.44 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32003/47780 [01:49<01:07, 233.94 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31934/47780 [01:49<00:57, 275.08 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20709/47780 [01:49<01:38, 274.84 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32764/47780 [01:49<00:46, 321.63 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31785/47780 [01:49<01:04, 248.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32794/47780 [01:49<00:47, 314.39 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34018/47780 [01:49<00:51, 266.10 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32033/47780 [01:49<01:04, 245.89 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31969/47780 [01:49<00:53, 296.17 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33164/47780 [01:49<00:45, 324.08 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32797/47780 [01:49<00:46, 323.98 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20738/47780 [01:49<01:40, 269.90 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31812/47780 [01:49<01:03, 252.01 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32833/47780 [01:49<00:44, 335.88 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34052/47780 [01:49<00:47, 286.76 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31999/47780 [01:49<00:53, 297.02 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32060/47780 [01:49<01:02, 249.59 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33198/47780 [01:49<00:44, 324.98 examples/s]Tokenizing train dataset (num_proc=32):  43%|████▎     | 20772/47780 [01:49<01:35, 284.27 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31839/47780 [01:49<01:02, 253.96 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32830/47780 [01:49<00:49, 304.07 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32867/47780 [01:49<00:46, 318.74 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34081/47780 [01:49<00:49, 277.72 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32092/47780 [01:49<00:59, 265.71 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32030/47780 [01:49<00:54, 287.88 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33231/47780 [01:49<00:46, 315.47 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20809/47780 [01:49<01:27, 306.91 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31866/47780 [01:49<01:02, 255.69 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32861/47780 [01:49<00:49, 302.74 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32905/47780 [01:49<00:44, 335.92 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32121/47780 [01:49<00:57, 272.26 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34110/47780 [01:49<00:54, 253.06 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32060/47780 [01:49<00:57, 273.13 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20842/47780 [01:49<01:26, 311.15 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33263/47780 [01:49<00:48, 297.19 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32896/47780 [01:49<00:47, 312.51 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31892/47780 [01:49<01:03, 250.58 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32941/47780 [01:49<00:43, 339.18 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32151/47780 [01:50<00:57, 274.08 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34141/47780 [01:50<00:50, 268.27 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32093/47780 [01:50<00:55, 285.08 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▎     | 20881/47780 [01:50<01:20, 332.32 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33298/47780 [01:50<00:46, 308.20 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31918/47780 [01:50<01:04, 247.36 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32928/47780 [01:50<00:49, 300.91 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32976/47780 [01:50<00:46, 320.08 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32181/47780 [01:50<00:55, 281.40 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34173/47780 [01:50<00:49, 276.50 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32126/47780 [01:50<00:53, 291.22 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33330/47780 [01:50<00:46, 310.96 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20915/47780 [01:50<01:27, 306.22 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32964/47780 [01:50<00:47, 314.04 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31947/47780 [01:50<01:03, 248.84 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32211/47780 [01:50<00:54, 286.55 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33017/47780 [01:50<00:43, 341.42 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34203/47780 [01:50<00:48, 279.93 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32156/47780 [01:50<00:54, 287.06 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33362/47780 [01:50<00:47, 303.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20947/47780 [01:50<01:28, 302.95 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32996/47780 [01:50<00:48, 305.32 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31973/47780 [01:50<01:04, 243.95 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32241/47780 [01:50<00:54, 287.36 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33052/47780 [01:50<00:43, 339.52 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34232/47780 [01:50<00:50, 269.97 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32194/47780 [01:50<00:50, 309.99 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33393/47780 [01:50<00:47, 305.32 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33030/47780 [01:50<00:47, 311.63 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32003/47780 [01:50<01:00, 259.46 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 20978/47780 [01:50<01:35, 280.23 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32270/47780 [01:50<00:53, 287.37 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33090/47780 [01:50<00:42, 347.53 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32237/47780 [01:50<00:45, 344.05 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34260/47780 [01:50<00:54, 245.92 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33424/47780 [01:50<00:51, 281.00 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33070/47780 [01:50<00:44, 329.22 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21008/47780 [01:50<01:33, 285.47 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32031/47780 [01:50<01:01, 256.36 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32300/47780 [01:50<00:54, 281.85 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33125/47780 [01:50<00:44, 328.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32272/47780 [01:50<00:45, 338.26 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33454/47780 [01:50<00:50, 286.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34295/47780 [01:50<00:49, 269.71 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33113/47780 [01:50<00:41, 353.88 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21037/47780 [01:50<01:35, 280.20 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32336/47780 [01:50<00:51, 301.00 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33159/47780 [01:50<00:45, 318.09 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32057/47780 [01:50<01:08, 228.33 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32311/47780 [01:50<00:44, 349.09 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33484/47780 [01:50<00:49, 286.04 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34323/47780 [01:50<00:50, 267.49 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33149/47780 [01:50<00:41, 348.42 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32370/47780 [01:50<00:49, 308.75 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21066/47780 [01:50<01:39, 268.24 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32114/47780 [01:50<00:49, 315.88 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32347/47780 [01:50<00:44, 348.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33192/47780 [01:50<00:46, 310.62 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33513/47780 [01:50<00:50, 281.61 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34351/47780 [01:50<00:51, 259.09 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32404/47780 [01:50<00:48, 313.99 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33185/47780 [01:50<00:44, 325.10 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21095/47780 [01:50<01:40, 265.74 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32152/47780 [01:50<00:47, 330.11 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33230/47780 [01:50<00:45, 323.17 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32384/47780 [01:50<00:44, 342.49 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33542/47780 [01:50<00:51, 277.45 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34378/47780 [01:50<00:53, 251.47 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21130/47780 [01:50<01:34, 282.66 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32436/47780 [01:50<00:52, 291.91 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33224/47780 [01:50<00:44, 328.38 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32188/47780 [01:50<00:46, 338.30 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33263/47780 [01:50<00:46, 314.27 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33574/47780 [01:51<00:49, 286.45 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32420/47780 [01:51<00:49, 311.64 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34416/47780 [01:51<00:48, 276.77 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33260/47780 [01:51<00:43, 333.47 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21159/47780 [01:51<01:35, 278.15 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32466/47780 [01:51<00:53, 284.86 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32223/47780 [01:51<00:46, 337.56 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33295/47780 [01:51<00:48, 299.55 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33604/47780 [01:51<00:51, 274.42 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34444/47780 [01:51<00:48, 272.17 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32495/47780 [01:51<00:53, 283.16 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21187/47780 [01:51<01:40, 264.33 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32452/47780 [01:51<00:59, 258.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33296/47780 [01:51<00:46, 309.17 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33333/47780 [01:51<00:45, 314.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32258/47780 [01:51<00:50, 305.81 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33633/47780 [01:51<00:51, 275.93 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34476/47780 [01:51<00:47, 279.36 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32524/47780 [01:51<00:54, 281.51 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21214/47780 [01:51<01:40, 265.55 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33330/47780 [01:51<00:46, 313.52 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33366/47780 [01:51<00:45, 318.88 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32291/47780 [01:51<00:50, 309.64 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32481/47780 [01:51<01:00, 254.13 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33668/47780 [01:51<00:48, 293.45 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34508/47780 [01:51<00:45, 290.69 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32561/47780 [01:51<00:50, 299.98 examples/s]Tokenizing train dataset (num_proc=32):  44%|████▍     | 21245/47780 [01:51<01:38, 270.27 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33402/47780 [01:51<00:44, 325.90 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32510/47780 [01:51<00:59, 257.72 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33362/47780 [01:51<00:48, 295.97 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32325/47780 [01:51<00:51, 301.37 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33700/47780 [01:51<00:47, 295.58 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34539/47780 [01:51<00:48, 274.16 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32592/47780 [01:51<00:51, 297.72 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21273/47780 [01:51<01:37, 272.05 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32540/47780 [01:51<00:56, 268.34 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32361/47780 [01:51<00:49, 314.02 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33398/47780 [01:51<00:46, 307.62 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33435/47780 [01:51<00:47, 300.33 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33730/47780 [01:51<00:49, 282.39 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34571/47780 [01:51<00:46, 283.90 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32622/47780 [01:51<00:51, 293.25 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21301/47780 [01:51<01:43, 256.48 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32393/47780 [01:51<00:49, 311.88 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33471/47780 [01:51<00:45, 313.40 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33430/47780 [01:51<00:48, 294.81 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32568/47780 [01:51<01:01, 247.34 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33759/47780 [01:51<00:50, 279.65 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34600/47780 [01:51<00:47, 278.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32652/47780 [01:51<00:51, 291.92 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21327/47780 [01:51<01:46, 249.46 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32425/47780 [01:51<00:52, 294.02 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33503/47780 [01:51<00:47, 299.38 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32605/47780 [01:51<00:55, 273.95 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33466/47780 [01:51<00:48, 293.44 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33788/47780 [01:51<00:51, 271.93 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34629/47780 [01:51<00:48, 273.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32682/47780 [01:51<00:52, 290.27 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21355/47780 [01:51<01:43, 255.05 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32459/47780 [01:51<00:50, 303.77 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33535/47780 [01:51<00:46, 304.27 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32636/47780 [01:51<00:54, 277.67 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33504/47780 [01:51<00:45, 313.23 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33816/47780 [01:51<00:52, 268.28 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34657/47780 [01:51<00:48, 272.16 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32717/47780 [01:51<00:49, 304.98 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21385/47780 [01:51<01:39, 265.84 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33572/47780 [01:51<00:44, 319.10 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32492/47780 [01:51<00:49, 307.63 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32669/47780 [01:51<00:51, 291.72 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33541/47780 [01:51<00:43, 328.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32749/47780 [01:52<00:48, 309.23 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33843/47780 [01:52<00:58, 239.16 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21413/47780 [01:52<01:38, 268.70 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34685/47780 [01:52<00:52, 251.49 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33607/47780 [01:52<00:43, 327.75 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32699/47780 [01:52<00:51, 290.65 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32524/47780 [01:52<00:52, 290.67 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33576/47780 [01:52<00:45, 309.31 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32780/47780 [01:52<00:49, 302.55 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33878/47780 [01:52<00:53, 260.45 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21440/47780 [01:52<01:39, 265.25 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34716/47780 [01:52<00:50, 260.92 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33644/47780 [01:52<00:42, 336.20 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32729/47780 [01:52<00:51, 290.36 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32558/47780 [01:52<00:51, 292.74 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32814/47780 [01:52<00:47, 313.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33608/47780 [01:52<00:47, 300.28 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21469/47780 [01:52<01:36, 271.64 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33905/47780 [01:52<00:54, 253.84 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34743/47780 [01:52<00:50, 256.91 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33683/47780 [01:52<00:40, 351.54 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32759/47780 [01:52<00:52, 285.76 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32592/47780 [01:52<00:49, 304.63 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32846/47780 [01:52<00:47, 315.31 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33639/47780 [01:52<00:47, 296.01 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34772/47780 [01:52<00:49, 261.98 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33943/47780 [01:52<00:50, 274.14 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33724/47780 [01:52<00:39, 352.42 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32793/47780 [01:52<00:50, 298.49 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▍     | 21497/47780 [01:52<01:55, 228.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32623/47780 [01:52<00:52, 290.23 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32878/47780 [01:52<00:50, 292.59 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33669/47780 [01:52<00:48, 288.07 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34802/47780 [01:52<00:49, 263.78 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33971/47780 [01:52<00:50, 275.64 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33764/47780 [01:52<00:39, 353.84 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21527/47780 [01:52<01:46, 245.88 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32824/47780 [01:52<00:53, 279.41 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32658/47780 [01:52<00:49, 303.34 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32920/47780 [01:52<00:45, 328.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33710/47780 [01:52<00:44, 318.20 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34004/47780 [01:52<00:47, 290.54 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34831/47780 [01:52<00:47, 270.83 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33801/47780 [01:52<00:39, 358.06 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32870/47780 [01:52<00:46, 322.14 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21555/47780 [01:52<01:47, 244.48 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32689/47780 [01:52<00:50, 301.78 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33743/47780 [01:52<00:44, 317.86 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32954/47780 [01:52<00:48, 306.49 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34034/47780 [01:52<00:47, 290.28 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34859/47780 [01:52<00:52, 245.74 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33837/47780 [01:52<00:40, 346.60 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32903/47780 [01:52<00:45, 324.30 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21581/47780 [01:52<01:47, 243.56 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32720/47780 [01:52<00:50, 299.76 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33775/47780 [01:52<00:43, 318.44 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34068/47780 [01:52<00:45, 304.43 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32989/47780 [01:52<00:47, 308.85 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34886/47780 [01:52<00:51, 249.55 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32936/47780 [01:52<00:45, 325.89 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21610/47780 [01:52<01:43, 253.46 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33872/47780 [01:52<00:43, 322.31 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32751/47780 [01:52<00:51, 289.91 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33807/47780 [01:52<00:45, 307.95 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34102/47780 [01:52<00:44, 307.26 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33021/47780 [01:52<00:48, 302.82 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34914/47780 [01:52<00:51, 249.49 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32969/47780 [01:52<00:45, 323.42 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21637/47780 [01:52<01:41, 257.98 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33909/47780 [01:52<00:42, 328.11 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32782/47780 [01:52<00:51, 292.59 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34134/47780 [01:52<00:44, 307.87 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33838/47780 [01:52<00:48, 288.55 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33052/47780 [01:53<00:52, 281.77 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33003/47780 [01:53<00:45, 321.77 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34940/47780 [01:53<00:52, 243.45 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21664/47780 [01:53<01:41, 258.23 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32816/47780 [01:53<00:50, 298.94 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33943/47780 [01:53<00:45, 307.49 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33875/47780 [01:53<00:45, 308.17 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34165/47780 [01:53<00:45, 301.35 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33083/47780 [01:53<00:51, 283.61 examples/s]Tokenizing train dataset (num_proc=32):  45%|████▌     | 21691/47780 [01:53<01:41, 256.00 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34973/47780 [01:53<00:49, 259.79 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33036/47780 [01:53<00:49, 298.84 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32853/47780 [01:53<00:47, 316.50 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33975/47780 [01:53<00:46, 298.17 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33919/47780 [01:53<00:40, 341.43 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34196/47780 [01:53<00:45, 299.61 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33113/47780 [01:53<00:54, 267.70 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35003/47780 [01:53<00:48, 265.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33067/47780 [01:53<00:48, 301.80 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21717/47780 [01:53<01:47, 243.22 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32885/47780 [01:53<00:49, 299.90 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34006/47780 [01:53<00:45, 301.29 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34229/47780 [01:53<00:44, 305.74 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33955/47780 [01:53<00:43, 321.11 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33099/47780 [01:53<00:47, 306.90 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33141/47780 [01:53<00:56, 259.95 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21750/47780 [01:53<01:37, 267.22 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32918/47780 [01:53<00:48, 304.83 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35030/47780 [01:53<00:52, 241.91 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34037/47780 [01:53<00:46, 296.92 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34268/47780 [01:53<00:41, 326.37 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33994/47780 [01:53<00:40, 339.91 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33135/47780 [01:53<00:46, 315.19 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21778/47780 [01:53<01:37, 266.52 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33169/47780 [01:53<00:56, 256.62 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35061/47780 [01:53<00:49, 254.83 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32949/47780 [01:53<00:49, 299.44 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34302/47780 [01:53<00:42, 315.37 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34035/47780 [01:53<00:38, 355.59 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34067/47780 [01:53<00:50, 273.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33174/47780 [01:53<00:43, 336.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21809/47780 [01:53<01:34, 274.40 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32980/47780 [01:53<00:48, 302.08 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35087/47780 [01:53<00:50, 253.49 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33195/47780 [01:53<01:02, 234.93 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34338/47780 [01:53<00:41, 323.14 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34095/47780 [01:53<00:51, 263.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34072/47780 [01:53<00:40, 336.16 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21840/47780 [01:53<01:32, 279.50 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33208/47780 [01:53<00:45, 322.64 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35115/47780 [01:53<00:48, 259.10 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33222/47780 [01:53<00:59, 242.98 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33011/47780 [01:53<00:51, 287.89 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34371/47780 [01:53<00:42, 315.77 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34122/47780 [01:53<00:51, 262.81 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34109/47780 [01:53<00:39, 342.42 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21875/47780 [01:53<01:26, 298.21 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33242/47780 [01:53<00:45, 320.38 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35149/47780 [01:53<00:44, 280.82 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33249/47780 [01:53<00:58, 248.98 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33041/47780 [01:53<00:51, 288.31 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34407/47780 [01:53<00:40, 328.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34152/47780 [01:53<00:50, 269.35 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34144/47780 [01:53<00:44, 309.66 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21905/47780 [01:53<01:28, 291.96 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33275/47780 [01:53<00:44, 323.09 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35178/47780 [01:53<00:44, 283.36 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33279/47780 [01:53<00:56, 257.32 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33080/47780 [01:53<00:47, 310.23 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34180/47780 [01:53<00:51, 264.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34440/47780 [01:53<00:44, 297.95 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34176/47780 [01:54<00:43, 309.24 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21939/47780 [01:53<01:26, 298.81 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35207/47780 [01:54<00:44, 281.94 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33310/47780 [01:54<00:53, 271.93 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33308/47780 [01:54<00:48, 297.02 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33114/47780 [01:54<00:46, 318.58 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34475/47780 [01:54<00:43, 308.70 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34207/47780 [01:54<00:52, 256.48 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 21969/47780 [01:54<01:28, 292.44 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35243/47780 [01:54<00:41, 304.59 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34210/47780 [01:54<00:45, 298.09 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33338/47780 [01:54<00:53, 268.22 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33339/47780 [01:54<00:50, 285.47 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33146/47780 [01:54<00:49, 296.99 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34236/47780 [01:54<00:51, 260.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34511/47780 [01:54<00:42, 309.39 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22001/47780 [01:54<01:26, 297.05 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34241/47780 [01:54<00:45, 300.68 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35277/47780 [01:54<00:42, 297.59 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33369/47780 [01:54<00:51, 279.83 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33372/47780 [01:54<00:48, 297.41 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33180/47780 [01:54<00:47, 307.10 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34543/47780 [01:54<00:43, 305.25 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22031/47780 [01:54<01:26, 297.57 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34263/47780 [01:54<00:57, 234.29 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34272/47780 [01:54<00:46, 292.66 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33398/47780 [01:54<00:51, 279.62 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35307/47780 [01:54<00:43, 285.44 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33215/47780 [01:54<00:46, 315.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33404/47780 [01:54<00:49, 290.93 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34580/47780 [01:54<00:40, 323.12 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34305/47780 [01:54<00:48, 280.24 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22061/47780 [01:54<01:31, 282.18 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35338/47780 [01:54<00:43, 288.88 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34302/47780 [01:54<00:47, 283.56 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33442/47780 [01:54<00:45, 312.09 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33427/47780 [01:54<00:55, 258.52 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33247/47780 [01:54<00:48, 299.74 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34613/47780 [01:54<00:41, 319.45 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34335/47780 [01:54<00:47, 285.59 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▌     | 22092/47780 [01:54<01:28, 289.97 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34332/47780 [01:54<00:49, 273.10 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35368/47780 [01:54<00:44, 279.16 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33474/47780 [01:54<00:47, 300.73 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33283/47780 [01:54<00:46, 313.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34646/47780 [01:54<00:41, 317.27 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33454/47780 [01:54<01:01, 231.55 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34369/47780 [01:54<00:45, 297.62 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22122/47780 [01:54<01:28, 289.59 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34367/47780 [01:54<00:46, 290.86 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35401/47780 [01:54<00:44, 278.03 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33512/47780 [01:54<00:46, 309.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33315/47780 [01:54<00:47, 301.36 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33492/47780 [01:54<00:52, 269.77 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34679/47780 [01:54<00:41, 314.00 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22152/47780 [01:54<01:28, 289.20 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34401/47780 [01:54<00:45, 291.32 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34406/47780 [01:54<00:42, 318.04 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35429/47780 [01:54<00:45, 269.59 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33544/47780 [01:54<00:45, 311.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33346/47780 [01:54<00:48, 300.27 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33522/47780 [01:54<00:51, 277.86 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34717/47780 [01:54<00:39, 329.12 examples/s]Tokenizing train dataset (num_proc=32):  46%|████▋     | 22185/47780 [01:54<01:27, 290.87 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34440/47780 [01:54<00:41, 320.83 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34431/47780 [01:54<00:49, 269.82 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35463/47780 [01:54<00:42, 288.93 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33576/47780 [01:54<00:47, 300.48 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33377/47780 [01:54<00:51, 281.43 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33551/47780 [01:54<00:52, 269.27 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34751/47780 [01:54<00:42, 306.80 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22225/47780 [01:54<01:19, 321.91 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34474/47780 [01:54<00:41, 318.09 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34459/47780 [01:55<00:50, 266.14 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35493/47780 [01:55<00:43, 282.46 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33607/47780 [01:55<00:46, 303.13 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33420/47780 [01:55<00:44, 321.49 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33579/47780 [01:55<00:52, 271.95 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34788/47780 [01:55<00:40, 321.39 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22259/47780 [01:55<01:18, 323.69 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34507/47780 [01:55<00:44, 297.15 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35534/47780 [01:55<00:38, 314.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33640/47780 [01:55<00:45, 310.71 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34486/47780 [01:55<00:54, 243.30 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33453/47780 [01:55<00:44, 323.75 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33607/47780 [01:55<00:53, 265.27 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34823/47780 [01:55<00:39, 327.49 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22292/47780 [01:55<01:23, 303.98 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34540/47780 [01:55<00:43, 304.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35572/47780 [01:55<00:37, 329.86 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33672/47780 [01:55<00:48, 293.15 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33489/47780 [01:55<00:43, 326.20 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34511/47780 [01:55<00:57, 230.65 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34860/47780 [01:55<00:38, 334.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33634/47780 [01:55<00:55, 252.65 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22323/47780 [01:55<01:37, 262.06 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35606/47780 [01:55<00:39, 310.99 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34571/47780 [01:55<00:47, 280.81 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33707/47780 [01:55<00:46, 302.47 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34542/47780 [01:55<00:52, 249.85 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33522/47780 [01:55<00:46, 306.38 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33666/47780 [01:55<00:53, 265.33 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34899/47780 [01:55<00:37, 342.26 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22370/47780 [01:55<01:20, 314.92 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34570/47780 [01:55<00:51, 256.69 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35638/47780 [01:55<00:41, 291.26 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33703/47780 [01:55<00:48, 291.17 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33738/47780 [01:55<00:50, 276.60 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34600/47780 [01:55<00:51, 257.93 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33555/47780 [01:55<00:49, 286.39 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34935/47780 [01:55<00:40, 317.58 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22404/47780 [01:55<01:19, 319.92 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34597/47780 [01:55<00:51, 257.56 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35676/47780 [01:55<00:39, 308.44 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33773/47780 [01:55<00:47, 294.66 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34629/47780 [01:55<00:49, 264.06 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33733/47780 [01:55<00:50, 276.95 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33587/47780 [01:55<00:49, 287.59 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34968/47780 [01:55<00:42, 304.94 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34624/47780 [01:55<00:52, 252.62 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35715/47780 [01:55<00:37, 323.66 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22438/47780 [01:55<01:28, 287.74 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34661/47780 [01:55<00:48, 273.08 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33804/47780 [01:55<00:48, 287.59 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33619/47780 [01:55<00:47, 296.16 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33762/47780 [01:55<00:52, 266.95 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34999/47780 [01:55<00:43, 293.31 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34650/47780 [01:55<00:52, 251.78 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35753/47780 [01:55<00:35, 335.56 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22481/47780 [01:55<01:19, 317.42 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34690/47780 [01:55<00:48, 268.66 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33839/47780 [01:55<00:47, 295.44 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33650/47780 [01:55<00:49, 287.33 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33789/47780 [01:55<00:53, 259.35 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35038/47780 [01:55<00:40, 316.33 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34676/47780 [01:55<00:52, 248.55 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35787/47780 [01:55<00:37, 321.70 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34718/47780 [01:55<00:48, 267.56 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33869/47780 [01:55<00:47, 293.40 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22515/47780 [01:55<01:19, 318.26 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33684/47780 [01:55<00:46, 301.55 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35077/47780 [01:55<00:38, 332.94 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33816/47780 [01:55<00:57, 241.12 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34701/47780 [01:56<00:53, 243.27 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35837/47780 [01:56<00:32, 367.68 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22548/47780 [01:56<01:19, 318.28 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34745/47780 [01:56<00:48, 266.46 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33909/47780 [01:56<00:43, 316.15 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33715/47780 [01:56<00:48, 291.17 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35114/47780 [01:56<00:37, 335.82 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33845/47780 [01:56<00:54, 254.04 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34729/47780 [01:56<00:52, 250.98 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22581/47780 [01:56<01:21, 310.94 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35876/47780 [01:56<00:33, 357.61 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34773/47780 [01:56<00:49, 261.21 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33946/47780 [01:56<00:42, 327.50 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33745/47780 [01:56<00:49, 281.16 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33884/47780 [01:56<00:48, 284.99 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35148/47780 [01:56<00:40, 315.38 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22613/47780 [01:56<01:20, 313.40 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33992/47780 [01:56<00:38, 361.20 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35915/47780 [01:56<00:32, 362.82 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34755/47780 [01:56<00:56, 229.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34801/47780 [01:56<00:49, 261.15 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33777/47780 [01:56<00:49, 285.47 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33916/47780 [01:56<00:47, 294.45 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35190/47780 [01:56<00:37, 336.98 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34789/47780 [01:56<00:50, 257.05 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34835/47780 [01:56<00:45, 283.09 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35960/47780 [01:56<00:30, 383.11 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22645/47780 [01:56<01:25, 293.27 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 34030/47780 [01:56<00:39, 346.72 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33946/47780 [01:56<00:46, 295.37 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33810/47780 [01:56<00:48, 288.24 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35225/47780 [01:56<00:37, 336.49 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34865/47780 [01:56<00:46, 278.51 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34816/47780 [01:56<00:51, 251.92 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35999/47780 [01:56<00:32, 368.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34065/47780 [01:56<00:39, 343.69 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33977/47780 [01:56<00:46, 297.15 examples/s]Tokenizing train dataset (num_proc=32):  47%|████▋     | 22683/47780 [01:56<01:25, 293.56 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33839/47780 [01:56<00:48, 288.42 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35260/47780 [01:56<00:37, 332.74 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34898/47780 [01:56<00:43, 293.05 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34851/47780 [01:56<00:46, 276.33 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34105/47780 [01:56<00:38, 355.71 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36037/47780 [01:56<00:32, 359.34 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22713/47780 [01:56<01:25, 291.62 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33868/47780 [01:56<00:49, 279.00 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34007/47780 [01:56<00:49, 279.29 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35294/47780 [01:56<00:39, 316.98 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34141/47780 [01:56<00:38, 352.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34928/47780 [01:56<00:45, 281.77 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36074/47780 [01:56<00:32, 360.12 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34880/47780 [01:56<00:48, 267.95 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34036/47780 [01:56<00:48, 281.24 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33896/47780 [01:56<00:51, 268.00 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22743/47780 [01:56<01:33, 267.79 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35326/47780 [01:56<00:40, 304.29 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34908/47780 [01:56<00:50, 256.84 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36112/47780 [01:56<00:34, 337.38 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34957/47780 [01:56<00:49, 258.25 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34177/47780 [01:56<00:42, 320.93 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34065/47780 [01:56<00:49, 277.76 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33926/47780 [01:56<00:51, 270.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22776/47780 [01:56<01:28, 284.03 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35357/47780 [01:56<00:45, 270.32 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34934/47780 [01:56<00:50, 256.62 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36148/47780 [01:56<00:34, 336.25 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34213/47780 [01:56<00:41, 328.68 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34997/47780 [01:56<00:44, 289.94 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34093/47780 [01:56<00:50, 269.17 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33955/47780 [01:56<00:50, 273.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22805/47780 [01:56<01:30, 274.98 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34960/47780 [01:57<00:50, 253.41 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35385/47780 [01:57<00:47, 261.15 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36187/47780 [01:57<00:33, 350.02 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34247/47780 [01:57<00:40, 330.69 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35033/47780 [01:57<00:42, 302.12 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33989/47780 [01:57<00:47, 288.78 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34127/47780 [01:57<00:49, 276.66 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22833/47780 [01:57<01:47, 232.61 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36223/47780 [01:57<00:33, 349.26 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35413/47780 [01:57<00:47, 259.12 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34287/47780 [01:57<00:39, 340.01 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35064/47780 [01:57<00:42, 297.99 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34019/47780 [01:57<00:47, 288.75 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34157/47780 [01:57<00:48, 279.98 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34986/47780 [01:57<00:59, 215.98 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35450/47780 [01:57<00:43, 282.66 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35097/47780 [01:57<00:41, 303.12 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34322/47780 [01:57<00:41, 324.63 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34194/47780 [01:57<00:44, 305.15 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34052/47780 [01:57<00:48, 281.29 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22858/47780 [01:57<01:59, 208.15 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35024/47780 [01:57<00:50, 252.76 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36259/47780 [01:57<00:39, 290.20 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35480/47780 [01:57<00:42, 287.06 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35132/47780 [01:57<00:40, 310.04 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34225/47780 [01:57<00:45, 295.87 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34087/47780 [01:57<00:46, 297.00 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34355/47780 [01:57<00:44, 299.63 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22881/47780 [01:57<02:01, 205.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36299/47780 [01:57<00:36, 317.76 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35051/47780 [01:57<00:52, 242.09 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35519/47780 [01:57<00:39, 309.16 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35164/47780 [01:57<00:42, 299.29 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34255/47780 [01:57<00:46, 287.98 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34386/47780 [01:57<00:44, 299.20 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 22987/47780 [01:57<00:59, 415.24 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34118/47780 [01:57<00:48, 284.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36334/47780 [01:57<00:35, 326.21 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35080/47780 [01:57<00:52, 242.98 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35552/47780 [01:57<00:41, 294.62 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35195/47780 [01:57<00:43, 286.48 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34152/47780 [01:57<00:45, 296.73 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36368/47780 [01:57<00:34, 329.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34284/47780 [01:57<00:50, 267.36 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34417/47780 [01:57<00:48, 275.06 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35105/47780 [01:57<00:52, 243.48 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23034/47780 [01:57<01:07, 368.25 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35582/47780 [01:57<00:42, 287.29 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35229/47780 [01:57<00:42, 297.79 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34182/47780 [01:57<00:45, 297.45 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36417/47780 [01:57<00:30, 373.75 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34317/47780 [01:57<00:47, 284.31 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34446/47780 [01:57<00:48, 276.10 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35133/47780 [01:57<00:51, 245.65 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23076/47780 [01:57<01:09, 356.68 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35611/47780 [01:57<00:44, 272.99 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34212/47780 [01:57<00:46, 291.76 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35259/47780 [01:57<00:43, 285.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36456/47780 [01:57<00:30, 370.82 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34481/47780 [01:57<00:45, 289.78 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34346/47780 [01:57<00:50, 264.16 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35170/47780 [01:57<00:46, 273.64 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35639/47780 [01:57<00:45, 269.11 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23115/47780 [01:57<01:11, 343.61 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36494/47780 [01:57<00:30, 365.30 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35295/47780 [01:57<00:42, 296.35 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34242/47780 [01:57<00:48, 278.20 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34521/47780 [01:57<00:41, 316.43 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35200/47780 [01:57<00:44, 280.92 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34373/47780 [01:57<00:53, 252.85 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35668/47780 [01:58<00:44, 274.81 examples/s]Tokenizing train dataset (num_proc=32):  48%|████▊     | 23152/47780 [01:57<01:11, 344.39 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36532/47780 [01:58<00:30, 364.54 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35326/47780 [01:58<00:43, 288.14 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34275/47780 [01:58<00:47, 281.79 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34558/47780 [01:58<00:40, 327.87 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34405/47780 [01:58<00:49, 268.44 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35230/47780 [01:58<00:47, 265.20 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35696/47780 [01:58<00:44, 270.04 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36569/47780 [01:58<00:31, 350.83 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23188/47780 [01:58<01:14, 327.91 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35359/47780 [01:58<00:42, 293.58 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34304/47780 [01:58<00:50, 264.82 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34593/47780 [01:58<00:41, 315.64 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34434/47780 [01:58<00:50, 262.78 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35268/47780 [01:58<00:43, 287.11 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35729/47780 [01:58<00:42, 280.82 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35389/47780 [01:58<00:42, 291.04 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36605/47780 [01:58<00:33, 338.48 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34333/47780 [01:58<00:49, 271.40 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34629/47780 [01:58<00:40, 321.36 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35305/47780 [01:58<00:40, 309.45 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34462/47780 [01:58<00:51, 258.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35764/47780 [01:58<00:40, 298.40 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23222/47780 [01:58<01:31, 267.72 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35421/47780 [01:58<00:41, 295.61 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36640/47780 [01:58<00:33, 333.72 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34663/47780 [01:58<00:40, 326.51 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34361/47780 [01:58<00:51, 259.34 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34492/47780 [01:58<00:50, 261.78 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35337/47780 [01:58<00:42, 290.05 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▊     | 23272/47780 [01:58<01:17, 318.13 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36679/47780 [01:58<00:32, 345.47 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35794/47780 [01:58<00:46, 259.16 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34696/47780 [01:58<00:41, 316.48 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35451/47780 [01:58<00:45, 271.94 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34531/47780 [01:58<00:44, 296.86 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34388/47780 [01:58<00:53, 248.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35367/47780 [01:58<00:43, 283.33 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23308/47780 [01:58<01:19, 307.30 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36717/47780 [01:58<00:32, 344.11 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34728/47780 [01:58<00:41, 317.04 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35484/47780 [01:58<00:43, 285.01 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34563/47780 [01:58<00:45, 293.05 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34414/47780 [01:58<00:56, 235.73 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35821/47780 [01:58<00:54, 218.49 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23346/47780 [01:58<01:15, 325.21 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35396/47780 [01:58<00:49, 249.63 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34761/47780 [01:58<00:40, 317.90 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36752/47780 [01:58<00:33, 330.90 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34593/47780 [01:58<00:45, 292.36 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35513/47780 [01:58<00:46, 262.72 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34439/47780 [01:58<00:57, 232.74 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35885/47780 [01:58<00:37, 318.52 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23381/47780 [01:58<01:13, 330.83 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35422/47780 [01:58<00:49, 249.98 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34795/47780 [01:58<00:40, 318.87 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36786/47780 [01:58<00:34, 315.20 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35553/47780 [01:58<00:40, 298.71 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34623/47780 [01:58<00:47, 277.98 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34469/47780 [01:58<00:53, 248.41 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35921/47780 [01:58<00:38, 310.21 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35448/47780 [01:58<00:49, 247.12 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34828/47780 [01:58<00:40, 316.48 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23416/47780 [01:58<01:20, 300.96 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35584/47780 [01:58<00:41, 292.56 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34652/47780 [01:58<00:47, 278.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36818/47780 [01:58<00:37, 294.11 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34496/47780 [01:58<00:55, 240.96 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35956/47780 [01:58<00:38, 304.84 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34861/47780 [01:58<00:40, 316.66 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35474/47780 [01:59<00:52, 235.54 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23448/47780 [01:58<01:22, 293.48 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35614/47780 [01:59<00:42, 285.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36858/47780 [01:59<00:34, 318.63 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34521/47780 [01:59<00:54, 242.85 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34681/47780 [01:59<00:49, 263.28 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34893/47780 [01:59<00:41, 313.85 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23479/47780 [01:59<01:22, 295.07 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35509/47780 [01:59<00:47, 257.81 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35644/47780 [01:59<00:42, 286.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35989/47780 [01:59<00:42, 277.16 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36892/47780 [01:59<00:35, 310.97 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34548/47780 [01:59<00:53, 248.24 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34708/47780 [01:59<00:52, 248.62 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34926/47780 [01:59<00:40, 315.06 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35539/47780 [01:59<00:45, 266.30 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23510/47780 [01:59<01:22, 292.50 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35673/47780 [01:59<00:42, 285.40 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36924/47780 [01:59<00:35, 307.50 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36021/47780 [01:59<00:43, 269.17 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34573/47780 [01:59<00:54, 243.09 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34735/47780 [01:59<00:51, 252.80 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34958/47780 [01:59<00:41, 312.40 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23543/47780 [01:59<01:21, 296.55 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35566/47780 [01:59<00:48, 253.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35702/47780 [01:59<00:42, 282.28 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36957/47780 [01:59<00:34, 312.34 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34600/47780 [01:59<00:53, 248.17 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36052/47780 [01:59<00:42, 276.59 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34761/47780 [01:59<00:55, 236.65 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34990/47780 [01:59<00:42, 301.09 examples/s]Tokenizing train dataset (num_proc=32):  49%|████▉     | 23580/47780 [01:59<01:16, 316.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35738/47780 [01:59<00:39, 304.16 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35593/47780 [01:59<00:48, 249.69 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36990/47780 [01:59<00:34, 308.52 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34625/47780 [01:59<00:53, 245.92 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36081/47780 [01:59<00:43, 266.14 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34804/47780 [01:59<00:45, 285.27 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35021/47780 [01:59<00:42, 300.16 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23615/47780 [01:59<01:14, 322.69 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35619/47780 [01:59<00:48, 251.84 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35769/47780 [01:59<00:40, 296.04 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37022/47780 [01:59<00:34, 308.08 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34653/47780 [01:59<00:51, 252.75 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36112/47780 [01:59<00:42, 274.77 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34834/47780 [01:59<00:46, 277.20 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23650/47780 [01:59<01:13, 326.66 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35052/47780 [01:59<00:45, 277.51 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35799/47780 [01:59<00:40, 293.52 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35645/47780 [01:59<00:50, 238.45 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34681/47780 [01:59<00:50, 257.69 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37053/47780 [01:59<00:36, 297.87 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36143/47780 [01:59<00:41, 281.55 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34863/47780 [01:59<00:47, 271.77 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23683/47780 [01:59<01:14, 323.32 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35082/47780 [01:59<00:45, 277.63 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35829/47780 [01:59<00:41, 285.77 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35673/47780 [01:59<00:49, 244.74 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34709/47780 [01:59<00:50, 258.14 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37083/47780 [01:59<00:36, 295.65 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36172/47780 [01:59<00:40, 283.26 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23717/47780 [01:59<01:14, 325.09 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34891/47780 [01:59<00:53, 242.23 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34740/47780 [01:59<00:47, 272.91 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37113/47780 [01:59<00:36, 290.36 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35111/47780 [01:59<00:49, 255.77 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35705/47780 [01:59<00:48, 249.10 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36201/47780 [01:59<00:44, 259.04 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23754/47780 [01:59<01:11, 337.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35858/47780 [01:59<00:51, 231.71 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35148/47780 [01:59<00:44, 285.84 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34769/47780 [02:00<00:48, 265.68 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37148/47780 [02:00<00:35, 300.45 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35730/47780 [02:00<00:49, 241.61 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23795/47780 [02:00<01:06, 359.03 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34917/47780 [02:00<01:01, 208.23 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36228/47780 [02:00<00:47, 243.56 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35909/47780 [02:00<00:40, 294.65 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37183/47780 [02:00<00:34, 304.20 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34799/47780 [02:00<00:49, 263.58 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35755/47780 [02:00<00:52, 228.90 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23838/47780 [02:00<01:03, 379.80 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34963/47780 [02:00<00:47, 267.71 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35946/47780 [02:00<00:37, 313.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36257/47780 [02:00<00:45, 253.27 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35178/47780 [02:00<00:52, 239.86 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37214/47780 [02:00<00:35, 298.12 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34826/47780 [02:00<00:51, 253.65 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35781/47780 [02:00<00:50, 237.21 examples/s]Tokenizing train dataset (num_proc=32):  50%|████▉     | 23877/47780 [02:00<01:06, 357.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36283/47780 [02:00<00:46, 249.53 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35981/47780 [02:00<00:38, 307.24 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34994/47780 [02:00<00:51, 248.30 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34852/47780 [02:00<00:54, 238.84 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37244/47780 [02:00<00:39, 268.83 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35204/47780 [02:00<01:02, 199.81 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 23914/47780 [02:00<01:06, 356.82 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36328/47780 [02:00<00:38, 295.01 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35805/47780 [02:00<00:57, 208.84 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36013/47780 [02:00<00:39, 297.40 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35021/47780 [02:00<00:52, 241.59 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37293/47780 [02:00<00:32, 327.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34880/47780 [02:00<00:52, 245.53 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36360/47780 [02:00<00:38, 295.44 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35832/47780 [02:00<00:53, 221.50 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23951/47780 [02:00<01:10, 337.79 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36044/47780 [02:00<00:39, 297.58 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35226/47780 [02:00<01:07, 186.12 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35047/47780 [02:00<00:52, 241.64 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37331/47780 [02:00<00:31, 335.17 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36396/47780 [02:00<00:36, 309.97 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34905/47780 [02:00<00:56, 228.92 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36078/47780 [02:00<00:38, 302.97 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35325/47780 [02:00<00:34, 364.85 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 23986/47780 [02:00<01:13, 325.94 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35856/47780 [02:00<00:57, 206.64 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35073/47780 [02:00<00:51, 246.39 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37376/47780 [02:00<00:28, 359.78 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34931/47780 [02:00<00:55, 232.57 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36428/47780 [02:00<00:38, 292.62 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35894/47780 [02:00<00:47, 251.19 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36109/47780 [02:00<00:40, 288.45 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35102/47780 [02:00<00:50, 252.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24019/47780 [02:00<01:19, 298.29 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35369/47780 [02:00<00:38, 319.09 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34965/47780 [02:00<00:49, 258.84 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37416/47780 [02:00<00:31, 329.63 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36459/47780 [02:00<00:39, 288.18 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36142/47780 [02:00<00:39, 293.79 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35923/47780 [02:00<00:45, 258.75 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35138/47780 [02:00<00:44, 281.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24057/47780 [02:00<01:14, 316.37 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34992/47780 [02:00<00:49, 256.58 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37450/47780 [02:00<00:32, 321.82 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36174/47780 [02:00<00:38, 297.84 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36490/47780 [02:00<00:40, 277.63 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35407/47780 [02:00<00:42, 293.62 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24090/47780 [02:00<01:15, 311.84 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35167/47780 [02:00<00:47, 263.73 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35950/47780 [02:01<00:54, 218.68 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35018/47780 [02:01<00:50, 254.24 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36207/47780 [02:01<00:38, 303.59 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35442/47780 [02:01<00:40, 303.26 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37484/47780 [02:01<00:33, 304.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36520/47780 [02:01<00:40, 275.99 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35194/47780 [02:01<00:52, 240.78 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35998/47780 [02:01<00:41, 282.99 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35045/47780 [02:01<00:50, 250.31 examples/s]Tokenizing train dataset (num_proc=32):  50%|█████     | 24122/47780 [02:01<01:29, 265.06 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36238/47780 [02:01<00:38, 301.65 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36548/47780 [02:01<00:40, 274.11 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37515/47780 [02:01<00:36, 280.60 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35222/47780 [02:01<00:50, 246.91 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35476/47780 [02:01<00:44, 275.43 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35071/47780 [02:01<00:52, 241.84 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36029/47780 [02:01<00:45, 257.96 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24150/47780 [02:01<01:34, 249.77 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36580/47780 [02:01<00:39, 286.88 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36269/47780 [02:01<00:41, 275.78 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35249/47780 [02:01<00:50, 247.72 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35507/47780 [02:01<00:44, 273.04 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37544/47780 [02:01<00:40, 253.64 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35098/47780 [02:01<00:51, 247.31 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36065/47780 [02:01<00:41, 280.47 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36613/47780 [02:01<00:39, 284.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24176/47780 [02:01<01:41, 233.59 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36298/47780 [02:01<00:45, 250.00 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35280/47780 [02:01<00:48, 259.00 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35536/47780 [02:01<00:44, 277.11 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35128/47780 [02:01<00:48, 259.23 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37570/47780 [02:01<00:42, 240.87 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36643/47780 [02:01<00:38, 286.25 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36095/47780 [02:01<00:45, 256.27 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24201/47780 [02:01<01:45, 224.50 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35307/47780 [02:01<00:48, 259.18 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36324/47780 [02:01<00:46, 244.90 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35155/47780 [02:01<00:49, 256.54 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35566/47780 [02:01<00:47, 259.52 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37595/47780 [02:01<00:43, 231.61 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36672/47780 [02:01<00:39, 278.86 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36123/47780 [02:01<00:44, 259.60 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24224/47780 [02:01<01:48, 216.97 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35334/47780 [02:01<00:48, 256.26 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36349/47780 [02:01<00:48, 236.44 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35182/47780 [02:01<00:48, 260.37 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35613/47780 [02:01<00:38, 312.28 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37627/47780 [02:01<00:39, 253.92 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36702/47780 [02:01<00:39, 281.59 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36151/47780 [02:01<00:43, 264.93 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24253/47780 [02:01<01:40, 233.53 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35360/47780 [02:01<00:49, 251.42 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36381/47780 [02:01<00:44, 255.73 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35213/47780 [02:01<00:46, 271.45 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35646/47780 [02:01<00:39, 310.14 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37656/47780 [02:01<00:38, 260.82 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36732/47780 [02:01<00:38, 283.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36189/47780 [02:01<00:39, 292.99 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24277/47780 [02:01<01:40, 232.78 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35386/47780 [02:01<00:50, 247.80 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36417/47780 [02:01<00:40, 281.10 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35243/47780 [02:01<00:45, 276.62 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35679/47780 [02:01<00:40, 302.21 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37683/47780 [02:01<00:38, 260.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36761/47780 [02:01<00:39, 278.84 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36226/47780 [02:01<00:37, 306.37 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24302/47780 [02:01<01:39, 234.94 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35413/47780 [02:01<00:49, 249.36 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36448/47780 [02:01<00:39, 288.46 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35278/47780 [02:01<00:42, 294.50 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37720/47780 [02:02<00:36, 278.60 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35711/47780 [02:02<00:41, 288.89 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36789/47780 [02:02<00:42, 258.68 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36258/47780 [02:02<00:39, 292.01 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24327/47780 [02:02<01:39, 236.47 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35443/47780 [02:02<00:47, 260.79 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36483/47780 [02:02<00:37, 299.81 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35317/47780 [02:02<00:39, 318.56 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37750/47780 [02:02<00:35, 284.21 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35741/47780 [02:02<00:42, 282.65 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36817/47780 [02:02<00:41, 261.64 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24355/47780 [02:02<01:34, 248.43 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36293/47780 [02:02<00:37, 303.43 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35476/47780 [02:02<00:43, 280.55 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36514/47780 [02:02<00:37, 302.65 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35353/47780 [02:02<00:38, 326.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37784/47780 [02:02<00:33, 297.04 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36844/47780 [02:02<00:41, 263.94 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35770/47780 [02:02<00:45, 264.52 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24388/47780 [02:02<01:27, 266.06 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35506/47780 [02:02<00:43, 282.95 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36555/47780 [02:02<00:34, 329.82 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36324/47780 [02:02<00:41, 272.85 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35388/47780 [02:02<00:38, 322.00 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37814/47780 [02:02<00:33, 297.33 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36874/47780 [02:02<00:40, 271.21 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35798/47780 [02:02<00:46, 255.44 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24415/47780 [02:02<01:31, 255.41 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35535/47780 [02:02<00:44, 276.29 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35421/47780 [02:02<00:38, 317.33 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36589/47780 [02:02<00:36, 304.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36353/47780 [02:02<00:45, 253.44 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37844/47780 [02:02<00:36, 273.22 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36906/47780 [02:02<00:38, 282.01 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35824/47780 [02:02<00:47, 253.85 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35563/47780 [02:02<00:45, 270.14 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24441/47780 [02:02<01:36, 242.77 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36621/47780 [02:02<00:36, 305.69 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35453/47780 [02:02<00:40, 300.92 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37873/47780 [02:02<00:36, 273.42 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36937/47780 [02:02<00:37, 286.71 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35854/47780 [02:02<00:45, 263.59 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36380/47780 [02:02<00:50, 227.35 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████     | 24471/47780 [02:02<01:32, 253.28 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35591/47780 [02:02<00:46, 263.64 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36652/47780 [02:02<00:37, 296.52 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35484/47780 [02:02<00:44, 278.46 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36966/47780 [02:02<00:37, 287.18 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37901/47780 [02:02<00:38, 257.77 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35881/47780 [02:02<00:45, 262.47 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36408/47780 [02:02<00:50, 227.04 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35618/47780 [02:02<00:46, 263.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36683/47780 [02:02<00:37, 292.12 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24497/47780 [02:02<01:41, 229.69 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36995/47780 [02:02<00:38, 281.75 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35513/47780 [02:02<00:45, 272.35 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35908/47780 [02:02<00:45, 261.67 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37928/47780 [02:02<00:39, 246.32 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35646/47780 [02:02<00:45, 267.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36436/47780 [02:02<00:47, 237.80 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24522/47780 [02:02<01:40, 232.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36713/47780 [02:02<00:38, 286.15 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37024/47780 [02:02<00:40, 267.28 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35947/47780 [02:02<00:40, 294.82 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35541/47780 [02:02<00:47, 255.27 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37954/47780 [02:02<00:39, 247.13 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36468/47780 [02:02<00:43, 258.51 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35673/47780 [02:02<00:46, 259.28 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24546/47780 [02:02<01:40, 232.03 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36742/47780 [02:02<00:39, 278.48 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37058/47780 [02:03<00:37, 282.87 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35571/47780 [02:03<00:47, 259.24 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 37986/47780 [02:03<00:36, 264.74 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36496/47780 [02:03<00:43, 261.94 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35978/47780 [02:03<00:45, 257.91 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24575/47780 [02:03<01:34, 245.42 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35701/47780 [02:03<00:50, 240.27 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36772/47780 [02:03<00:39, 281.41 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37087/47780 [02:03<00:38, 275.61 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35602/47780 [02:03<00:45, 269.97 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38018/47780 [02:03<00:35, 274.02 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36527/47780 [02:03<00:41, 269.48 examples/s]Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24605/47780 [02:03<01:28, 260.77 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35730/47780 [02:03<00:49, 245.87 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36801/47780 [02:03<00:40, 271.49 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36005/47780 [02:03<00:52, 225.35 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35631/47780 [02:03<00:44, 272.35 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37118/47780 [02:03<00:38, 278.84 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38046/47780 [02:03<00:36, 266.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36555/47780 [02:03<00:42, 265.98 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24632/47780 [02:03<01:29, 259.98 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35757/47780 [02:03<00:48, 247.08 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36829/47780 [02:03<00:41, 265.03 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36073/47780 [02:03<00:35, 333.28 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37147/47780 [02:03<00:37, 281.84 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35659/47780 [02:03<00:46, 262.60 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38074/47780 [02:03<00:36, 267.41 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24681/47780 [02:03<01:11, 323.75 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36582/47780 [02:03<00:45, 244.69 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35782/47780 [02:03<00:48, 247.87 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36856/47780 [02:03<00:41, 263.15 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37176/47780 [02:03<00:37, 284.08 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38107/47780 [02:03<00:34, 282.06 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35695/47780 [02:03<00:43, 279.27 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36110/47780 [02:03<00:37, 310.86 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36607/47780 [02:03<00:47, 236.84 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36892/47780 [02:03<00:37, 290.19 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35807/47780 [02:03<00:51, 231.32 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37205/47780 [02:03<00:37, 285.73 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24714/47780 [02:03<01:23, 275.24 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36144/47780 [02:03<00:36, 314.90 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35724/47780 [02:03<00:45, 265.65 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38136/47780 [02:03<00:38, 249.95 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36632/47780 [02:03<00:48, 230.46 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36924/47780 [02:03<00:36, 295.95 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35831/47780 [02:03<00:51, 232.60 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24751/47780 [02:03<01:17, 295.36 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37234/47780 [02:03<00:39, 268.26 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35751/47780 [02:03<00:45, 264.21 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36186/47780 [02:03<00:35, 328.54 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38162/47780 [02:03<00:38, 249.95 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36664/47780 [02:03<00:44, 251.82 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36954/47780 [02:03<00:39, 271.90 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37268/47780 [02:03<00:36, 288.38 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24782/47780 [02:03<01:21, 281.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35856/47780 [02:03<00:58, 202.76 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36221/47780 [02:03<00:34, 330.65 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38190/47780 [02:03<00:37, 258.01 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35778/47780 [02:03<00:47, 251.53 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36690/47780 [02:03<00:44, 251.28 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36985/47780 [02:03<00:38, 282.34 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37298/47780 [02:03<00:38, 270.41 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35884/47780 [02:03<00:54, 216.48 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36257/47780 [02:03<00:34, 338.57 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24812/47780 [02:03<01:27, 263.56 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38217/47780 [02:03<00:36, 260.43 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35808/47780 [02:03<00:45, 262.18 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36728/47780 [02:03<00:38, 284.24 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37014/47780 [02:03<00:39, 269.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37326/47780 [02:03<00:38, 269.73 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35907/47780 [02:03<00:55, 215.04 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38246/47780 [02:04<00:35, 266.99 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24845/47780 [02:03<01:23, 275.49 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35837/47780 [02:04<00:44, 266.84 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36293/47780 [02:03<00:35, 326.37 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36760/47780 [02:04<00:37, 291.12 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37047/47780 [02:04<00:37, 283.10 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35932/47780 [02:04<00:53, 222.41 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38273/47780 [02:04<00:35, 267.83 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24875/47780 [02:04<01:21, 281.95 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37354/47780 [02:04<00:41, 250.30 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35866/47780 [02:04<00:44, 270.10 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36328/47780 [02:04<00:35, 325.92 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36791/47780 [02:04<00:37, 292.65 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37076/47780 [02:04<00:39, 269.64 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35955/47780 [02:04<00:53, 222.09 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24905/47780 [02:04<01:19, 286.05 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38301/47780 [02:04<00:35, 265.31 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37383/47780 [02:04<00:39, 260.86 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36361/47780 [02:04<00:34, 326.54 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36826/47780 [02:04<00:35, 306.13 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35895/47780 [02:04<00:45, 258.38 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37114/47780 [02:04<00:36, 290.60 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35983/47780 [02:04<00:49, 235.95 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37410/47780 [02:04<00:39, 260.83 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36394/47780 [02:04<00:35, 324.31 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38328/47780 [02:04<00:36, 257.53 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24937/47780 [02:04<01:23, 274.64 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36858/47780 [02:04<00:35, 305.95 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35922/47780 [02:04<00:51, 228.76 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36007/47780 [02:04<00:49, 236.64 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37144/47780 [02:04<00:37, 282.01 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38354/47780 [02:04<00:37, 254.45 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37441/47780 [02:04<00:38, 265.65 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24966/47780 [02:04<01:22, 275.75 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36427/47780 [02:04<00:36, 307.74 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36889/47780 [02:04<00:38, 284.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35949/47780 [02:04<00:50, 232.25 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36031/47780 [02:04<00:52, 222.14 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38380/47780 [02:04<00:37, 248.88 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37173/47780 [02:04<00:40, 262.84 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24997/47780 [02:04<01:21, 279.26 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36467/47780 [02:04<00:34, 326.86 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37469/47780 [02:04<00:41, 250.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36924/47780 [02:04<00:35, 302.72 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35973/47780 [02:04<00:55, 214.06 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38405/47780 [02:04<00:37, 248.80 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36057/47780 [02:04<00:51, 227.92 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37200/47780 [02:04<00:40, 259.29 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25026/47780 [02:04<01:23, 273.19 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37500/47780 [02:04<00:39, 260.64 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36501/47780 [02:04<00:35, 314.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36961/47780 [02:04<00:34, 312.59 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36086/47780 [02:04<00:47, 244.97 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38430/47780 [02:04<00:38, 243.38 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35995/47780 [02:04<00:56, 209.12 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37228/47780 [02:04<00:39, 264.25 examples/s]Tokenizing train dataset (num_proc=32):  52%|█████▏    | 25059/47780 [02:04<01:18, 288.64 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37531/47780 [02:04<00:37, 271.20 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36533/47780 [02:04<00:36, 310.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36993/47780 [02:04<00:36, 296.26 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36111/47780 [02:04<00:48, 241.29 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37261/47780 [02:04<00:37, 277.04 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25089/47780 [02:04<01:19, 285.70 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36567/47780 [02:04<00:35, 318.80 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37563/47780 [02:04<00:36, 278.57 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36018/47780 [02:04<01:00, 194.34 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37024/47780 [02:04<00:35, 299.94 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38456/47780 [02:04<00:43, 216.00 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37289/47780 [02:04<00:38, 274.81 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36136/47780 [02:04<00:51, 227.85 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36601/47780 [02:04<00:34, 321.19 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37597/47780 [02:04<00:34, 295.61 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25124/47780 [02:04<01:16, 295.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36044/47780 [02:05<00:57, 202.73 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38485/47780 [02:05<00:41, 223.69 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37055/47780 [02:05<00:38, 277.03 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37320/47780 [02:05<00:37, 281.64 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37627/47780 [02:05<00:34, 294.72 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36164/47780 [02:05<00:49, 234.75 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36634/47780 [02:05<00:35, 313.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36079/47780 [02:05<00:49, 238.22 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38508/47780 [02:05<00:41, 223.05 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25154/47780 [02:05<01:27, 259.53 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37084/47780 [02:05<00:39, 272.32 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37352/47780 [02:05<00:36, 289.28 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37657/47780 [02:05<00:35, 288.69 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36188/47780 [02:05<00:52, 221.35 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36666/47780 [02:05<00:37, 294.61 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38539/47780 [02:05<00:37, 246.55 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36104/47780 [02:05<00:50, 231.11 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25195/47780 [02:05<01:16, 296.19 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37112/47780 [02:05<00:39, 271.65 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37382/47780 [02:05<00:38, 273.55 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37686/47780 [02:05<00:36, 276.35 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36212/47780 [02:05<00:51, 224.16 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38566/47780 [02:05<00:36, 250.35 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36131/47780 [02:05<00:48, 239.34 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36696/47780 [02:05<00:39, 283.69 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25226/47780 [02:05<01:18, 287.04 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37145/47780 [02:05<00:38, 275.98 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37410/47780 [02:05<00:38, 267.06 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37719/47780 [02:05<00:35, 285.00 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36235/47780 [02:05<00:52, 218.45 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38593/47780 [02:05<00:35, 255.86 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36156/47780 [02:05<00:47, 242.24 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36728/47780 [02:05<00:38, 287.73 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25261/47780 [02:05<01:14, 301.31 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37173/47780 [02:05<00:41, 257.26 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37440/47780 [02:05<00:37, 275.57 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37749/47780 [02:05<00:35, 286.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38624/47780 [02:05<00:34, 268.46 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36184/47780 [02:05<00:46, 250.15 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36257/47780 [02:05<00:53, 214.00 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36764/47780 [02:05<00:35, 307.51 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25292/47780 [02:05<01:14, 300.14 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37203/47780 [02:05<00:39, 268.64 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37468/47780 [02:05<00:37, 273.34 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36214/47780 [02:05<00:43, 264.29 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38664/47780 [02:05<00:30, 302.52 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36285/47780 [02:05<00:49, 230.06 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36804/47780 [02:05<00:33, 329.78 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37778/47780 [02:05<00:37, 266.00 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25323/47780 [02:05<01:18, 287.13 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37231/47780 [02:05<00:40, 257.55 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37496/47780 [02:05<00:39, 260.31 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38698/47780 [02:05<00:29, 310.06 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36309/47780 [02:05<00:49, 229.97 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36241/47780 [02:05<00:44, 258.41 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37805/47780 [02:05<00:38, 261.35 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36843/47780 [02:05<00:32, 335.72 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25357/47780 [02:05<01:15, 295.10 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37260/47780 [02:05<00:40, 260.82 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37523/47780 [02:05<00:39, 260.39 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36339/47780 [02:05<00:46, 247.49 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38730/47780 [02:05<00:30, 292.79 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36878/47780 [02:05<00:32, 331.13 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36268/47780 [02:05<00:46, 244.98 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37832/47780 [02:05<00:39, 252.26 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25392/47780 [02:05<01:16, 294.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37289/47780 [02:05<00:39, 268.78 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36372/47780 [02:05<00:42, 267.98 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37550/47780 [02:05<00:41, 249.20 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36923/47780 [02:05<00:30, 361.90 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36294/47780 [02:05<00:46, 247.77 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38760/47780 [02:05<00:31, 288.12 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37863/47780 [02:05<00:37, 264.11 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37327/47780 [02:06<00:35, 296.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25422/47780 [02:05<01:19, 282.99 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37585/47780 [02:06<00:36, 276.97 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36402/47780 [02:06<00:42, 267.89 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36319/47780 [02:06<00:46, 244.11 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37892/47780 [02:06<00:38, 258.05 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38789/47780 [02:06<00:34, 259.57 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37365/47780 [02:06<00:32, 320.31 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36961/47780 [02:06<00:33, 318.82 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25451/47780 [02:06<01:20, 276.26 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37624/47780 [02:06<00:32, 308.73 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36429/47780 [02:06<00:42, 265.59 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36344/47780 [02:06<00:47, 240.89 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37923/47780 [02:06<00:36, 270.08 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38820/47780 [02:06<00:33, 266.55 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36996/47780 [02:06<00:33, 321.10 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25482/47780 [02:06<01:18, 282.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37398/47780 [02:06<00:34, 298.76 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36463/47780 [02:06<00:39, 283.66 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37656/47780 [02:06<00:34, 292.02 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36370/47780 [02:06<00:46, 244.47 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38851/47780 [02:06<00:32, 273.19 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25520/47780 [02:06<01:12, 308.96 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37029/47780 [02:06<00:34, 313.37 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37951/47780 [02:06<00:41, 236.28 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36499/47780 [02:06<00:37, 298.72 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37429/47780 [02:06<00:37, 277.25 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37686/47780 [02:06<00:35, 287.81 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36395/47780 [02:06<00:48, 237.09 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38890/47780 [02:06<00:29, 298.73 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37061/47780 [02:06<00:34, 314.96 examples/s]Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25552/47780 [02:06<01:14, 298.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 37995/47780 [02:06<00:33, 288.03 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37461/47780 [02:06<00:36, 286.03 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37720/47780 [02:06<00:33, 302.35 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36529/47780 [02:06<00:38, 291.97 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36421/47780 [02:06<00:47, 238.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25585/47780 [02:06<01:13, 302.74 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38921/47780 [02:06<00:31, 280.08 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37093/47780 [02:06<00:36, 296.71 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38026/47780 [02:06<00:34, 286.49 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36447/47780 [02:06<00:46, 244.49 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37491/47780 [02:06<00:38, 268.95 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37751/47780 [02:06<00:35, 279.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36561/47780 [02:06<00:41, 269.26 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25616/47780 [02:06<01:15, 293.40 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38957/47780 [02:06<00:29, 295.18 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38056/47780 [02:06<00:34, 281.47 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37124/47780 [02:06<00:37, 287.80 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37519/47780 [02:06<00:38, 265.97 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37784/47780 [02:06<00:34, 292.23 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36472/47780 [02:06<00:47, 235.66 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36591/47780 [02:06<00:41, 272.60 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38091/47780 [02:06<00:32, 297.53 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38990/47780 [02:06<00:29, 298.24 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37154/47780 [02:06<00:36, 287.99 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25646/47780 [02:06<01:20, 273.86 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37546/47780 [02:06<00:38, 265.46 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37814/47780 [02:06<00:34, 291.97 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36496/47780 [02:06<00:48, 231.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36620/47780 [02:06<00:43, 257.15 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39021/47780 [02:06<00:29, 293.65 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37183/47780 [02:06<00:39, 270.57 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37574/47780 [02:06<00:38, 268.54 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25675/47780 [02:06<01:24, 260.99 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38122/47780 [02:06<00:36, 267.50 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37844/47780 [02:06<00:35, 278.49 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36520/47780 [02:06<00:51, 216.99 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36647/47780 [02:06<00:44, 249.65 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39055/47780 [02:07<00:29, 297.95 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37604/47780 [02:07<00:37, 274.58 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37211/47780 [02:07<00:40, 258.98 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25704/47780 [02:07<01:23, 263.25 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38163/47780 [02:07<00:32, 299.14 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36542/47780 [02:07<00:52, 213.09 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37874/47780 [02:07<00:39, 248.57 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36673/47780 [02:07<00:45, 241.46 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39094/47780 [02:07<00:26, 323.50 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25731/47780 [02:07<01:25, 256.87 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37633/47780 [02:07<00:39, 255.57 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37238/47780 [02:07<00:44, 238.88 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36564/47780 [02:07<00:52, 212.55 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38194/47780 [02:07<00:35, 270.27 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36699/47780 [02:07<00:45, 242.16 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39127/47780 [02:07<00:26, 320.97 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37900/47780 [02:07<00:43, 229.07 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25762/47780 [02:07<01:22, 268.44 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37659/47780 [02:07<00:39, 254.00 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37264/47780 [02:07<00:43, 244.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36586/47780 [02:07<00:52, 212.15 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38224/47780 [02:07<00:34, 277.10 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36731/47780 [02:07<00:43, 252.31 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39160/47780 [02:07<00:28, 306.84 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37924/47780 [02:07<00:42, 230.71 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25790/47780 [02:07<01:21, 268.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37295/47780 [02:07<00:40, 262.02 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38259/47780 [02:07<00:32, 289.01 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36612/47780 [02:07<00:51, 218.42 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37685/47780 [02:07<00:43, 234.71 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39191/47780 [02:07<00:27, 307.65 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36763/47780 [02:07<00:41, 264.96 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37948/47780 [02:07<00:42, 230.44 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25818/47780 [02:07<01:22, 265.84 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37328/47780 [02:07<00:37, 277.92 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38289/47780 [02:07<00:32, 287.81 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36638/47780 [02:07<00:48, 227.64 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37709/47780 [02:07<00:42, 235.93 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36799/47780 [02:07<00:37, 291.11 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37978/47780 [02:07<00:41, 239.04 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39222/47780 [02:07<00:30, 279.59 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25856/47780 [02:07<01:14, 294.76 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37357/47780 [02:07<00:37, 280.64 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38322/47780 [02:07<00:31, 299.23 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37734/47780 [02:07<00:41, 239.72 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36661/47780 [02:07<00:49, 223.18 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36833/47780 [02:07<00:36, 303.20 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38004/47780 [02:07<00:39, 244.48 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37393/47780 [02:07<00:34, 299.63 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25886/47780 [02:07<01:15, 288.51 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39251/47780 [02:07<00:31, 268.01 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38354/47780 [02:07<00:31, 298.62 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36689/47780 [02:07<00:47, 234.12 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37761/47780 [02:07<00:42, 237.80 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36868/47780 [02:07<00:36, 301.19 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38029/47780 [02:07<00:41, 236.02 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25921/47780 [02:07<01:11, 303.80 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39279/47780 [02:07<00:33, 257.39 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38387/47780 [02:07<00:30, 303.97 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37424/47780 [02:07<00:37, 277.09 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36720/47780 [02:07<00:43, 252.79 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37787/47780 [02:07<00:41, 241.32 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36909/47780 [02:07<00:32, 331.36 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38053/47780 [02:07<00:41, 231.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25952/47780 [02:07<01:13, 295.30 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39306/47780 [02:07<00:32, 260.34 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38426/47780 [02:07<00:29, 321.30 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36752/47780 [02:07<00:40, 271.95 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37813/47780 [02:07<00:40, 246.51 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37453/47780 [02:07<00:37, 272.66 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36943/47780 [02:07<00:34, 316.08 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25984/47780 [02:07<01:12, 302.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38077/47780 [02:07<00:42, 229.10 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36783/47780 [02:08<00:39, 279.85 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38463/47780 [02:08<00:28, 331.41 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37844/47780 [02:08<00:38, 258.45 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39333/47780 [02:08<00:34, 241.50 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37481/47780 [02:08<00:39, 262.20 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36975/47780 [02:08<00:34, 317.13 examples/s]Tokenizing train dataset (num_proc=32):  54%|█████▍    | 26015/47780 [02:08<01:12, 300.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38105/47780 [02:08<00:41, 231.81 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38502/47780 [02:08<00:26, 347.82 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37873/47780 [02:08<00:37, 266.70 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37511/47780 [02:08<00:38, 267.67 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39368/47780 [02:08<00:31, 265.29 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36812/47780 [02:08<00:42, 258.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26052/47780 [02:08<01:08, 317.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38134/47780 [02:08<00:39, 246.40 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38537/47780 [02:08<00:28, 329.39 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37902/47780 [02:08<00:38, 259.78 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39395/47780 [02:08<00:31, 263.55 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37538/47780 [02:08<00:39, 256.97 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36839/47780 [02:08<00:43, 250.70 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37007/47780 [02:08<00:44, 241.17 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26088/47780 [02:08<01:05, 329.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38161/47780 [02:08<00:38, 252.97 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37934/47780 [02:08<00:36, 267.68 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38572/47780 [02:08<00:29, 317.40 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37571/47780 [02:08<00:37, 273.93 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39422/47780 [02:08<00:33, 251.16 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36865/47780 [02:08<00:43, 248.73 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26122/47780 [02:08<01:06, 327.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38192/47780 [02:08<00:36, 266.27 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37036/47780 [02:08<00:46, 228.94 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38609/47780 [02:08<00:27, 331.82 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37964/47780 [02:08<00:35, 273.50 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37599/47780 [02:08<00:37, 269.66 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39448/47780 [02:08<00:33, 245.92 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36892/47780 [02:08<00:43, 248.36 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38222/47780 [02:08<00:35, 272.93 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37130/47780 [02:08<00:27, 391.36 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26155/47780 [02:08<01:10, 304.62 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 37995/47780 [02:08<00:34, 280.77 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37627/47780 [02:08<00:38, 266.58 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38644/47780 [02:08<00:28, 319.17 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36922/47780 [02:08<00:41, 259.80 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39473/47780 [02:08<00:34, 241.48 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38250/47780 [02:08<00:35, 271.82 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26186/47780 [02:08<01:13, 292.13 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38025/47780 [02:08<00:34, 283.20 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39499/47780 [02:08<00:33, 244.22 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38680/47780 [02:08<00:28, 319.00 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37175/47780 [02:08<00:31, 341.47 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37654/47780 [02:08<00:41, 245.39 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36949/47780 [02:08<00:45, 240.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38278/47780 [02:08<00:35, 270.76 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26218/47780 [02:08<01:14, 291.15 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38717/47780 [02:08<00:27, 330.43 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39529/47780 [02:08<00:32, 254.19 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38054/47780 [02:08<00:37, 261.12 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37688/47780 [02:08<00:38, 265.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38308/47780 [02:08<00:34, 276.93 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36974/47780 [02:08<00:45, 238.21 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37214/47780 [02:08<00:32, 320.19 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26251/47780 [02:08<01:12, 298.67 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39556/47780 [02:08<00:32, 255.75 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38086/47780 [02:08<00:35, 271.14 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37715/47780 [02:08<00:38, 262.51 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38753/47780 [02:08<00:29, 309.84 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38336/47780 [02:08<00:34, 270.45 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36999/47780 [02:08<00:45, 236.02 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37252/47780 [02:08<00:31, 330.52 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26282/47780 [02:08<01:16, 282.70 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39584/47780 [02:09<00:31, 259.74 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38122/47780 [02:09<00:33, 289.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37742/47780 [02:09<00:38, 259.60 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37032/47780 [02:09<00:41, 259.40 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38364/47780 [02:09<00:34, 269.95 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38786/47780 [02:09<00:29, 306.08 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37288/47780 [02:09<00:32, 322.33 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26311/47780 [02:09<01:19, 270.07 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39612/47780 [02:09<00:31, 258.69 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38157/47780 [02:09<00:31, 306.10 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37059/47780 [02:09<00:41, 259.79 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37769/47780 [02:09<00:40, 248.58 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38817/47780 [02:09<00:30, 293.73 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38392/47780 [02:09<00:38, 243.71 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37324/47780 [02:09<00:34, 307.27 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26342/47780 [02:09<01:16, 280.68 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39641/47780 [02:09<00:30, 265.56 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38190/47780 [02:09<00:30, 310.46 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37091/47780 [02:09<00:39, 273.70 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37795/47780 [02:09<00:40, 249.10 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38847/47780 [02:09<00:31, 286.95 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38418/47780 [02:09<00:37, 246.93 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26371/47780 [02:09<01:17, 277.09 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39668/47780 [02:09<00:30, 266.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37356/47780 [02:09<00:35, 295.53 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37825/47780 [02:09<00:38, 260.69 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38222/47780 [02:09<00:34, 277.43 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38879/47780 [02:09<00:30, 292.65 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37119/47780 [02:09<00:42, 252.65 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38447/47780 [02:09<00:36, 258.78 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39699/47780 [02:09<00:29, 276.38 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26399/47780 [02:09<01:18, 271.99 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37387/47780 [02:09<00:35, 290.48 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37852/47780 [02:09<00:38, 257.47 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38910/47780 [02:09<00:30, 294.42 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37152/47780 [02:09<00:38, 273.57 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38252/47780 [02:09<00:34, 274.55 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38476/47780 [02:09<00:36, 255.95 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26427/47780 [02:09<01:17, 274.01 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37421/47780 [02:09<00:35, 294.15 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37879/47780 [02:09<00:38, 255.20 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38280/47780 [02:09<00:35, 267.39 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39727/47780 [02:09<00:36, 222.85 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38940/47780 [02:09<00:32, 268.78 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38503/47780 [02:09<00:37, 248.73 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37181/47780 [02:09<00:42, 249.62 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26462/47780 [02:09<01:13, 289.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37453/47780 [02:09<00:34, 297.82 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37906/47780 [02:09<00:38, 253.19 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38314/47780 [02:09<00:32, 287.09 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39770/47780 [02:09<00:29, 274.66 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38976/47780 [02:09<00:30, 293.18 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38529/47780 [02:09<00:38, 241.34 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37220/47780 [02:09<00:38, 272.67 examples/s]Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26493/47780 [02:09<01:17, 276.32 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37488/47780 [02:09<00:33, 308.64 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37935/47780 [02:09<00:37, 261.20 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38344/47780 [02:09<00:33, 284.10 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39800/47780 [02:09<00:29, 273.77 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39006/47780 [02:09<00:31, 279.51 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37249/47780 [02:09<00:38, 275.20 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26530/47780 [02:09<01:12, 292.40 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38554/47780 [02:09<00:42, 219.52 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37520/47780 [02:09<00:35, 292.10 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37962/47780 [02:09<00:37, 260.64 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38373/47780 [02:09<00:33, 283.95 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39830/47780 [02:09<00:28, 275.29 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39035/47780 [02:09<00:32, 273.14 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37278/47780 [02:09<00:38, 275.51 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26568/47780 [02:09<01:07, 313.29 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38583/47780 [02:09<00:39, 235.49 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38402/47780 [02:10<00:32, 284.56 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 37993/47780 [02:09<00:36, 265.71 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37550/47780 [02:10<00:37, 276.18 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39859/47780 [02:10<00:29, 266.04 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39067/47780 [02:10<00:30, 283.30 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37317/47780 [02:10<00:34, 307.22 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26602/47780 [02:10<01:06, 317.31 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38608/47780 [02:10<00:38, 236.77 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38020/47780 [02:10<00:36, 263.99 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38435/47780 [02:10<00:32, 290.96 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37578/47780 [02:10<00:39, 260.92 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39888/47780 [02:10<00:29, 267.07 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39099/47780 [02:10<00:29, 290.14 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37349/47780 [02:10<00:35, 297.32 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38637/47780 [02:10<00:36, 248.84 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26634/47780 [02:10<01:12, 291.56 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38047/47780 [02:10<00:37, 259.22 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37609/47780 [02:10<00:37, 273.08 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38465/47780 [02:10<00:33, 274.68 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39916/47780 [02:10<00:29, 267.49 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39129/47780 [02:10<00:30, 280.34 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37381/47780 [02:10<00:35, 290.03 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38663/47780 [02:10<00:36, 248.75 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26664/47780 [02:10<01:13, 287.23 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38073/47780 [02:10<00:39, 248.61 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37640/47780 [02:10<00:36, 280.88 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38493/47780 [02:10<00:33, 276.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39949/47780 [02:10<00:28, 278.84 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37411/47780 [02:10<00:36, 283.90 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39158/47780 [02:10<00:33, 259.85 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38689/47780 [02:10<00:37, 241.31 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26696/47780 [02:10<01:11, 295.09 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38100/47780 [02:10<00:38, 251.81 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37669/47780 [02:10<00:36, 277.23 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38521/47780 [02:10<00:37, 246.25 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39978/47780 [02:10<00:28, 269.90 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37440/47780 [02:10<00:36, 282.61 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39185/47780 [02:10<00:32, 262.41 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38718/47780 [02:10<00:35, 254.90 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26726/47780 [02:10<01:13, 284.80 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38130/47780 [02:10<00:38, 251.17 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38549/47780 [02:10<00:36, 255.14 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37697/47780 [02:10<00:40, 249.84 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40007/47780 [02:10<00:28, 268.51 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37483/47780 [02:10<00:32, 320.45 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39216/47780 [02:10<00:31, 272.70 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38747/47780 [02:10<00:34, 259.04 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26756/47780 [02:10<01:14, 283.04 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38161/47780 [02:10<00:37, 258.82 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37727/47780 [02:10<00:38, 260.50 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38579/47780 [02:10<00:35, 256.47 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37516/47780 [02:10<00:31, 322.76 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39251/47780 [02:10<00:28, 294.38 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38774/47780 [02:10<00:34, 259.05 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40035/47780 [02:10<00:32, 239.89 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26785/47780 [02:10<01:14, 281.79 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38187/47780 [02:10<00:37, 256.05 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37758/47780 [02:10<00:36, 270.90 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38606/47780 [02:10<00:36, 251.94 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39281/47780 [02:10<00:29, 292.72 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37549/47780 [02:10<00:33, 304.22 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38801/47780 [02:10<00:35, 256.44 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26815/47780 [02:10<01:13, 286.78 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40063/47780 [02:10<00:31, 243.14 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38217/47780 [02:10<00:35, 265.75 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37786/47780 [02:10<00:37, 264.72 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39314/47780 [02:10<00:27, 303.23 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38648/47780 [02:10<00:31, 291.56 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37590/47780 [02:10<00:30, 333.63 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38836/47780 [02:10<00:31, 282.66 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26850/47780 [02:10<01:09, 301.66 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40095/47780 [02:10<00:29, 260.85 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38244/47780 [02:10<00:35, 266.68 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37816/47780 [02:11<00:36, 271.38 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39345/47780 [02:11<00:28, 291.84 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38865/47780 [02:11<00:31, 284.75 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37626/47780 [02:11<00:29, 340.66 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38680/47780 [02:11<00:33, 269.12 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26881/47780 [02:11<01:10, 295.16 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40122/47780 [02:11<00:30, 251.98 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38273/47780 [02:11<00:35, 268.57 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37851/47780 [02:11<00:34, 287.13 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39376/47780 [02:11<00:28, 293.61 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38902/47780 [02:11<00:28, 306.86 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37661/47780 [02:11<00:32, 311.55 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38709/47780 [02:11<00:33, 272.08 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26925/47780 [02:11<01:02, 331.53 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40148/47780 [02:11<00:31, 244.60 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38300/47780 [02:11<00:35, 264.95 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37880/47780 [02:11<00:35, 279.22 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39406/47780 [02:11<00:28, 292.06 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38933/47780 [02:11<00:30, 287.51 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37694/47780 [02:11<00:32, 313.00 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38739/47780 [02:11<00:33, 273.87 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40175/47780 [02:11<00:30, 250.83 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26959/47780 [02:11<01:07, 308.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38327/47780 [02:11<00:36, 257.18 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39438/47780 [02:11<00:27, 300.11 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37909/47780 [02:11<00:35, 275.37 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38964/47780 [02:11<00:30, 293.68 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37726/47780 [02:11<00:32, 311.40 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38772/47780 [02:11<00:31, 286.51 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40206/47780 [02:11<00:28, 264.24 examples/s]Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26991/47780 [02:11<01:10, 295.59 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38353/47780 [02:11<00:38, 244.09 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39469/47780 [02:11<00:28, 289.53 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37937/47780 [02:11<00:39, 251.31 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38994/47780 [02:11<00:31, 279.73 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37759/47780 [02:11<00:32, 306.38 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40233/47780 [02:11<00:29, 260.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38801/47780 [02:11<00:33, 266.18 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27031/47780 [02:11<01:05, 317.51 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38386/47780 [02:11<00:35, 262.42 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39499/47780 [02:11<00:28, 285.63 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39028/47780 [02:11<00:29, 296.49 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37970/47780 [02:11<00:36, 266.49 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40263/47780 [02:11<00:28, 265.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37790/47780 [02:11<00:35, 284.41 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38829/47780 [02:11<00:34, 258.53 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27064/47780 [02:11<01:04, 320.88 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38418/47780 [02:11<00:33, 275.44 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39528/47780 [02:11<00:30, 274.75 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38006/47780 [02:11<00:34, 285.71 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39058/47780 [02:11<00:31, 278.55 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40290/47780 [02:11<00:28, 263.67 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38862/47780 [02:11<00:32, 275.25 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27097/47780 [02:11<01:03, 323.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37824/47780 [02:11<00:34, 290.46 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38446/47780 [02:11<00:34, 270.61 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39564/47780 [02:11<00:27, 295.20 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38040/47780 [02:11<00:33, 294.27 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39103/47780 [02:11<00:27, 318.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40318/47780 [02:11<00:28, 265.00 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27135/47780 [02:11<01:01, 335.78 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37855/47780 [02:11<00:34, 289.32 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38890/47780 [02:11<00:33, 267.45 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38481/47780 [02:11<00:32, 286.58 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39596/47780 [02:11<00:27, 295.45 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39143/47780 [02:11<00:25, 337.67 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38070/47780 [02:11<00:35, 277.21 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40345/47780 [02:11<00:28, 256.43 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37886/47780 [02:11<00:33, 295.02 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27173/47780 [02:11<01:00, 340.62 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38917/47780 [02:11<00:33, 267.90 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38514/47780 [02:11<00:31, 295.98 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39633/47780 [02:11<00:26, 309.79 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39181/47780 [02:12<00:24, 345.64 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38105/47780 [02:12<00:32, 293.96 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40371/47780 [02:12<00:29, 253.17 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37917/47780 [02:12<00:34, 289.55 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38944/47780 [02:12<00:34, 258.21 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27208/47780 [02:12<01:06, 311.30 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38544/47780 [02:12<00:33, 273.70 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39670/47780 [02:12<00:25, 323.14 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39218/47780 [02:12<00:24, 348.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38137/47780 [02:12<00:32, 297.75 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40398/47780 [02:12<00:28, 257.69 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38979/47780 [02:12<00:31, 279.75 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37947/47780 [02:12<00:35, 277.18 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27254/47780 [02:12<00:59, 347.74 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38580/47780 [02:12<00:31, 288.85 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39704/47780 [02:12<00:24, 326.95 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39254/47780 [02:12<00:24, 351.60 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40425/47780 [02:12<00:28, 255.63 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39008/47780 [02:12<00:32, 273.02 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37975/47780 [02:12<00:37, 261.87 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38168/47780 [02:12<00:37, 257.88 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38618/47780 [02:12<00:29, 310.61 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27290/47780 [02:12<01:02, 325.47 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39742/47780 [02:12<00:23, 335.60 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39293/47780 [02:12<00:23, 354.90 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40453/47780 [02:12<00:28, 256.74 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39036/47780 [02:12<00:32, 272.28 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38003/47780 [02:12<00:37, 262.72 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38195/47780 [02:12<00:37, 257.44 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38650/47780 [02:12<00:29, 307.92 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39776/47780 [02:12<00:25, 314.45 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39329/47780 [02:12<00:23, 352.20 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27324/47780 [02:12<01:10, 289.55 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40483/47780 [02:12<00:27, 266.12 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39064/47780 [02:12<00:32, 271.23 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38239/47780 [02:12<00:31, 303.63 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39813/47780 [02:12<00:24, 326.93 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38030/47780 [02:12<00:41, 233.78 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38682/47780 [02:12<00:32, 275.80 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39365/47780 [02:12<00:25, 335.11 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40519/47780 [02:12<00:25, 289.78 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39092/47780 [02:12<00:32, 270.67 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27354/47780 [02:12<01:21, 251.39 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38271/47780 [02:12<00:32, 289.11 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39846/47780 [02:12<00:24, 327.76 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38059/47780 [02:12<00:39, 245.79 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39400/47780 [02:12<00:24, 335.56 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38711/47780 [02:12<00:33, 267.99 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40551/47780 [02:12<00:25, 288.51 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39123/47780 [02:12<00:31, 278.71 examples/s]Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27407/47780 [02:12<01:04, 317.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38301/47780 [02:12<00:34, 274.06 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39879/47780 [02:12<00:25, 304.04 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38085/47780 [02:12<00:41, 234.33 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39434/47780 [02:12<00:25, 327.52 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40580/47780 [02:12<00:25, 287.99 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38741/47780 [02:12<00:33, 268.04 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39151/47780 [02:12<00:30, 278.71 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27442/47780 [02:12<01:02, 325.32 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39913/47780 [02:12<00:25, 313.86 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39471/47780 [02:12<00:24, 336.82 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38331/47780 [02:12<00:35, 268.16 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38116/47780 [02:12<00:38, 249.36 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39179/47780 [02:12<00:31, 275.95 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40609/47780 [02:12<00:26, 273.42 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38773/47780 [02:12<00:33, 270.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27477/47780 [02:12<01:04, 315.58 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38150/47780 [02:12<00:35, 273.68 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38359/47780 [02:12<00:36, 259.11 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39208/47780 [02:12<00:30, 277.23 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39505/47780 [02:12<00:25, 319.65 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40637/47780 [02:13<00:26, 269.00 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38806/47780 [02:12<00:31, 282.71 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39945/47780 [02:13<00:28, 275.36 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27512/47780 [02:13<01:02, 324.64 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38178/47780 [02:13<00:35, 272.52 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38389/47780 [02:13<00:34, 269.75 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39546/47780 [02:13<00:24, 341.55 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39979/47780 [02:13<00:26, 292.04 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39236/47780 [02:13<00:34, 247.36 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38835/47780 [02:13<00:36, 247.52 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40664/47780 [02:13<00:31, 225.25 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27546/47780 [02:13<01:08, 296.39 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38207/47780 [02:13<00:35, 271.38 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38417/47780 [02:13<00:36, 259.77 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39582/47780 [02:13<00:24, 339.10 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39273/47780 [02:13<00:30, 279.51 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40011/47780 [02:13<00:27, 281.34 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38863/47780 [02:13<00:34, 255.52 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40701/47780 [02:13<00:27, 255.27 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27580/47780 [02:13<01:05, 307.74 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38235/47780 [02:13<00:36, 261.84 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39623/47780 [02:13<00:22, 355.24 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38444/47780 [02:13<00:36, 258.56 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39303/47780 [02:13<00:30, 281.83 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38890/47780 [02:13<00:36, 241.47 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27618/47780 [02:13<01:02, 320.50 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40040/47780 [02:13<00:31, 249.18 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40728/47780 [02:13<00:28, 243.62 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38262/47780 [02:13<00:36, 258.38 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39659/47780 [02:13<00:23, 340.96 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38471/47780 [02:13<00:37, 247.99 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39334/47780 [02:13<00:29, 289.70 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38922/47780 [02:13<00:34, 253.94 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27651/47780 [02:13<01:03, 315.89 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40066/47780 [02:13<00:30, 249.41 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40755/47780 [02:13<00:28, 248.22 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38289/47780 [02:13<00:36, 261.51 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39695/47780 [02:13<00:23, 338.74 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38496/47780 [02:13<00:38, 240.62 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39370/47780 [02:13<00:27, 306.80 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40126/47780 [02:13<00:22, 341.12 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38960/47780 [02:13<00:31, 284.40 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27684/47780 [02:13<01:05, 306.30 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38320/47780 [02:13<00:35, 269.22 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39734/47780 [02:13<00:23, 345.49 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38525/47780 [02:13<00:36, 251.53 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40781/47780 [02:13<00:31, 224.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39401/47780 [02:13<00:28, 290.96 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40162/47780 [02:13<00:22, 333.09 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27716/47780 [02:13<01:05, 306.51 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38991/47780 [02:13<00:31, 278.77 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38350/47780 [02:13<00:34, 274.81 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39777/47780 [02:13<00:21, 365.15 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40821/47780 [02:13<00:26, 266.96 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38551/47780 [02:13<00:37, 245.36 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39437/47780 [02:13<00:26, 310.02 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40198/47780 [02:13<00:22, 339.03 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38380/47780 [02:13<00:33, 281.94 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27747/47780 [02:13<01:08, 291.36 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39020/47780 [02:13<00:34, 257.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38576/47780 [02:13<00:37, 244.24 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40849/47780 [02:13<00:27, 251.43 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39469/47780 [02:13<00:28, 289.85 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40233/47780 [02:13<00:22, 337.64 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38409/47780 [02:13<00:34, 274.58 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39816/47780 [02:13<00:27, 292.30 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27777/47780 [02:13<01:08, 290.59 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38603/47780 [02:13<00:36, 248.69 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39047/47780 [02:13<00:36, 240.36 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39500/47780 [02:13<00:28, 289.11 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40877/47780 [02:14<00:29, 232.45 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39852/47780 [02:14<00:25, 305.58 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38437/47780 [02:14<00:34, 267.12 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40269/47780 [02:14<00:24, 312.71 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27807/47780 [02:14<01:10, 283.34 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38633/47780 [02:14<00:34, 263.14 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39072/47780 [02:14<00:37, 233.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39530/47780 [02:14<00:31, 265.47 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40904/47780 [02:14<00:29, 232.55 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39902/47780 [02:14<00:22, 351.70 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40303/47780 [02:14<00:23, 317.44 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27847/47780 [02:14<01:03, 312.76 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38663/47780 [02:14<00:33, 270.87 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38464/47780 [02:14<00:36, 253.74 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39113/47780 [02:14<00:32, 268.04 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39589/47780 [02:14<00:23, 351.37 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27883/47780 [02:14<01:02, 318.93 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39940/47780 [02:14<00:22, 341.03 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38693/47780 [02:14<00:32, 276.12 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40336/47780 [02:14<00:25, 297.29 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38490/47780 [02:14<00:37, 244.60 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40928/47780 [02:14<00:32, 208.27 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39149/47780 [02:14<00:29, 291.68 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39627/47780 [02:14<00:23, 340.02 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27916/47780 [02:14<01:03, 314.69 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38721/47780 [02:14<00:33, 274.06 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39976/47780 [02:14<00:23, 331.29 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40964/47780 [02:14<00:27, 243.77 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38525/47780 [02:14<00:35, 259.36 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40367/47780 [02:14<00:26, 282.48 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39181/47780 [02:14<00:28, 296.91 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39663/47780 [02:14<00:23, 338.32 examples/s]Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27949/47780 [02:14<01:02, 318.01 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40011/47780 [02:14<00:23, 329.63 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40993/47780 [02:14<00:26, 253.07 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38556/47780 [02:14<00:34, 270.08 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38749/47780 [02:14<00:36, 246.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40404/47780 [02:14<00:24, 299.22 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39700/47780 [02:14<00:23, 342.11 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27982/47780 [02:14<01:03, 312.00 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39212/47780 [02:14<00:33, 252.73 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40045/47780 [02:14<00:23, 325.68 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41027/47780 [02:14<00:24, 276.10 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38584/47780 [02:14<00:34, 266.84 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38778/47780 [02:14<00:35, 255.96 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40435/47780 [02:14<00:26, 277.96 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39260/47780 [02:14<00:27, 309.59 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28014/47780 [02:14<01:05, 303.38 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40080/47780 [02:14<00:23, 332.19 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39735/47780 [02:14<00:25, 310.92 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41056/47780 [02:14<00:24, 271.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38806/47780 [02:14<00:36, 248.81 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38612/47780 [02:14<00:36, 247.90 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40464/47780 [02:14<00:26, 271.07 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39294/47780 [02:14<00:27, 311.00 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▊    | 28052/47780 [02:14<01:01, 320.63 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40114/47780 [02:14<00:23, 330.51 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39767/47780 [02:14<00:25, 310.05 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38836/47780 [02:14<00:34, 262.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38638/47780 [02:14<00:37, 246.20 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40498/47780 [02:14<00:25, 285.17 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41084/47780 [02:14<00:28, 235.13 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28085/47780 [02:14<01:01, 320.85 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39327/47780 [02:14<00:28, 295.07 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40148/47780 [02:14<00:24, 315.77 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38864/47780 [02:14<00:34, 259.91 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40529/47780 [02:14<00:25, 289.92 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41119/47780 [02:14<00:25, 263.69 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38663/47780 [02:14<00:38, 234.74 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39799/47780 [02:14<00:31, 257.02 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28125/47780 [02:14<00:59, 332.14 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39358/47780 [02:15<00:28, 297.44 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40181/47780 [02:15<00:25, 299.71 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38896/47780 [02:15<00:32, 270.54 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41150/47780 [02:15<00:24, 275.95 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40559/47780 [02:15<00:24, 290.85 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38695/47780 [02:15<00:36, 252.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39861/47780 [02:15<00:23, 341.48 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38926/47780 [02:15<00:31, 277.96 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28159/47780 [02:15<01:09, 283.14 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39390/47780 [02:15<00:32, 261.51 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40589/47780 [02:15<00:25, 284.09 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41179/47780 [02:15<00:24, 269.31 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40212/47780 [02:15<00:28, 267.60 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38721/47780 [02:15<00:37, 238.70 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39899/47780 [02:15<00:24, 318.74 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38958/47780 [02:15<00:30, 289.81 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28220/47780 [02:15<00:53, 366.65 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40620/47780 [02:15<00:24, 288.48 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41207/47780 [02:15<00:24, 266.41 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39418/47780 [02:15<00:33, 253.14 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40240/47780 [02:15<00:28, 262.68 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38752/47780 [02:15<00:35, 255.07 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39938/47780 [02:15<00:23, 329.93 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38991/47780 [02:15<00:29, 301.25 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28260/47780 [02:15<00:54, 360.06 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41235/47780 [02:15<00:24, 265.63 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40649/47780 [02:15<00:25, 276.07 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39445/47780 [02:15<00:32, 254.64 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40278/47780 [02:15<00:25, 290.35 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39975/47780 [02:15<00:22, 340.25 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38778/47780 [02:15<00:38, 235.64 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39023/47780 [02:15<00:30, 289.95 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41262/47780 [02:15<00:24, 266.81 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28304/47780 [02:15<00:52, 373.57 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39478/47780 [02:15<00:30, 271.91 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40309/47780 [02:15<00:25, 294.96 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40678/47780 [02:15<00:27, 262.40 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38803/47780 [02:15<00:38, 234.53 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 40012/47780 [02:15<00:24, 311.23 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39053/47780 [02:15<00:30, 283.16 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41290/47780 [02:15<00:25, 258.80 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39511/47780 [02:15<00:29, 281.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40339/47780 [02:15<00:25, 287.24 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40705/47780 [02:15<00:27, 256.03 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28343/47780 [02:15<00:57, 337.23 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38834/47780 [02:15<00:35, 251.90 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39082/47780 [02:15<00:30, 284.97 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39555/47780 [02:15<00:25, 324.98 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40045/47780 [02:15<00:26, 288.18 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41317/47780 [02:15<00:26, 248.26 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40733/47780 [02:15<00:26, 262.15 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40369/47780 [02:15<00:27, 272.29 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28379/47780 [02:15<01:02, 311.31 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38860/47780 [02:15<00:38, 232.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39113/47780 [02:15<00:30, 285.76 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40075/47780 [02:15<00:26, 286.76 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39589/47780 [02:15<00:26, 308.04 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40407/47780 [02:15<00:24, 298.87 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40762/47780 [02:15<00:26, 261.74 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41343/47780 [02:15<00:27, 235.96 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38889/47780 [02:15<00:36, 241.45 examples/s]Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28412/47780 [02:15<01:03, 303.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39146/47780 [02:15<00:29, 289.12 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40793/47780 [02:15<00:25, 275.21 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40107/47780 [02:15<00:28, 272.85 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40439/47780 [02:15<00:25, 288.65 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41367/47780 [02:15<00:28, 222.47 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39621/47780 [02:15<00:29, 278.19 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38919/47780 [02:15<00:34, 254.53 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28450/47780 [02:15<01:00, 317.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39179/47780 [02:16<00:28, 296.83 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40824/47780 [02:16<00:24, 278.96 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40135/47780 [02:16<00:28, 266.37 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40478/47780 [02:16<00:23, 312.87 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41390/47780 [02:16<00:29, 213.35 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38946/47780 [02:16<00:34, 253.76 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28484/47780 [02:16<00:59, 321.82 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39650/47780 [02:16<00:31, 259.49 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39216/47780 [02:16<00:27, 314.03 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40861/47780 [02:16<00:23, 295.74 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40510/47780 [02:16<00:23, 311.12 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40163/47780 [02:16<00:29, 259.10 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41421/47780 [02:16<00:26, 238.89 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28523/47780 [02:16<00:56, 337.95 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38977/47780 [02:16<00:33, 262.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39250/47780 [02:16<00:26, 321.42 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39678/47780 [02:16<00:32, 247.20 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40908/47780 [02:16<00:19, 344.14 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40552/47780 [02:16<00:21, 338.33 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40203/47780 [02:16<00:25, 293.31 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41446/47780 [02:16<00:26, 239.35 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39283/47780 [02:16<00:26, 323.46 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39004/47780 [02:16<00:33, 264.92 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28558/47780 [02:16<01:01, 310.19 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39704/47780 [02:16<00:33, 240.00 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40588/47780 [02:16<00:20, 344.12 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40235/47780 [02:16<00:25, 297.15 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40943/47780 [02:16<00:21, 316.21 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41471/47780 [02:16<00:26, 239.51 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39033/47780 [02:16<00:33, 257.28 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28594/47780 [02:16<00:59, 319.83 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39316/47780 [02:16<00:29, 285.62 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40634/47780 [02:16<00:19, 373.85 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39729/47780 [02:16<00:36, 222.69 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40978/47780 [02:16<00:21, 318.92 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41498/47780 [02:16<00:25, 242.77 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40266/47780 [02:16<00:26, 281.66 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39059/47780 [02:16<00:34, 255.40 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39349/47780 [02:16<00:28, 291.38 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28627/47780 [02:16<01:03, 299.49 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40676/47780 [02:16<00:18, 382.72 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39753/47780 [02:16<00:37, 216.10 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40297/47780 [02:16<00:26, 286.55 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41011/47780 [02:16<00:21, 308.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41523/47780 [02:16<00:27, 229.85 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39085/47780 [02:16<00:34, 251.04 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39388/47780 [02:16<00:26, 316.35 examples/s]Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28660/47780 [02:16<01:02, 304.66 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40715/47780 [02:16<00:18, 380.04 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39787/47780 [02:16<00:32, 245.41 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40329/47780 [02:16<00:25, 289.40 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41045/47780 [02:16<00:21, 307.41 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41549/47780 [02:16<00:26, 234.81 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39118/47780 [02:16<00:31, 273.27 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39422/47780 [02:16<00:26, 310.60 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28697/47780 [02:16<00:59, 318.44 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40754/47780 [02:16<00:19, 366.24 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39816/47780 [02:16<00:30, 257.23 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40360/47780 [02:16<00:25, 285.61 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41076/47780 [02:16<00:22, 300.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39148/47780 [02:16<00:31, 277.84 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41575/47780 [02:16<00:26, 232.88 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28731/47780 [02:16<01:00, 312.95 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39844/47780 [02:16<00:30, 258.62 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39454/47780 [02:16<00:28, 288.01 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40791/47780 [02:16<00:20, 340.22 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41111/47780 [02:16<00:21, 308.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39176/47780 [02:16<00:31, 275.30 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40389/47780 [02:16<00:26, 274.39 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41609/47780 [02:16<00:23, 258.14 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28763/47780 [02:16<01:03, 299.81 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39484/47780 [02:17<00:28, 287.06 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39871/47780 [02:17<00:32, 241.80 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39205/47780 [02:17<00:31, 276.22 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40827/47780 [02:17<00:21, 320.63 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41635/47780 [02:17<00:24, 253.07 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40418/47780 [02:17<00:27, 267.07 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41143/47780 [02:17<00:23, 288.09 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28802/47780 [02:17<00:59, 321.07 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39514/47780 [02:17<00:28, 285.50 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39238/47780 [02:17<00:29, 288.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39911/47780 [02:17<00:28, 278.65 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41671/47780 [02:17<00:22, 277.29 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40445/47780 [02:17<00:27, 262.27 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41176/47780 [02:17<00:22, 293.08 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40860/47780 [02:17<00:22, 302.10 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39543/47780 [02:17<00:29, 277.42 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28835/47780 [02:17<01:02, 303.05 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39272/47780 [02:17<00:28, 303.32 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39940/47780 [02:17<00:29, 269.82 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41699/47780 [02:17<00:22, 274.29 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40472/47780 [02:17<00:27, 264.04 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41216/47780 [02:17<00:20, 322.35 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40895/47780 [02:17<00:22, 307.14 examples/s]Tokenizing train dataset (num_proc=32):  60%|██████    | 28866/47780 [02:17<01:03, 298.55 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39571/47780 [02:17<00:30, 266.39 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39968/47780 [02:17<00:28, 269.74 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41251/47780 [02:17<00:19, 330.07 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39303/47780 [02:17<00:30, 279.13 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41727/47780 [02:17<00:22, 267.17 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40499/47780 [02:17<00:28, 254.58 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40927/47780 [02:17<00:25, 272.41 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28901/47780 [02:17<01:02, 302.80 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39998/47780 [02:17<00:28, 273.80 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39598/47780 [02:17<00:33, 245.48 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41285/47780 [02:17<00:19, 325.67 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40527/47780 [02:17<00:28, 258.69 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39339/47780 [02:17<00:28, 291.92 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41754/47780 [02:17<00:23, 258.63 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40957/47780 [02:17<00:24, 274.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 28937/47780 [02:17<00:59, 315.18 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39628/47780 [02:17<00:31, 257.76 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40026/47780 [02:17<00:28, 270.58 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41321/47780 [02:17<00:19, 328.17 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40553/47780 [02:17<00:28, 255.87 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41783/47780 [02:17<00:22, 263.63 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39369/47780 [02:17<00:31, 270.20 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40986/47780 [02:17<00:25, 271.68 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39657/47780 [02:17<00:30, 263.48 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40056/47780 [02:17<00:28, 272.96 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 28969/47780 [02:17<01:05, 287.60 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40579/47780 [02:17<00:28, 254.54 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41354/47780 [02:17<00:20, 310.88 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39398/47780 [02:17<00:31, 269.79 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41810/47780 [02:17<00:24, 239.57 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41014/47780 [02:17<00:25, 260.99 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29008/47780 [02:17<00:59, 314.77 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40084/47780 [02:17<00:28, 268.59 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39684/47780 [02:17<00:31, 253.66 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40605/47780 [02:17<00:28, 247.55 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41387/47780 [02:17<00:20, 312.50 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39426/47780 [02:17<00:31, 269.37 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41835/47780 [02:17<00:26, 227.74 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40631/47780 [02:17<00:28, 251.06 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29041/47780 [02:17<01:01, 305.42 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40111/47780 [02:17<00:29, 260.44 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39710/47780 [02:17<00:32, 246.83 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41041/47780 [02:17<00:28, 233.55 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39454/47780 [02:17<00:30, 269.65 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41419/47780 [02:17<00:22, 288.81 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41859/47780 [02:17<00:26, 226.15 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40147/47780 [02:18<00:26, 288.32 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29082/47780 [02:17<00:56, 330.49 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39736/47780 [02:18<00:32, 248.55 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40657/47780 [02:18<00:29, 239.85 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41457/47780 [02:18<00:20, 313.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39496/47780 [02:18<00:28, 295.29 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41886/47780 [02:18<00:25, 232.98 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41065/47780 [02:18<00:33, 202.52 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40683/47780 [02:18<00:28, 245.34 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29116/47780 [02:18<00:58, 318.57 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40177/47780 [02:18<00:27, 273.08 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39761/47780 [02:18<00:34, 229.79 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41489/47780 [02:18<00:21, 291.90 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39527/47780 [02:18<00:29, 277.69 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41914/47780 [02:18<00:25, 234.42 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41087/47780 [02:18<00:35, 190.44 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40714/47780 [02:18<00:27, 260.91 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29149/47780 [02:18<00:59, 315.24 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40208/47780 [02:18<00:27, 280.17 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39810/47780 [02:18<00:26, 298.18 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41525/47780 [02:18<00:20, 304.32 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41945/47780 [02:18<00:23, 253.50 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39559/47780 [02:18<00:29, 283.19 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29182/47780 [02:18<00:58, 319.35 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40741/47780 [02:18<00:27, 260.17 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40244/47780 [02:18<00:25, 299.34 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39842/47780 [02:18<00:26, 304.23 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41107/47780 [02:18<00:39, 169.91 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41560/47780 [02:18<00:19, 315.65 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41973/47780 [02:18<00:22, 260.46 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39589/47780 [02:18<00:28, 287.73 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████    | 29219/47780 [02:18<00:56, 329.96 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40278/47780 [02:18<00:24, 303.85 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39874/47780 [02:18<00:26, 301.87 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40768/47780 [02:18<00:28, 245.99 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41174/47780 [02:18<00:23, 280.23 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42000/47780 [02:18<00:23, 249.37 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39618/47780 [02:18<00:29, 275.46 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41594/47780 [02:18<00:21, 288.09 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40800/47780 [02:18<00:26, 262.17 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40309/47780 [02:18<00:26, 285.99 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29253/47780 [02:18<01:01, 301.13 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39905/47780 [02:18<00:29, 265.02 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41630/47780 [02:18<00:20, 300.67 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39646/47780 [02:18<00:31, 260.08 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42026/47780 [02:18<00:24, 236.58 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40351/47780 [02:18<00:23, 319.73 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41206/47780 [02:18<00:27, 234.86 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29290/47780 [02:18<00:58, 313.62 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40827/47780 [02:18<00:27, 251.93 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39933/47780 [02:18<00:30, 255.36 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41665/47780 [02:18<00:19, 313.61 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39673/47780 [02:18<00:31, 259.83 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42050/47780 [02:18<00:24, 237.49 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41280/47780 [02:18<00:18, 346.13 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40384/47780 [02:18<00:23, 311.80 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40863/47780 [02:18<00:25, 275.84 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29324/47780 [02:18<01:00, 304.01 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39965/47780 [02:18<00:28, 269.71 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42075/47780 [02:18<00:23, 240.95 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39710/47780 [02:18<00:28, 287.24 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41697/47780 [02:18<00:21, 286.77 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40892/47780 [02:18<00:24, 276.77 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40418/47780 [02:18<00:23, 312.87 examples/s]Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29355/47780 [02:18<01:01, 298.88 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39996/47780 [02:18<00:28, 271.84 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39742/47780 [02:18<00:27, 296.37 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41321/47780 [02:18<00:20, 308.07 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42100/47780 [02:18<00:24, 230.45 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41727/47780 [02:18<00:21, 275.95 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40920/47780 [02:19<00:24, 277.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40451/47780 [02:19<00:23, 310.70 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29391/47780 [02:18<00:58, 315.66 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40029/47780 [02:19<00:27, 284.52 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41357/47780 [02:19<00:20, 313.82 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42126/47780 [02:19<00:23, 236.15 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39773/47780 [02:19<00:28, 280.99 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41757/47780 [02:19<00:21, 279.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40949/47780 [02:19<00:24, 274.94 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29423/47780 [02:19<00:59, 306.96 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40483/47780 [02:19<00:25, 281.12 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40067/47780 [02:19<00:25, 307.50 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42150/47780 [02:19<00:23, 234.59 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39809/47780 [02:19<00:26, 302.72 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41786/47780 [02:19<00:22, 267.39 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40977/47780 [02:19<00:25, 267.23 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29460/47780 [02:19<00:56, 324.62 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41392/47780 [02:19<00:23, 273.09 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40099/47780 [02:19<00:25, 300.98 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42183/47780 [02:19<00:21, 261.58 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39853/47780 [02:19<00:23, 340.31 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40513/47780 [02:19<00:27, 266.76 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41008/47780 [02:19<00:24, 279.33 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41816/47780 [02:19<00:21, 273.50 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29497/47780 [02:19<00:54, 337.57 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42215/47780 [02:19<00:20, 275.44 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41425/47780 [02:19<00:24, 262.38 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40542/47780 [02:19<00:27, 266.84 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39888/47780 [02:19<00:24, 323.77 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40130/47780 [02:19<00:27, 278.19 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41041/47780 [02:19<00:23, 287.06 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29538/47780 [02:19<00:52, 350.44 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41844/47780 [02:19<00:23, 257.77 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40576/47780 [02:19<00:25, 283.91 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41456/47780 [02:19<00:23, 268.14 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42245/47780 [02:19<00:20, 272.98 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40159/47780 [02:19<00:27, 272.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39921/47780 [02:19<00:25, 306.50 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29575/47780 [02:19<00:52, 347.50 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41871/47780 [02:19<00:23, 247.97 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41070/47780 [02:19<00:26, 257.95 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40605/47780 [02:19<00:25, 285.27 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41485/47780 [02:19<00:23, 265.39 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42275/47780 [02:19<00:20, 265.57 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40187/47780 [02:19<00:28, 269.04 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39961/47780 [02:19<00:23, 328.96 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29619/47780 [02:19<00:49, 370.48 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41897/47780 [02:19<00:24, 243.48 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41097/47780 [02:19<00:26, 256.22 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40648/47780 [02:19<00:22, 316.30 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41518/47780 [02:19<00:22, 276.54 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42305/47780 [02:19<00:20, 272.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40224/47780 [02:19<00:25, 296.67 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29657/47780 [02:19<00:50, 360.60 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41930/47780 [02:19<00:21, 266.85 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41123/47780 [02:19<00:25, 257.17 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40680/47780 [02:19<00:22, 316.96 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39995/47780 [02:19<00:28, 271.61 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41550/47780 [02:19<00:21, 284.92 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40261/47780 [02:19<00:23, 315.95 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42334/47780 [02:19<00:20, 265.08 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29695/47780 [02:19<00:50, 355.52 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41156/47780 [02:19<00:23, 277.62 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41962/47780 [02:19<00:21, 275.49 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40712/47780 [02:19<00:22, 314.00 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40295/47780 [02:19<00:24, 310.10 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41581/47780 [02:19<00:22, 270.84 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42361/47780 [02:19<00:21, 254.48 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40025/47780 [02:19<00:31, 244.90 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42002/47780 [02:19<00:18, 306.96 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29731/47780 [02:19<00:53, 336.32 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41187/47780 [02:20<00:24, 274.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40745/47780 [02:20<00:22, 314.94 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40327/47780 [02:20<00:24, 302.67 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42387/47780 [02:20<00:22, 243.23 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41613/47780 [02:20<00:23, 264.38 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40052/47780 [02:20<00:33, 231.20 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42040/47780 [02:20<00:17, 324.04 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29765/47780 [02:20<00:53, 336.94 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41217/47780 [02:20<00:23, 279.81 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40778/47780 [02:20<00:23, 302.60 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40362/47780 [02:20<00:23, 312.48 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42421/47780 [02:20<00:20, 266.72 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41640/47780 [02:20<00:23, 257.83 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40148/47780 [02:20<00:18, 403.76 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29803/47780 [02:20<00:52, 342.79 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42078/47780 [02:20<00:17, 332.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41250/47780 [02:20<00:22, 287.12 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40817/47780 [02:20<00:21, 317.15 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42458/47780 [02:20<00:18, 295.37 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40394/47780 [02:20<00:24, 300.47 examples/s]Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29860/47780 [02:20<00:44, 406.20 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42119/47780 [02:20<00:15, 354.44 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41667/47780 [02:20<00:24, 247.48 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41283/47780 [02:20<00:22, 295.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40194/47780 [02:20<00:20, 376.13 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40849/47780 [02:20<00:23, 293.50 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40425/47780 [02:20<00:25, 287.33 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42488/47780 [02:20<00:19, 271.66 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29902/47780 [02:20<00:43, 409.00 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41695/47780 [02:20<00:24, 251.55 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42155/47780 [02:20<00:16, 336.49 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41313/47780 [02:20<00:23, 271.54 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40236/47780 [02:20<00:21, 358.16 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40879/47780 [02:20<00:24, 283.29 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40458/47780 [02:20<00:24, 296.04 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42516/47780 [02:20<00:19, 270.92 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41724/47780 [02:20<00:23, 259.17 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29944/47780 [02:20<00:44, 399.35 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42189/47780 [02:20<00:17, 326.54 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40278/47780 [02:20<00:20, 369.95 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40917/47780 [02:20<00:22, 309.15 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41342/47780 [02:20<00:27, 236.17 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40492/47780 [02:20<00:24, 298.27 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41752/47780 [02:20<00:22, 264.30 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29985/47780 [02:20<00:45, 393.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42224/47780 [02:20<00:16, 332.89 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42544/47780 [02:20<00:22, 237.06 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40951/47780 [02:20<00:21, 314.22 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40320/47780 [02:20<00:20, 364.05 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41382/47780 [02:20<00:23, 277.02 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41780/47780 [02:20<00:22, 263.35 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40523/47780 [02:20<00:25, 288.43 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30025/47780 [02:20<00:46, 385.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42258/47780 [02:20<00:17, 317.97 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42572/47780 [02:20<00:21, 245.62 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40989/47780 [02:20<00:20, 329.03 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40360/47780 [02:20<00:21, 351.91 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41811/47780 [02:20<00:21, 273.47 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40557/47780 [02:20<00:24, 293.19 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30064/47780 [02:20<00:46, 378.03 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41412/47780 [02:20<00:25, 252.85 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42294/47780 [02:20<00:16, 326.24 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41023/47780 [02:20<00:20, 332.12 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40400/47780 [02:20<00:20, 360.21 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41839/47780 [02:20<00:21, 274.94 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40598/47780 [02:20<00:22, 321.96 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30103/47780 [02:20<00:47, 370.41 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42598/47780 [02:20<00:26, 198.80 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41441/47780 [02:20<00:25, 252.34 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42327/47780 [02:20<00:17, 313.84 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41058/47780 [02:20<00:20, 333.60 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40438/47780 [02:21<00:20, 358.01 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41867/47780 [02:21<00:22, 264.15 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40631/47780 [02:21<00:22, 313.34 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30141/47780 [02:21<00:50, 346.61 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41468/47780 [02:21<00:25, 244.13 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42359/47780 [02:21<00:19, 278.71 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41092/47780 [02:21<00:21, 313.25 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41897/47780 [02:21<00:21, 271.62 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40664/47780 [02:21<00:22, 314.80 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42620/47780 [02:21<00:31, 165.36 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40475/47780 [02:21<00:22, 322.54 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41494/47780 [02:21<00:25, 248.19 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30176/47780 [02:21<00:52, 335.17 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42398/47780 [02:21<00:17, 307.59 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41124/47780 [02:21<00:22, 298.81 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40698/47780 [02:21<00:22, 321.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42678/47780 [02:21<00:20, 251.68 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41521/47780 [02:21<00:24, 251.59 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40509/47780 [02:21<00:23, 314.06 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41925/47780 [02:21<00:25, 230.33 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42431/47780 [02:21<00:17, 308.20 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30212/47780 [02:21<00:57, 304.19 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41160/47780 [02:21<00:21, 313.09 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40731/47780 [02:21<00:22, 316.95 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42710/47780 [02:21<00:19, 264.38 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40546/47780 [02:21<00:22, 325.66 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41555/47780 [02:21<00:22, 272.95 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41962/47780 [02:21<00:22, 264.17 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42464/47780 [02:21<00:17, 310.50 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30266/47780 [02:21<00:48, 363.83 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41200/47780 [02:21<00:19, 336.41 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40770/47780 [02:21<00:20, 333.82 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40580/47780 [02:21<00:22, 318.70 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42741/47780 [02:21<00:19, 252.74 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41584/47780 [02:21<00:23, 263.06 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41990/47780 [02:21<00:21, 268.14 examples/s]Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30305/47780 [02:21<00:47, 365.34 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42497/47780 [02:21<00:18, 287.69 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41235/47780 [02:21<00:20, 323.04 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40804/47780 [02:21<00:22, 314.19 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42771/47780 [02:21<00:19, 259.53 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40613/47780 [02:21<00:22, 314.77 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42018/47780 [02:21<00:21, 263.42 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41611/47780 [02:21<00:25, 241.05 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30343/47780 [02:21<00:48, 357.72 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41278/47780 [02:21<00:18, 351.51 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42807/47780 [02:21<00:17, 283.29 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40836/47780 [02:21<00:23, 292.96 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42527/47780 [02:21<00:21, 248.29 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42047/47780 [02:21<00:21, 267.80 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41636/47780 [02:21<00:25, 238.42 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30383/47780 [02:21<00:47, 365.26 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41321/47780 [02:21<00:17, 373.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40645/47780 [02:21<00:25, 276.57 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40867/47780 [02:21<00:23, 288.05 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42076/47780 [02:21<00:20, 274.01 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42580/47780 [02:21<00:16, 312.01 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42838/47780 [02:21<00:18, 269.09 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41663/47780 [02:21<00:25, 241.65 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30421/47780 [02:21<00:49, 353.59 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41360/47780 [02:21<00:17, 361.94 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40675/47780 [02:21<00:26, 271.98 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40900/47780 [02:21<00:22, 299.39 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42108/47780 [02:21<00:19, 283.79 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42614/47780 [02:21<00:16, 318.37 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42867/47780 [02:21<00:18, 269.29 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30457/47780 [02:21<00:49, 347.25 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40713/47780 [02:21<00:23, 299.31 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41397/47780 [02:21<00:17, 359.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41688/47780 [02:21<00:26, 229.80 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40932/47780 [02:22<00:22, 302.03 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42145/47780 [02:22<00:18, 302.18 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42895/47780 [02:22<00:18, 265.74 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42648/47780 [02:22<00:17, 301.56 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40748/47780 [02:22<00:22, 307.20 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41439/47780 [02:22<00:17, 360.66 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41712/47780 [02:22<00:27, 221.92 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30492/47780 [02:22<00:53, 322.63 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40974/47780 [02:22<00:20, 335.08 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42688/47780 [02:22<00:15, 327.36 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42176/47780 [02:22<00:19, 281.50 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40790/47780 [02:22<00:20, 334.56 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42923/47780 [02:22<00:19, 248.48 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41486/47780 [02:22<00:16, 387.11 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41735/47780 [02:22<00:27, 219.61 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30534/47780 [02:22<00:49, 345.82 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41011/47780 [02:22<00:20, 333.95 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42728/47780 [02:22<00:14, 339.68 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42212/47780 [02:22<00:18, 296.84 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42955/47780 [02:22<00:18, 261.98 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40825/47780 [02:22<00:21, 320.91 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41764/47780 [02:22<00:25, 238.71 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30570/47780 [02:22<00:49, 345.25 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41526/47780 [02:22<00:16, 369.72 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41045/47780 [02:22<00:20, 334.86 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42250/47780 [02:22<00:17, 316.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42763/47780 [02:22<00:15, 328.75 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40859/47780 [02:22<00:21, 322.22 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30606/47780 [02:22<00:49, 346.19 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42985/47780 [02:22<00:18, 255.71 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41565/47780 [02:22<00:16, 371.21 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41789/47780 [02:22<00:26, 229.08 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41079/47780 [02:22<00:20, 325.78 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42284/47780 [02:22<00:17, 315.99 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42797/47780 [02:22<00:15, 324.75 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30645/47780 [02:22<00:47, 358.55 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41821/47780 [02:22<00:23, 254.04 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43011/47780 [02:22<00:19, 241.56 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41603/47780 [02:22<00:17, 353.28 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41112/47780 [02:22<00:21, 306.14 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40892/47780 [02:22<00:25, 272.86 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42316/47780 [02:22<00:17, 310.00 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42831/47780 [02:22<00:15, 321.63 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30687/47780 [02:22<00:46, 367.89 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41857/47780 [02:22<00:21, 280.95 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43042/47780 [02:22<00:18, 256.71 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41639/47780 [02:22<00:18, 333.40 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40930/47780 [02:22<00:22, 299.78 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41143/47780 [02:22<00:22, 297.19 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42867/47780 [02:22<00:14, 331.88 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42348/47780 [02:22<00:17, 305.62 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41886/47780 [02:22<00:21, 280.33 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30724/47780 [02:22<00:48, 352.22 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43069/47780 [02:22<00:19, 246.79 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41674/47780 [02:22<00:19, 320.85 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41174/47780 [02:22<00:22, 294.40 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42381/47780 [02:22<00:17, 309.09 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42901/47780 [02:22<00:15, 322.90 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40962/47780 [02:22<00:24, 278.64 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41916/47780 [02:22<00:20, 284.52 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30767/47780 [02:22<00:45, 369.98 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41708/47780 [02:22<00:18, 325.85 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43094/47780 [02:22<00:20, 225.65 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41205/47780 [02:22<00:22, 288.73 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42934/47780 [02:22<00:15, 311.08 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40992/47780 [02:22<00:25, 267.51 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41946/47780 [02:22<00:20, 283.98 examples/s]Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30805/47780 [02:22<00:46, 368.43 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42412/47780 [02:22<00:20, 261.73 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41742/47780 [02:22<00:18, 326.38 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43125/47780 [02:23<00:19, 242.82 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42969/47780 [02:23<00:15, 318.40 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41234/47780 [02:23<00:24, 265.86 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30842/47780 [02:23<00:46, 365.00 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41975/47780 [02:23<00:20, 276.92 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41020/47780 [02:23<00:25, 260.19 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42461/47780 [02:23<00:17, 310.58 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41775/47780 [02:23<00:19, 309.82 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43153/47780 [02:23<00:18, 247.40 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43002/47780 [02:23<00:15, 318.11 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41053/47780 [02:23<00:24, 275.42 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42003/47780 [02:23<00:22, 259.19 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41261/47780 [02:23<00:27, 238.86 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30881/47780 [02:23<00:54, 308.32 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41812/47780 [02:23<00:18, 315.88 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43188/47780 [02:23<00:16, 271.82 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42494/47780 [02:23<00:18, 283.11 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43039/47780 [02:23<00:14, 332.89 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41087/47780 [02:23<00:22, 292.65 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41306/47780 [02:23<00:22, 292.52 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42031/47780 [02:23<00:22, 253.70 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41844/47780 [02:23<00:18, 315.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43216/47780 [02:23<00:16, 269.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30914/47780 [02:23<00:55, 305.48 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42524/47780 [02:23<00:18, 280.49 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43079/47780 [02:23<00:13, 340.31 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41121/47780 [02:23<00:22, 298.14 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42057/47780 [02:23<00:24, 237.33 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41337/47780 [02:23<00:24, 268.23 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31007/47780 [02:23<00:36, 462.24 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41879/47780 [02:23<00:18, 312.65 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43244/47780 [02:23<00:17, 262.89 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43118/47780 [02:23<00:13, 350.71 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42556/47780 [02:23<00:18, 277.54 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41163/47780 [02:23<00:19, 330.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42086/47780 [02:23<00:22, 251.27 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41920/47780 [02:23<00:17, 336.04 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41366/47780 [02:23<00:25, 255.86 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42586/47780 [02:23<00:18, 280.24 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43154/47780 [02:23<00:13, 337.93 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43271/47780 [02:23<00:18, 245.70 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41198/47780 [02:23<00:19, 335.00 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 31056/47780 [02:23<00:39, 428.12 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42112/47780 [02:23<00:23, 240.40 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41971/47780 [02:23<00:15, 381.00 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43297/47780 [02:23<00:17, 249.23 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42615/47780 [02:23<00:19, 270.92 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41394/47780 [02:23<00:26, 242.27 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43188/47780 [02:23<00:14, 323.87 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41232/47780 [02:23<00:20, 323.27 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31101/47780 [02:23<00:41, 404.49 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42138/47780 [02:23<00:23, 240.62 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42644/47780 [02:23<00:18, 273.66 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42011/47780 [02:23<00:16, 354.14 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43332/47780 [02:23<00:16, 271.57 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41267/47780 [02:23<00:19, 329.38 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43221/47780 [02:23<00:14, 308.14 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31143/47780 [02:23<00:42, 392.34 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41419/47780 [02:23<00:31, 203.28 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43367/47780 [02:23<00:15, 293.41 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42672/47780 [02:23<00:18, 272.39 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41301/47780 [02:23<00:19, 332.39 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42047/47780 [02:23<00:16, 343.89 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31184/47780 [02:23<00:42, 392.84 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42164/47780 [02:23<00:27, 203.37 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41474/47780 [02:23<00:22, 283.06 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41336/47780 [02:24<00:19, 337.32 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43253/47780 [02:24<00:18, 251.23 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43397/47780 [02:24<00:15, 282.58 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42701/47780 [02:24<00:19, 254.49 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31231/47780 [02:24<00:40, 409.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42083/47780 [02:24<00:17, 317.25 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41513/47780 [02:24<00:20, 306.39 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41372/47780 [02:24<00:18, 341.75 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42186/47780 [02:24<00:31, 179.26 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43426/47780 [02:24<00:15, 284.53 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42124/47780 [02:24<00:16, 338.46 examples/s]Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31276/47780 [02:24<00:40, 407.63 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42727/47780 [02:24<00:21, 237.98 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43280/47780 [02:24<00:19, 225.48 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41407/47780 [02:24<00:18, 338.64 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43458/47780 [02:24<00:14, 291.36 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42206/47780 [02:24<00:31, 179.11 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41547/47780 [02:24<00:23, 267.92 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42160/47780 [02:24<00:16, 333.40 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31321/47780 [02:24<00:39, 414.06 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42764/47780 [02:24<00:18, 269.40 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41448/47780 [02:24<00:17, 355.38 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43492/47780 [02:24<00:14, 305.35 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42228/47780 [02:24<00:29, 185.47 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43304/47780 [02:24<00:23, 187.20 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42194/47780 [02:24<00:16, 335.15 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31363/47780 [02:24<00:40, 406.57 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42803/47780 [02:24<00:16, 293.10 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41577/47780 [02:24<00:25, 245.12 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42248/47780 [02:24<00:29, 185.40 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43523/47780 [02:24<00:14, 289.88 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41484/47780 [02:24<00:18, 336.36 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43376/47780 [02:24<00:14, 300.75 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31405/47780 [02:24<00:39, 409.71 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42228/47780 [02:24<00:17, 325.61 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42833/47780 [02:24<00:16, 294.58 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41604/47780 [02:24<00:27, 228.60 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41520/47780 [02:24<00:18, 332.41 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43553/47780 [02:24<00:15, 279.96 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43412/47780 [02:24<00:14, 303.18 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42277/47780 [02:24<00:14, 367.37 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42267/47780 [02:24<00:32, 167.25 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31447/47780 [02:24<00:42, 387.01 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42864/47780 [02:24<00:17, 274.72 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41637/47780 [02:24<00:24, 251.23 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41554/47780 [02:24<00:18, 330.90 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43588/47780 [02:24<00:14, 289.85 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31493/47780 [02:24<00:40, 406.90 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43447/47780 [02:24<00:14, 299.82 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42285/47780 [02:24<00:33, 162.28 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42315/47780 [02:24<00:15, 346.91 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42893/47780 [02:24<00:18, 267.23 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41590/47780 [02:24<00:18, 335.31 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43618/47780 [02:24<00:15, 274.34 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31536/47780 [02:24<00:40, 404.32 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43482/47780 [02:24<00:13, 309.32 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42405/47780 [02:24<00:12, 422.75 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42926/47780 [02:24<00:17, 281.12 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41664/47780 [02:24<00:29, 209.65 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42352/47780 [02:24<00:17, 317.81 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31587/47780 [02:24<00:37, 434.02 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43647/47780 [02:24<00:15, 267.05 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41624/47780 [02:24<00:21, 292.76 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42965/47780 [02:24<00:15, 310.75 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42389/47780 [02:24<00:16, 329.03 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41688/47780 [02:24<00:28, 212.64 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43516/47780 [02:24<00:16, 262.74 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42453/47780 [02:24<00:14, 364.34 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43674/47780 [02:25<00:15, 266.48 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31632/47780 [02:24<00:38, 423.19 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41655/47780 [02:25<00:21, 287.80 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 43001/47780 [02:25<00:15, 317.96 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42423/47780 [02:25<00:16, 327.86 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41725/47780 [02:25<00:24, 245.81 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43706/47780 [02:25<00:14, 279.77 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31680/47780 [02:25<00:37, 430.74 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42494/47780 [02:25<00:15, 335.98 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43545/47780 [02:25<00:17, 235.85 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41685/47780 [02:25<00:22, 274.20 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42457/47780 [02:25<00:16, 320.58 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43034/47780 [02:25<00:15, 297.31 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41754/47780 [02:25<00:24, 244.68 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43743/47780 [02:25<00:13, 301.95 examples/s]Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31726/47780 [02:25<00:37, 433.73 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42539/47780 [02:25<00:14, 353.51 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41715/47780 [02:25<00:22, 275.18 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43573/47780 [02:25<00:18, 233.15 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41781/47780 [02:25<00:24, 246.05 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42490/47780 [02:25<00:17, 300.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43065/47780 [02:25<00:17, 276.96 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43782/47780 [02:25<00:12, 323.34 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42578/47780 [02:25<00:15, 345.56 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43659/47780 [02:25<00:10, 377.14 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41744/47780 [02:25<00:22, 267.20 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  66%|██████▋   | 31771/47780 [02:25<00:42, 374.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41807/47780 [02:25<00:25, 236.97 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42521/47780 [02:25<00:18, 279.11 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43095/47780 [02:25<00:17, 263.68 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43816/47780 [02:25<00:12, 310.28 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42615/47780 [02:25<00:15, 325.51 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41771/47780 [02:25<00:23, 252.09 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43704/47780 [02:25<00:11, 356.36 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31810/47780 [02:25<00:45, 349.52 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43133/47780 [02:25<00:15, 293.85 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41832/47780 [02:25<00:26, 221.88 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42553/47780 [02:25<00:18, 278.75 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43848/47780 [02:25<00:13, 296.08 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41805/47780 [02:25<00:21, 275.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42650/47780 [02:25<00:15, 328.35 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31888/47780 [02:25<00:34, 458.97 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41857/47780 [02:25<00:25, 228.89 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42583/47780 [02:25<00:18, 279.98 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43164/47780 [02:25<00:16, 277.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43880/47780 [02:25<00:13, 290.25 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41834/47780 [02:25<00:22, 263.34 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31937/47780 [02:25<00:34, 461.84 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43743/47780 [02:25<00:14, 284.25 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41882/47780 [02:25<00:25, 232.49 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42686/47780 [02:25<00:16, 304.75 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43201/47780 [02:25<00:15, 301.65 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42612/47780 [02:25<00:19, 271.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43911/47780 [02:25<00:13, 292.58 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41871/47780 [02:25<00:20, 287.72 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31994/47780 [02:25<00:32, 486.74 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41906/47780 [02:25<00:25, 226.77 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42719/47780 [02:25<00:16, 301.69 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43776/47780 [02:25<00:14, 268.78 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42641/47780 [02:25<00:19, 265.01 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43943/47780 [02:25<00:12, 300.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43232/47780 [02:25<00:16, 276.75 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32047/47780 [02:25<00:32, 481.53 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42756/47780 [02:25<00:15, 319.27 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41930/47780 [02:25<00:25, 225.73 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41901/47780 [02:25<00:22, 259.72 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43829/47780 [02:25<00:12, 322.89 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43975/47780 [02:25<00:12, 298.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42669/47780 [02:25<00:20, 245.25 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32098/47780 [02:26<00:33, 464.75 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43261/47780 [02:26<00:19, 237.75 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42793/47780 [02:26<00:15, 326.41 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41962/47780 [02:26<00:23, 246.50 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41948/47780 [02:26<00:18, 311.03 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44015/47780 [02:26<00:11, 327.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42697/47780 [02:26<00:20, 251.86 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43288/47780 [02:26<00:18, 244.98 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41997/47780 [02:26<00:21, 272.49 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42829/47780 [02:26<00:15, 323.35 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32146/47780 [02:26<00:35, 439.94 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44058/47780 [02:26<00:10, 353.26 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43866/47780 [02:26<00:15, 254.70 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41985/47780 [02:26<00:20, 289.21 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42723/47780 [02:26<00:21, 238.56 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43333/47780 [02:26<00:15, 295.05 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42028/47780 [02:26<00:20, 279.98 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42868/47780 [02:26<00:14, 335.98 examples/s]Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32191/47780 [02:26<00:35, 433.35 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43925/47780 [02:26<00:12, 317.96 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44094/47780 [02:26<00:11, 314.52 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42754/47780 [02:26<00:19, 254.82 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42017/47780 [02:26<00:20, 276.07 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42057/47780 [02:26<00:20, 279.61 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42905/47780 [02:26<00:14, 337.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32236/47780 [02:26<00:35, 433.25 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43365/47780 [02:26<00:17, 248.80 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42784/47780 [02:26<00:18, 266.96 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42050/47780 [02:26<00:20, 285.61 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43963/47780 [02:26<00:12, 302.09 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42090/47780 [02:26<00:19, 293.91 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44127/47780 [02:26<00:13, 267.47 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42940/47780 [02:26<00:15, 319.86 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32280/47780 [02:26<00:37, 412.23 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43405/47780 [02:26<00:15, 282.22 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42813/47780 [02:26<00:19, 251.25 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42120/47780 [02:26<00:19, 292.19 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42081/47780 [02:26<00:21, 269.52 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43998/47780 [02:26<00:12, 291.94 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44157/47780 [02:26<00:13, 275.37 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42978/47780 [02:26<00:14, 336.18 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32327/47780 [02:26<00:36, 418.71 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42158/47780 [02:26<00:17, 317.67 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42851/47780 [02:26<00:17, 273.90 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43021/47780 [02:26<00:13, 354.57 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44186/47780 [02:26<00:13, 268.25 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44031/47780 [02:26<00:13, 279.13 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43436/47780 [02:26<00:18, 238.55 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32371/47780 [02:26<00:38, 401.88 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42110/47780 [02:26<00:25, 226.05 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42879/47780 [02:26<00:18, 261.55 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43465/47780 [02:26<00:17, 248.09 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44215/47780 [02:26<00:13, 259.48 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43057/47780 [02:26<00:14, 326.39 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44061/47780 [02:26<00:14, 265.37 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32412/47780 [02:26<00:40, 383.61 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42190/47780 [02:26<00:22, 253.30 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42174/47780 [02:26<00:17, 318.80 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42914/47780 [02:26<00:17, 285.01 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44249/47780 [02:26<00:12, 278.43 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43493/47780 [02:26<00:17, 246.09 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43091/47780 [02:26<00:14, 316.72 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32451/47780 [02:26<00:40, 377.14 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44089/47780 [02:26<00:14, 258.66 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42210/47780 [02:26<00:17, 310.60 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42947/47780 [02:26<00:16, 297.25 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42219/47780 [02:27<00:24, 228.21 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44280/47780 [02:27<00:12, 286.70 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44117/47780 [02:27<00:13, 262.92 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32495/47780 [02:27<00:39, 387.90 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43135/47780 [02:27<00:13, 338.84 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43520/47780 [02:27<00:18, 233.40 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42978/47780 [02:27<00:16, 297.72 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42244/47780 [02:27<00:18, 297.49 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42277/47780 [02:27<00:17, 311.50 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44310/47780 [02:27<00:12, 281.23 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32534/47780 [02:27<00:39, 382.60 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43172/47780 [02:27<00:13, 343.10 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44146/47780 [02:27<00:13, 262.93 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43551/47780 [02:27<00:17, 247.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43017/47780 [02:27<00:14, 319.39 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42312/47780 [02:27<00:18, 295.82 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42276/47780 [02:27<00:20, 273.29 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43590/47780 [02:27<00:14, 284.50 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44339/47780 [02:27<00:13, 257.37 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44173/47780 [02:27<00:14, 256.12 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43208/47780 [02:27<00:13, 329.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43050/47780 [02:27<00:15, 305.50 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42305/47780 [02:27<00:19, 274.15 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42345/47780 [02:27<00:18, 296.71 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43628/47780 [02:27<00:13, 310.02 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44373/47780 [02:27<00:12, 276.91 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44211/47780 [02:27<00:12, 280.78 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32574/47780 [02:27<00:53, 282.57 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43087/47780 [02:27<00:14, 319.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43242/47780 [02:27<00:15, 297.74 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42382/47780 [02:27<00:17, 309.50 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42335/47780 [02:27<00:19, 275.19 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43661/47780 [02:27<00:13, 312.18 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44405/47780 [02:27<00:11, 288.29 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44241/47780 [02:27<00:12, 273.89 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43274/47780 [02:27<00:14, 302.94 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43120/47780 [02:27<00:15, 309.25 examples/s]Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32607/47780 [02:27<01:00, 249.96 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42364/47780 [02:27<00:20, 270.35 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44435/47780 [02:27<00:11, 290.76 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42417/47780 [02:27<00:17, 304.26 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43695/47780 [02:27<00:13, 291.79 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43313/47780 [02:27<00:13, 319.49 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44269/47780 [02:27<00:13, 253.90 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42392/47780 [02:27<00:19, 272.67 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32767/47780 [02:27<00:28, 528.36 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43154/47780 [02:27<00:16, 278.72 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44465/47780 [02:27<00:12, 272.90 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42449/47780 [02:27<00:18, 287.00 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43748/47780 [02:27<00:11, 350.88 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44302/47780 [02:27<00:12, 270.93 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43346/47780 [02:27<00:14, 308.47 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42420/47780 [02:27<00:19, 272.09 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43204/47780 [02:27<00:13, 334.70 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44337/47780 [02:27<00:11, 289.26 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32832/47780 [02:27<00:30, 484.87 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43785/47780 [02:27<00:12, 327.22 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42479/47780 [02:27<00:20, 260.56 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43378/47780 [02:27<00:14, 305.08 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44493/47780 [02:27<00:14, 233.74 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42458/47780 [02:27<00:17, 302.39 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43255/47780 [02:27<00:11, 377.77 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44367/47780 [02:27<00:11, 288.90 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43821/47780 [02:27<00:11, 332.47 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42506/47780 [02:27<00:20, 252.77 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43409/47780 [02:27<00:14, 294.63 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44530/47780 [02:28<00:12, 262.60 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32889/47780 [02:27<00:31, 466.42 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42498/47780 [02:28<00:16, 319.56 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43302/47780 [02:27<00:11, 398.98 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44397/47780 [02:28<00:11, 282.54 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42532/47780 [02:28<00:20, 251.86 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43439/47780 [02:28<00:15, 285.78 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43855/47780 [02:28<00:12, 304.34 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44582/47780 [02:28<00:10, 316.27 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42534/47780 [02:28<00:16, 327.12 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43346/47780 [02:28<00:10, 410.45 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44427/47780 [02:28<00:11, 283.96 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32943/47780 [02:28<00:36, 402.44 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42558/47780 [02:28<00:21, 241.10 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42567/47780 [02:28<00:16, 320.73 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43468/47780 [02:28<00:15, 274.30 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44618/47780 [02:28<00:10, 314.42 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43887/47780 [02:28<00:13, 287.43 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43389/47780 [02:28<00:11, 392.85 examples/s]Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32989/47780 [02:28<00:35, 413.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44457/47780 [02:28<00:11, 282.35 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42586/47780 [02:28<00:20, 249.07 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42603/47780 [02:28<00:15, 331.93 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43506/47780 [02:28<00:14, 300.45 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43918/47780 [02:28<00:13, 287.63 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43430/47780 [02:28<00:11, 380.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44651/47780 [02:28<00:10, 285.36 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33037/47780 [02:28<00:34, 422.34 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42615/47780 [02:28<00:19, 258.82 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42638/47780 [02:28<00:15, 329.37 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44489/47780 [02:28<00:13, 253.04 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43948/47780 [02:28<00:13, 284.81 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43537/47780 [02:28<00:15, 281.23 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43469/47780 [02:28<00:11, 368.96 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44687/47780 [02:28<00:10, 298.17 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33082/47780 [02:28<00:34, 429.02 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42675/47780 [02:28<00:15, 337.24 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42642/47780 [02:28<00:20, 248.30 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44542/47780 [02:28<00:10, 321.81 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43566/47780 [02:28<00:15, 266.28 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43977/47780 [02:28<00:14, 268.70 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44724/47780 [02:28<00:09, 310.39 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33140/47780 [02:28<00:31, 459.18 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43509/47780 [02:28<00:14, 302.54 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44577/47780 [02:28<00:09, 322.40 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42668/47780 [02:28<00:22, 232.29 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44005/47780 [02:28<00:14, 265.94 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44760/47780 [02:28<00:09, 323.49 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43599/47780 [02:28<00:15, 266.27 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42709/47780 [02:28<00:18, 279.00 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33196/47780 [02:28<00:30, 480.80 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43545/47780 [02:28<00:13, 313.90 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42692/47780 [02:28<00:21, 233.86 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44039/47780 [02:28<00:13, 285.91 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44612/47780 [02:28<00:10, 306.14 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44793/47780 [02:28<00:09, 320.46 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43633/47780 [02:28<00:14, 283.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42745/47780 [02:28<00:17, 294.59 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33252/47780 [02:28<00:29, 491.83 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43583/47780 [02:28<00:12, 330.64 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42717/47780 [02:28<00:21, 236.70 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44069/47780 [02:28<00:13, 283.70 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44647/47780 [02:28<00:10, 311.13 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44828/47780 [02:28<00:09, 315.88 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33320/47780 [02:28<00:26, 537.77 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42780/47780 [02:28<00:16, 302.64 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43662/47780 [02:28<00:15, 266.93 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43619/47780 [02:28<00:12, 334.86 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44690/47780 [02:28<00:09, 341.56 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42741/47780 [02:28<00:22, 219.56 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44098/47780 [02:28<00:13, 270.86 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44862/47780 [02:29<00:09, 307.50 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33376/47780 [02:29<00:27, 526.59 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42812/47780 [02:29<00:17, 291.40 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43690/47780 [02:29<00:15, 257.03 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43656/47780 [02:29<00:11, 344.30 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44727/47780 [02:29<00:08, 343.18 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42769/47780 [02:29<00:21, 231.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44126/47780 [02:29<00:13, 264.03 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43716/47780 [02:29<00:16, 252.47 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42842/47780 [02:29<00:17, 278.95 examples/s]Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33431/47780 [02:29<00:29, 492.13 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43692/47780 [02:29<00:11, 348.56 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44893/47780 [02:29<00:10, 277.95 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42804/47780 [02:29<00:19, 260.84 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44766/47780 [02:29<00:08, 345.22 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44153/47780 [02:29<00:14, 254.63 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43755/47780 [02:29<00:13, 289.55 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44922/47780 [02:29<00:10, 270.92 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43728/47780 [02:29<00:12, 325.60 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42871/47780 [02:29<00:19, 254.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42842/47780 [02:29<00:16, 290.96 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44801/47780 [02:29<00:08, 338.79 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44193/47780 [02:29<00:12, 290.42 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43785/47780 [02:29<00:14, 282.81 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33482/47780 [02:29<00:37, 378.25 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44953/47780 [02:29<00:10, 281.22 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42911/47780 [02:29<00:16, 288.82 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43763/47780 [02:29<00:13, 305.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42872/47780 [02:29<00:17, 286.20 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44843/47780 [02:29<00:08, 357.86 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44232/47780 [02:29<00:11, 311.98 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43823/47780 [02:29<00:13, 303.24 examples/s]Tokenizing train dataset (num_proc=32):  70%|███████   | 33577/47780 [02:29<00:28, 505.64 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44985/47780 [02:29<00:09, 288.85 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42942/47780 [02:29<00:16, 291.69 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43795/47780 [02:29<00:13, 302.74 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44880/47780 [02:29<00:08, 348.89 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42901/47780 [02:29<00:18, 269.66 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44265/47780 [02:29<00:11, 313.15 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43858/47780 [02:29<00:12, 312.91 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45017/47780 [02:29<00:09, 287.70 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42975/47780 [02:29<00:15, 302.00 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33637/47780 [02:29<00:29, 476.83 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44921/47780 [02:29<00:07, 362.45 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43835/47780 [02:29<00:12, 319.18 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44297/47780 [02:29<00:11, 295.13 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42929/47780 [02:29<00:19, 247.63 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43890/47780 [02:29<00:12, 301.19 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45046/47780 [02:29<00:09, 276.22 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43009/47780 [02:29<00:15, 305.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33709/47780 [02:29<00:26, 530.74 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43869/47780 [02:29<00:12, 324.76 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44962/47780 [02:29<00:07, 367.66 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44327/47780 [02:29<00:12, 278.25 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43921/47780 [02:29<00:13, 291.72 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43040/47780 [02:29<00:15, 306.75 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45075/47780 [02:29<00:10, 268.06 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42955/47780 [02:29<00:21, 221.10 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43902/47780 [02:29<00:12, 318.93 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33768/47780 [02:29<00:27, 504.81 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45002/47780 [02:29<00:07, 364.13 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44359/47780 [02:29<00:12, 283.38 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43955/47780 [02:29<00:12, 301.83 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43079/47780 [02:29<00:14, 327.28 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42983/47780 [02:29<00:20, 233.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45102/47780 [02:29<00:10, 257.29 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33828/47780 [02:29<00:26, 528.61 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45042/47780 [02:29<00:07, 366.30 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43935/47780 [02:29<00:13, 292.77 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44388/47780 [02:30<00:12, 273.26 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43986/47780 [02:30<00:12, 293.14 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43112/47780 [02:30<00:14, 318.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43014/47780 [02:30<00:18, 253.30 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45133/47780 [02:30<00:09, 268.67 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43982/47780 [02:30<00:11, 339.91 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33884/47780 [02:30<00:29, 476.66 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45080/47780 [02:30<00:08, 329.13 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44417/47780 [02:30<00:12, 274.90 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44019/47780 [02:30<00:12, 301.46 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43043/47780 [02:30<00:17, 263.21 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45161/47780 [02:30<00:09, 268.92 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43145/47780 [02:30<00:15, 293.69 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44025/47780 [02:30<00:10, 356.96 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 33954/47780 [02:30<00:25, 532.60 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45114/47780 [02:30<00:08, 318.25 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43080/47780 [02:30<00:16, 292.92 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44050/47780 [02:30<00:12, 288.58 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44451/47780 [02:30<00:12, 271.94 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45190/47780 [02:30<00:09, 271.76 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43182/47780 [02:30<00:14, 314.20 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44062/47780 [02:30<00:10, 352.28 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████   | 34015/47780 [02:30<00:26, 525.07 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45147/47780 [02:30<00:08, 308.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44080/47780 [02:30<00:13, 283.16 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45218/47780 [02:30<00:09, 271.08 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43110/47780 [02:30<00:17, 264.39 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43214/47780 [02:30<00:15, 292.72 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44479/47780 [02:30<00:14, 225.51 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44098/47780 [02:30<00:11, 315.71 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34070/47780 [02:30<00:27, 490.08 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45179/47780 [02:30<00:08, 299.96 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44113/47780 [02:30<00:12, 292.97 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45249/47780 [02:30<00:09, 266.95 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43253/47780 [02:30<00:14, 312.36 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43138/47780 [02:30<00:18, 247.80 examples/s]Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34121/47780 [02:30<00:27, 495.01 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44503/47780 [02:30<00:15, 215.85 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44145/47780 [02:30<00:12, 297.11 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44133/47780 [02:30<00:11, 305.60 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45211/47780 [02:30<00:08, 291.64 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45276/47780 [02:30<00:09, 261.65 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43288/47780 [02:30<00:14, 319.45 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43164/47780 [02:30<00:18, 245.82 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44569/47780 [02:30<00:09, 324.46 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44186/47780 [02:30<00:11, 325.67 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34172/47780 [02:30<00:29, 464.76 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44167/47780 [02:30<00:11, 301.46 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45303/47780 [02:30<00:09, 261.34 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45242/47780 [02:30<00:09, 270.66 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43321/47780 [02:30<00:14, 310.64 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43190/47780 [02:30<00:18, 244.37 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44220/47780 [02:30<00:10, 327.93 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34224/47780 [02:30<00:28, 478.34 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44214/47780 [02:30<00:10, 342.93 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45332/47780 [02:30<00:09, 263.52 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44605/47780 [02:30<00:10, 297.58 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43377/47780 [02:30<00:11, 377.19 examples/s]Tokenizing train dataset (num_proc=32):  90%|█████████ | 43219/47780 [02:30<00:17, 253.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45270/47780 [02:30<00:10, 245.12 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44260/47780 [02:30<00:10, 342.84 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34275/47780 [02:30<00:27, 482.76 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44252/47780 [02:30<00:10, 349.32 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43248/47780 [02:30<00:17, 262.62 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43418/47780 [02:30<00:11, 369.80 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44639/47780 [02:30<00:11, 282.86 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45362/47780 [02:30<00:09, 243.38 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45296/47780 [02:30<00:10, 239.08 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34324/47780 [02:30<00:28, 473.47 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44295/47780 [02:31<00:11, 308.80 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43278/47780 [02:31<00:16, 268.59 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43457/47780 [02:31<00:11, 370.69 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44288/47780 [02:31<00:11, 307.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44670/47780 [02:31<00:11, 265.95 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45389/47780 [02:31<00:10, 226.55 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45371/47780 [02:31<00:06, 362.32 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34373/47780 [02:31<00:28, 477.89 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44330/47780 [02:31<00:10, 319.82 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43306/47780 [02:31<00:16, 265.83 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44328/47780 [02:31<00:10, 331.21 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43498/47780 [02:31<00:11, 369.79 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45419/47780 [02:31<00:09, 242.83 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44698/47780 [02:31<00:12, 256.61 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34422/47780 [02:31<00:28, 471.36 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45410/47780 [02:31<00:06, 344.26 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44363/47780 [02:31<00:11, 309.17 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44363/47780 [02:31<00:10, 329.52 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43333/47780 [02:31<00:17, 258.04 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45444/47780 [02:31<00:09, 239.52 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43536/47780 [02:31<00:13, 319.10 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34470/47780 [02:31<00:28, 468.01 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45455/47780 [02:31<00:06, 367.87 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44403/47780 [02:31<00:10, 327.06 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44725/47780 [02:31<00:13, 230.39 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43363/47780 [02:31<00:16, 267.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44397/47780 [02:31<00:10, 321.93 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45472/47780 [02:31<00:09, 247.86 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43584/47780 [02:31<00:11, 360.09 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34518/47780 [02:31<00:28, 471.37 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45508/47780 [02:31<00:05, 406.78 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44446/47780 [02:31<00:09, 349.39 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43394/47780 [02:31<00:15, 279.08 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44440/47780 [02:31<00:09, 337.98 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44749/47780 [02:31<00:14, 214.32 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45501/47780 [02:31<00:08, 256.63 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34566/47780 [02:31<00:28, 469.19 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43622/47780 [02:31<00:12, 339.93 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44482/47780 [02:31<00:09, 330.35 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45550/47780 [02:31<00:06, 355.96 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43423/47780 [02:31<00:16, 269.70 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44775/47780 [02:31<00:13, 225.14 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44475/47780 [02:31<00:10, 326.25 examples/s]Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34616/47780 [02:31<00:27, 472.47 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45527/47780 [02:31<00:09, 246.49 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43661/47780 [02:31<00:11, 346.95 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44520/47780 [02:31<00:09, 338.74 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43455/47780 [02:31<00:15, 280.78 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44803/47780 [02:31<00:12, 234.20 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44508/47780 [02:31<00:10, 316.60 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45554/47780 [02:31<00:08, 249.08 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34664/47780 [02:31<00:28, 457.97 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45588/47780 [02:31<00:07, 308.56 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43697/47780 [02:31<00:12, 328.19 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43486/47780 [02:31<00:14, 288.36 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44560/47780 [02:31<00:09, 348.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44831/47780 [02:31<00:12, 245.21 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34719/47780 [02:31<00:27, 479.70 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45580/47780 [02:31<00:08, 244.82 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44542/47780 [02:31<00:10, 297.01 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43732/47780 [02:31<00:12, 330.54 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45622/47780 [02:31<00:07, 288.34 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43517/47780 [02:31<00:14, 288.71 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44596/47780 [02:31<00:09, 332.79 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44584/47780 [02:31<00:09, 326.07 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34768/47780 [02:31<00:28, 460.98 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45605/47780 [02:31<00:09, 230.98 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44857/47780 [02:31<00:14, 207.51 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43548/47780 [02:31<00:14, 294.64 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43766/47780 [02:31<00:12, 311.28 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44630/47780 [02:32<00:10, 313.58 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45656/47780 [02:32<00:07, 265.92 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34817/47780 [02:32<00:28, 459.10 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45635/47780 [02:32<00:08, 247.25 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44618/47780 [02:32<00:10, 312.52 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44881/47780 [02:32<00:15, 190.84 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43578/47780 [02:32<00:15, 271.11 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44663/47780 [02:32<00:09, 317.58 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45687/47780 [02:32<00:07, 275.88 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43799/47780 [02:32<00:14, 276.32 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34867/47780 [02:32<00:27, 470.64 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44652/47780 [02:32<00:10, 310.20 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45661/47780 [02:32<00:09, 223.43 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44910/47780 [02:32<00:13, 210.66 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44696/47780 [02:32<00:10, 292.71 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34918/47780 [02:32<00:27, 471.05 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44685/47780 [02:32<00:09, 315.51 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45718/47780 [02:32<00:08, 252.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45698/47780 [02:32<00:07, 261.63 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43607/47780 [02:32<00:19, 212.77 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44935/47780 [02:32<00:13, 216.04 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43829/47780 [02:32<00:17, 229.53 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44727/47780 [02:32<00:10, 297.26 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34966/47780 [02:32<00:28, 452.54 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45747/47780 [02:32<00:07, 258.66 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45729/47780 [02:32<00:07, 274.75 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44717/47780 [02:32<00:10, 284.57 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43659/47780 [02:32<00:14, 284.21 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44959/47780 [02:32<00:12, 222.04 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43898/47780 [02:32<00:11, 333.00 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44764/47780 [02:32<00:09, 307.06 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35012/47780 [02:32<00:29, 439.62 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45775/47780 [02:32<00:07, 253.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45761/47780 [02:32<00:07, 281.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44748/47780 [02:32<00:10, 282.11 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43938/47780 [02:32<00:11, 349.27 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44982/47780 [02:32<00:13, 205.04 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43691/47780 [02:32<00:15, 259.63 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44798/47780 [02:32<00:09, 307.94 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35057/47780 [02:32<00:30, 419.67 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45801/47780 [02:32<00:07, 250.35 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45790/47780 [02:32<00:07, 277.16 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43977/47780 [02:32<00:10, 359.69 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44778/47780 [02:32<00:11, 270.25 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45008/47780 [02:32<00:12, 218.50 examples/s]Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35110/47780 [02:32<00:28, 445.11 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45819/47780 [02:32<00:07, 278.06 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43720/47780 [02:32<00:16, 241.47 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45831/47780 [02:32<00:07, 257.96 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44829/47780 [02:32<00:10, 273.58 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45051/47780 [02:32<00:09, 273.27 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44017/47780 [02:32<00:10, 344.32 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44806/47780 [02:32<00:12, 246.71 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45859/47780 [02:32<00:07, 258.38 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43747/47780 [02:32<00:16, 238.65 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35155/47780 [02:32<00:31, 405.43 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45848/47780 [02:32<00:07, 257.93 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45088/47780 [02:32<00:09, 290.21 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44055/47780 [02:32<00:11, 336.31 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44861/47780 [02:32<00:11, 244.81 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44868/47780 [02:32<00:08, 331.45 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45886/47780 [02:32<00:07, 255.94 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35199/47780 [02:32<00:30, 406.23 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43773/47780 [02:32<00:17, 233.01 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45886/47780 [02:32<00:06, 272.13 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44896/47780 [02:33<00:10, 267.67 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45118/47780 [02:32<00:09, 280.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44091/47780 [02:33<00:11, 331.72 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45912/47780 [02:33<00:07, 244.79 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44903/47780 [02:33<00:09, 293.60 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43803/47780 [02:33<00:16, 244.91 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35250/47780 [02:33<00:29, 419.07 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44925/47780 [02:33<00:10, 273.33 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45915/47780 [02:33<00:07, 261.20 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44126/47780 [02:33<00:11, 311.01 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45148/47780 [02:33<00:10, 257.48 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44946/47780 [02:33<00:08, 320.60 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45937/47780 [02:33<00:07, 237.85 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43829/47780 [02:33<00:16, 246.57 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35296/47780 [02:33<00:29, 427.23 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45950/47780 [02:33<00:06, 281.88 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44957/47780 [02:33<00:10, 268.51 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44162/47780 [02:33<00:11, 319.76 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45183/47780 [02:33<00:09, 270.33 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44980/47780 [02:33<00:08, 312.48 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45966/47780 [02:33<00:07, 242.49 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35342/47780 [02:33<00:30, 412.95 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43855/47780 [02:33<00:16, 232.36 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45982/47780 [02:33<00:06, 290.32 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44988/47780 [02:33<00:10, 274.51 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44195/47780 [02:33<00:11, 309.36 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45213/47780 [02:33<00:09, 261.89 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45013/47780 [02:33<00:08, 311.03 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 45991/47780 [02:33<00:07, 240.31 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35387/47780 [02:33<00:30, 409.92 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43879/47780 [02:33<00:17, 222.17 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45026/47780 [02:33<00:09, 298.81 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44232/47780 [02:33<00:11, 322.04 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46012/47780 [02:33<00:07, 247.79 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45244/47780 [02:33<00:09, 271.33 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45046/47780 [02:33<00:08, 306.15 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46016/47780 [02:33<00:07, 229.06 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35431/47780 [02:33<00:30, 409.26 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43902/47780 [02:33<00:17, 222.42 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45059/47780 [02:33<00:09, 300.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44272/47780 [02:33<00:10, 343.38 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46043/47780 [02:33<00:06, 263.28 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45273/47780 [02:33<00:09, 262.34 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35474/47780 [02:33<00:29, 415.00 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45078/47780 [02:33<00:09, 299.25 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43933/47780 [02:33<00:15, 243.59 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45092/47780 [02:33<00:08, 305.65 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46039/47780 [02:33<00:08, 205.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44310/47780 [02:33<00:09, 350.56 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46072/47780 [02:33<00:06, 256.83 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45305/47780 [02:33<00:09, 271.99 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35527/47780 [02:33<00:28, 432.86 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45113/47780 [02:33<00:08, 300.98 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43959/47780 [02:33<00:15, 245.12 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45124/47780 [02:33<00:08, 306.59 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44346/47780 [02:33<00:09, 352.34 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46061/47780 [02:33<00:08, 201.59 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45333/47780 [02:33<00:08, 274.14 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46099/47780 [02:33<00:06, 242.77 examples/s]Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35584/47780 [02:33<00:26, 466.33 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43992/47780 [02:33<00:14, 268.58 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45144/47780 [02:33<00:09, 279.26 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45155/47780 [02:33<00:09, 290.63 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44382/47780 [02:33<00:09, 346.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46084/47780 [02:33<00:08, 204.23 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45361/47780 [02:33<00:09, 261.18 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46124/47780 [02:33<00:06, 236.77 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35631/47780 [02:33<00:26, 455.85 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44021/47780 [02:33<00:14, 263.20 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45187/47780 [02:33<00:08, 295.45 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44417/47780 [02:33<00:09, 340.15 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46107/47780 [02:33<00:08, 205.02 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45173/47780 [02:33<00:09, 261.05 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45388/47780 [02:34<00:09, 260.75 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46150/47780 [02:34<00:06, 239.35 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44050/47780 [02:34<00:14, 264.87 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45220/47780 [02:34<00:08, 304.66 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44452/47780 [02:34<00:09, 340.87 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35678/47780 [02:34<00:30, 395.75 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45200/47780 [02:34<00:09, 259.49 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46128/47780 [02:34<00:08, 200.69 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44084/47780 [02:34<00:13, 282.98 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45415/47780 [02:34<00:09, 246.74 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46176/47780 [02:34<00:06, 229.74 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45253/47780 [02:34<00:08, 309.04 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44490/47780 [02:34<00:09, 351.72 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35748/47780 [02:34<00:25, 473.17 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46151/47780 [02:34<00:07, 207.38 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45227/47780 [02:34<00:10, 246.71 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46205/47780 [02:34<00:06, 242.84 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45440/47780 [02:34<00:09, 239.54 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44113/47780 [02:34<00:13, 266.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44529/47780 [02:34<00:09, 358.88 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45285/47780 [02:34<00:08, 301.63 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35803/47780 [02:34<00:24, 492.45 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46172/47780 [02:34<00:08, 199.15 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45252/47780 [02:34<00:10, 240.15 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46231/47780 [02:34<00:06, 237.26 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44142/47780 [02:34<00:13, 264.49 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44565/47780 [02:34<00:09, 349.08 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45465/47780 [02:34<00:10, 227.50 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45316/47780 [02:34<00:08, 293.16 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45283/47780 [02:34<00:09, 255.87 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35854/47780 [02:34<00:27, 430.68 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46255/47780 [02:34<00:06, 234.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46193/47780 [02:34<00:09, 168.51 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44173/47780 [02:34<00:13, 270.50 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45494/47780 [02:34<00:09, 242.23 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44600/47780 [02:34<00:09, 336.39 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45347/47780 [02:34<00:08, 289.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45311/47780 [02:34<00:09, 259.63 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46279/47780 [02:34<00:06, 228.94 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46220/47780 [02:34<00:08, 190.00 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44201/47780 [02:34<00:13, 267.64 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35900/47780 [02:34<00:31, 381.57 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44636/47780 [02:34<00:09, 333.28 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45377/47780 [02:34<00:08, 282.20 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45338/47780 [02:34<00:09, 259.21 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45519/47780 [02:34<00:10, 205.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46240/47780 [02:34<00:08, 192.49 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46305/47780 [02:34<00:06, 234.40 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36004/47780 [02:34<00:22, 532.59 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44678/47780 [02:34<00:08, 346.17 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45406/47780 [02:34<00:08, 281.01 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44228/47780 [02:34<00:14, 251.06 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45365/47780 [02:34<00:09, 245.72 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46269/47780 [02:34<00:06, 216.55 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45542/47780 [02:34<00:11, 192.56 examples/s]Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36065/47780 [02:34<00:21, 546.53 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45436/47780 [02:34<00:08, 274.30 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44254/47780 [02:34<00:14, 245.36 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46330/47780 [02:34<00:06, 212.58 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44714/47780 [02:34<00:09, 320.65 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45390/47780 [02:34<00:10, 236.90 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45580/47780 [02:34<00:09, 238.25 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46292/47780 [02:34<00:06, 213.17 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44282/47780 [02:34<00:13, 252.53 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45465/47780 [02:34<00:08, 275.37 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36124/47780 [02:34<00:22, 514.81 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46360/47780 [02:34<00:06, 227.44 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44769/47780 [02:34<00:07, 378.85 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45420/47780 [02:34<00:09, 253.10 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45606/47780 [02:35<00:09, 240.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46319/47780 [02:35<00:06, 224.56 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45499/47780 [02:35<00:07, 286.78 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44309/47780 [02:35<00:13, 249.70 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36179/47780 [02:35<00:22, 507.95 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44813/47780 [02:35<00:07, 388.90 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46385/47780 [02:35<00:06, 219.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45449/47780 [02:35<00:08, 261.52 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45632/47780 [02:35<00:09, 238.65 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46343/47780 [02:35<00:06, 207.46 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45528/47780 [02:35<00:08, 281.06 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36234/47780 [02:35<00:22, 513.72 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44337/47780 [02:35<00:13, 249.28 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44857/47780 [02:35<00:07, 397.10 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46408/47780 [02:35<00:06, 217.38 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45476/47780 [02:35<00:09, 250.45 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45662/47780 [02:35<00:08, 250.29 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46371/47780 [02:35<00:06, 219.79 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36296/47780 [02:35<00:21, 542.23 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45558/47780 [02:35<00:07, 284.07 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44363/47780 [02:35<00:13, 247.96 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44900/47780 [02:35<00:07, 388.87 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46431/47780 [02:35<00:06, 213.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45502/47780 [02:35<00:09, 243.79 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45689/47780 [02:35<00:08, 244.76 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45587/47780 [02:35<00:07, 285.76 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36353/47780 [02:35<00:21, 532.35 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46394/47780 [02:35<00:06, 204.86 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44388/47780 [02:35<00:15, 224.39 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44940/47780 [02:35<00:07, 363.16 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46455/47780 [02:35<00:06, 206.64 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45527/47780 [02:35<00:09, 230.59 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45714/47780 [02:35<00:08, 243.44 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45626/47780 [02:35<00:07, 305.73 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36409/47780 [02:35<00:21, 527.45 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46415/47780 [02:35<00:06, 197.91 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44413/47780 [02:35<00:14, 229.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46476/47780 [02:35<00:06, 205.28 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44977/47780 [02:35<00:08, 326.74 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45551/47780 [02:35<00:10, 214.35 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45657/47780 [02:35<00:06, 306.74 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36465/47780 [02:35<00:21, 525.92 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45739/47780 [02:35<00:09, 214.44 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46504/47780 [02:35<00:05, 225.68 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44437/47780 [02:35<00:15, 222.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46436/47780 [02:35<00:07, 190.97 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45037/47780 [02:35<00:06, 394.83 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45579/47780 [02:35<00:09, 229.45 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45689/47780 [02:35<00:06, 310.12 examples/s]Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36523/47780 [02:35<00:21, 535.12 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45763/47780 [02:35<00:09, 220.84 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44460/47780 [02:35<00:14, 223.06 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46456/47780 [02:35<00:07, 189.00 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45079/47780 [02:35<00:06, 398.83 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46527/47780 [02:35<00:06, 202.45 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45725/47780 [02:35<00:06, 322.71 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45604/47780 [02:35<00:09, 234.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36594/47780 [02:35<00:19, 584.62 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45786/47780 [02:35<00:09, 199.82 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44485/47780 [02:35<00:14, 222.01 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46476/47780 [02:35<00:07, 184.59 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46550/47780 [02:35<00:05, 209.15 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36653/47780 [02:35<00:19, 584.95 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45628/47780 [02:35<00:09, 215.85 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45121/47780 [02:35<00:07, 355.27 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45758/47780 [02:35<00:07, 280.96 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44517/47780 [02:35<00:13, 247.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45810/47780 [02:35<00:09, 204.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46495/47780 [02:35<00:06, 184.36 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46573/47780 [02:36<00:05, 210.25 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36712/47780 [02:35<00:19, 573.10 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45174/47780 [02:36<00:06, 391.02 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45651/47780 [02:36<00:10, 209.83 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45790/47780 [02:36<00:06, 285.27 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44543/47780 [02:36<00:13, 244.58 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45831/47780 [02:36<00:10, 193.08 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46596/47780 [02:36<00:05, 215.68 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46516/47780 [02:36<00:07, 176.31 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36770/47780 [02:36<00:19, 556.22 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45215/47780 [02:36<00:06, 393.62 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45823/47780 [02:36<00:06, 297.34 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45673/47780 [02:36<00:10, 204.16 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44571/47780 [02:36<00:12, 254.47 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45852/47780 [02:36<00:09, 197.38 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46618/47780 [02:36<00:05, 214.50 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36834/47780 [02:36<00:19, 567.66 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45258/47780 [02:36<00:06, 391.33 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46534/47780 [02:36<00:07, 158.05 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45854/47780 [02:36<00:06, 290.71 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44597/47780 [02:36<00:12, 255.93 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45694/47780 [02:36<00:11, 188.97 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46645/47780 [02:36<00:05, 225.32 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45873/47780 [02:36<00:10, 184.92 examples/s]Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36891/47780 [02:36<00:20, 520.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45886/47780 [02:36<00:06, 286.07 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45298/47780 [02:36<00:06, 364.29 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45714/47780 [02:36<00:10, 190.06 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44623/47780 [02:36<00:13, 237.85 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46551/47780 [02:36<00:08, 142.26 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45898/47780 [02:36<00:09, 197.86 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46668/47780 [02:36<00:05, 197.30 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36945/47780 [02:36<00:20, 525.74 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45734/47780 [02:36<00:10, 186.74 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45915/47780 [02:36<00:06, 269.76 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44650/47780 [02:36<00:12, 241.49 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45336/47780 [02:36<00:07, 338.90 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45929/47780 [02:36<00:08, 227.85 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46567/47780 [02:36<00:09, 132.45 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 37001/47780 [02:36<00:20, 527.96 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46689/47780 [02:36<00:06, 181.69 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45758/47780 [02:36<00:10, 200.96 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45948/47780 [02:36<00:06, 284.02 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44676/47780 [02:36<00:12, 243.44 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45371/47780 [02:36<00:07, 339.13 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45953/47780 [02:36<00:08, 221.23 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46581/47780 [02:36<00:09, 128.19 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46708/47780 [02:36<00:05, 183.38 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44701/47780 [02:36<00:12, 244.19 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45977/47780 [02:36<00:06, 278.41 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45781/47780 [02:36<00:09, 202.18 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45407/47780 [02:36<00:06, 343.39 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37058/47780 [02:36<00:23, 452.71 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45981/47780 [02:36<00:07, 227.70 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46595/47780 [02:36<00:09, 130.92 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44726/47780 [02:36<00:12, 244.39 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45804/47780 [02:36<00:09, 207.14 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46006/47780 [02:36<00:06, 268.80 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45442/47780 [02:36<00:07, 327.59 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46728/47780 [02:36<00:06, 170.07 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37175/47780 [02:36<00:16, 630.16 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46009/47780 [02:36<00:07, 236.88 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46610/47780 [02:36<00:08, 132.27 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44757/47780 [02:36<00:11, 257.57 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45826/47780 [02:36<00:09, 206.97 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45489/47780 [02:36<00:06, 360.32 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46746/47780 [02:36<00:06, 170.09 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46034/47780 [02:36<00:06, 250.64 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37244/47780 [02:36<00:17, 607.50 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46625/47780 [02:36<00:08, 131.62 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46039/47780 [02:36<00:07, 238.28 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44786/47780 [02:37<00:11, 265.16 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45848/47780 [02:37<00:09, 201.53 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45527/47780 [02:37<00:06, 359.97 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46765/47780 [02:37<00:05, 169.52 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46070/47780 [02:37<00:06, 274.33 examples/s]Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37311/47780 [02:37<00:17, 604.86 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46063/47780 [02:37<00:07, 238.23 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44815/47780 [02:37<00:11, 268.17 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46639/47780 [02:37<00:09, 119.32 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45871/47780 [02:37<00:09, 202.52 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46791/47780 [02:37<00:05, 193.70 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45565/47780 [02:37<00:06, 351.24 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46105/47780 [02:37<00:06, 276.26 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37374/47780 [02:37<00:17, 581.87 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46087/47780 [02:37<00:07, 218.15 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44843/47780 [02:37<00:11, 266.64 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46652/47780 [02:37<00:09, 117.19 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45895/47780 [02:37<00:08, 211.33 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45602/47780 [02:37<00:06, 353.53 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46811/47780 [02:37<00:05, 185.34 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46133/47780 [02:37<00:05, 275.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37435/47780 [02:37<00:18, 571.92 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44870/47780 [02:37<00:11, 255.55 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46666/47780 [02:37<00:09, 118.22 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45917/47780 [02:37<00:08, 207.81 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46111/47780 [02:37<00:08, 202.04 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45639/47780 [02:37<00:06, 344.13 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46835/47780 [02:37<00:04, 194.05 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46161/47780 [02:37<00:05, 272.15 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37496/47780 [02:37<00:17, 580.01 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44897/47780 [02:37<00:11, 258.39 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45938/47780 [02:37<00:08, 206.10 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46136/47780 [02:37<00:07, 212.44 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46678/47780 [02:37<00:09, 114.92 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45675/47780 [02:37<00:06, 344.97 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46859/47780 [02:37<00:04, 203.27 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37566/47780 [02:37<00:16, 608.78 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46192/47780 [02:37<00:05, 269.52 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44927/47780 [02:37<00:10, 268.40 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46160/47780 [02:37<00:07, 215.46 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46690/47780 [02:37<00:09, 115.22 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45717/47780 [02:37<00:05, 364.50 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45966/47780 [02:37<00:08, 216.19 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37647/47780 [02:37<00:15, 663.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46223/47780 [02:37<00:05, 278.12 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46881/47780 [02:37<00:04, 185.80 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44957/47780 [02:37<00:10, 274.91 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45756/47780 [02:37<00:05, 369.27 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 45990/47780 [02:37<00:08, 221.19 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46183/47780 [02:37<00:07, 206.99 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46702/47780 [02:37<00:09, 108.50 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37715/47780 [02:37<00:15, 664.34 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46251/47780 [02:37<00:05, 266.56 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44985/47780 [02:37<00:10, 264.26 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45794/47780 [02:37<00:05, 358.51 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46014/47780 [02:37<00:08, 219.07 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46204/47780 [02:37<00:07, 206.57 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46718/47780 [02:37<00:08, 121.21 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46902/47780 [02:37<00:05, 159.38 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37784/47780 [02:37<00:15, 646.16 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46279/47780 [02:37<00:06, 248.83 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45015/47780 [02:37<00:10, 272.43 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45833/47780 [02:37<00:05, 360.22 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46037/47780 [02:37<00:07, 218.02 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46734/47780 [02:37<00:08, 130.36 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37852/47780 [02:37<00:15, 643.70 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46920/47780 [02:37<00:05, 153.81 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46227/47780 [02:37<00:08, 186.80 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45870/47780 [02:38<00:05, 359.47 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46066/47780 [02:37<00:07, 237.86 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46305/47780 [02:38<00:06, 226.85 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45043/47780 [02:38<00:11, 246.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46753/47780 [02:38<00:07, 143.97 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46247/47780 [02:38<00:08, 188.92 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37917/47780 [02:38<00:16, 582.09 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46938/47780 [02:38<00:05, 146.35 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46333/47780 [02:38<00:06, 239.43 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46092/47780 [02:38<00:07, 237.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45075/47780 [02:38<00:10, 259.18 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45909/47780 [02:38<00:05, 322.25 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46270/47780 [02:38<00:07, 199.31 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46768/47780 [02:38<00:07, 129.64 examples/s]Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37983/47780 [02:38<00:16, 601.44 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46127/47780 [02:38<00:06, 269.57 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46358/47780 [02:38<00:06, 235.74 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46956/47780 [02:38<00:05, 140.31 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45111/47780 [02:38<00:09, 277.28 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46784/47780 [02:38<00:07, 137.35 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46292/47780 [02:38<00:07, 198.59 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45943/47780 [02:38<00:05, 310.98 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38046/47780 [02:38<00:17, 570.70 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46156/47780 [02:38<00:06, 260.26 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46382/47780 [02:38<00:06, 222.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45141/47780 [02:38<00:09, 277.27 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46313/47780 [02:38<00:07, 195.30 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46807/47780 [02:38<00:06, 155.53 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46972/47780 [02:38<00:06, 126.91 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45975/47780 [02:38<00:05, 306.23 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38106/47780 [02:38<00:17, 547.45 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46405/47780 [02:38<00:06, 224.34 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46183/47780 [02:38<00:06, 255.26 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45170/47780 [02:38<00:09, 268.60 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46007/47780 [02:38<00:05, 304.18 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46334/47780 [02:38<00:07, 181.34 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46824/47780 [02:38<00:06, 144.03 examples/s]Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38163/47780 [02:38<00:17, 552.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46986/47780 [02:38<00:06, 116.49 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45201/47780 [02:38<00:09, 274.15 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46429/47780 [02:38<00:06, 213.92 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46209/47780 [02:38<00:06, 234.00 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46038/47780 [02:38<00:06, 289.70 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46353/47780 [02:38<00:07, 181.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38219/47780 [02:38<00:19, 502.51 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46999/47780 [02:38<00:06, 111.88 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46457/47780 [02:38<00:05, 229.97 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45230/47780 [02:38<00:09, 273.84 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46840/47780 [02:38<00:07, 128.46 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46233/47780 [02:38<00:06, 222.51 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46068/47780 [02:38<00:06, 273.78 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46372/47780 [02:38<00:08, 166.36 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45263/47780 [02:38<00:08, 288.67 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46483/47780 [02:38<00:05, 234.20 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38271/47780 [02:38<00:19, 477.86 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46257/47780 [02:38<00:06, 224.95 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47011/47780 [02:38<00:07, 100.62 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46854/47780 [02:38<00:07, 116.86 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46096/47780 [02:38<00:06, 267.27 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46390/47780 [02:38<00:08, 169.36 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45293/47780 [02:38<00:08, 288.02 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38320/47780 [02:38<00:20, 460.30 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46507/47780 [02:38<00:05, 222.28 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46280/47780 [02:38<00:06, 222.81 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46128/47780 [02:38<00:05, 279.76 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46411/47780 [02:38<00:07, 178.59 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46868/47780 [02:38<00:08, 113.02 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47022/47780 [02:38<00:08, 92.02 examples/s] Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45323/47780 [02:38<00:08, 291.31 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38376/47780 [02:38<00:19, 476.00 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46539/47780 [02:39<00:05, 240.86 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46304/47780 [02:39<00:06, 214.12 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46157/47780 [02:39<00:05, 279.90 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46433/47780 [02:39<00:07, 187.29 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47032/47780 [02:39<00:07, 93.64 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46880/47780 [02:39<00:08, 106.05 examples/s]Tokenizing train dataset (num_proc=32):  80%|████████  | 38432/47780 [02:39<00:18, 496.38 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45354/47780 [02:39<00:08, 277.26 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46564/47780 [02:39<00:05, 226.29 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46337/47780 [02:39<00:05, 244.82 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46186/47780 [02:39<00:05, 277.26 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46452/47780 [02:39<00:07, 187.33 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47043/47780 [02:39<00:07, 96.68 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46892/47780 [02:39<00:08, 107.34 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38484/47780 [02:39<00:18, 502.32 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45385/47780 [02:39<00:08, 282.57 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46587/47780 [02:39<00:05, 218.19 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46362/47780 [02:39<00:06, 228.74 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46214/47780 [02:39<00:05, 274.11 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46482/47780 [02:39<00:05, 216.82 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47053/47780 [02:39<00:07, 91.02 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38544/47780 [02:39<00:17, 525.02 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45417/47780 [02:39<00:08, 286.72 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46903/47780 [02:39<00:09, 93.61 examples/s] Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46609/47780 [02:39<00:05, 208.83 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46387/47780 [02:39<00:05, 232.26 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46242/47780 [02:39<00:06, 254.97 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46504/47780 [02:39<00:06, 193.22 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38597/47780 [02:39<00:17, 512.68 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47064/47780 [02:39<00:08, 89.19 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45446/47780 [02:39<00:08, 268.28 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46913/47780 [02:39<00:09, 94.10 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46416/47780 [02:39<00:05, 246.04 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46630/47780 [02:39<00:05, 200.11 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38652/47780 [02:39<00:17, 517.52 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46269/47780 [02:39<00:06, 239.19 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46525/47780 [02:39<00:06, 188.68 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45477/47780 [02:39<00:08, 277.81 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47075/47780 [02:39<00:07, 88.81 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46927/47780 [02:39<00:08, 103.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46449/47780 [02:39<00:05, 259.61 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46652/47780 [02:39<00:05, 197.09 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38712/47780 [02:39<00:17, 531.93 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46294/47780 [02:39<00:06, 234.65 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46548/47780 [02:39<00:06, 183.26 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47097/47780 [02:39<00:05, 116.17 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45507/47780 [02:39<00:08, 259.84 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46476/47780 [02:39<00:05, 245.44 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46941/47780 [02:39<00:08, 101.76 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46672/47780 [02:39<00:06, 183.95 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46321/47780 [02:39<00:05, 243.81 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████  | 38772/47780 [02:39<00:16, 543.59 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46568/47780 [02:39<00:06, 187.18 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45535/47780 [02:39<00:08, 265.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47109/47780 [02:39<00:05, 115.64 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46502/47780 [02:39<00:05, 246.15 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46952/47780 [02:39<00:08, 102.39 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46693/47780 [02:39<00:05, 189.35 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38829/47780 [02:39<00:17, 526.40 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46347/47780 [02:39<00:06, 238.44 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46588/47780 [02:39<00:06, 186.44 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45577/47780 [02:39<00:07, 307.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47121/47780 [02:39<00:05, 113.57 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46527/47780 [02:39<00:05, 246.13 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46964/47780 [02:39<00:08, 101.05 examples/s]Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38889/47780 [02:39<00:16, 543.16 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46715/47780 [02:39<00:05, 187.86 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46372/47780 [02:39<00:05, 237.74 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45613/47780 [02:39<00:06, 322.02 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46607/47780 [02:39<00:06, 183.21 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46561/47780 [02:40<00:04, 271.17 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47134/47780 [02:40<00:06, 102.73 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 38957/47780 [02:40<00:15, 581.61 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46978/47780 [02:40<00:07, 110.27 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46396/47780 [02:40<00:05, 234.84 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46734/47780 [02:40<00:05, 182.66 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45647/47780 [02:40<00:06, 308.36 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46626/47780 [02:40<00:06, 167.39 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46589/47780 [02:40<00:04, 256.03 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39017/47780 [02:40<00:15, 577.21 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46991/47780 [02:40<00:06, 112.73 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46425/47780 [02:40<00:05, 248.80 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47148/47780 [02:40<00:05, 106.41 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46754/47780 [02:40<00:05, 179.72 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45680/47780 [02:40<00:06, 312.80 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46647/47780 [02:40<00:06, 178.49 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46615/47780 [02:40<00:04, 244.36 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39077/47780 [02:40<00:15, 577.63 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47162/47780 [02:40<00:05, 114.20 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46452/47780 [02:40<00:05, 247.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46773/47780 [02:40<00:05, 177.67 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47004/47780 [02:40<00:07, 103.29 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45713/47780 [02:40<00:07, 294.57 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46673/47780 [02:40<00:05, 190.35 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46643/47780 [02:40<00:04, 253.32 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39136/47780 [02:40<00:15, 566.70 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46486/47780 [02:40<00:04, 272.06 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46798/47780 [02:40<00:05, 192.14 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47174/47780 [02:40<00:05, 103.19 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47018/47780 [02:40<00:07, 106.61 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45743/47780 [02:40<00:07, 286.16 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46693/47780 [02:40<00:05, 188.54 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46674/47780 [02:40<00:04, 265.23 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39199/47780 [02:40<00:15, 564.98 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46515/47780 [02:40<00:04, 266.51 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46819/47780 [02:40<00:04, 196.78 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47034/47780 [02:40<00:06, 116.95 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47185/47780 [02:40<00:06, 95.87 examples/s] Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45780/47780 [02:40<00:06, 299.62 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46712/47780 [02:40<00:05, 184.20 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46704/47780 [02:40<00:03, 271.76 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39263/47780 [02:40<00:14, 577.34 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46542/47780 [02:40<00:04, 264.33 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46839/47780 [02:40<00:04, 193.82 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47047/47780 [02:40<00:06, 115.35 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47197/47780 [02:40<00:05, 97.27 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46732/47780 [02:40<00:03, 270.10 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46731/47780 [02:40<00:06, 174.41 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45812/47780 [02:40<00:07, 276.77 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46570/47780 [02:40<00:04, 253.48 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46860/47780 [02:40<00:04, 191.54 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39322/47780 [02:40<00:16, 524.72 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46760/47780 [02:40<00:03, 265.95 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47060/47780 [02:40<00:06, 108.05 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46751/47780 [02:40<00:05, 171.66 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45841/47780 [02:40<00:07, 265.55 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47212/47780 [02:40<00:05, 98.45 examples/s]Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39387/47780 [02:40<00:15, 553.64 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46605/47780 [02:40<00:04, 268.52 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46881/47780 [02:40<00:04, 184.91 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46787/47780 [02:40<00:04, 247.97 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46772/47780 [02:40<00:05, 173.98 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47072/47780 [02:40<00:06, 104.31 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45869/47780 [02:40<00:07, 255.64 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39444/47780 [02:40<00:15, 545.56 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47226/47780 [02:40<00:05, 103.85 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46902/47780 [02:40<00:04, 191.05 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46633/47780 [02:40<00:04, 256.94 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46823/47780 [02:41<00:03, 278.51 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46796/47780 [02:41<00:05, 189.75 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47088/47780 [02:41<00:05, 118.23 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45895/47780 [02:41<00:07, 255.24 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39504/47780 [02:41<00:14, 558.13 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47244/47780 [02:41<00:04, 121.72 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46662/47780 [02:41<00:04, 265.87 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46923/47780 [02:41<00:04, 184.37 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46853/47780 [02:41<00:03, 274.64 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39564/47780 [02:41<00:14, 567.88 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45928/47780 [02:41<00:06, 267.94 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47106/47780 [02:41<00:05, 127.68 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46816/47780 [02:41<00:05, 172.93 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47258/47780 [02:41<00:04, 117.86 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46942/47780 [02:41<00:04, 182.81 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46690/47780 [02:41<00:04, 236.66 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46884/47780 [02:41<00:03, 276.29 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39627/47780 [02:41<00:13, 583.20 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47119/47780 [02:41<00:05, 125.99 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45955/47780 [02:41<00:07, 251.93 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46834/47780 [02:41<00:05, 168.46 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46961/47780 [02:41<00:04, 176.94 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47271/47780 [02:41<00:04, 110.83 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46716/47780 [02:41<00:04, 229.83 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39688/47780 [02:41<00:13, 581.07 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46912/47780 [02:41<00:03, 268.36 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45981/47780 [02:41<00:07, 244.69 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46979/47780 [02:41<00:04, 177.32 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47133/47780 [02:41<00:05, 115.16 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46853/47780 [02:41<00:05, 158.46 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46742/47780 [02:41<00:04, 233.76 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47284/47780 [02:41<00:04, 107.18 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39747/47780 [02:41<00:14, 565.34 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46940/47780 [02:41<00:03, 244.86 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46008/47780 [02:41<00:07, 242.62 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47146/47780 [02:41<00:05, 113.04 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46769/47780 [02:41<00:04, 241.85 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46870/47780 [02:41<00:05, 156.34 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46997/47780 [02:41<00:05, 156.54 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47295/47780 [02:41<00:04, 103.64 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39811/47780 [02:41<00:13, 577.44 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46037/47780 [02:41<00:07, 247.39 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46965/47780 [02:41<00:03, 231.34 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46888/47780 [02:41<00:05, 160.39 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47159/47780 [02:41<00:05, 112.23 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47016/47780 [02:41<00:04, 161.75 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47309/47780 [02:41<00:04, 111.66 examples/s]Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39869/47780 [02:41<00:13, 573.40 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46795/47780 [02:41<00:04, 211.90 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46063/47780 [02:41<00:07, 239.00 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46989/47780 [02:41<00:03, 218.11 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39935/47780 [02:41<00:13, 595.45 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47322/47780 [02:41<00:04, 113.65 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47172/47780 [02:41<00:05, 108.06 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47033/47780 [02:41<00:05, 148.81 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46906/47780 [02:41<00:06, 142.44 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46818/47780 [02:41<00:04, 199.92 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47012/47780 [02:41<00:03, 205.92 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39996/47780 [02:41<00:13, 596.22 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46087/47780 [02:41<00:07, 211.82 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47334/47780 [02:41<00:04, 109.87 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47184/47780 [02:41<00:05, 106.20 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46922/47780 [02:41<00:06, 142.27 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47049/47780 [02:41<00:05, 141.75 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46839/47780 [02:41<00:04, 197.58 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47033/47780 [02:41<00:03, 206.26 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40062/47780 [02:41<00:12, 607.73 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46109/47780 [02:41<00:08, 206.99 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47347/47780 [02:42<00:03, 114.80 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47200/47780 [02:42<00:05, 112.97 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47064/47780 [02:42<00:05, 139.76 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46937/47780 [02:42<00:06, 132.36 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47056/47780 [02:42<00:03, 207.68 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40124/47780 [02:42<00:12, 597.84 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46860/47780 [02:42<00:05, 177.51 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46131/47780 [02:42<00:08, 199.48 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47215/47780 [02:42<00:04, 119.36 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47360/47780 [02:42<00:03, 106.06 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47081/47780 [02:42<00:04, 141.64 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46954/47780 [02:42<00:05, 139.69 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40184/47780 [02:42<00:13, 575.74 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47077/47780 [02:42<00:03, 195.85 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46880/47780 [02:42<00:05, 169.25 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46152/47780 [02:42<00:08, 195.23 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47371/47780 [02:42<00:03, 103.18 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47097/47780 [02:42<00:04, 143.91 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47236/47780 [02:42<00:04, 133.46 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46970/47780 [02:42<00:05, 143.00 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40244/47780 [02:42<00:13, 564.61 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46172/47780 [02:42<00:08, 195.93 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46899/47780 [02:42<00:05, 172.02 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47100/47780 [02:42<00:03, 192.32 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47384/47780 [02:42<00:03, 106.84 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47254/47780 [02:42<00:03, 139.17 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46985/47780 [02:42<00:05, 138.60 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47112/47780 [02:42<00:04, 134.42 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40307/47780 [02:42<00:12, 582.38 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46917/47780 [02:42<00:04, 173.00 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47132/47780 [02:42<00:02, 219.69 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46192/47780 [02:42<00:09, 175.50 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47396/47780 [02:42<00:03, 107.04 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47002/47780 [02:42<00:05, 146.95 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47268/47780 [02:42<00:03, 134.17 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47126/47780 [02:42<00:05, 127.13 examples/s]Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40366/47780 [02:42<00:12, 570.98 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46935/47780 [02:42<00:05, 164.91 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47407/47780 [02:42<00:03, 107.28 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46210/47780 [02:42<00:09, 172.53 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47158/47780 [02:42<00:03, 206.73 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47022/47780 [02:42<00:04, 156.97 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47143/47780 [02:42<00:04, 136.70 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40435/47780 [02:42<00:12, 595.41 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47282/47780 [02:42<00:04, 117.02 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46957/47780 [02:42<00:04, 177.13 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47184/47780 [02:42<00:02, 219.95 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47420/47780 [02:42<00:03, 110.89 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46228/47780 [02:42<00:09, 172.21 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47038/47780 [02:42<00:05, 140.88 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47157/47780 [02:42<00:04, 130.20 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40497/47780 [02:42<00:12, 577.77 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47295/47780 [02:42<00:04, 113.35 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46977/47780 [02:42<00:04, 174.18 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46253/47780 [02:42<00:08, 187.51 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47432/47780 [02:42<00:03, 107.04 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47207/47780 [02:42<00:02, 195.70 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47171/47780 [02:42<00:04, 127.07 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47057/47780 [02:42<00:04, 146.14 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40556/47780 [02:42<00:13, 552.56 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46995/47780 [02:42<00:04, 173.68 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47307/47780 [02:42<00:04, 108.21 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46275/47780 [02:42<00:07, 195.43 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47446/47780 [02:42<00:02, 111.83 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47075/47780 [02:42<00:04, 151.18 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47188/47780 [02:42<00:04, 134.96 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40612/47780 [02:42<00:13, 539.07 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47231/47780 [02:42<00:02, 186.99 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47020/47780 [02:42<00:04, 188.34 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47319/47780 [02:43<00:04, 104.97 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46295/47780 [02:43<00:08, 182.64 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47460/47780 [02:43<00:02, 110.92 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47203/47780 [02:43<00:04, 137.85 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40693/47780 [02:43<00:11, 613.53 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47251/47780 [02:43<00:02, 188.47 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47091/47780 [02:43<00:04, 140.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47045/47780 [02:43<00:03, 200.17 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47330/47780 [02:43<00:04, 105.89 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46315/47780 [02:43<00:08, 180.84 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47472/47780 [02:43<00:02, 108.69 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40757/47780 [02:43<00:11, 620.93 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47219/47780 [02:43<00:03, 142.58 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47108/47780 [02:43<00:04, 147.41 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47273/47780 [02:43<00:02, 185.42 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47066/47780 [02:43<00:03, 192.30 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47341/47780 [02:43<00:04, 99.65 examples/s] Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47488/47780 [02:43<00:02, 122.08 examples/s]Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40826/47780 [02:43<00:10, 640.25 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47235/47780 [02:43<00:03, 146.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46335/47780 [02:43<00:08, 164.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47292/47780 [02:43<00:02, 180.42 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47088/47780 [02:43<00:03, 197.59 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47125/47780 [02:43<00:04, 142.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47353/47780 [02:43<00:04, 102.43 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47501/47780 [02:43<00:02, 124.27 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47252/47780 [02:43<00:03, 151.51 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40891/47780 [02:43<00:11, 607.68 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46352/47780 [02:43<00:08, 160.70 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47108/47780 [02:43<00:03, 193.88 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47140/47780 [02:43<00:04, 138.69 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47366/47780 [02:43<00:03, 108.31 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47514/47780 [02:43<00:02, 124.78 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40953/47780 [02:43<00:11, 603.31 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47311/47780 [02:43<00:03, 150.49 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47268/47780 [02:43<00:03, 142.55 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46373/47780 [02:43<00:08, 172.32 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47155/47780 [02:43<00:04, 137.63 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47129/47780 [02:43<00:03, 186.97 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47377/47780 [02:43<00:03, 108.37 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47529/47780 [02:43<00:01, 131.47 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41017/47780 [02:43<00:11, 604.85 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46391/47780 [02:43<00:08, 167.98 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47327/47780 [02:43<00:03, 144.19 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47283/47780 [02:43<00:03, 128.37 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47173/47780 [02:43<00:04, 147.61 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47162/47780 [02:43<00:02, 224.85 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47390/47780 [02:43<00:03, 113.24 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41087/47780 [02:43<00:10, 628.41 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47544/47780 [02:43<00:01, 122.04 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46409/47780 [02:43<00:08, 161.13 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47344/47780 [02:43<00:03, 141.96 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47189/47780 [02:43<00:02, 235.74 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47189/47780 [02:43<00:03, 148.11 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47297/47780 [02:43<00:03, 122.51 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47404/47780 [02:43<00:03, 117.41 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41152/47780 [02:43<00:10, 605.70 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46436/47780 [02:43<00:07, 189.39 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47557/47780 [02:43<00:01, 113.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47359/47780 [02:43<00:03, 136.35 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47214/47780 [02:43<00:02, 224.18 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47310/47780 [02:43<00:03, 118.20 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47420/47780 [02:43<00:03, 118.27 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41221/47780 [02:43<00:10, 611.43 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47206/47780 [02:43<00:04, 125.86 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46457/47780 [02:43<00:07, 181.24 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47569/47780 [02:43<00:01, 107.85 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47380/47780 [02:43<00:02, 149.74 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47322/47780 [02:44<00:03, 117.76 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47237/47780 [02:44<00:02, 204.79 examples/s]Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41284/47780 [02:44<00:10, 611.35 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47432/47780 [02:44<00:03, 107.35 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47221/47780 [02:44<00:04, 123.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46479/47780 [02:44<00:07, 182.80 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47335/47780 [02:44<00:03, 120.65 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47580/47780 [02:44<00:02, 98.43 examples/s] Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47258/47780 [02:44<00:02, 196.99 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47397/47780 [02:44<00:02, 133.04 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41346/47780 [02:44<00:11, 573.60 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47443/47780 [02:44<00:03, 104.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47235/47780 [02:44<00:04, 127.83 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47349/47780 [02:44<00:03, 124.62 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46507/47780 [02:44<00:06, 199.00 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41407/47780 [02:44<00:10, 582.17 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47592/47780 [02:44<00:02, 92.06 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47413/47780 [02:44<00:02, 130.04 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47280/47780 [02:44<00:02, 184.13 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47249/47780 [02:44<00:04, 121.20 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46550/47780 [02:44<00:04, 259.06 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47362/47780 [02:44<00:03, 120.77 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47455/47780 [02:44<00:03, 93.88 examples/s] Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41469/47780 [02:44<00:10, 582.00 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47301/47780 [02:44<00:02, 183.39 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47602/47780 [02:44<00:02, 87.04 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47427/47780 [02:44<00:02, 123.12 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46579/47780 [02:44<00:04, 266.13 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47379/47780 [02:44<00:03, 127.85 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47264/47780 [02:44<00:04, 117.20 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41531/47780 [02:44<00:10, 571.86 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47470/47780 [02:44<00:03, 95.59 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47322/47780 [02:44<00:02, 176.01 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47445/47780 [02:44<00:02, 129.46 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46609/47780 [02:44<00:04, 256.02 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47613/47780 [02:44<00:02, 82.86 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47394/47780 [02:44<00:02, 131.67 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47276/47780 [02:44<00:04, 110.52 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41589/47780 [02:44<00:11, 548.56 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46647/47780 [02:44<00:03, 283.82 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47408/47780 [02:44<00:02, 130.06 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47463/47780 [02:44<00:02, 134.37 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47481/47780 [02:44<00:03, 82.39 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47340/47780 [02:44<00:02, 156.01 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47288/47780 [02:44<00:04, 107.32 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47624/47780 [02:44<00:01, 79.27 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41645/47780 [02:44<00:11, 542.21 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46680/47780 [02:44<00:03, 296.43 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47477/47780 [02:44<00:02, 135.27 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47490/47780 [02:44<00:03, 83.24 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47423/47780 [02:44<00:02, 129.73 examples/s]Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41701/47780 [02:44<00:11, 540.30 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47633/47780 [02:44<00:01, 80.08 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47356/47780 [02:44<00:02, 144.44 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47301/47780 [02:44<00:04, 102.72 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47491/47780 [02:44<00:02, 136.05 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46711/47780 [02:44<00:03, 287.02 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47439/47780 [02:44<00:02, 135.50 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47499/47780 [02:44<00:03, 79.50 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41757/47780 [02:44<00:11, 534.14 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47317/47780 [02:44<00:04, 113.43 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47642/47780 [02:44<00:01, 74.94 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47371/47780 [02:44<00:03, 130.26 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46742/47780 [02:44<00:03, 270.02 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47455/47780 [02:45<00:02, 133.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47509/47780 [02:45<00:03, 82.01 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41820/47780 [02:44<00:10, 546.25 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47506/47780 [02:45<00:02, 110.03 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47329/47780 [02:45<00:04, 108.53 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47387/47780 [02:45<00:02, 137.14 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47651/47780 [02:45<00:01, 69.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47473/47780 [02:45<00:02, 144.08 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41878/47780 [02:45<00:10, 545.16 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47518/47780 [02:45<00:03, 77.46 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46773/47780 [02:45<00:04, 237.38 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47341/47780 [02:45<00:04, 109.63 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47519/47780 [02:45<00:02, 110.18 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47660/47780 [02:45<00:01, 73.66 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47402/47780 [02:45<00:03, 124.67 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41936/47780 [02:45<00:10, 537.90 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47528/47780 [02:45<00:03, 82.10 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47489/47780 [02:45<00:02, 124.90 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46798/47780 [02:45<00:04, 223.74 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47353/47780 [02:45<00:04, 104.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47532/47780 [02:45<00:02, 108.45 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47416/47780 [02:45<00:02, 121.97 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47539/47780 [02:45<00:02, 88.37 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47668/47780 [02:45<00:01, 67.11 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41995/47780 [02:45<00:11, 522.12 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47503/47780 [02:45<00:02, 119.94 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47364/47780 [02:45<00:04, 103.86 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47544/47780 [02:45<00:02, 109.53 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46823/47780 [02:45<00:04, 204.83 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47430/47780 [02:45<00:02, 121.81 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47549/47780 [02:45<00:02, 89.19 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47676/47780 [02:45<00:01, 68.60 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42051/47780 [02:45<00:10, 523.60 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47375/47780 [02:45<00:04, 99.35 examples/s] Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47556/47780 [02:45<00:02, 102.95 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47443/47780 [02:45<00:02, 118.97 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42105/47780 [02:45<00:11, 515.62 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46854/47780 [02:45<00:04, 212.92 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47516/47780 [02:45<00:02, 102.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47559/47780 [02:45<00:02, 84.98 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47389/47780 [02:45<00:03, 104.04 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47567/47780 [02:45<00:02, 94.71 examples/s] Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42158/47780 [02:45<00:11, 493.31 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47457/47780 [02:45<00:02, 116.82 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46878/47780 [02:45<00:04, 206.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47568/47780 [02:45<00:02, 82.45 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47528/47780 [02:45<00:02, 95.81 examples/s] Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47684/47780 [02:45<00:01, 49.95 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47402/47780 [02:45<00:03, 105.35 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42220/47780 [02:45<00:10, 526.67 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46900/47780 [02:45<00:04, 209.09 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47470/47780 [02:45<00:02, 113.93 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47577/47780 [02:45<00:02, 86.96 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47579/47780 [02:45<00:02, 77.47 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47690/47780 [02:45<00:01, 47.59 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47539/47780 [02:45<00:02, 89.00 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47418/47780 [02:45<00:03, 113.29 examples/s]Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42277/47780 [02:45<00:10, 530.93 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46925/47780 [02:45<00:03, 215.34 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47587/47780 [02:45<00:02, 86.43 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47483/47780 [02:45<00:02, 106.60 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47587/47780 [02:45<00:02, 75.99 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42333/47780 [02:45<00:10, 535.54 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47551/47780 [02:46<00:02, 90.96 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47430/47780 [02:46<00:03, 103.85 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46947/47780 [02:46<00:04, 199.37 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47597/47780 [02:46<00:02, 87.73 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47497/47780 [02:46<00:02, 113.59 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47696/47780 [02:46<00:01, 42.64 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47595/47780 [02:46<00:02, 73.16 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42387/47780 [02:46<00:10, 533.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47562/47780 [02:46<00:02, 88.77 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47441/47780 [02:46<00:03, 96.79 examples/s] Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46969/47780 [02:46<00:04, 184.73 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47612/47780 [02:46<00:01, 92.06 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47701/47780 [02:46<00:01, 40.99 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42460/47780 [02:46<00:09, 580.32 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47509/47780 [02:46<00:02, 98.64 examples/s] Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47454/47780 [02:46<00:03, 102.98 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46992/47780 [02:46<00:04, 191.75 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42537/47780 [02:46<00:08, 629.97 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47521/47780 [02:46<00:02, 102.58 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47707/47780 [02:46<00:01, 41.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47627/47780 [02:46<00:01, 97.00 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47603/47780 [02:46<00:03, 53.53 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47572/47780 [02:46<00:03, 67.69 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47466/47780 [02:46<00:03, 101.72 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42601/47780 [02:46<00:08, 620.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47013/47780 [02:46<00:04, 180.45 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47714/47780 [02:46<00:01, 46.12 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47637/47780 [02:46<00:01, 89.95 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47481/47780 [02:46<00:02, 113.33 examples/s]Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42673/47780 [02:46<00:07, 647.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47532/47780 [02:46<00:02, 84.07 examples/s] Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47581/47780 [02:46<00:03, 61.20 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47720/47780 [02:46<00:01, 45.43 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47034/47780 [02:46<00:04, 160.67 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47647/47780 [02:46<00:01, 83.88 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42766/47780 [02:46<00:06, 724.62 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47499/47780 [02:46<00:02, 123.10 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47542/47780 [02:46<00:02, 79.40 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47588/47780 [02:46<00:03, 60.16 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47055/47780 [02:46<00:04, 170.63 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47610/47780 [02:46<00:04, 37.31 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42842/47780 [02:46<00:06, 730.27 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47725/47780 [02:46<00:01, 41.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47656/47780 [02:46<00:01, 78.89 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47516/47780 [02:46<00:02, 123.50 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47076/47780 [02:46<00:03, 178.04 examples/s]Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42923/47780 [02:46<00:06, 746.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47561/47780 [02:46<00:02, 92.07 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47731/47780 [02:46<00:01, 43.65 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47533/47780 [02:46<00:01, 131.38 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47596/47780 [02:46<00:03, 54.16 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47666/47780 [02:46<00:01, 76.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 43000/47780 [02:46<00:06, 719.89 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47095/47780 [02:46<00:04, 157.63 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47571/47780 [02:46<00:02, 86.26 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47615/47780 [02:46<00:05, 31.02 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47738/47780 [02:46<00:00, 47.98 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47555/47780 [02:46<00:01, 148.85 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47602/47780 [02:47<00:03, 53.97 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47675/47780 [02:46<00:01, 78.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43074/47780 [02:47<00:06, 716.95 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47112/47780 [02:47<00:04, 153.49 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47587/47780 [02:47<00:01, 99.34 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47748/47780 [02:47<00:00, 59.30 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47571/47780 [02:47<00:01, 148.08 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47608/47780 [02:47<00:03, 50.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43150/47780 [02:47<00:06, 717.73 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47684/47780 [02:47<00:01, 68.54 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47134/47780 [02:47<00:03, 166.58 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47757/47780 [02:47<00:00, 64.11 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47619/47780 [02:47<00:06, 26.57 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47586/47780 [02:47<00:01, 140.74 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43229/47780 [02:47<00:06, 735.14 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47616/47780 [02:47<00:03, 53.45 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47154/47780 [02:47<00:03, 167.44 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47768/47780 [02:47<00:00, 74.39 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47598/47780 [02:47<00:02, 76.89 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47692/47780 [02:47<00:01, 63.20 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47624/47780 [02:47<00:05, 29.37 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47602/47780 [02:47<00:01, 140.53 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43304/47780 [02:47<00:06, 700.81 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47628/47780 [02:47<00:02, 65.61 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47179/47780 [02:47<00:03, 186.09 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47618/47780 [02:47<00:01, 142.45 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47630/47780 [02:47<00:04, 34.18 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47699/47780 [02:47<00:01, 58.09 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43377/47780 [02:47<00:06, 674.35 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47210/47780 [02:47<00:02, 218.70 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47639/47780 [02:47<00:01, 72.85 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47609/47780 [02:47<00:02, 69.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47635/47780 [02:47<00:00, 147.91 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47707/47780 [02:47<00:01, 60.81 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43447/47780 [02:47<00:06, 664.14 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47652/47780 [02:47<00:00, 153.83 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47234/47780 [02:47<00:02, 202.66 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47618/47780 [02:47<00:02, 68.73 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47650/47780 [02:47<00:01, 71.84 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47638/47780 [02:47<00:04, 34.46 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43515/47780 [02:47<00:06, 661.98 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47715/47780 [02:47<00:01, 58.20 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47626/47780 [02:47<00:02, 66.55 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47669/47780 [02:47<00:00, 139.56 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47258/47780 [02:47<00:02, 190.96 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47645/47780 [02:47<00:03, 38.69 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████ | 43588/47780 [02:47<00:06, 656.26 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47722/47780 [02:47<00:00, 59.70 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47658/47780 [02:47<00:02, 60.78 examples/s]Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43662/47780 [02:47<00:06, 669.81 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47279/47780 [02:47<00:02, 175.87 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47633/47780 [02:47<00:02, 59.99 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47685/47780 [02:47<00:00, 124.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47667/47780 [02:47<00:01, 64.28 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47653/47780 [02:47<00:03, 40.37 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47732/47780 [02:48<00:00, 59.85 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43731/47780 [02:48<00:06, 643.06 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47699/47780 [02:48<00:00, 125.37 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47641/47780 [02:48<00:02, 59.45 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47298/47780 [02:48<00:03, 152.72 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43814/47780 [02:48<00:05, 681.35 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47659/47780 [02:48<00:03, 36.04 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47648/47780 [02:48<00:02, 59.19 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47713/47780 [02:48<00:00, 110.00 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47316/47780 [02:48<00:03, 149.57 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47675/47780 [02:48<00:02, 48.74 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43886/47780 [02:48<00:06, 645.37 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47740/47780 [02:48<00:00, 46.32 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47656/47780 [02:48<00:02, 59.88 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43961/47780 [02:48<00:05, 662.81 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47333/47780 [02:48<00:03, 139.81 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47725/47780 [02:48<00:00, 100.10 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47681/47780 [02:48<00:02, 43.84 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47664/47780 [02:48<00:03, 30.50 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44033/47780 [02:48<00:05, 676.22 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47746/47780 [02:48<00:00, 39.90 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47664/47780 [02:48<00:02, 53.58 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47348/47780 [02:48<00:03, 127.31 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47737/47780 [02:48<00:00, 94.43 examples/s] Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47692/47780 [02:48<00:01, 54.29 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47670/47780 [02:48<00:03, 32.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44103/47780 [02:48<00:05, 662.69 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47363/47780 [02:48<00:03, 125.85 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47673/47780 [02:48<00:01, 55.86 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47700/47780 [02:48<00:01, 57.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47747/47780 [02:48<00:00, 84.77 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47674/47780 [02:48<00:03, 33.29 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47752/47780 [02:48<00:00, 36.89 examples/s]Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44171/47780 [02:48<00:05, 630.70 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47679/47780 [02:48<00:01, 54.84 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47708/47780 [02:48<00:01, 60.35 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47377/47780 [02:48<00:03, 116.38 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47756/47780 [02:48<00:00, 81.97 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47678/47780 [02:48<00:03, 33.81 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44236/47780 [02:48<00:05, 616.09 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47759/47780 [02:48<00:00, 40.43 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47685/47780 [02:48<00:01, 52.52 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44305/47780 [02:48<00:05, 630.52 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47390/47780 [02:48<00:03, 111.70 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47765/47780 [02:48<00:00, 74.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47715/47780 [02:49<00:01, 48.53 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47683/47780 [02:49<00:03, 29.41 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44371/47780 [02:49<00:05, 614.96 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47765/47780 [02:49<00:00, 36.89 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47692/47780 [02:49<00:01, 52.48 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47405/47780 [02:49<00:03, 113.84 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47724/47780 [02:49<00:00, 56.38 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44434/47780 [02:49<00:05, 616.47 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47770/47780 [02:49<00:00, 38.93 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47687/47780 [02:49<00:03, 29.16 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47417/47780 [02:49<00:03, 103.79 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47702/47780 [02:49<00:01, 53.46 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44503/47780 [02:49<00:05, 619.71 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47692/47780 [02:49<00:02, 32.36 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47433/47780 [02:49<00:03, 110.21 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44570/47780 [02:49<00:05, 622.84 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47708/47780 [02:49<00:01, 49.53 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47737/47780 [02:49<00:00, 53.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47701/47780 [02:49<00:01, 42.83 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47448/47780 [02:49<00:03, 106.76 examples/s]Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44633/47780 [02:49<00:05, 571.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47743/47780 [02:49<00:00, 53.06 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47713/47780 [02:49<00:01, 43.00 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44702/47780 [02:49<00:05, 603.01 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47707/47780 [02:49<00:01, 39.54 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47750/47780 [02:49<00:00, 55.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47464/47780 [02:49<00:02, 111.98 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44766/47780 [02:49<00:05, 586.18 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47476/47780 [02:49<00:02, 107.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47719/47780 [02:49<00:01, 38.77 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47757/47780 [02:49<00:00, 48.91 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44827/47780 [02:49<00:05, 552.60 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47713/47780 [02:49<00:02, 33.41 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47491/47780 [02:49<00:02, 113.54 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47724/47780 [02:49<00:01, 38.17 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47765/47780 [02:49<00:00, 52.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44890/47780 [02:49<00:05, 571.74 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47504/47780 [02:49<00:02, 106.87 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47717/47780 [02:50<00:02, 31.07 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47731/47780 [02:50<00:01, 40.21 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44948/47780 [02:50<00:04, 571.84 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47772/47780 [02:50<00:00, 48.27 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47516/47780 [02:50<00:02, 105.13 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45012/47780 [02:50<00:04, 570.23 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47721/47780 [02:50<00:02, 28.71 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47737/47780 [02:50<00:01, 37.90 examples/s]Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47527/47780 [02:50<00:02, 102.32 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45070/47780 [02:50<00:04, 566.49 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47725/47780 [02:50<00:01, 27.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47540/47780 [02:50<00:02, 101.24 examples/s]Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45135/47780 [02:50<00:04, 569.66 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47742/47780 [02:50<00:01, 31.15 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47553/47780 [02:50<00:02, 105.94 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47730/47780 [02:50<00:01, 30.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45194/47780 [02:50<00:05, 512.32 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47566/47780 [02:50<00:02, 103.90 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47746/47780 [02:50<00:01, 29.18 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47734/47780 [02:50<00:01, 29.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45249/47780 [02:50<00:05, 496.66 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47578/47780 [02:50<00:01, 107.87 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45301/47780 [02:50<00:05, 485.20 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47738/47780 [02:50<00:01, 28.28 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45351/47780 [02:50<00:05, 484.05 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47593/47780 [02:50<00:01, 104.23 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47751/47780 [02:50<00:01, 25.18 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47742/47780 [02:50<00:01, 27.88 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45403/47780 [02:50<00:04, 487.06 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47606/47780 [02:50<00:01, 101.66 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45452/47780 [02:51<00:04, 485.91 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47755/47780 [02:51<00:01, 24.65 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47746/47780 [02:51<00:01, 26.73 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47619/47780 [02:51<00:01, 101.71 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45511/47780 [02:51<00:04, 501.67 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47758/47780 [02:51<00:00, 22.74 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47750/47780 [02:51<00:01, 26.54 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47630/47780 [02:51<00:01, 93.64 examples/s] 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45563/47780 [02:51<00:04, 497.14 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47761/47780 [02:51<00:00, 22.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47754/47780 [02:51<00:00, 27.70 examples/s]Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45614/47780 [02:51<00:04, 474.61 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47644/47780 [02:51<00:01, 95.78 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45664/47780 [02:51<00:04, 479.89 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47758/47780 [02:51<00:00, 28.91 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47765/47780 [02:51<00:00, 24.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47655/47780 [02:51<00:01, 85.29 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45713/47780 [02:51<00:04, 457.15 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47765/47780 [02:51<00:00, 35.77 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47769/47780 [02:51<00:00, 24.64 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47665/47780 [02:51<00:01, 87.41 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45765/47780 [02:51<00:04, 470.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47770/47780 [02:51<00:00, 35.34 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47773/47780 [02:51<00:00, 24.82 examples/s]Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45814/47780 [02:51<00:04, 444.95 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47676/47780 [02:51<00:01, 74.17 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47774/47780 [02:51<00:00, 35.23 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45867/47780 [02:51<00:04, 456.11 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45913/47780 [02:52<00:04, 443.88 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47685/47780 [02:52<00:01, 58.68 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45960/47780 [02:52<00:04, 448.96 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46015/47780 [02:52<00:03, 465.38 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47692/47780 [02:52<00:01, 52.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46069/47780 [02:52<00:03, 477.98 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46117/47780 [02:52<00:03, 473.82 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47699/47780 [02:52<00:01, 48.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46165/47780 [02:52<00:03, 462.65 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47706/47780 [02:52<00:01, 45.32 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46212/47780 [02:52<00:03, 435.48 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46258/47780 [02:52<00:03, 440.48 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47712/47780 [02:52<00:01, 40.01 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46311/47780 [02:52<00:03, 463.70 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47776/47780 [02:53<00:00,  4.80 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47718/47780 [02:53<00:01, 42.01 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46368/47780 [02:53<00:03, 469.89 examples/s]Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46421/47780 [02:53<00:02, 456.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47724/47780 [02:53<00:01, 38.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46468/47780 [02:53<00:02, 446.08 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47729/47780 [02:53<00:01, 37.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46514/47780 [02:53<00:02, 428.00 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47733/47780 [02:53<00:01, 36.39 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46559/47780 [02:53<00:02, 410.11 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46609/47780 [02:53<00:02, 423.02 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47737/47780 [02:53<00:01, 31.91 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46656/47780 [02:53<00:02, 433.01 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47742/47780 [02:53<00:01, 32.91 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46701/47780 [02:53<00:02, 409.33 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47746/47780 [02:53<00:01, 31.83 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46744/47780 [02:53<00:02, 372.66 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47750/47780 [02:54<00:00, 30.66 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47774/47780 [02:54<00:00,  6.25 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46782/47780 [02:54<00:02, 341.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47754/47780 [02:54<00:00, 30.86 examples/s]Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46819/47780 [02:54<00:03, 317.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47758/47780 [02:54<00:00, 30.49 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46855/47780 [02:54<00:02, 327.34 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47762/47780 [02:54<00:00, 30.25 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46891/47780 [02:54<00:02, 323.15 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47767/47780 [02:54<00:00, 34.38 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46927/47780 [02:54<00:02, 305.67 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47772/47780 [02:54<00:00, 35.18 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46960/47780 [02:54<00:02, 307.65 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47775/47780 [02:54<00:01,  3.26 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46992/47780 [02:54<00:02, 283.05 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47027/47780 [02:54<00:02, 281.45 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47067/47780 [02:55<00:02, 308.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47100/47780 [02:55<00:02, 274.75 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47129/47780 [02:55<00:02, 269.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47173/47780 [02:55<00:01, 310.57 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47207/47780 [02:55<00:02, 279.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47240/47780 [02:55<00:01, 286.38 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47270/47780 [02:55<00:02, 254.91 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47297/47780 [02:55<00:01, 248.72 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47323/47780 [02:56<00:01, 234.88 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47354/47780 [02:56<00:01, 246.24 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47382/47780 [02:56<00:01, 237.06 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47412/47780 [02:56<00:01, 232.26 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47438/47780 [02:56<00:01, 212.06 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47460/47780 [02:56<00:01, 206.33 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47481/47780 [02:56<00:01, 196.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47510/47780 [02:56<00:01, 214.81 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47533/47780 [02:57<00:01, 198.75 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47779/47780 [02:57<00:00,  2.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47554/47780 [02:57<00:01, 190.36 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47576/47780 [02:57<00:01, 163.40 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47594/47780 [02:57<00:01, 151.69 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47610/47780 [02:57<00:01, 134.57 examples/s]Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [02:57<00:00, 268.69 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47624/47780 [02:57<00:01, 107.99 examples/s]Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [02:58<00:00,  2.15 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47636/47780 [02:58<00:01, 103.52 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47649/47780 [02:58<00:01, 97.11 examples/s] 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47660/47780 [02:58<00:01, 96.10 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47670/47780 [02:58<00:01, 79.17 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:00<00:25, 1829.42 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  15%|█▍        | 7000/47780 [00:00<00:02, 13819.38 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47680/47780 [02:58<00:01, 72.61 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47777/47780 [02:58<00:00,  3.61 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  38%|███▊      | 17975/47780 [00:00<00:00, 35340.00 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47689/47780 [02:58<00:01, 71.07 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  85%|████████▍ | 40385/47780 [00:00<00:00, 79793.94 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47699/47780 [02:58<00:01, 70.84 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [02:59<00:00,  2.55 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [02:59<00:00,  4.17 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47709/47780 [02:59<00:00, 71.35 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47721/47780 [02:59<00:00, 79.00 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47730/47780 [02:59<00:00, 75.08 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [02:59<00:00,  3.22 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47739/47780 [02:59<00:00, 66.74 examples/s]Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [02:59<00:00, 265.70 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47747/47780 [02:59<00:00, 50.28 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47754/47780 [03:00<00:00, 46.17 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47760/47780 [03:00<00:00, 42.18 examples/s]Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:00<00:00, 264.91 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:00<00:30, 1551.97 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  10%|█         | 5000/47780 [00:00<00:05, 8467.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  61%|██████    | 28988/47780 [00:00<00:00, 55559.84 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  93%|█████████▎| 44329/47780 [00:00<00:00, 76945.37 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47766/47780 [03:01<00:00, 17.91 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:00<00:37, 1259.91 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  27%|██▋       | 13000/47780 [00:00<00:01, 19270.81 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  74%|███████▍  | 35455/47780 [00:01<00:00, 55325.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:01<00:00,  1.67 examples/s]Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:01<00:00, 262.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:00<00:29, 1571.53 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  17%|█▋        | 8000/47780 [00:00<00:02, 13934.41 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  54%|█████▍    | 25961/47780 [00:00<00:00, 47758.67 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  93%|█████████▎| 44329/47780 [00:00<00:00, 78134.19 examples/s]Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:05<00:00, 258.11 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:00<00:22, 2047.73 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  13%|█▎        | 6000/47780 [00:00<00:03, 12587.56 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  34%|███▍      | 16481/47780 [00:00<00:00, 33904.55 examples/s]Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:06<00:00,  1.06s/ examples]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  79%|███████▉  | 37906/47780 [00:00<00:00, 78964.12 examples/s]Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:06<00:00, 256.29 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:00<00:28, 1638.90 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  31%|███▏      | 15000/47780 [00:00<00:01, 26838.84 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  85%|████████▍ | 40385/47780 [00:00<00:00, 72348.23 examples/s]Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:15<00:00, 55325.09 examples/s]Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:17<00:00, 79793.94 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:18<00:00, 1745.19 examples/s] 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:16<00:00, 76945.37 examples/s]Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:15<00:00, 78134.19 examples/s]Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:12<00:00, 78964.12 examples/s]Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47769/47780 [03:18<00:00, 17.91 examples/s]Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:18<00:00,  4.17 examples/s]Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:11<00:00, 72348.23 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47772/47780 [03:18<00:06,  1.24 examples/s]Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:20<00:00, 1742.02 examples/s] 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47776/47780 [03:21<00:03,  1.30 examples/s]Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:26<00:00, 231.31 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  81%|████████  | 38821/47780 [00:00<?, ? examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:30<00:00, 1745.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  83%|████████▎ | 39821/47780 [00:00<00:07, 1107.54 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:29<00:00, 971.05 examples/s]  
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:27<00:00, 1049.24 examples/s] Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:29<00:00, 1592.85 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:33:14,210] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:26<00:00, 1224.38 examples/s] df: /root/.triton/autotune: No such file or directory
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:34<00:00, 1390.15 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:25<00:00, 1273.39 examples/s] backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:33:15,920] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:33:16,903] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:33:17,628] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:34<00:00, 1397.78 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:36<00:00, 1294.64 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:37<00:00,  1.47s/ examples]Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:31<00:00, 1497.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:30<00:00, 1561.50 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:33:20,042] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  94%|█████████▍| 44794/47780 [00:09<00:04, 607.46 examples/s] Truncating train dataset (num_proc=32):  94%|█████████▍| 44794/47780 [00:09<00:04, 608.37 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:33:20,664] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:33:21,065] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:33:21,084] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [03:38<00:00, 218.59 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:33:21,464] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:33:21,632] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:33:21,765] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:33:22,125] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:33:22,303] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:33:22,324] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:33:22,717] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:33:23,034] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   0%|          | 0/10 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3505)[0m  10%|█         | 1/10 [00:45<06:47, 45.28s/it]
[36m(head, rank=0, pid=3505)[0m  20%|██        | 2/10 [01:24<05:35, 41.97s/it]
[36m(head, rank=0, pid=3505)[0m  30%|███       | 3/10 [02:04<04:46, 40.87s/it]
[36m(head, rank=0, pid=3505)[0m  40%|████      | 4/10 [02:43<04:01, 40.28s/it]
[36m(head, rank=0, pid=3505)[0m  50%|█████     | 5/10 [03:23<03:20, 40.07s/it]
[36m(head, rank=0, pid=3505)[0m  60%|██████    | 6/10 [04:01<02:37, 39.43s/it]
[36m(head, rank=0, pid=3505)[0m  70%|███████   | 7/10 [04:41<01:58, 39.55s/it]
[36m(head, rank=0, pid=3505)[0m  80%|████████  | 8/10 [05:21<01:19, 39.61s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(head, rank=0, pid=3505)[0m  90%|█████████ | 9/10 [05:59<00:39, 39.22s/it]100%|██████████| 10/10 [06:36<00:00, 38.50s/it]Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3505)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3505)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3505)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3505)[0m                                                {'loss': 124.4492, 'grad_norm': 35.656002044677734, 'learning_rate': 2.0000000000000003e-06, 'num_tokens': 9501248.0, 'epoch': 0.03}
[36m(head, rank=0, pid=3505)[0m 100%|██████████| 10/10 [06:36<00:00, 38.50s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3505)[0m Starting Save checkpoint...
[36m(head, rank=0, pid=3505)[0m Completed Save checkpoint in 186.38 seconds
[36m(head, rank=0, pid=3505)[0m Completed Save checkpoint in 186.38 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint save time: 186.38s (Total: 186.38s)
[36m(head, rank=0, pid=3505)[0m Checkpoint save time: 186.38s (Total: 186.38s)
[36m(head, rank=0, pid=3505)[0m Completed Save checkpoint in 186.38 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint save time: 186.38s (Total: 186.38s)
[36m(head, rank=0, pid=3505)[0m Completed Save checkpoint in 186.38 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint save time: 186.38s (Total: 186.38s)
[36m(head, rank=0, pid=3505)[0m Completed Save checkpoint in 186.38 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint save time: 186.38s (Total: 186.38s)
[36m(head, rank=0, pid=3505)[0m Completed Save checkpoint in 186.38 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint save time: 186.38s (Total: 186.38s)
[36m(head, rank=0, pid=3505)[0m Completed Save checkpoint in 186.38 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint save time: 186.38s (Total: 186.38s)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Save checkpoint in 186.38 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint save time: 186.38s (Total: 186.38s)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Save checkpoint in 186.38 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint save time: 186.38s (Total: 186.38s)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Save checkpoint in 186.38 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint save time: 186.38s (Total: 186.38s)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Save checkpoint in 186.38 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint save time: 186.38s (Total: 186.38s)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Save checkpoint in 186.38 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint save time: 186.38s (Total: 186.38s)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Save checkpoint in 186.38 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint save time: 186.38s (Total: 186.38s)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Save checkpoint in 186.39 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Save checkpoint in 186.39 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint save time: 186.39s (Total: 186.39s)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint save time: 186.39s (Total: 186.39s)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 1083.19 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total checkpoint save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average save time per checkpoint: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total batch sample time: 0.34s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average batch sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max batch sample time: 0.08s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:Completed Training in 1083.08 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total training step time: 356.60s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average training step time: 4.46s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min training step time: 3.66s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max training step time: 9.27s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total checkpoint save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average save time per checkpoint: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total batch sample time: 0.34s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average batch sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max batch sample time: 0.07s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total training step time: 356.86s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average training step time: 4.46s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min training step time: 3.66s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max training step time: 9.29s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 1083.13 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total checkpoint save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average save time per checkpoint: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total batch sample time: 0.39s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max batch sample time: 0.13s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total training step time: 356.94s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average training step time: 4.46s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min training step time: 3.66s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max training step time: 9.21s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 1083.13 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 1083.04 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 1083.08 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total checkpoint save time: 186.39s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average save time per checkpoint: 186.39s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min save time: 186.39sCheckpoint Save Statistics:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max save time: 186.39s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total checkpoint save time: 186.38s  - Number of batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average save time per checkpoint: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total batch sample time: 0.34s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average batch sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min batch sample time: 0.02s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:  - Max batch sample time: 0.08s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of batch samples: 10Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of training steps: 80  - Total batch sample time: 0.34s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average batch sample time: 0.03s  - Total training step time: 356.89s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min batch sample time: 0.03s  - Average training step time: 4.46s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max batch sample time: 0.08s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min training step time: 3.66s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max training step time: 9.28s  - Number of training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training completed successfully for run 1  - Total training step time: 356.42s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average training step time: 4.46s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min training step time: 3.66s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max training step time: 9.28s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total checkpoint save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average save time per checkpoint: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total batch sample time: 0.35s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max batch sample time: 0.09s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total training step time: 357.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average training step time: 4.46s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min training step time: 3.66s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max training step time: 9.27s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved training info to: /tmp/checkpoint/training_run_3_1_info.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved training info to: /tmp/checkpoint/training_run_7_1_info.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 1063.42 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total checkpoint save time: 186.39s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average save time per checkpoint: 186.39s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min save time: 186.39s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max save time: 186.39s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total batch sample time: 0.35s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average batch sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max batch sample time: 0.09s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total training step time: 355.98s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average training step time: 4.45s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min training step time: 3.67s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max training step time: 8.09s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved training info to: /tmp/checkpoint/training_run_2_1_info.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved training info to: /tmp/checkpoint/training_run_4_1_info.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved training info to: /tmp/checkpoint/training_run_1_1_info.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved training info to: /tmp/checkpoint/training_run_5_1_info.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved training info to: /tmp/checkpoint/training_run_0_1_info.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 1083.10 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total checkpoint save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average save time per checkpoint: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total batch sample time: 0.41s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max batch sample time: 0.15s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total training step time: 356.70s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average training step time: 4.46s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min training step time: 3.66s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max training step time: 9.19s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved training info to: /tmp/checkpoint/training_run_6_1_info.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed run 1/1
[36m(head, rank=0, pid=3505)[0m Completed Save checkpoint in 316.56 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint save time: 316.56s (Total: 316.56s)
[36m(head, rank=0, pid=3505)[0m                                                {'train_runtime': 713.1273, 'train_samples_per_second': 1.795, 'train_steps_per_second': 0.014, 'train_loss': 124.44921875, 'epoch': 0.03}
[36m(head, rank=0, pid=3505)[0m 100%|██████████| 10/10 [11:53<00:00, 38.50s/it]100%|██████████| 10/10 [11:53<00:00, 71.31s/it]
[36m(head, rank=0, pid=3505)[0m Completed Training in 1063.00 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3505)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   - Total checkpoint save time: 316.56s
[36m(head, rank=0, pid=3505)[0m   - Average save time per checkpoint: 316.56s
[36m(head, rank=0, pid=3505)[0m   - Min save time: 316.56s
[36m(head, rank=0, pid=3505)[0m   - Max save time: 316.56s
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3505)[0m   - Total batch sample time: 0.35s
[36m(head, rank=0, pid=3505)[0m   - Average batch sample time: 0.04s
[36m(head, rank=0, pid=3505)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3505)[0m   - Total training step time: 356.28s
[36m(head, rank=0, pid=3505)[0m   - Average training step time: 4.45s
[36m(head, rank=0, pid=3505)[0m   - Min training step time: 3.66s
[36m(head, rank=0, pid=3505)[0m   - Max training step time: 8.18s
[36m(head, rank=0, pid=3505)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3505)[0m Saved training info to: /tmp/checkpoint/training_run_0_1_info.json
[36m(head, rank=0, pid=3505)[0m Completed run 1/1
[36m(head, rank=0, pid=3505)[0m Completed Training in 1083.06 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3505)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   - Total checkpoint save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   - Average save time per checkpoint: 186.38s
[36m(head, rank=0, pid=3505)[0m   - Min save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   - Max save time: 186.38s
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3505)[0m   - Total batch sample time: 0.35s
[36m(head, rank=0, pid=3505)[0m   - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   - Max batch sample time: 0.08s
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3505)[0m   - Total training step time: 356.80s
[36m(head, rank=0, pid=3505)[0m   - Average training step time: 4.46s
[36m(head, rank=0, pid=3505)[0m   - Min training step time: 3.66s
[36m(head, rank=0, pid=3505)[0m   - Max training step time: 9.28s
[36m(head, rank=0, pid=3505)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3505)[0m Completed Training in 1083.12 seconds
[36m(head, rank=0, pid=3505)[0m Completed Training in 1083.37 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3505)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   - Total checkpoint save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   - Average save time per checkpoint: 186.38s
[36m(head, rank=0, pid=3505)[0m   - Min save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   - Max save time: 186.38s
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3505)[0m   - Total batch sample time: 0.34s
[36m(head, rank=0, pid=3505)[0m   - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   - Max batch sample time: 0.08s
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3505)[0m   - Total training step time: 357.42s
[36m(head, rank=0, pid=3505)[0m   - Average training step time: 4.47s
[36m(head, rank=0, pid=3505)[0m   - Min training step time: 3.67s
[36m(head, rank=0, pid=3505)[0m   - Max training step time: 9.28s
[36m(head, rank=0, pid=3505)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3505)[0m Completed Training in 1083.03 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3505)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   - Total checkpoint save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   - Average save time per checkpoint: 186.38s
[36m(head, rank=0, pid=3505)[0m   - Min save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   - Max save time: 186.38s
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3505)[0m   - Total batch sample time: 0.32s
[36m(head, rank=0, pid=3505)[0m   - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   - Min batch sample time: 0.02s
[36m(head, rank=0, pid=3505)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3505)[0m   - Total training step time: 356.01s
[36m(head, rank=0, pid=3505)[0m   - Average training step time: 4.45s
[36m(head, rank=0, pid=3505)[0m   - Min training step time: 3.66s
[36m(head, rank=0, pid=3505)[0m   - Max training step time: 9.28s
[36m(head, rank=0, pid=3505)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3505)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3505)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   - Total checkpoint save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   - Average save time per checkpoint: 186.38s
[36m(head, rank=0, pid=3505)[0m   - Min save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   - Max save time: 186.38s
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3505)[0m   - Total batch sample time: 0.38s
[36m(head, rank=0, pid=3505)[0m   - Average batch sample time: 0.04s
[36m(head, rank=0, pid=3505)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   - Max batch sample time: 0.08s
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3505)[0m   - Total training step time: 356.62s
[36m(head, rank=0, pid=3505)[0m   - Average training step time: 4.46s
[36m(head, rank=0, pid=3505)[0m   - Min training step time: 3.67s
[36m(head, rank=0, pid=3505)[0m   - Max training step time: 9.27s
[36m(head, rank=0, pid=3505)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3505)[0m Saved training info to: /tmp/checkpoint/training_run_6_1_info.json
[36m(head, rank=0, pid=3505)[0m Completed run 1/1
[36m(head, rank=0, pid=3505)[0m Completed Training in 1083.10 seconds
[36m(head, rank=0, pid=3505)[0m Completed Training in 1083.08 seconds
[36m(head, rank=0, pid=3505)[0m Completed Training in 1083.07 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3505)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   - Total checkpoint save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   - Average save time per checkpoint: 186.38s
[36m(head, rank=0, pid=3505)[0m   - Min save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   - Max save time: 186.38s
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3505)[0m   - Total batch sample time: 0.33s
[36m(head, rank=0, pid=3505)[0m   - Average batch sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3505)[0m   - Total training step time: 356.53s
[36m(head, rank=0, pid=3505)[0m   - Average training step time: 4.46s
[36m(head, rank=0, pid=3505)[0m   - Min training step time: 3.67s
[36m(head, rank=0, pid=3505)[0m   - Max training step time: 9.29s
[36m(head, rank=0, pid=3505)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3505)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3505)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   - Total checkpoint save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   - Average save time per checkpoint: 186.38s
[36m(head, rank=0, pid=3505)[0m   - Min save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   - Max save time: 186.38s
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3505)[0m Checkpoint Save Statistics:  - Total batch sample time: 0.33s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   - Average batch sample time: 0.03s  - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   - Min batch sample time: 0.02s
[36m(head, rank=0, pid=3505)[0m   - Total checkpoint save time: 186.38s  - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   - Average save time per checkpoint: 186.38sTraining Step Performance:
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   - Number of training steps: 80  - Min save time: 186.38s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   - Total training step time: 356.63s  - Max save time: 186.38s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:  - Average training step time: 4.46s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   - Number of batch samples: 10  - Min training step time: 3.66s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   - Max training step time: 9.29s  - Total batch sample time: 0.34s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   - Average batch sample time: 0.03sTraining completed successfully for run 1
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   - Max batch sample time: 0.07s
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3505)[0m   - Total training step time: 357.49s
[36m(head, rank=0, pid=3505)[0m   - Average training step time: 4.47s
[36m(head, rank=0, pid=3505)[0m   - Min training step time: 3.67s
[36m(head, rank=0, pid=3505)[0m   - Max training step time: 9.30s
[36m(head, rank=0, pid=3505)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3505)[0m Saved training info to: /tmp/checkpoint/training_run_2_1_info.jsonSaved training info to: /tmp/checkpoint/training_run_3_1_info.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Completed run 1/1
[36m(head, rank=0, pid=3505)[0m Completed run 1/1
[36m(head, rank=0, pid=3505)[0m Saved training info to: /tmp/checkpoint/training_run_4_1_info.json
[36m(head, rank=0, pid=3505)[0m Completed run 1/1
[36m(head, rank=0, pid=3505)[0m Saved training info to: /tmp/checkpoint/training_run_7_1_info.json
[36m(head, rank=0, pid=3505)[0m Completed run 1/1
[36m(head, rank=0, pid=3505)[0m Saved training info to: /tmp/checkpoint/training_run_1_1_info.json
[36m(head, rank=0, pid=3505)[0m Completed run 1/1
[36m(head, rank=0, pid=3505)[0m Saved training info to: /tmp/checkpoint/training_run_5_1_info.json
[36m(head, rank=0, pid=3505)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 2.22s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 2.22s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 2.22s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 2.36s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 2.22s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 2.36s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 0.98s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 2.36s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 0.98s  • Total time: 2.36s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 0.98s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 0.98s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 20.93s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1083.08s  • Min time: 20.93s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1083.08s  • Max time: 20.93s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 20.93s  • Max time: 1083.08s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Performance:  • Total time: 1083.08s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1063.42s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1063.42s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training steps: 80  • Max time: 1063.42s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 1063.42s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average step time per step: 4.46s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min step time: 3.66s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training steps: 80  • Max step time: 9.29s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training step time: 356.86s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average step time per step: 4.45s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min step time: 3.67s  • Total batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max step time: 8.09s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average sample time per batch: 0.03s  • Total training step time: 355.98s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:  • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max sample time: 0.07s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch sample time: 0.34s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average sample time per batch: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max sample time: 0.09s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch sample time: 0.35s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average save time per checkpoint: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoints saved: 1  • Min save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoint save time: 186.38s  • Average save time per checkpoint: 186.39s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min save time: 186.39s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max save time: 186.39s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average total time per run: 1086.28s  • Total checkpoint save time: 186.39s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min total time: 1086.28s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max total time: 1086.28s  • Average total time per run: 1086.70s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time across all runs: 1086.28s  • Min total time: 1086.70s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max total time: 1086.70s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time across all runs: 1086.70s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved timing summary to: timing_summary_7.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved timing summary to: timing_summary_0.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 2.13s
[36m(head, rank=0, pid=3505)[0m   • Min time: 2.13s
[36m(head, rank=0, pid=3505)[0m   • Max time: 2.13s  • Average time: 2.08s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total time: 2.13s
[36m(head, rank=0, pid=3505)[0m   • Min time: 2.08s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Model Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 1.05s
[36m(head, rank=0, pid=3505)[0m   • Max time: 2.08s
[36m(head, rank=0, pid=3505)[0m   • Total time: 2.08s  • Min time: 1.05s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Model Loading Performance:  • Max time: 1.05s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Average time: 0.96s  • Total time: 1.05s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Performance:
[36m(head, rank=0, pid=3505)[0m   • Min time: 0.96s  • Average time: 1083.10s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Max time: 0.96s
[36m(head, rank=0, pid=3505)[0m   • Min time: 1083.10s  • Total time: 0.96s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Max time: 1083.10s
[36m(head, rank=0, pid=3505)[0m Training Performance:
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total time: 1083.10s  • Average time: 1083.37s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   • Min time: 1083.37s
[36m(head, rank=0, pid=3505)[0m   • Max time: 1083.37s
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m TRAINING PERFORMANCE SUMMARY  • Total time: 1083.37s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m ================================================================================  • Average step time per step: 4.46s
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Total Runs Completed: 1  • Min step time: 3.67s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total training steps: 80  • Max step time: 9.29s
[36m(head, rank=0, pid=3505)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total training step time: 356.53s  • Average step time per step: 4.45s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   • Min step time: 3.66s  • Total batch samples: 10
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Average time: 2.08s
[36m(head, rank=0, pid=3505)[0m   • Max step time: 9.28s  • Average sample time per batch: 0.03s  • Min time: 2.08s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total training step time: 356.01s  • Min sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Max time: 2.08s
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:  • Max sample time: 0.07s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total time: 2.08s  • Total batch samples: 10
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total batch sample time: 0.33s
[36m(head, rank=0, pid=3505)[0m Model Loading Performance:
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Checkpoint Saving Performance:  • Average sample time per batch: 0.03s  • Average time: 1.05s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total checkpoints saved: 1  • Min sample time: 0.02s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Min time: 1.05s  • Max sample time: 0.07s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Average save time per checkpoint: 186.38s  • Max time: 1.05s  • Total batch sample time: 0.32s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total time: 1.05s  • Min save time: 186.38s
[36m(head, rank=0, pid=3505)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Performance:  • Total checkpoints saved: 1  • Max save time: 186.38s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Average time: 1083.12s  • Total checkpoint save time: 186.38s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Average save time per checkpoint: 186.38s  • Min time: 1083.12s
[36m(head, rank=0, pid=3505)[0m Overall Run Performance:
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Max time: 1083.12s  • Min save time: 186.38s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total time: 1083.12s  • Max save time: 186.38s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Step Performance:  • Average total time per run: 1086.27s
[36m(head, rank=0, pid=3505)[0m   • Total checkpoint save time: 186.38s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Min total time: 1086.27s
[36m(head, rank=0, pid=3505)[0m Overall Run Performance:  • Total training steps: 80
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Max total time: 1086.27s  • Average total time per run: 1086.41s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Average step time per step: 4.47s  • Total time across all runs: 1086.27s
[36m(head, rank=0, pid=3505)[0m   • Min total time: 1086.41s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m ================================================================================  • Min step time: 3.67s  • Max total time: 1086.41s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Max step time: 9.28s  • Total time across all runs: 1086.41s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m ================================================================================  • Total training step time: 357.42s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3505)[0m   • Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3505)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   • Max sample time: 0.08s
[36m(head, rank=0, pid=3505)[0m   • Total batch sample time: 0.34s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3505)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   • Average save time per checkpoint: 186.38s
[36m(head, rank=0, pid=3505)[0m   • Min save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   • Max save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   • Total checkpoint save time: 186.38s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Overall Run Performance:
[36m(head, rank=0, pid=3505)[0m   • Average total time per run: 1086.25s
[36m(head, rank=0, pid=3505)[0m   • Min total time: 1086.25s
[36m(head, rank=0, pid=3505)[0m   • Max total time: 1086.25s
[36m(head, rank=0, pid=3505)[0m   • Total time across all runs: 1086.25s
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Saved timing summary to: timing_summary_7.json
[36m(head, rank=0, pid=3505)[0m Saved timing summary to: timing_summary_2.json
[36m(head, rank=0, pid=3505)[0m Saved timing summary to: timing_summary_3.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 2.14s
[36m(head, rank=0, pid=3505)[0m   • Min time: 2.14s
[36m(head, rank=0, pid=3505)[0m   • Max time: 2.14s
[36m(head, rank=0, pid=3505)[0m   • Total time: 2.14s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Model Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 1.05s
[36m(head, rank=0, pid=3505)[0m   • Min time: 1.05s
[36m(head, rank=0, pid=3505)[0m   • Max time: 1.05s
[36m(head, rank=0, pid=3505)[0m   • Total time: 1.05s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 1083.07s
[36m(head, rank=0, pid=3505)[0m   • Min time: 1083.07s
[36m(head, rank=0, pid=3505)[0m   • Max time: 1083.07s
[36m(head, rank=0, pid=3505)[0m   • Total time: 1083.07s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3505)[0m   • Average step time per step: 4.46s
[36m(head, rank=0, pid=3505)[0m   • Min step time: 3.66s
[36m(head, rank=0, pid=3505)[0m   • Max step time: 9.29s
[36m(head, rank=0, pid=3505)[0m   • Total training step time: 356.63s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3505)[0m   • Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3505)[0m   • Min sample time: 0.02s
[36m(head, rank=0, pid=3505)[0m   • Max sample time: 0.07s
[36m(head, rank=0, pid=3505)[0m   • Total batch sample time: 0.33s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3505)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   • Average save time per checkpoint: 186.38s
[36m(head, rank=0, pid=3505)[0m   • Min save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   • Max save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   • Total checkpoint save time: 186.38s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Overall Run Performance:
[36m(head, rank=0, pid=3505)[0m   • Average total time per run: 1086.25s
[36m(head, rank=0, pid=3505)[0m   • Min total time: 1086.25s
[36m(head, rank=0, pid=3505)[0m   • Max total time: 1086.25s
[36m(head, rank=0, pid=3505)[0m   • Total time across all runs: 1086.25s
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Saved timing summary to: timing_summary_1.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 2.24s
[36m(head, rank=0, pid=3505)[0m   • Min time: 2.24s
[36m(head, rank=0, pid=3505)[0m   • Max time: 2.24s
[36m(head, rank=0, pid=3505)[0m   • Total time: 2.24s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Model Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 0.98s
[36m(head, rank=0, pid=3505)[0m   • Min time: 0.98s
[36m(head, rank=0, pid=3505)[0m   • Max time: 0.98s
[36m(head, rank=0, pid=3505)[0m   • Total time: 0.98s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 1083.06s
[36m(head, rank=0, pid=3505)[0m   • Min time: 1083.06s
[36m(head, rank=0, pid=3505)[0m   • Max time: 1083.06s
[36m(head, rank=0, pid=3505)[0m   • Total time: 1083.06s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3505)[0m   • Average step time per step: 4.46s
[36m(head, rank=0, pid=3505)[0m   • Min step time: 3.66s
[36m(head, rank=0, pid=3505)[0m   • Max step time: 9.28s
[36m(head, rank=0, pid=3505)[0m   • Total training step time: 356.80s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3505)[0m   • Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3505)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   • Max sample time: 0.08s
[36m(head, rank=0, pid=3505)[0m   • Total batch sample time: 0.35s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3505)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   • Average save time per checkpoint: 186.38s
[36m(head, rank=0, pid=3505)[0m   • Min save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   • Max save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   • Total checkpoint save time: 186.38s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Overall Run Performance:
[36m(head, rank=0, pid=3505)[0m   • Average total time per run: 1086.28s
[36m(head, rank=0, pid=3505)[0m   • Min total time: 1086.28s
[36m(head, rank=0, pid=3505)[0m   • Max total time: 1086.28s
[36m(head, rank=0, pid=3505)[0m   • Total time across all runs: 1086.28s
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Saved timing summary to: timing_summary_6.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 2.36s
[36m(head, rank=0, pid=3505)[0m   • Min time: 2.36s
[36m(head, rank=0, pid=3505)[0m   • Max time: 2.36s
[36m(head, rank=0, pid=3505)[0m   • Total time: 2.36s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Model Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 1.02s
[36m(head, rank=0, pid=3505)[0m   • Min time: 1.02s
[36m(head, rank=0, pid=3505)[0m   • Max time: 1.02s
[36m(head, rank=0, pid=3505)[0m   • Total time: 1.02s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 1083.03s
[36m(head, rank=0, pid=3505)[0m   • Min time: 1083.03s
[36m(head, rank=0, pid=3505)[0m   • Max time: 1083.03s
[36m(head, rank=0, pid=3505)[0m   • Total time: 1083.03s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3505)[0m   • Average step time per step: 4.46s
[36m(head, rank=0, pid=3505)[0m   • Min step time: 3.67s
[36m(head, rank=0, pid=3505)[0m   • Max step time: 9.27s
[36m(head, rank=0, pid=3505)[0m   • Total training step time: 356.62s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3505)[0m   • Average sample time per batch: 0.04s
[36m(head, rank=0, pid=3505)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   • Max sample time: 0.08s
[36m(head, rank=0, pid=3505)[0m   • Total batch sample time: 0.38s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3505)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   • Average save time per checkpoint: 186.38s
[36m(head, rank=0, pid=3505)[0m   • Min save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   • Max save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   • Total checkpoint save time: 186.38s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Overall Run Performance:
[36m(head, rank=0, pid=3505)[0m   • Average total time per run: 1086.42s
[36m(head, rank=0, pid=3505)[0m   • Min total time: 1086.42s
[36m(head, rank=0, pid=3505)[0m   • Max total time: 1086.42s
[36m(head, rank=0, pid=3505)[0m   • Total time across all runs: 1086.42s
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Saved timing summary to: timing_summary_4.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 2.25s
[36m(head, rank=0, pid=3505)[0m   • Min time: 2.25s
[36m(head, rank=0, pid=3505)[0m   • Max time: 2.25s
[36m(head, rank=0, pid=3505)[0m   • Total time: 2.25s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Model Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 21.50s
[36m(head, rank=0, pid=3505)[0m   • Min time: 21.50s
[36m(head, rank=0, pid=3505)[0m   • Max time: 21.50s
[36m(head, rank=0, pid=3505)[0m   • Total time: 21.50s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 1063.00s
[36m(head, rank=0, pid=3505)[0m   • Min time: 1063.00s
[36m(head, rank=0, pid=3505)[0m   • Max time: 1063.00s
[36m(head, rank=0, pid=3505)[0m   • Total time: 1063.00s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3505)[0m   • Average step time per step: 4.45s
[36m(head, rank=0, pid=3505)[0m   • Min step time: 3.66s
[36m(head, rank=0, pid=3505)[0m   • Max step time: 8.18s
[36m(head, rank=0, pid=3505)[0m   • Total training step time: 356.28s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3505)[0m   • Average sample time per batch: 0.04s
[36m(head, rank=0, pid=3505)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   • Max sample time: 0.07s
[36m(head, rank=0, pid=3505)[0m   • Total batch sample time: 0.35s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3505)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   • Average save time per checkpoint: 316.56s
[36m(head, rank=0, pid=3505)[0m   • Min save time: 316.56s
[36m(head, rank=0, pid=3505)[0m   • Max save time: 316.56s
[36m(head, rank=0, pid=3505)[0m   • Total checkpoint save time: 316.56s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Overall Run Performance:
[36m(head, rank=0, pid=3505)[0m   • Average total time per run: 1086.74s
[36m(head, rank=0, pid=3505)[0m   • Min total time: 1086.74s
[36m(head, rank=0, pid=3505)[0m   • Max total time: 1086.74s
[36m(head, rank=0, pid=3505)[0m   • Total time across all runs: 1086.74s
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Saved timing summary to: timing_summary_0.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 2.15s
[36m(head, rank=0, pid=3505)[0m   • Min time: 2.15s
[36m(head, rank=0, pid=3505)[0m   • Max time: 2.15s
[36m(head, rank=0, pid=3505)[0m   • Total time: 2.15s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Model Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 1.05s
[36m(head, rank=0, pid=3505)[0m   • Min time: 1.05s
[36m(head, rank=0, pid=3505)[0m   • Max time: 1.05s
[36m(head, rank=0, pid=3505)[0m   • Total time: 1.05s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 1083.08s
[36m(head, rank=0, pid=3505)[0m   • Min time: 1083.08s
[36m(head, rank=0, pid=3505)[0m   • Max time: 1083.08s
[36m(head, rank=0, pid=3505)[0m   • Total time: 1083.08s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3505)[0m   • Average step time per step: 4.47s
[36m(head, rank=0, pid=3505)[0m   • Min step time: 3.67s
[36m(head, rank=0, pid=3505)[0m   • Max step time: 9.30s
[36m(head, rank=0, pid=3505)[0m   • Total training step time: 357.49s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3505)[0m   • Average sample time per batch: 0.03s
[36m(head, rank=0, pid=3505)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   • Max sample time: 0.07s
[36m(head, rank=0, pid=3505)[0m   • Total batch sample time: 0.34s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3505)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   • Average save time per checkpoint: 186.38s
[36m(head, rank=0, pid=3505)[0m   • Min save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   • Max save time: 186.38s
[36m(head, rank=0, pid=3505)[0m   • Total checkpoint save time: 186.38s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Overall Run Performance:
[36m(head, rank=0, pid=3505)[0m   • Average total time per run: 1086.27s
[36m(head, rank=0, pid=3505)[0m   • Min total time: 1086.27s
[36m(head, rank=0, pid=3505)[0m   • Max total time: 1086.27s
[36m(head, rank=0, pid=3505)[0m   • Total time across all runs: 1086.27s
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Saved timing summary to: timing_summary_5.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 2.14s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 2.14s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 2.14s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 2.14s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 0.97s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 0.97s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 0.97s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 0.97s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1083.13s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1083.13s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 1083.13s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 1083.13s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average step time per step: 4.46s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min step time: 3.66s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max step time: 9.28s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training step time: 356.42s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average sample time per batch: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max sample time: 0.08s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch sample time: 0.34s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average save time per checkpoint: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoint save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average total time per run: 1086.24s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min total time: 1086.24s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max total time: 1086.24s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time across all runs: 1086.24s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved timing summary to: timing_summary_1.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 2.26s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 2.26s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 2.26s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 2.26s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1.17s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1.17s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 1.17s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 1.17s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1083.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1083.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 1083.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 1083.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average step time per step: 4.46s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min step time: 3.66s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max step time: 9.28s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training step time: 356.89s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average sample time per batch: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min sample time: 0.02s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max sample time: 0.08s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch sample time: 0.34s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average save time per checkpoint: 186.39s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min save time: 186.39s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max save time: 186.39s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoint save time: 186.39s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average total time per run: 1086.48s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min total time: 1086.48s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max total time: 1086.48s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time across all runs: 1086.48s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved timing summary to: timing_summary_4.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 2.13s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 2.13s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 2.13s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 2.13s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 0.95s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 0.95s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 0.95s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 0.95s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1083.19s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1083.19s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 1083.19s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 1083.19s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average step time per step: 4.46s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min step time: 3.66s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max step time: 9.27s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training step time: 356.60s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average sample time per batch: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max sample time: 0.08s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch sample time: 0.34s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average save time per checkpoint: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoint save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average total time per run: 1086.26s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min total time: 1086.26s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max total time: 1086.26s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time across all runs: 1086.26s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved timing summary to: timing_summary_3.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 2.14s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 2.14s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 2.14s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 2.14s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 0.96s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 0.96s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 0.96s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 0.96s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1083.10s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1083.10s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 1083.10s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 1083.10s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average step time per step: 4.46s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min step time: 3.66s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max step time: 9.19s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training step time: 356.70s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max sample time: 0.15s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch sample time: 0.41s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average save time per checkpoint: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoint save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average total time per run: 1086.20s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min total time: 1086.20s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max total time: 1086.20s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time across all runs: 1086.20s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved timing summary to: timing_summary_6.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 2.32s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 2.32s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 2.32s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 2.32s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 1.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 1.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1083.08s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1083.08s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 1083.08s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 1083.08s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average step time per step: 4.46s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min step time: 3.66s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max step time: 9.27s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training step time: 357.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max sample time: 0.09s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch sample time: 0.35s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average save time per checkpoint: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoint save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average total time per run: 1086.44s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min total time: 1086.44s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max total time: 1086.44s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time across all runs: 1086.44s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved timing summary to: timing_summary_5.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 2.12s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 2.12s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 2.12s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 2.12s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 0.99s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 0.99s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 0.99s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 0.99s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1083.13s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1083.13s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 1083.13s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 1083.13s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average step time per step: 4.46s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min step time: 3.66s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max step time: 9.21s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training step time: 356.94s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max sample time: 0.13s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch sample time: 0.39s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average save time per checkpoint: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoint save time: 186.38s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average total time per run: 1086.25s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min total time: 1086.25s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max total time: 1086.25s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time across all runs: 1086.25s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved timing summary to: timing_summary_2.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(head, rank=0, pid=3505)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Removing checkpoint exception [Errno 2] No such file or directory: 'pytorch_model-00001-of-00012.bin'
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /mnt/data/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /mnt/data/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /mnt/data/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /mnt/data/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/mnt/data/checkpoints'
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.21 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.20 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.22 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.23 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.26 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.28 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.32 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.39 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.12 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.63 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.14 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.18 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.25 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.30 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.30 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.45 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /mnt/data/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 61.19it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 60.31it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 61.22it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 60.74it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 61.11it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 63.73it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 65.21it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 0.98 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 1.01 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 1.01 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 1.08 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 0.94 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 1.01 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 1.09 seconds
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 63.66it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 61.80it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 60.52it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 0.99 seconds
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 55.45it/s]
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 57.28it/s]
[36m(head, rank=0, pid=3505)[0m Completed Load model in 1.08 seconds
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 56.79it/s]
[36m(head, rank=0, pid=3505)[0m Completed Load model in 0.98 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Completed Load model in 1.11 seconds
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 64.77it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Completed Load model in 1.11 seconds
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Completed Load model in 1.25 seconds
[36m(head, rank=0, pid=3505)[0m Completed Load model in 1.10 seconds
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:22,  5.59s/it]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:21,  5.29s/it]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:10<00:15,  5.10s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:10<00:15,  5.33s/it]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:15<00:10,  5.03s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:15<00:10,  5.21s/it]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:20<00:04,  4.97s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:24<00:00,  4.80s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:24<00:00,  4.91s/it]
[36m(head, rank=0, pid=3505)[0m Completed Load model in 25.51 seconds
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:20<00:05,  5.11s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:25<00:00,  4.92s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:25<00:00,  5.07s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 26.18 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:46:51,619] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:46:52,915] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:46:52,994] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:46:53,001] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:46:53,001] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:46:53,005] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:46:53,006] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:46:53,010] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:46:53,015] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:46:53,410] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:46:53,410] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:46:53,413] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:46:53,414] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:46:53,414] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:46:53,414] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:46:53,417] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:46:53,417] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:46:54,238] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:46:54,248] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:46:54,259] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:46:54,259] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:46:54,269] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:46:54,269] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m [2025-08-02 20:46:54,269] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:46:54,586] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:46:54,588] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:46:54,591] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:46:54,607] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:46:54,607] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:46:54,627] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:46:54,627] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 20:46:54,630] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   0%|          | 0/10 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3505)[0m  10%|█         | 1/10 [00:39<05:51, 39.01s/it]
[36m(head, rank=0, pid=3505)[0m  20%|██        | 2/10 [01:15<04:57, 37.24s/it]
[36m(head, rank=0, pid=3505)[0m  30%|███       | 3/10 [01:50<04:14, 36.41s/it]
[36m(head, rank=0, pid=3505)[0m  40%|████      | 4/10 [02:25<03:36, 36.02s/it]
[36m(head, rank=0, pid=3505)[0m  50%|█████     | 5/10 [03:02<03:01, 36.26s/it]
[36m(head, rank=0, pid=3505)[0m  60%|██████    | 6/10 [03:37<02:22, 35.74s/it]
[36m(head, rank=0, pid=3505)[0m  70%|███████   | 7/10 [04:13<01:47, 35.96s/it]
[36m(head, rank=0, pid=3505)[0m  80%|████████  | 8/10 [04:50<01:12, 36.21s/it]
[36m(head, rank=0, pid=3505)[0m  90%|█████████ | 9/10 [05:25<00:35, 35.82s/it]100%|██████████| 10/10 [05:59<00:00, 35.28s/it]Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m                                                {'loss': 124.4492, 'grad_norm': 35.656002044677734, 'learning_rate': 2.0000000000000003e-06, 'num_tokens': 9501248.0, 'epoch': 0.03}
[36m(head, rank=0, pid=3505)[0m 100%|██████████| 10/10 [05:59<00:00, 35.28s/it]Starting Save checkpoint...
[36m(head, rank=0, pid=3505)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Save checkpoint...Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Save checkpoint...Starting Save checkpoint...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Save checkpoint...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Save checkpoint in 368.04 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint save time: 368.04s (Total: 368.04s)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Save checkpoint in 368.04 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint save time: 368.04s (Total: 368.04s)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Save checkpoint in 368.04 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint save time: 368.04s (Total: 368.04s)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Save checkpoint in 368.05 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint save time: 368.05s (Total: 368.05s)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Save checkpoint in 368.05 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint save time: 368.05s (Total: 368.05s)
[36m(head, rank=0, pid=3505)[0m Completed Save checkpoint in 368.04 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint save time: 368.04s (Total: 368.04s)
[36m(head, rank=0, pid=3505)[0m Completed Save checkpoint in 368.04 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint save time: 368.04s (Total: 368.04s)
[36m(head, rank=0, pid=3505)[0m Completed Save checkpoint in 368.04 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint save time: 368.04s (Total: 368.04s)
[36m(head, rank=0, pid=3505)[0m Completed Save checkpoint in 368.05 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint save time: 368.05s (Total: 368.05s)
[36m(head, rank=0, pid=3505)[0m Completed Save checkpoint in 368.05 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint save time: 368.05s (Total: 368.05s)
[36m(head, rank=0, pid=3505)[0m Completed Save checkpoint in 368.05 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint save time: 368.05s (Total: 368.05s)
[36m(head, rank=0, pid=3505)[0m Completed Save checkpoint in 368.05 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint save time: 368.05s (Total: 368.05s)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Save checkpoint in 368.05 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint save time: 368.05s (Total: 368.05s)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Save checkpoint in 368.05 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint save time: 368.05s (Total: 368.05s)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Save checkpoint in 368.05 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint save time: 368.05s (Total: 368.05s)
[36m(head, rank=0, pid=3505)[0m Completed Save checkpoint in 717.15 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint save time: 717.15s (Total: 717.15s)
[36m(head, rank=0, pid=3505)[0m                                                {'train_runtime': 1076.6241, 'train_samples_per_second': 1.189, 'train_steps_per_second': 0.009, 'train_loss': 124.44921875, 'epoch': 0.03}
[36m(head, rank=0, pid=3505)[0m 100%|██████████| 10/10 [17:56<00:00, 35.28s/it]100%|██████████| 10/10 [17:56<00:00, 107.66s/it]
[36m(head, rank=0, pid=3505)[0m Completed Training in 1133.10 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3505)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   - Total checkpoint save time: 368.05s
[36m(head, rank=0, pid=3505)[0m   - Average save time per checkpoint: 368.05s
[36m(head, rank=0, pid=3505)[0m   - Min save time: 368.05s
[36m(head, rank=0, pid=3505)[0m   - Max save time: 368.05s
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3505)[0m   - Total batch sample time: 0.50s
[36m(head, rank=0, pid=3505)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3505)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   - Max batch sample time: 0.13s
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3505)[0m   - Total training step time: 319.42s
[36m(head, rank=0, pid=3505)[0m   - Average training step time: 3.99s
[36m(head, rank=0, pid=3505)[0m   - Min training step time: 3.52s
[36m(head, rank=0, pid=3505)[0m   - Max training step time: 6.66s
[36m(head, rank=0, pid=3505)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3505)[0m Completed Training in 1133.18 seconds
[36m(head, rank=0, pid=3505)[0m Completed Training in 1133.28 secondsCheckpoint Save Statistics:
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   - Total checkpoint save time: 368.04s
[36m(head, rank=0, pid=3505)[0m   - Average save time per checkpoint: 368.04s
[36m(head, rank=0, pid=3505)[0m   - Min save time: 368.04s
[36m(head, rank=0, pid=3505)[0m   - Max save time: 368.04s
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3505)[0m   - Total batch sample time: 0.54s
[36m(head, rank=0, pid=3505)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3505)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   - Max batch sample time: 0.16s
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3505)[0m   - Total training step time: 319.96s
[36m(head, rank=0, pid=3505)[0m   - Average training step time: 4.00s
[36m(head, rank=0, pid=3505)[0m   - Min training step time: 3.51s
[36m(head, rank=0, pid=3505)[0m   - Max training step time: 6.63s
[36m(head, rank=0, pid=3505)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3505)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3505)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   - Total checkpoint save time: 368.04s
[36m(head, rank=0, pid=3505)[0m   - Average save time per checkpoint: 368.04s
[36m(head, rank=0, pid=3505)[0m   - Min save time: 368.04s
[36m(head, rank=0, pid=3505)[0m   - Max save time: 368.04s
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3505)[0m   - Total batch sample time: 0.46s
[36m(head, rank=0, pid=3505)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3505)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   - Max batch sample time: 0.13s
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3505)[0m   - Total training step time: 319.52s
[36m(head, rank=0, pid=3505)[0m   - Average training step time: 3.99s
[36m(head, rank=0, pid=3505)[0m   - Min training step time: 3.52s
[36m(head, rank=0, pid=3505)[0m   - Max training step time: 6.66s
[36m(head, rank=0, pid=3505)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3505)[0m Completed Training in 1133.11 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3505)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   - Total checkpoint save time: 368.05s
[36m(head, rank=0, pid=3505)[0m   - Average save time per checkpoint: 368.05s
[36m(head, rank=0, pid=3505)[0m   - Min save time: 368.05s
[36m(head, rank=0, pid=3505)[0m   - Max save time: 368.05s
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3505)[0m   - Total batch sample time: 0.52s
[36m(head, rank=0, pid=3505)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3505)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   - Max batch sample time: 0.16s
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3505)[0m   - Total training step time: 319.49s
[36m(head, rank=0, pid=3505)[0m   - Average training step time: 3.99s
[36m(head, rank=0, pid=3505)[0m   - Min training step time: 3.55s
[36m(head, rank=0, pid=3505)[0m   - Max training step time: 6.64s
[36m(head, rank=0, pid=3505)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3505)[0m Completed Training in 1133.18 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3505)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   - Total checkpoint save time: 368.05s
[36m(head, rank=0, pid=3505)[0m   - Average save time per checkpoint: 368.05s
[36m(head, rank=0, pid=3505)[0m   - Min save time: 368.05s
[36m(head, rank=0, pid=3505)[0m   - Max save time: 368.05s
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3505)[0m   - Total batch sample time: 0.52s
[36m(head, rank=0, pid=3505)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3505)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   - Max batch sample time: 0.16s
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3505)[0m   - Total training step time: 319.65s
[36m(head, rank=0, pid=3505)[0m   - Average training step time: 4.00s
[36m(head, rank=0, pid=3505)[0m   - Min training step time: 3.51s
[36m(head, rank=0, pid=3505)[0m   - Max training step time: 6.63s
[36m(head, rank=0, pid=3505)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3505)[0m Completed Training in 1109.48 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3505)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   - Total checkpoint save time: 717.15s
[36m(head, rank=0, pid=3505)[0m   - Average save time per checkpoint: 717.15s
[36m(head, rank=0, pid=3505)[0m   - Min save time: 717.15s
[36m(head, rank=0, pid=3505)[0m   - Max save time: 717.15s
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3505)[0m   - Total batch sample time: 0.48s
[36m(head, rank=0, pid=3505)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3505)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   - Max batch sample time: 0.10s
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3505)[0m   - Total training step time: 318.95s
[36m(head, rank=0, pid=3505)[0m   - Average training step time: 3.99s
[36m(head, rank=0, pid=3505)[0m   - Min training step time: 3.52s
[36m(head, rank=0, pid=3505)[0m   - Max training step time: 5.61s
[36m(head, rank=0, pid=3505)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3505)[0m Saved training info to: /mnt/data/training_run_7_1_info.json
[36m(head, rank=0, pid=3505)[0m Completed run 1/1
[36m(head, rank=0, pid=3505)[0m Saved training info to: /mnt/data/training_run_5_1_info.json
[36m(head, rank=0, pid=3505)[0m Completed run 1/1
[36m(head, rank=0, pid=3505)[0m Saved training info to: /mnt/data/training_run_1_1_info.json
[36m(head, rank=0, pid=3505)[0m Completed run 1/1
[36m(head, rank=0, pid=3505)[0m Saved training info to: /mnt/data/training_run_4_1_info.jsonSaved training info to: /mnt/data/training_run_6_1_info.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Completed run 1/1
[36m(head, rank=0, pid=3505)[0m Completed run 1/1
[36m(head, rank=0, pid=3505)[0m Saved training info to: /mnt/data/training_run_0_1_info.json
[36m(head, rank=0, pid=3505)[0m Completed run 1/1
[36m(head, rank=0, pid=3505)[0m Completed Training in 1133.86 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3505)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   - Total checkpoint save time: 368.04s
[36m(head, rank=0, pid=3505)[0m   - Average save time per checkpoint: 368.04s
[36m(head, rank=0, pid=3505)[0m   - Min save time: 368.04s
[36m(head, rank=0, pid=3505)[0m   - Max save time: 368.04s
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3505)[0m   - Total batch sample time: 0.52s
[36m(head, rank=0, pid=3505)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3505)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   - Max batch sample time: 0.15s
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3505)[0m   - Total training step time: 320.18s
[36m(head, rank=0, pid=3505)[0m   - Average training step time: 4.00s
[36m(head, rank=0, pid=3505)[0m   - Min training step time: 3.54s
[36m(head, rank=0, pid=3505)[0m   - Max training step time: 6.64s
[36m(head, rank=0, pid=3505)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3505)[0m Completed Training in 1133.11 seconds
[36m(head, rank=0, pid=3505)[0m Checkpoint Save Statistics:
[36m(head, rank=0, pid=3505)[0m   - Number of checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   - Total checkpoint save time: 368.05s
[36m(head, rank=0, pid=3505)[0m   - Average save time per checkpoint: 368.05s
[36m(head, rank=0, pid=3505)[0m   - Min save time: 368.05s
[36m(head, rank=0, pid=3505)[0m   - Max save time: 368.05s
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of batch samples: 10
[36m(head, rank=0, pid=3505)[0m   - Total batch sample time: 0.50s
[36m(head, rank=0, pid=3505)[0m   - Average batch sample time: 0.05s
[36m(head, rank=0, pid=3505)[0m   - Min batch sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   - Max batch sample time: 0.16s
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   - Number of training steps: 80
[36m(head, rank=0, pid=3505)[0m   - Total training step time: 318.88s
[36m(head, rank=0, pid=3505)[0m   - Average training step time: 3.99s
[36m(head, rank=0, pid=3505)[0m   - Min training step time: 3.53s
[36m(head, rank=0, pid=3505)[0m   - Max training step time: 6.63s
[36m(head, rank=0, pid=3505)[0m Training completed successfully for run 1
[36m(head, rank=0, pid=3505)[0m Saved training info to: /mnt/data/training_run_3_1_info.json
[36m(head, rank=0, pid=3505)[0m Completed run 1/1
[36m(head, rank=0, pid=3505)[0m Saved training info to: /mnt/data/training_run_2_1_info.json
[36m(head, rank=0, pid=3505)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 1133.83 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total checkpoint save time: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average save time per checkpoint: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min save time: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max save time: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total batch sample time: 0.51s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average batch sample time: 0.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max batch sample time: 0.16s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total training step time: 320.01s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average training step time: 4.00s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min training step time: 3.52s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max training step time: 6.63s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 1133.87 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 1133.87 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 1109.15 secondsCheckpoint Save Statistics:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Save Statistics:  - Total checkpoint save time: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average save time per checkpoint: 368.04s  - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min save time: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total checkpoint save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max save time: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average save time per checkpoint: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total batch sample time: 0.54s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average batch sample time: 0.05s  - Number of batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total batch sample time: 0.55s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max batch sample time: 0.15s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average batch sample time: 0.05sTraining Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min batch sample time: 0.03s  - Number of training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max batch sample time: 0.16s  - Total training step time: 319.75s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average training step time: 4.00s  - Number of training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min training step time: 3.51s  - Total training step time: 320.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max training step time: 6.64s  - Average training step time: 4.00s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training completed successfully for run 1  - Min training step time: 3.52s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max training step time: 6.63s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 1133.90 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of checkpoints saved: 1Completed Training in 1133.83 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total checkpoint save time: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average save time per checkpoint: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min save time: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max save time: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total batch sample time: 0.45s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average batch sample time: 0.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max batch sample time: 0.08s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total training step time: 318.72s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average training step time: 3.98s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min training step time: 3.52s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max training step time: 5.21s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total checkpoint save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 1133.91 seconds  - Average save time per checkpoint: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Save Statistics:  - Total batch sample time: 0.45s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average batch sample time: 0.04s  - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total checkpoint save time: 368.05s  - Max batch sample time: 0.13s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:  - Average save time per checkpoint: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of training steps: 80  - Min save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total training step time: 319.47s  - Max save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average training step time: 3.99sBatch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min training step time: 3.51s  - Number of batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max training step time: 6.67s  - Total batch sample time: 0.55s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training completed successfully for run 1  - Average batch sample time: 0.06s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max batch sample time: 0.17s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total training step time: 320.18s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average training step time: 4.00s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min training step time: 3.58s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max training step time: 6.63s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total checkpoint save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average save time per checkpoint: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total batch sample time: 0.51s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average batch sample time: 0.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max batch sample time: 0.17s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total training step time: 319.50s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average training step time: 3.99s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min training step time: 3.54s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max training step time: 6.62s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 1133.96 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Save Statistics:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total checkpoint save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average save time per checkpoint: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total batch sample time: 0.52s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average batch sample time: 0.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min batch sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max batch sample time: 0.16s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Number of training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Total training step time: 319.80s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Average training step time: 4.00s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Min training step time: 3.51s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   - Max training step time: 6.64s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training completed successfully for run 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved training info to: /mnt/data/training_run_2_1_info.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved training info to: /mnt/data/training_run_5_1_info.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved training info to: /mnt/data/training_run_7_1_info.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved training info to: /mnt/data/training_run_0_1_info.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved training info to: /mnt/data/training_run_3_1_info.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved training info to: /mnt/data/training_run_6_1_info.jsonSaved training info to: /mnt/data/training_run_1_1_info.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed run 1/1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved training info to: /mnt/data/training_run_4_1_info.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed run 1/1
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m TRAINING PERFORMANCE SUMMARYTotal Runs Completed: 1
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3505)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 2.14s
[36m(head, rank=0, pid=3505)[0m   • Min time: 2.14s  • Average time: 2.25s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Min time: 2.25s
[36m(head, rank=0, pid=3505)[0m   • Max time: 2.14s
[36m(head, rank=0, pid=3505)[0m   • Total time: 2.14s
[36m(head, rank=0, pid=3505)[0m   • Max time: 2.25s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Model Loading Performance:  • Total time: 2.25s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Average time: 1.08s
[36m(head, rank=0, pid=3505)[0m Model Loading Performance:
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Average time: 1.11s
[36m(head, rank=0, pid=3505)[0m   • Min time: 1.08s
[36m(head, rank=0, pid=3505)[0m   • Min time: 1.11s  • Max time: 1.08s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Max time: 1.11s  • Total time: 1.08s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Performance:  • Total time: 1.11s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Average time: 1133.28s
[36m(head, rank=0, pid=3505)[0m Training Performance:
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Min time: 1133.28s  • Average time: 1133.18s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Max time: 1133.28s  • Min time: 1133.18s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total time: 1133.28s  • Max time: 1133.18s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   • Total time: 1133.18s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3505)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3505)[0m   • Average step time per step: 3.99s
[36m(head, rank=0, pid=3505)[0m   • Min step time: 3.52s  • Average step time per step: 4.00s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Max step time: 6.66s  • Min step time: 3.51s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total training step time: 319.52s  • Max step time: 6.63s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:  • Total training step time: 319.96s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3505)[0m   • Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3505)[0m   • Average sample time per batch: 0.05s  • Min sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Min sample time: 0.03s  • Max sample time: 0.13s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Max sample time: 0.16s  • Total batch sample time: 0.46s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total batch sample time: 0.54s
[36m(head, rank=0, pid=3505)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Checkpoint Saving Performance:  • Total checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   • Average save time per checkpoint: 368.04s
[36m(head, rank=0, pid=3505)[0m   • Average save time per checkpoint: 368.04s  • Min save time: 368.04s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Min save time: 368.04s  • Max save time: 368.04s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Max save time: 368.04s  • Total checkpoint save time: 368.04s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total checkpoint save time: 368.04s
[36m(head, rank=0, pid=3505)[0m Overall Run Performance:
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Overall Run Performance:
[36m(head, rank=0, pid=3505)[0m   • Average total time per run: 1136.50s
[36m(head, rank=0, pid=3505)[0m   • Average total time per run: 1136.53s  • Min total time: 1136.50s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Min total time: 1136.53s  • Max total time: 1136.50s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Max total time: 1136.53s  • Total time across all runs: 1136.50s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total time across all runs: 1136.53s================================================================================
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Saved timing summary to: timing_summary_5.json
[36m(head, rank=0, pid=3505)[0m Saved timing summary to: timing_summary_1.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 2.45s
[36m(head, rank=0, pid=3505)[0m   • Min time: 2.45s
[36m(head, rank=0, pid=3505)[0m   • Max time: 2.45s
[36m(head, rank=0, pid=3505)[0m   • Total time: 2.45s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Model Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 1.10s
[36m(head, rank=0, pid=3505)[0m   • Min time: 1.10s
[36m(head, rank=0, pid=3505)[0m   • Max time: 1.10s
[36m(head, rank=0, pid=3505)[0m   • Total time: 1.10s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Performance:
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m ================================================================================  • Average time: 1133.10s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3505)[0m   • Min time: 1133.10s================================================================================
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Max time: 1133.10sTotal Runs Completed: 1
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total time: 1133.10s
[36m(head, rank=0, pid=3505)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3505)[0m   • Average step time per step: 3.99s
[36m(head, rank=0, pid=3505)[0m   • Average time: 2.30s
[36m(head, rank=0, pid=3505)[0m   • Min step time: 3.52s
[36m(head, rank=0, pid=3505)[0m   • Min time: 2.30s
[36m(head, rank=0, pid=3505)[0m   • Max step time: 6.66s
[36m(head, rank=0, pid=3505)[0m   • Total training step time: 319.42s  • Max time: 2.30s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:  • Total time: 2.30s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3505)[0m Model Loading Performance:
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Average time: 0.98s
[36m(head, rank=0, pid=3505)[0m   • Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3505)[0m   • Min time: 0.98s  • Min sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Max time: 0.98s  • Max sample time: 0.13s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total time: 0.98s
[36m(head, rank=0, pid=3505)[0m   • Total batch sample time: 0.50s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Performance:
[36m(head, rank=0, pid=3505)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total checkpoints saved: 1  • Average time: 1133.18s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Min time: 1133.18s
[36m(head, rank=0, pid=3505)[0m   • Average save time per checkpoint: 368.05s  • Max time: 1133.18s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Min save time: 368.05s  • Total time: 1133.18s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Step Performance:  • Max save time: 368.05s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total checkpoint save time: 368.05s
[36m(head, rank=0, pid=3505)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Overall Run Performance:
[36m(head, rank=0, pid=3505)[0m   • Average step time per step: 4.00s  • Average total time per run: 1136.64s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Min total time: 1136.64s  • Min step time: 3.51s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Max total time: 1136.64s  • Max step time: 6.63s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total time across all runs: 1136.64s  • Total training step time: 319.65s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3505)[0m   • Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3505)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   • Max sample time: 0.16s
[36m(head, rank=0, pid=3505)[0m   • Total batch sample time: 0.52s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3505)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   • Average save time per checkpoint: 368.05s
[36m(head, rank=0, pid=3505)[0m   • Min save time: 368.05s
[36m(head, rank=0, pid=3505)[0m   • Max save time: 368.05s
[36m(head, rank=0, pid=3505)[0m   • Total checkpoint save time: 368.05s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Overall Run Performance:
[36m(head, rank=0, pid=3505)[0m   • Average total time per run: 1136.46s
[36m(head, rank=0, pid=3505)[0m   • Min total time: 1136.46s
[36m(head, rank=0, pid=3505)[0m   • Max total time: 1136.46s
[36m(head, rank=0, pid=3505)[0m   • Total time across all runs: 1136.46s
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Saved timing summary to: timing_summary_7.json
[36m(head, rank=0, pid=3505)[0m Saved timing summary to: timing_summary_4.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 2.30s
[36m(head, rank=0, pid=3505)[0m   • Min time: 2.30s
[36m(head, rank=0, pid=3505)[0m   • Max time: 2.30s
[36m(head, rank=0, pid=3505)[0m   • Total time: 2.30s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Model Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 1.11s
[36m(head, rank=0, pid=3505)[0m   • Min time: 1.11s
[36m(head, rank=0, pid=3505)[0m   • Max time: 1.11s
[36m(head, rank=0, pid=3505)[0m   • Total time: 1.11s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 1133.11s
[36m(head, rank=0, pid=3505)[0m   • Min time: 1133.11s
[36m(head, rank=0, pid=3505)[0m   • Max time: 1133.11s
[36m(head, rank=0, pid=3505)[0m   • Total time: 1133.11s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3505)[0m   • Average step time per step: 3.99s
[36m(head, rank=0, pid=3505)[0m   • Min step time: 3.55s
[36m(head, rank=0, pid=3505)[0m   • Max step time: 6.64s
[36m(head, rank=0, pid=3505)[0m   • Total training step time: 319.49s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3505)[0m   • Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3505)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   • Max sample time: 0.16s
[36m(head, rank=0, pid=3505)[0m   • Total batch sample time: 0.52s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3505)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   • Average save time per checkpoint: 368.05s
[36m(head, rank=0, pid=3505)[0m   • Min save time: 368.05s
[36m(head, rank=0, pid=3505)[0m   • Max save time: 368.05s
[36m(head, rank=0, pid=3505)[0m   • Total checkpoint save time: 368.05s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Overall Run Performance:
[36m(head, rank=0, pid=3505)[0m   • Average total time per run: 1136.51s
[36m(head, rank=0, pid=3505)[0m   • Min total time: 1136.51s
[36m(head, rank=0, pid=3505)[0m   • Max total time: 1136.51s
[36m(head, rank=0, pid=3505)[0m   • Total time across all runs: 1136.51s
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Saved timing summary to: timing_summary_6.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 2.32s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 2.32s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 2.32s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 2.32s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1.01s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1.01s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 1.01s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 1.01s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1133.83s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1133.83s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 1133.83s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 1133.83s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average step time per step: 4.00s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min step time: 3.52s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max step time: 6.63s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training step time: 320.01s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average sample time per batch: 0.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max sample time: 0.16s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch sample time: 0.51s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average save time per checkpoint: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min save time: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max save time: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoint save time: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average total time per run: 1137.16s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min total time: 1137.16s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max total time: 1137.16s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time across all runs: 1137.16s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved timing summary to: timing_summary_2.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved overall training summary to: all_training_runs_summary_5.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 2.23s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 2.23s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 2.23s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 2.23s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1.08s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1.08s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 1.08s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 1.08s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1133.87s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1133.87s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 1133.87s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 1133.87s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average step time per step: 4.00s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min step time: 3.52s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max step time: 6.63s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training step time: 320.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average sample time per batch: 0.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max sample time: 0.16s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch sample time: 0.55s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average save time per checkpoint: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoint save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average total time per run: 1137.18s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min total time: 1137.18s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max total time: 1137.18s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time across all runs: 1137.18s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved timing summary to: timing_summary_5.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved overall training summary to: all_training_runs_summary_7.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 2.26s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 2.26s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 2.26s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 2.26s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1.09s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1.09s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 1.09s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 1.09s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1133.87s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1133.87s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 1133.87s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 1133.87s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average step time per step: 4.00s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min step time: 3.51s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max step time: 6.64s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training step time: 319.75s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average sample time per batch: 0.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max sample time: 0.15s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch sample time: 0.54s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average save time per checkpoint: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min save time: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max save time: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoint save time: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average total time per run: 1137.22s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min total time: 1137.22s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max total time: 1137.22s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time across all runs: 1137.22s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved timing summary to: timing_summary_7.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 2.39s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 2.39s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 2.39s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 2.39s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 0.94s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 0.94s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 0.94s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 0.94s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1133.83s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1133.83s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 1133.83s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 1133.83s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average step time per step: 4.00s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min step time: 3.58s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max step time: 6.63s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training step time: 320.18s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average sample time per batch: 0.06s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max sample time: 0.17s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch sample time: 0.55s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average save time per checkpoint: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoint save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average total time per run: 1137.16s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min total time: 1137.16s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max total time: 1137.16s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time across all runs: 1137.16s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved timing summary to: timing_summary_3.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved overall training summary to: all_training_runs_summary_6.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 2.22s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 2.22s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 2.22s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 2.22s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 0.98s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 0.98s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 0.98s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 0.98s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1133.96s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1133.96s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 1133.96s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 1133.96s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average step time per step: 4.00s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min step time: 3.51s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max step time: 6.64s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training step time: 319.80s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average sample time per batch: 0.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max sample time: 0.16s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch sample time: 0.52s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average save time per checkpoint: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoint save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average total time per run: 1137.16s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min total time: 1137.16s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max total time: 1137.16s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time across all runs: 1137.16s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved timing summary to: timing_summary_6.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved overall training summary to: all_training_runs_summary_1.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved overall training summary to: all_training_runs_summary_4.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 2.21s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 2.21s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================  • Max time: 2.21s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 2.21s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1.01s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1.01s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 1.01s  • Average time: 2.20s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 1.01s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 2.20s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1133.90s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 2.20s  • Min time: 1133.90s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 2.20s  • Max time: 1133.90s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model Loading Performance:  • Total time: 1133.90s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:  • Average time: 1.01s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1.01s  • Total training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 1.01s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average step time per step: 3.99s  • Total time: 1.01s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Performance:  • Min step time: 3.51s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1133.91s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max step time: 6.67s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1133.91s  • Total training step time: 319.47s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 1133.91s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 1133.91s  • Total batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training steps: 80  • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max sample time: 0.13s  • Average step time per step: 3.99s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch sample time: 0.45s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min step time: 3.54s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoints saved: 1  • Max step time: 6.62s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training step time: 319.50s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:  • Average save time per checkpoint: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch samples: 10  • Min save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average sample time per batch: 0.05s  • Total checkpoint save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Overall Run Performance:  • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average total time per run: 1137.13s  • Max sample time: 0.17s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min total time: 1137.13s  • Total batch sample time: 0.51s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max total time: 1137.13s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time across all runs: 1137.13s  • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average save time per checkpoint: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoint save time: 368.05s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average total time per run: 1137.12s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min total time: 1137.12s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max total time: 1137.12s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time across all runs: 1137.12s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved timing summary to: timing_summary_1.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved timing summary to: timing_summary_4.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m TRAINING PERFORMANCE SUMMARY
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Total Runs Completed: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 2.28s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 2.28s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 2.28s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 2.28s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model Loading Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 26.18s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 26.18s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 26.18s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 26.18s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average time: 1109.15s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min time: 1109.15s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max time: 1109.15s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time: 1109.15s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Training Step Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training steps: 80
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average step time per step: 3.98s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min step time: 3.52s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max step time: 5.21s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total training step time: 318.72s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Batch Sampling Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch samples: 10
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average sample time per batch: 0.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min sample time: 0.03s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max sample time: 0.08s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total batch sample time: 0.45s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint Saving Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoints saved: 1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average save time per checkpoint: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min save time: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max save time: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total checkpoint save time: 368.04s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Overall Run Performance:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Average total time per run: 1137.62s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Min total time: 1137.62s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Max total time: 1137.62s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   • Total time across all runs: 1137.62s
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ================================================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Saved timing summary to: timing_summary_0.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Saved overall training summary to: all_training_runs_summary_0.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 2.63s
[36m(head, rank=0, pid=3505)[0m   • Min time: 2.63s
[36m(head, rank=0, pid=3505)[0m   • Max time: 2.63s
[36m(head, rank=0, pid=3505)[0m   • Total time: 2.63s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Model Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 25.51s
[36m(head, rank=0, pid=3505)[0m   • Min time: 25.51s
[36m(head, rank=0, pid=3505)[0m   • Max time: 25.51s
[36m(head, rank=0, pid=3505)[0m   • Total time: 25.51s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 1109.48s
[36m(head, rank=0, pid=3505)[0m   • Min time: 1109.48s
[36m(head, rank=0, pid=3505)[0m   • Max time: 1109.48s
[36m(head, rank=0, pid=3505)[0m   • Total time: 1109.48s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3505)[0m   • Average step time per step: 3.99s
[36m(head, rank=0, pid=3505)[0m   • Min step time: 3.52s
[36m(head, rank=0, pid=3505)[0m   • Max step time: 5.61s
[36m(head, rank=0, pid=3505)[0m   • Total training step time: 318.95s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3505)[0m   • Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3505)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   • Max sample time: 0.10s
[36m(head, rank=0, pid=3505)[0m   • Total batch sample time: 0.48s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3505)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   • Average save time per checkpoint: 717.15s
[36m(head, rank=0, pid=3505)[0m   • Min save time: 717.15s
[36m(head, rank=0, pid=3505)[0m   • Max save time: 717.15s
[36m(head, rank=0, pid=3505)[0m   • Total checkpoint save time: 717.15s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Overall Run Performance:
[36m(head, rank=0, pid=3505)[0m   • Average total time per run: 1137.62s
[36m(head, rank=0, pid=3505)[0m   • Min total time: 1137.62s
[36m(head, rank=0, pid=3505)[0m   • Max total time: 1137.62s
[36m(head, rank=0, pid=3505)[0m   • Total time across all runs: 1137.62s
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Saved timing summary to: timing_summary_0.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Saved overall training summary to: all_training_runs_summary_2.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 2.18s
[36m(head, rank=0, pid=3505)[0m   • Min time: 2.18s
[36m(head, rank=0, pid=3505)[0m   • Max time: 2.18s
[36m(head, rank=0, pid=3505)[0m   • Total time: 2.18s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Model Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 1.25s
[36m(head, rank=0, pid=3505)[0m   • Min time: 1.25s
[36m(head, rank=0, pid=3505)[0m   • Max time: 1.25s
[36m(head, rank=0, pid=3505)[0m   • Total time: 1.25s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 1133.11s
[36m(head, rank=0, pid=3505)[0m   • Min time: 1133.11s
[36m(head, rank=0, pid=3505)[0m   • Max time: 1133.11s
[36m(head, rank=0, pid=3505)[0m   • Total time: 1133.11s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3505)[0m   • Average step time per step: 3.99s
[36m(head, rank=0, pid=3505)[0m   • Min step time: 3.53s
[36m(head, rank=0, pid=3505)[0m   • Max step time: 6.63s
[36m(head, rank=0, pid=3505)[0m   • Total training step time: 318.88s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3505)[0m   • Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3505)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   • Max sample time: 0.16s
[36m(head, rank=0, pid=3505)[0m   • Total batch sample time: 0.50s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3505)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   • Average save time per checkpoint: 368.05s
[36m(head, rank=0, pid=3505)[0m   • Min save time: 368.05s
[36m(head, rank=0, pid=3505)[0m   • Max save time: 368.05s
[36m(head, rank=0, pid=3505)[0m   • Total checkpoint save time: 368.05s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Overall Run Performance:
[36m(head, rank=0, pid=3505)[0m   • Average total time per run: 1136.54s
[36m(head, rank=0, pid=3505)[0m   • Min total time: 1136.54s
[36m(head, rank=0, pid=3505)[0m   • Max total time: 1136.54s
[36m(head, rank=0, pid=3505)[0m   • Total time across all runs: 1136.54s
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Saved timing summary to: timing_summary_2.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Saved overall training summary to: all_training_runs_summary_3.json
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m TRAINING PERFORMANCE SUMMARY
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Total Runs Completed: 1
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Dataset Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 2.12s
[36m(head, rank=0, pid=3505)[0m   • Min time: 2.12s
[36m(head, rank=0, pid=3505)[0m   • Max time: 2.12s
[36m(head, rank=0, pid=3505)[0m   • Total time: 2.12s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Model Loading Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 0.99s
[36m(head, rank=0, pid=3505)[0m   • Min time: 0.99s
[36m(head, rank=0, pid=3505)[0m   • Max time: 0.99s
[36m(head, rank=0, pid=3505)[0m   • Total time: 0.99s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Performance:
[36m(head, rank=0, pid=3505)[0m   • Average time: 1133.86s
[36m(head, rank=0, pid=3505)[0m   • Min time: 1133.86s
[36m(head, rank=0, pid=3505)[0m   • Max time: 1133.86s
[36m(head, rank=0, pid=3505)[0m   • Total time: 1133.86s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Training Step Performance:
[36m(head, rank=0, pid=3505)[0m   • Total training steps: 80
[36m(head, rank=0, pid=3505)[0m   • Average step time per step: 4.00s
[36m(head, rank=0, pid=3505)[0m   • Min step time: 3.54s
[36m(head, rank=0, pid=3505)[0m   • Max step time: 6.64s
[36m(head, rank=0, pid=3505)[0m   • Total training step time: 320.18s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Batch Sampling Performance:
[36m(head, rank=0, pid=3505)[0m   • Total batch samples: 10
[36m(head, rank=0, pid=3505)[0m   • Average sample time per batch: 0.05s
[36m(head, rank=0, pid=3505)[0m   • Min sample time: 0.03s
[36m(head, rank=0, pid=3505)[0m   • Max sample time: 0.15s
[36m(head, rank=0, pid=3505)[0m   • Total batch sample time: 0.52s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Checkpoint Saving Performance:
[36m(head, rank=0, pid=3505)[0m   • Total checkpoints saved: 1
[36m(head, rank=0, pid=3505)[0m   • Average save time per checkpoint: 368.04s
[36m(head, rank=0, pid=3505)[0m   • Min save time: 368.04s
[36m(head, rank=0, pid=3505)[0m   • Max save time: 368.04s
[36m(head, rank=0, pid=3505)[0m   • Total checkpoint save time: 368.04s
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Overall Run Performance:
[36m(head, rank=0, pid=3505)[0m   • Average total time per run: 1136.97s
[36m(head, rank=0, pid=3505)[0m   • Min total time: 1136.97s
[36m(head, rank=0, pid=3505)[0m   • Max total time: 1136.97s
[36m(head, rank=0, pid=3505)[0m   • Total time across all runs: 1136.97s
[36m(head, rank=0, pid=3505)[0m ================================================================================
[36m(head, rank=0, pid=3505)[0m Saved timing summary to: timing_summary_3.json
[36m(head, rank=0, pid=3505)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /checkpoints_s3/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /checkpoints_s3/checkpoints
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3/checkpoints'
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.76 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.76 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.73 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.71 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.71 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.77 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.78 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.83 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.76 seconds
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.74 secondsStarting Load model...
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.80 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.75 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.77 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.78 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.76 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.76 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /checkpoints_s3/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3505)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  7.34it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  8.11it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  5.04it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  9.45it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  5.63it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  6.36it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  8.97it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  8.96it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  8.34it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  6.23it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  4.91it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  5.91it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00, 10.24it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  8.39it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  7.23it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  7.02it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  8.40it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  7.19it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  4.50it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  8.62it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  6.89it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  6.54it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  6.41it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  8.10it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  6.48it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  8.17it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  8.22it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  9.00it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  8.08it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  8.23it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  9.01it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  5.84it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  9.18it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  8.85it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  7.75it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  8.01it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  7.65it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  7.70it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  8.78it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  7.64it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  7.85it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  7.70it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  8.32it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  7.67it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  8.84it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  9.21it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  8.40it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  7.89it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  8.40it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  8.34it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  7.97it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  7.33it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.26it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.14it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.18it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.90it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.27it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.00it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.16it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.00it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.51it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.10it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.04it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.87it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.87it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.71it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  7.94it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.34it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.15it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.56it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.43it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.53it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.56it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.01it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.34it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.90it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.45it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.29it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.33it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  6.97it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  7.63it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 1.80 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 1.85 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 1.85 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 1.84 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 1.85 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 1.83 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 1.87 seconds
[36m(head, rank=0, pid=3505)[0m Completed Load model in 1.83 seconds
[36m(head, rank=0, pid=3505)[0m Completed Load model in 1.84 seconds
[36m(head, rank=0, pid=3505)[0m Completed Load model in 1.84 seconds
[36m(head, rank=0, pid=3505)[0m Completed Load model in 1.84 seconds
[36m(head, rank=0, pid=3505)[0m Completed Load model in 1.85 seconds
[36m(head, rank=0, pid=3505)[0m Completed Load model in 1.85 seconds
[36m(head, rank=0, pid=3505)[0m Completed Load model in 1.85 seconds
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:10<00:40, 10.11s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:10<00:41, 10.32s/it]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:19<00:29,  9.97s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:20<00:29,  9.98s/it]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:29<00:19,  9.95s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:29<00:19,  9.89s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:39<00:09,  9.93s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:48<00:00,  9.51s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:48<00:00,  9.72s/it]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:39<00:09,  9.90s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:48<00:00,  9.55s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:48<00:00,  9.73s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 49.73 seconds
[36m(head, rank=0, pid=3505)[0m Completed Load model in 49.76 seconds
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Completed Training in 2.77 seconds
[36m(head, rank=0, pid=3505)[0m [rank0]: Traceback (most recent call last):
[36m(head, rank=0, pid=3505)[0m [rank0]:   File "/e2e/train.py", line 712, in <module>
[36m(head, rank=0, pid=3505)[0m [rank0]:     main()
[36m(head, rank=0, pid=3505)[0m [rank0]:   File "/e2e/train.py", line 612, in main
[36m(head, rank=0, pid=3505)[0m [rank0]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3505)[0m [rank0]:   File "/e2e/train.py", line 104, in __init__
[36m(head, rank=0, pid=3505)[0m [rank0]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3505)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3505)[0m [rank0]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3505)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 810, in _prepare_dataset
[36m(head, rank=0, pid=3505)[0m [rank0]:     dataset = dataset.map(
[36m(head, rank=0, pid=3505)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 560, in wrapper
[36m(head, rank=0, pid=3505)[0m [rank0]:     out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
[36m(head, rank=0, pid=3505)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3266, in map
[36m(head, rank=0, pid=3505)[0m [rank0]:     transformed_shards[rank] = load_processed_shard_from_cache(job_kwargs)
[36m(head, rank=0, pid=3505)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3153, in load_processed_shard_from_cache
[36m(head, rank=0, pid=3505)[0m [rank0]:     return Dataset.from_file(shard_kwargs["cache_file_name"], info=info, split=shard.split)
[36m(head, rank=0, pid=3505)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 800, in from_file
[36m(head, rank=0, pid=3505)[0m [rank0]:     table = ArrowReader.read_table(filename, in_memory=in_memory)
[36m(head, rank=0, pid=3505)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/arrow_reader.py", line 329, in read_table
[36m(head, rank=0, pid=3505)[0m [rank0]:     return table_cls.from_file(filename)
[36m(head, rank=0, pid=3505)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/table.py", line 1017, in from_file
[36m(head, rank=0, pid=3505)[0m [rank0]:     table = _memory_mapped_arrow_table_from_file(filename)
[36m(head, rank=0, pid=3505)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/table.py", line 63, in _memory_mapped_arrow_table_from_file
[36m(head, rank=0, pid=3505)[0m [rank0]:     opened_stream = _memory_mapped_record_batch_reader_from_file(filename)
[36m(head, rank=0, pid=3505)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/datasets/table.py", line 49, in _memory_mapped_record_batch_reader_from_file
[36m(head, rank=0, pid=3505)[0m [rank0]:     return pa.ipc.open_stream(memory_mapped_stream)
[36m(head, rank=0, pid=3505)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/pyarrow/ipc.py", line 187, in open_stream
[36m(head, rank=0, pid=3505)[0m [rank0]:     return RecordBatchStreamReader(source, options=options,
[36m(head, rank=0, pid=3505)[0m [rank0]:   File "/root/training/lib/python3.10/site-packages/pyarrow/ipc.py", line 52, in __init__
[36m(head, rank=0, pid=3505)[0m [rank0]:     self._open(source, options=options, memory_pool=memory_pool)
[36m(head, rank=0, pid=3505)[0m [rank0]:   File "pyarrow/ipc.pxi", line 1038, in pyarrow.lib._RecordBatchStreamReader._open
[36m(head, rank=0, pid=3505)[0m [rank0]:   File "pyarrow/error.pxi", line 155, in pyarrow.lib.pyarrow_internal_check_status
[36m(head, rank=0, pid=3505)[0m [rank0]:   File "pyarrow/error.pxi", line 92, in pyarrow.lib.check_status
[36m(head, rank=0, pid=3505)[0m [rank0]: pyarrow.lib.ArrowInvalid: Tried reading schema message, was null or length 0
[36m(head, rank=0, pid=3505)[0m Completed Training in 51.62 seconds
[36m(head, rank=0, pid=3505)[0m [rank1]: Traceback (most recent call last):
[36m(head, rank=0, pid=3505)[0m [rank1]:   File "/e2e/train.py", line 712, in <module>
[36m(head, rank=0, pid=3505)[0m [rank1]:     main()
[36m(head, rank=0, pid=3505)[0m [rank1]:   File "/e2e/train.py", line 612, in main
[36m(head, rank=0, pid=3505)[0m [rank1]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3505)[0m [rank1]:   File "/e2e/train.py", line 104, in __init__
[36m(head, rank=0, pid=3505)[0m [rank1]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3505)[0m [rank1]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3505)[0m [rank1]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3505)[0m [rank1]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(head, rank=0, pid=3505)[0m [rank1]:     with PartialState().main_process_first():
[36m(head, rank=0, pid=3505)[0m [rank1]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(head, rank=0, pid=3505)[0m [rank1]:     return next(self.gen)
[36m(head, rank=0, pid=3505)[0m [rank1]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(head, rank=0, pid=3505)[0m [rank1]:     yield from self._goes_first(self.is_main_process)
[36m(head, rank=0, pid=3505)[0m [rank1]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(head, rank=0, pid=3505)[0m [rank1]:     self.wait_for_everyone()
[36m(head, rank=0, pid=3505)[0m [rank1]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(head, rank=0, pid=3505)[0m [rank1]:     torch.distributed.barrier()
[36m(head, rank=0, pid=3505)[0m [rank1]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(head, rank=0, pid=3505)[0m [rank1]:     return func(*args, **kwargs)
[36m(head, rank=0, pid=3505)[0m [rank1]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(head, rank=0, pid=3505)[0m [rank1]:     work.wait()
[36m(head, rank=0, pid=3505)[0m [rank1]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.45]:22959
[36m(head, rank=0, pid=3505)[0m Completed Training in 51.44 seconds
[36m(head, rank=0, pid=3505)[0m [rank2]: Traceback (most recent call last):
[36m(head, rank=0, pid=3505)[0m [rank2]:   File "/e2e/train.py", line 712, in <module>
[36m(head, rank=0, pid=3505)[0m [rank2]:     main()
[36m(head, rank=0, pid=3505)[0m [rank2]:   File "/e2e/train.py", line 612, in main
[36m(head, rank=0, pid=3505)[0m [rank2]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3505)[0m [rank2]:   File "/e2e/train.py", line 104, in __init__
[36m(head, rank=0, pid=3505)[0m [rank2]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3505)[0m [rank2]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3505)[0m [rank2]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3505)[0m [rank2]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(head, rank=0, pid=3505)[0m [rank2]:     with PartialState().main_process_first():
[36m(head, rank=0, pid=3505)[0m [rank2]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(head, rank=0, pid=3505)[0m [rank2]:     return next(self.gen)
[36m(head, rank=0, pid=3505)[0m [rank2]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(head, rank=0, pid=3505)[0m [rank2]:     yield from self._goes_first(self.is_main_process)
[36m(head, rank=0, pid=3505)[0m [rank2]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(head, rank=0, pid=3505)[0m [rank2]:     self.wait_for_everyone()
[36m(head, rank=0, pid=3505)[0m [rank2]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(head, rank=0, pid=3505)[0m [rank2]:     torch.distributed.barrier()
[36m(head, rank=0, pid=3505)[0m [rank2]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(head, rank=0, pid=3505)[0m [rank2]:     return func(*args, **kwargs)
[36m(head, rank=0, pid=3505)[0m [rank2]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(head, rank=0, pid=3505)[0m [rank2]:     work.wait()
[36m(head, rank=0, pid=3505)[0m [rank2]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.45]:22959
[36m(head, rank=0, pid=3505)[0m Completed Training in 51.57 seconds
[36m(head, rank=0, pid=3505)[0m [rank4]: Traceback (most recent call last):
[36m(head, rank=0, pid=3505)[0m [rank4]:   File "/e2e/train.py", line 712, in <module>
[36m(head, rank=0, pid=3505)[0m [rank4]:     main()
[36m(head, rank=0, pid=3505)[0m [rank4]:   File "/e2e/train.py", line 612, in main
[36m(head, rank=0, pid=3505)[0m [rank4]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3505)[0m [rank4]:   File "/e2e/train.py", line 104, in __init__
[36m(head, rank=0, pid=3505)[0m [rank4]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3505)[0m [rank4]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3505)[0m [rank4]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3505)[0m [rank4]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(head, rank=0, pid=3505)[0m [rank4]:     with PartialState().main_process_first():
[36m(head, rank=0, pid=3505)[0m [rank4]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(head, rank=0, pid=3505)[0m [rank4]:     return next(self.gen)
[36m(head, rank=0, pid=3505)[0m [rank4]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(head, rank=0, pid=3505)[0m [rank4]:     yield from self._goes_first(self.is_main_process)
[36m(head, rank=0, pid=3505)[0m [rank4]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(head, rank=0, pid=3505)[0m [rank4]:     self.wait_for_everyone()
[36m(head, rank=0, pid=3505)[0m [rank4]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(head, rank=0, pid=3505)[0m [rank4]:     torch.distributed.barrier()
[36m(head, rank=0, pid=3505)[0m [rank4]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(head, rank=0, pid=3505)[0m [rank4]:     return func(*args, **kwargs)
[36m(head, rank=0, pid=3505)[0m [rank4]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(head, rank=0, pid=3505)[0m [rank4]:     work.wait()
[36m(head, rank=0, pid=3505)[0m [rank4]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.45]:42114
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 4.39 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:   File "/e2e/train.py", line 712, in <module>
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:     main()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:   File "/e2e/train.py", line 612, in main
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:   File "/e2e/train.py", line 104, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:     return next(self.gen)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]:     work.wait()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank8]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.45]:10393
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 51.52 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:   File "/e2e/train.py", line 712, in <module>
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:     main()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:   File "/e2e/train.py", line 612, in main
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:   File "/e2e/train.py", line 104, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:     return next(self.gen)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]:     work.wait()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank12]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.45]:38533
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 51.60 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:   File "/e2e/train.py", line 712, in <module>
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:     main()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:   File "/e2e/train.py", line 612, in main
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:   File "/e2e/train.py", line 104, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:     return next(self.gen)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]:     work.wait()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank14]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.45]:25311
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 51.56 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/e2e/train.py", line 712, in <module>
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     main()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/e2e/train.py", line 612, in main
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/e2e/train.py", line 104, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     return next(self.gen)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     work.wait()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.45]:59618
[36m(head, rank=0, pid=3505)[0m [rank0]:[W802 21:06:43.394430440 ProcessGroupNCCL.cpp:1479] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[36m(head, rank=0, pid=3505)[0m Completed Training in 51.93 seconds
[36m(head, rank=0, pid=3505)[0m [rank3]: Traceback (most recent call last):
[36m(head, rank=0, pid=3505)[0m [rank3]:   File "/e2e/train.py", line 712, in <module>
[36m(head, rank=0, pid=3505)[0m [rank3]:     main()
[36m(head, rank=0, pid=3505)[0m [rank3]:   File "/e2e/train.py", line 612, in main
[36m(head, rank=0, pid=3505)[0m [rank3]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3505)[0m [rank3]:   File "/e2e/train.py", line 104, in __init__
[36m(head, rank=0, pid=3505)[0m [rank3]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3505)[0m [rank3]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3505)[0m [rank3]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3505)[0m [rank3]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(head, rank=0, pid=3505)[0m [rank3]:     with PartialState().main_process_first():
[36m(head, rank=0, pid=3505)[0m [rank3]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(head, rank=0, pid=3505)[0m [rank3]:     return next(self.gen)
[36m(head, rank=0, pid=3505)[0m [rank3]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(head, rank=0, pid=3505)[0m [rank3]:     yield from self._goes_first(self.is_main_process)
[36m(head, rank=0, pid=3505)[0m [rank3]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(head, rank=0, pid=3505)[0m [rank3]:     self.wait_for_everyone()
[36m(head, rank=0, pid=3505)[0m [rank3]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(head, rank=0, pid=3505)[0m [rank3]:     torch.distributed.barrier()
[36m(head, rank=0, pid=3505)[0m [rank3]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(head, rank=0, pid=3505)[0m [rank3]:     return func(*args, **kwargs)
[36m(head, rank=0, pid=3505)[0m [rank3]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(head, rank=0, pid=3505)[0m [rank3]:     work.wait()
[36m(head, rank=0, pid=3505)[0m [rank3]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.45]:5823
[36m(head, rank=0, pid=3505)[0m Completed Training in 51.84 seconds
[36m(head, rank=0, pid=3505)[0m [rank5]: Traceback (most recent call last):
[36m(head, rank=0, pid=3505)[0m [rank5]:   File "/e2e/train.py", line 712, in <module>
[36m(head, rank=0, pid=3505)[0m [rank5]:     main()
[36m(head, rank=0, pid=3505)[0m [rank5]:   File "/e2e/train.py", line 612, in main
[36m(head, rank=0, pid=3505)[0m [rank5]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3505)[0m [rank5]:   File "/e2e/train.py", line 104, in __init__
[36m(head, rank=0, pid=3505)[0m [rank5]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3505)[0m [rank5]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3505)[0m [rank5]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3505)[0m [rank5]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(head, rank=0, pid=3505)[0m [rank5]:     with PartialState().main_process_first():
[36m(head, rank=0, pid=3505)[0m [rank5]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(head, rank=0, pid=3505)[0m [rank5]:     return next(self.gen)
[36m(head, rank=0, pid=3505)[0m [rank5]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(head, rank=0, pid=3505)[0m [rank5]:     yield from self._goes_first(self.is_main_process)
[36m(head, rank=0, pid=3505)[0m [rank5]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(head, rank=0, pid=3505)[0m [rank5]:     self.wait_for_everyone()
[36m(head, rank=0, pid=3505)[0m [rank5]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(head, rank=0, pid=3505)[0m [rank5]:     torch.distributed.barrier()
[36m(head, rank=0, pid=3505)[0m [rank5]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(head, rank=0, pid=3505)[0m [rank5]:     return func(*args, **kwargs)
[36m(head, rank=0, pid=3505)[0m [rank5]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(head, rank=0, pid=3505)[0m [rank5]:     work.wait()
[36m(head, rank=0, pid=3505)[0m [rank5]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.45]:63370
[36m(head, rank=0, pid=3505)[0m Completed Training in 51.97 seconds
[36m(head, rank=0, pid=3505)[0m [rank6]: Traceback (most recent call last):
[36m(head, rank=0, pid=3505)[0m [rank6]:   File "/e2e/train.py", line 712, in <module>
[36m(head, rank=0, pid=3505)[0m [rank6]:     main()
[36m(head, rank=0, pid=3505)[0m [rank6]:   File "/e2e/train.py", line 612, in main
[36m(head, rank=0, pid=3505)[0m [rank6]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(head, rank=0, pid=3505)[0m [rank6]:   File "/e2e/train.py", line 104, in __init__
[36m(head, rank=0, pid=3505)[0m [rank6]:     super().__init__(*args, **kwargs)
[36m(head, rank=0, pid=3505)[0m [rank6]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(head, rank=0, pid=3505)[0m [rank6]:     train_dataset = self._prepare_dataset(
[36m(head, rank=0, pid=3505)[0m [rank6]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(head, rank=0, pid=3505)[0m [rank6]:     with PartialState().main_process_first():
[36m(head, rank=0, pid=3505)[0m [rank6]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(head, rank=0, pid=3505)[0m [rank6]:     return next(self.gen)
[36m(head, rank=0, pid=3505)[0m [rank6]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(head, rank=0, pid=3505)[0m [rank6]:     yield from self._goes_first(self.is_main_process)
[36m(head, rank=0, pid=3505)[0m [rank6]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(head, rank=0, pid=3505)[0m [rank6]:     self.wait_for_everyone()
[36m(head, rank=0, pid=3505)[0m [rank6]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(head, rank=0, pid=3505)[0m [rank6]:     torch.distributed.barrier()
[36m(head, rank=0, pid=3505)[0m [rank6]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(head, rank=0, pid=3505)[0m [rank6]:     return func(*args, **kwargs)
[36m(head, rank=0, pid=3505)[0m [rank6]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(head, rank=0, pid=3505)[0m [rank6]:     work.wait()
[36m(head, rank=0, pid=3505)[0m [rank6]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.113.50.45]:61142
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 51.99 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:   File "/e2e/train.py", line 712, in <module>
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:     main()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:   File "/e2e/train.py", line 612, in main
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:   File "/e2e/train.py", line 104, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:     return next(self.gen)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]:     work.wait()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank10]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.102.30.60]:15237
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 52.14 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:   File "/e2e/train.py", line 712, in <module>
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:     main()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:   File "/e2e/train.py", line 612, in main
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:   File "/e2e/train.py", line 104, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:     return next(self.gen)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]:     work.wait()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank11]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.102.30.60]:25520
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 52.02 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/e2e/train.py", line 712, in <module>
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     main()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/e2e/train.py", line 612, in main
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/e2e/train.py", line 104, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     return next(self.gen)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     work.wait()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.102.30.60]:25520
[36m(head, rank=0, pid=3505)[0m W0802 21:06:44.125000 1964008 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1965993 closing signal SIGTERM
[36m(head, rank=0, pid=3505)[0m W0802 21:06:44.126000 1964008 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1965994 closing signal SIGTERM
[36m(head, rank=0, pid=3505)[0m W0802 21:06:44.126000 1964008 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1965996 closing signal SIGTERM
[36m(head, rank=0, pid=3505)[0m W0802 21:06:44.126000 1964008 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1965998 closing signal SIGTERM
[36m(head, rank=0, pid=3505)[0m W0802 21:06:44.127000 1964008 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1965999 closing signal SIGTERM
[36m(head, rank=0, pid=3505)[0m W0802 21:06:44.127000 1964008 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1966001 closing signal SIGTERM
[36m(head, rank=0, pid=3505)[0m W0802 21:06:44.127000 1964008 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1966003 closing signal SIGTERM
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 52.47 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:   File "/e2e/train.py", line 712, in <module>
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:     main()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:   File "/e2e/train.py", line 612, in main
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:   File "/e2e/train.py", line 104, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 683, in _prepare_dataset
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:     with PartialState().main_process_first():
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:   File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:     return next(self.gen)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 526, in main_process_first
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:     yield from self._goes_first(self.is_main_process)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 409, in _goes_first
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:     self.wait_for_everyone()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:   File "/root/training/lib/python3.10/site-packages/accelerate/state.py", line 403, in wait_for_everyone
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:     torch.distributed.barrier()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:     return func(*args, **kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:   File "/root/training/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 4640, in barrier
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]:     work.wait()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank9]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.102.30.60]:28066
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m W0802 21:06:44.634000 1734735 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1734923 closing signal SIGTERM
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m W0802 21:06:44.635000 1734735 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1734924 closing signal SIGTERM
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m W0802 21:06:44.635000 1734735 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1734925 closing signal SIGTERM
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m W0802 21:06:44.635000 1734735 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1734926 closing signal SIGTERM
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m W0802 21:06:44.635000 1734735 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1734927 closing signal SIGTERM
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m W0802 21:06:44.636000 1734735 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1734928 closing signal SIGTERM
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m W0802 21:06:44.636000 1734735 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1734930 closing signal SIGTERM
[36m(head, rank=0, pid=3505)[0m E0802 21:06:45.399000 1964008 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1965991) of binary: /root/training/bin/python3
[36m(head, rank=0, pid=3505)[0m Traceback (most recent call last):
[36m(head, rank=0, pid=3505)[0m   File "/root/training/bin/accelerate", line 10, in <module>
[36m(head, rank=0, pid=3505)[0m     sys.exit(main())
[36m(head, rank=0, pid=3505)[0m   File "/root/training/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
[36m(head, rank=0, pid=3505)[0m     args.func(args)
[36m(head, rank=0, pid=3505)[0m   File "/root/training/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1186, in launch_command
[36m(head, rank=0, pid=3505)[0m     multi_gpu_launcher(args)
[36m(head, rank=0, pid=3505)[0m   File "/root/training/lib/python3.10/site-packages/accelerate/commands/launch.py", line 815, in multi_gpu_launcher
[36m(head, rank=0, pid=3505)[0m     distrib_run.run(args)
[36m(head, rank=0, pid=3505)[0m   File "/root/training/lib/python3.10/site-packages/torch/distributed/run.py", line 883, in run
[36m(head, rank=0, pid=3505)[0m     elastic_launch(
[36m(head, rank=0, pid=3505)[0m   File "/root/training/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 139, in __call__
[36m(head, rank=0, pid=3505)[0m     return launch_agent(self._config, self._entrypoint, list(args))
[36m(head, rank=0, pid=3505)[0m   File "/root/training/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 270, in launch_agent
[36m(head, rank=0, pid=3505)[0m     raise ChildFailedError(
[36m(head, rank=0, pid=3505)[0m torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
[36m(head, rank=0, pid=3505)[0m ============================================================
[36m(head, rank=0, pid=3505)[0m /e2e/train.py FAILED
[36m(head, rank=0, pid=3505)[0m ------------------------------------------------------------
[36m(head, rank=0, pid=3505)[0m Failures:
[36m(head, rank=0, pid=3505)[0m   <NO_OTHER_FAILURES>
[36m(head, rank=0, pid=3505)[0m ------------------------------------------------------------
[36m(head, rank=0, pid=3505)[0m Root Cause (first observed failure):
[36m(head, rank=0, pid=3505)[0m [0]:
[36m(head, rank=0, pid=3505)[0m   time      : 2025-08-02_21:06:44
[36m(head, rank=0, pid=3505)[0m   host      : dd-3c0a52b3-head
[36m(head, rank=0, pid=3505)[0m   rank      : 0 (local_rank: 0)
[36m(head, rank=0, pid=3505)[0m   exitcode  : 1 (pid: 1965991)
[36m(head, rank=0, pid=3505)[0m   error_file: <N/A>
[36m(head, rank=0, pid=3505)[0m   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[36m(head, rank=0, pid=3505)[0m ============================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m E0802 21:06:46.035000 1734735 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 6 (pid: 1734929) of binary: /root/training/bin/python3
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Traceback (most recent call last):
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   File "/root/training/bin/accelerate", line 10, in <module>
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m     sys.exit(main())
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   File "/root/training/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m     args.func(args)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   File "/root/training/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1186, in launch_command
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m     multi_gpu_launcher(args)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   File "/root/training/lib/python3.10/site-packages/accelerate/commands/launch.py", line 815, in multi_gpu_launcher
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m     distrib_run.run(args)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   File "/root/training/lib/python3.10/site-packages/torch/distributed/run.py", line 883, in run
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m     elastic_launch(
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   File "/root/training/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 139, in __call__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m     return launch_agent(self._config, self._entrypoint, list(args))
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   File "/root/training/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 270, in launch_agent
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m     raise ChildFailedError(
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ============================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m /e2e/train.py FAILED
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ------------------------------------------------------------
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Failures:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   <NO_OTHER_FAILURES>
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ------------------------------------------------------------
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Root Cause (first observed failure):
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [0]:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   time      : 2025-08-02_21:06:44
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   host      : dd-3c0a52b3-worker1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   rank      : 14 (local_rank: 6)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   exitcode  : 1 (pid: 1734929)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   error_file: <N/A>
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ============================================================
[36m(head, rank=0, pid=3505)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m === Starting Run 1/1 ===
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset: open-r1/codeforces-cots
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m === Starting Run 1/1 ===
[36m(head, rank=0, pid=3505)[0m Dataset: open-r1/codeforces-cots
[36m(head, rank=0, pid=3505)[0m Dataset cache: /checkpoints_s3_mount_cached/dataset_cache
[36m(head, rank=0, pid=3505)[0m Model cache: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3505)[0m Checkpoint saving dir: /checkpoints_s3_mount_cached/checkpoints
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3505)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3505)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Removing checkpoint exception [Errno 2] No such file or directory: '/checkpoints_s3_mount_cached/checkpoints'
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load dataset...
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.40 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.40 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.40 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.40 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.40 secondsCompleted Load dataset in 2.40 seconds
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Starting Load model...Starting Load model...
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cacheLoading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.40 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(head, rank=0, pid=3505)[0m Completed Load dataset in 2.42 seconds
[36m(head, rank=0, pid=3505)[0m Starting Load model...
[36m(head, rank=0, pid=3505)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.44 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.44 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.44 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.44 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.44 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.44 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.44 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load dataset in 2.44 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Load model...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading model from cache directory: /checkpoints_s3_mount_cached/model_cache
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00, 27.57it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00, 26.84it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 52.28it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 51.03it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 53.60it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 43.18it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 43.12it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 112.84it/s]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 100.24it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00, 31.14it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 30.24it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 32.73it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 69.91it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 30.73it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 102.77it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 95.85it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(head, rank=0, pid=3505)[0m Completed Load model in 1.13 seconds
[36m(head, rank=0, pid=3505)[0m Completed Load model in 1.13 seconds
[36m(head, rank=0, pid=3505)[0m Completed Load model in 1.13 seconds
[36m(head, rank=0, pid=3505)[0m Completed Load model in 1.12 seconds
[36m(head, rank=0, pid=3505)[0m Completed Load model in 1.14 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 1.11 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 1.11 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 1.11 seconds
[36m(head, rank=0, pid=3505)[0m Completed Load model in 1.17 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 1.18 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 1.19 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 1.34 seconds
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:00,  8.85it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 39.37it/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(head, rank=0, pid=3505)[0m Completed Load model in 3.33 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00, 39.64it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00, 48.09it/s]
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 3.41 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:14<00:57, 14.30s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  20%|██        | 1/5 [00:21<01:26, 21.67s/it]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:36<00:56, 18.72s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  40%|████      | 2/5 [00:36<00:52, 17.40s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:57<00:38, 19.23s/it]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  60%|██████    | 3/5 [00:57<00:39, 19.95s/it]
[36m(head, rank=0, pid=3505)[0m Loading checkpoint shards:  80%|████████  | 4/5 [01:19<00:20, 20.56s/it]Loading checkpoint shards: 100%|██████████| 5/5 [01:39<00:00, 20.41s/it]Loading checkpoint shards: 100%|██████████| 5/5 [01:39<00:00, 19.83s/it]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Loading checkpoint shards:  80%|████████  | 4/5 [01:18<00:20, 20.12s/it]Loading checkpoint shards: 100%|██████████| 5/5 [01:39<00:00, 20.13s/it]Loading checkpoint shards: 100%|██████████| 5/5 [01:39<00:00, 19.82s/it]
[36m(head, rank=0, pid=3505)[0m Completed Load model in 100.27 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Load model in 100.23 seconds
[36m(head, rank=0, pid=3505)[0m Starting Training...
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Starting Training...
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   0%|          | 1/47780 [00:12<167:55:49, 12.65s/ examples]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   0%|          | 38/47780 [00:12<3:14:14,  4.10 examples/s] 
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   0%|          | 87/47780 [00:13<1:11:44, 11.08 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   0%|          | 162/47780 [00:13<31:48, 24.95 examples/s] 
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   1%|          | 239/47780 [00:14<18:31, 42.79 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   1%|          | 313/47780 [00:14<12:36, 62.76 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   1%|          | 388/47780 [00:14<09:23, 84.05 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   1%|          | 520/47780 [00:15<05:59, 131.37 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   1%|▏         | 689/47780 [00:15<04:02, 194.05 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 851/47780 [00:15<03:09, 247.26 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   2%|▏         | 1035/47780 [00:16<02:27, 316.02 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1215/47780 [00:16<02:07, 366.57 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1401/47780 [00:16<01:50, 420.81 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   3%|▎         | 1593/47780 [00:17<01:40, 460.22 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 1815/47780 [00:17<01:28, 518.92 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   4%|▍         | 2057/47780 [00:17<01:18, 582.78 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   5%|▍         | 2285/47780 [00:18<01:14, 614.20 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   5%|▌         | 2559/47780 [00:18<01:07, 671.22 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   6%|▌         | 2812/47780 [00:18<01:05, 689.82 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   6%|▋         | 3061/47780 [00:19<01:03, 703.39 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   7%|▋         | 3359/47780 [00:19<00:58, 758.73 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3668/47780 [00:19<00:54, 806.58 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   8%|▊         | 3947/47780 [00:20<00:53, 819.26 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):   9%|▉         | 4257/47780 [00:20<00:52, 830.96 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  10%|▉         | 4604/47780 [00:20<00:48, 885.07 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  10%|█         | 4971/47780 [00:21<00:46, 926.92 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  11%|█         | 5372/47780 [00:21<00:33, 1261.96 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5558/47780 [00:21<00:35, 1194.55 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5717/47780 [00:21<00:36, 1149.47 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  12%|█▏        | 5860/47780 [00:21<00:36, 1163.18 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 5996/47780 [00:21<00:36, 1159.12 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6127/47780 [00:22<00:35, 1178.86 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6259/47780 [00:22<00:34, 1187.35 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  13%|█▎        | 6385/47780 [00:22<00:36, 1121.27 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  14%|█▎        | 6502/47780 [00:22<00:38, 1083.69 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6617/47780 [00:22<00:38, 1064.21 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6749/47780 [00:22<00:36, 1126.66 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  14%|█▍        | 6881/47780 [00:22<00:34, 1173.93 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7002/47780 [00:22<00:35, 1139.64 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  15%|█▍        | 7123/47780 [00:22<00:35, 1154.01 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7240/47780 [00:23<00:37, 1094.14 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  15%|█▌        | 7367/47780 [00:23<00:35, 1138.58 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7492/47780 [00:23<00:34, 1163.15 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7610/47780 [00:23<00:35, 1145.42 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  16%|█▌        | 7730/47780 [00:23<00:34, 1160.68 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  16%|█▋        | 7848/47780 [00:23<00:34, 1159.69 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 7971/47780 [00:23<00:33, 1179.97 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8097/47780 [00:23<00:33, 1189.61 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  17%|█▋        | 8225/47780 [00:23<00:33, 1190.14 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8366/47780 [00:23<00:31, 1252.87 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8493/47780 [00:24<00:31, 1232.65 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8618/47780 [00:24<00:34, 1140.90 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  18%|█▊        | 8734/47780 [00:24<00:34, 1138.90 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  19%|█▊        | 8850/47780 [00:24<00:36, 1069.85 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 8972/47780 [00:24<00:34, 1110.86 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9085/47780 [00:24<00:34, 1115.85 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  19%|█▉        | 9202/47780 [00:24<00:34, 1127.16 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9332/47780 [00:24<00:32, 1177.06 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  20%|█▉        | 9454/47780 [00:24<00:32, 1184.75 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9574/47780 [00:25<00:33, 1130.94 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  20%|██        | 9699/47780 [00:25<00:32, 1160.19 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9822/47780 [00:25<00:32, 1179.65 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 9944/47780 [00:25<00:32, 1182.10 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  21%|██        | 10064/47780 [00:25<00:32, 1159.10 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  21%|██▏       | 10183/47780 [00:25<00:32, 1146.66 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10310/47780 [00:25<00:31, 1175.84 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10429/47780 [00:25<00:32, 1147.62 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10547/47780 [00:25<00:32, 1152.21 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  22%|██▏       | 10665/47780 [00:25<00:32, 1144.53 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10791/47780 [00:26<00:31, 1176.47 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 10922/47780 [00:26<00:30, 1210.60 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11045/47780 [00:26<00:30, 1213.49 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  23%|██▎       | 11167/47780 [00:26<00:31, 1158.33 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  24%|██▎       | 11297/47780 [00:26<00:30, 1190.63 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11420/47780 [00:26<00:30, 1200.95 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11544/47780 [00:26<00:30, 1181.80 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  24%|██▍       | 11666/47780 [00:26<00:30, 1177.86 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11790/47780 [00:26<00:30, 1186.20 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  25%|██▍       | 11923/47780 [00:27<00:29, 1227.70 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12050/47780 [00:27<00:28, 1238.27 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  25%|██▌       | 12180/47780 [00:27<00:28, 1246.74 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12306/47780 [00:27<00:28, 1228.85 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  26%|██▌       | 12430/47780 [00:27<00:28, 1222.76 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  26%|██▋       | 12554/47780 [00:27<00:29, 1190.78 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12684/47780 [00:27<00:28, 1217.63 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12824/47780 [00:27<00:27, 1257.00 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 12953/47780 [00:27<00:28, 1210.18 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  27%|██▋       | 13079/47780 [00:27<00:28, 1204.19 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13201/47780 [00:28<00:28, 1193.47 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13334/47780 [00:28<00:27, 1230.28 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13459/47780 [00:28<00:28, 1191.98 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  28%|██▊       | 13595/47780 [00:28<00:27, 1222.86 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  29%|██▊       | 13718/47780 [00:28<00:27, 1219.79 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13842/47780 [00:28<00:27, 1223.76 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  29%|██▉       | 13971/47780 [00:28<00:27, 1230.92 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14099/47780 [00:28<00:27, 1240.29 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  30%|██▉       | 14224/47780 [00:28<00:28, 1181.15 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14345/47780 [00:29<00:28, 1183.89 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  30%|███       | 14465/47780 [00:29<00:29, 1147.66 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14582/47780 [00:29<00:29, 1130.62 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14698/47780 [00:29<00:29, 1106.30 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  31%|███       | 14825/47780 [00:29<00:28, 1150.92 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  31%|███▏      | 14941/47780 [00:29<00:28, 1151.41 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15057/47780 [00:29<00:28, 1145.68 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15184/47780 [00:29<00:27, 1175.95 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15324/47780 [00:29<00:26, 1225.88 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  32%|███▏      | 15448/47780 [00:29<00:26, 1205.95 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15570/47780 [00:30<00:27, 1180.99 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15689/47780 [00:30<00:28, 1130.05 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15805/47780 [00:30<00:28, 1138.04 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  33%|███▎      | 15930/47780 [00:30<00:27, 1164.80 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  34%|███▎      | 16061/47780 [00:30<00:26, 1204.03 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16183/47780 [00:30<00:26, 1173.80 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16301/47780 [00:30<00:27, 1160.74 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  34%|███▍      | 16435/47780 [00:30<00:25, 1207.88 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16558/47780 [00:30<00:26, 1190.66 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  35%|███▍      | 16685/47780 [00:31<00:25, 1205.95 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16825/47780 [00:31<00:24, 1247.33 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  35%|███▌      | 16955/47780 [00:31<00:24, 1244.66 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17093/47780 [00:31<00:23, 1279.27 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  36%|███▌      | 17222/47780 [00:31<00:24, 1224.13 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  36%|███▋      | 17353/47780 [00:31<00:24, 1247.81 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17479/47780 [00:31<00:25, 1183.80 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17604/47780 [00:31<00:25, 1197.07 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17729/47780 [00:31<00:25, 1201.17 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  37%|███▋      | 17852/47780 [00:31<00:24, 1197.22 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 17975/47780 [00:32<00:25, 1164.33 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18092/47780 [00:32<00:25, 1165.37 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18210/47780 [00:32<00:25, 1140.70 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  38%|███▊      | 18357/47780 [00:32<00:24, 1223.01 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  39%|███▊      | 18480/47780 [00:32<00:24, 1217.43 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18614/47780 [00:32<00:23, 1239.82 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18742/47780 [00:32<00:23, 1238.14 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  39%|███▉      | 18871/47780 [00:32<00:23, 1250.16 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  40%|███▉      | 18999/47780 [00:32<00:23, 1214.69 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19122/47780 [00:33<00:24, 1171.64 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  40%|████      | 19256/47780 [00:33<00:23, 1216.82 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19379/47780 [00:33<00:23, 1220.10 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19505/47780 [00:33<00:23, 1222.55 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  41%|████      | 19632/47780 [00:33<00:22, 1235.76 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  41%|████▏     | 19757/47780 [00:33<00:22, 1223.87 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 19880/47780 [00:33<00:23, 1190.56 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20004/47780 [00:33<00:23, 1188.29 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20124/47780 [00:33<00:23, 1153.53 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  42%|████▏     | 20245/47780 [00:33<00:23, 1154.89 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20361/47780 [00:34<00:24, 1098.71 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20480/47780 [00:34<00:24, 1110.53 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20593/47780 [00:34<00:24, 1112.70 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  43%|████▎     | 20707/47780 [00:34<00:24, 1118.06 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  44%|████▎     | 20838/47780 [00:34<00:23, 1163.72 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 20956/47780 [00:34<00:23, 1147.87 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21084/47780 [00:34<00:22, 1182.87 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  44%|████▍     | 21206/47780 [00:34<00:23, 1147.70 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21329/47780 [00:34<00:22, 1163.66 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  45%|████▍     | 21452/47780 [00:35<00:22, 1181.82 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21572/47780 [00:35<00:22, 1162.92 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  45%|████▌     | 21696/47780 [00:35<00:22, 1172.84 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21824/47780 [00:35<00:22, 1175.89 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  46%|████▌     | 21962/47780 [00:35<00:21, 1191.54 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  46%|████▋     | 22101/47780 [00:35<00:20, 1240.45 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22227/47780 [00:35<00:21, 1180.62 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22357/47780 [00:35<00:21, 1200.66 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22505/47780 [00:35<00:19, 1278.54 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  47%|████▋     | 22638/47780 [00:35<00:19, 1263.24 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22767/47780 [00:36<00:20, 1246.74 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 22895/47780 [00:36<00:20, 1225.05 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23019/47780 [00:36<00:20, 1207.70 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  48%|████▊     | 23142/47780 [00:36<00:21, 1169.40 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  49%|████▊     | 23278/47780 [00:36<00:20, 1221.67 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23401/47780 [00:36<00:20, 1208.38 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23523/47780 [00:36<00:20, 1169.61 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  49%|████▉     | 23650/47780 [00:36<00:20, 1193.48 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23771/47780 [00:36<00:20, 1159.03 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  50%|████▉     | 23888/47780 [00:37<00:20, 1142.98 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24003/47780 [00:37<00:21, 1120.00 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  50%|█████     | 24122/47780 [00:37<00:20, 1138.14 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24238/47780 [00:37<00:21, 1110.16 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  51%|█████     | 24374/47780 [00:37<00:19, 1177.38 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  51%|█████▏    | 24494/47780 [00:37<00:20, 1148.03 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24629/47780 [00:37<00:19, 1198.66 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24750/47780 [00:37<00:20, 1113.56 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24864/47780 [00:37<00:21, 1073.58 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  52%|█████▏    | 24973/47780 [00:38<00:21, 1066.63 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25100/47780 [00:38<00:20, 1119.21 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25235/47780 [00:38<00:19, 1174.30 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25354/47780 [00:38<00:19, 1165.97 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  53%|█████▎    | 25474/47780 [00:38<00:20, 1113.75 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  54%|█████▎    | 25587/47780 [00:38<00:20, 1103.90 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25716/47780 [00:38<00:19, 1146.93 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25834/47780 [00:38<00:19, 1115.65 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  54%|█████▍    | 25953/47780 [00:38<00:19, 1133.51 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26069/47780 [00:38<00:19, 1134.28 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  55%|█████▍    | 26184/47780 [00:39<00:19, 1113.78 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26297/47780 [00:39<00:20, 1064.28 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26409/47780 [00:39<00:19, 1070.81 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  55%|█████▌    | 26517/47780 [00:39<00:20, 1015.12 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26628/47780 [00:39<00:20, 1022.29 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26758/47780 [00:39<00:19, 1094.84 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  56%|█████▌    | 26870/47780 [00:39<00:19, 1100.27 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  56%|█████▋    | 26991/47780 [00:39<00:18, 1122.39 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27106/47780 [00:39<00:18, 1128.57 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27221/47780 [00:40<00:19, 1061.71 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27330/47780 [00:40<00:19, 1051.46 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  57%|█████▋    | 27437/47780 [00:40<00:19, 1026.60 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27541/47780 [00:40<00:20, 1002.33 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27643/47780 [00:40<00:20, 959.41 examples/s] 
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27766/47780 [00:40<00:19, 1022.06 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  58%|█████▊    | 27869/47780 [00:40<00:20, 986.47 examples/s] 
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  59%|█████▊    | 27974/47780 [00:40<00:20, 953.06 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28084/47780 [00:40<00:20, 972.85 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28187/47780 [00:41<00:19, 987.74 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28287/47780 [00:41<00:19, 981.93 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  59%|█████▉    | 28387/47780 [00:41<00:20, 965.90 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28494/47780 [00:41<00:19, 984.69 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  60%|█████▉    | 28594/47780 [00:41<00:19, 979.23 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28698/47780 [00:41<00:19, 983.10 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28800/47780 [00:41<00:19, 974.33 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  60%|██████    | 28901/47780 [00:41<00:19, 975.89 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29013/47780 [00:41<00:18, 1015.36 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29116/47780 [00:42<00:18, 984.96 examples/s] 
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  61%|██████    | 29232/47780 [00:42<00:17, 1030.82 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  61%|██████▏   | 29338/47780 [00:42<00:17, 1034.49 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29442/47780 [00:42<00:18, 1013.96 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29544/47780 [00:42<00:18, 978.01 examples/s] 
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29655/47780 [00:42<00:17, 1007.53 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  62%|██████▏   | 29777/47780 [00:42<00:16, 1060.05 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29885/47780 [00:42<00:16, 1064.73 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 29993/47780 [00:42<00:16, 1069.03 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30119/47780 [00:42<00:15, 1111.26 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  63%|██████▎   | 30246/47780 [00:43<00:15, 1151.19 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  64%|██████▎   | 30383/47780 [00:43<00:14, 1211.39 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30505/47780 [00:43<00:14, 1160.89 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30623/47780 [00:43<00:15, 1116.43 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  64%|██████▍   | 30743/47780 [00:43<00:15, 1133.06 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30857/47780 [00:43<00:15, 1120.23 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  65%|██████▍   | 30971/47780 [00:43<00:15, 1070.18 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31079/47780 [00:43<00:16, 1019.79 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  65%|██████▌   | 31182/47780 [00:43<00:16, 1004.76 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31299/47780 [00:44<00:15, 1036.96 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31419/47780 [00:44<00:15, 1081.34 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31533/47780 [00:44<00:14, 1097.48 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  66%|██████▌   | 31654/47780 [00:44<00:14, 1128.80 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31774/47780 [00:44<00:14, 1141.94 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 31891/47780 [00:44<00:14, 1120.63 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32022/47780 [00:44<00:13, 1157.22 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  67%|██████▋   | 32139/47780 [00:44<00:13, 1157.86 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32263/47780 [00:44<00:13, 1174.29 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32381/47780 [00:44<00:13, 1146.47 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32507/47780 [00:45<00:13, 1165.11 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  68%|██████▊   | 32626/47780 [00:45<00:12, 1171.56 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  69%|██████▊   | 32744/47780 [00:45<00:13, 1122.86 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 32889/47780 [00:45<00:12, 1211.11 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33032/47780 [00:45<00:11, 1254.25 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  69%|██████▉   | 33161/47780 [00:45<00:12, 1209.83 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33302/47780 [00:45<00:11, 1254.65 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  70%|██████▉   | 33429/47780 [00:45<00:11, 1251.41 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33558/47780 [00:45<00:11, 1238.14 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  70%|███████   | 33684/47780 [00:46<00:11, 1206.83 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33806/47780 [00:46<00:11, 1184.12 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  71%|███████   | 33925/47780 [00:46<00:11, 1164.10 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34044/47780 [00:46<00:11, 1158.12 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  71%|███████▏  | 34161/47780 [00:46<00:12, 1104.08 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34272/47780 [00:46<00:13, 998.75 examples/s] 
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34375/47780 [00:46<00:13, 969.73 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34476/47780 [00:46<00:13, 952.05 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  72%|███████▏  | 34572/47780 [00:46<00:14, 923.93 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34666/47780 [00:47<00:14, 898.25 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34758/47780 [00:47<00:15, 859.42 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34863/47780 [00:47<00:14, 899.92 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 34955/47780 [00:47<00:15, 840.81 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  73%|███████▎  | 35054/47780 [00:47<00:14, 880.19 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  74%|███████▎  | 35145/47780 [00:47<00:14, 876.19 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35245/47780 [00:47<00:13, 898.80 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35338/47780 [00:47<00:13, 906.30 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35431/47780 [00:47<00:13, 897.28 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  74%|███████▍  | 35522/47780 [00:48<00:13, 881.19 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35611/47780 [00:48<00:13, 882.05 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35702/47780 [00:48<00:13, 888.40 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  75%|███████▍  | 35815/47780 [00:48<00:12, 958.77 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 35921/47780 [00:48<00:11, 988.50 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  75%|███████▌  | 36021/47780 [00:48<00:12, 959.62 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36125/47780 [00:48<00:11, 978.08 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36232/47780 [00:48<00:11, 1000.79 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  76%|███████▌  | 36342/47780 [00:48<00:11, 1005.30 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36443/47780 [00:48<00:11, 1004.94 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  76%|███████▋  | 36551/47780 [00:49<00:11, 1002.69 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36653/47780 [00:49<00:11, 998.46 examples/s] 
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36758/47780 [00:49<00:11, 997.41 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36859/47780 [00:49<00:10, 992.99 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  77%|███████▋  | 36959/47780 [00:49<00:10, 984.65 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37058/47780 [00:49<00:11, 925.32 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37153/47780 [00:49<00:11, 926.99 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37276/47780 [00:49<00:10, 1009.37 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37379/47780 [00:49<00:10, 1007.41 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  78%|███████▊  | 37481/47780 [00:50<00:10, 987.78 examples/s] 
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  79%|███████▊  | 37582/47780 [00:50<00:10, 972.36 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37698/47780 [00:50<00:09, 1022.12 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37819/47780 [00:50<00:09, 1061.71 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  79%|███████▉  | 37926/47780 [00:50<00:09, 1047.24 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38032/47780 [00:50<00:09, 1024.52 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  80%|███████▉  | 38137/47780 [00:50<00:10, 955.34 examples/s] 
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38252/47780 [00:50<00:09, 982.90 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  80%|████████  | 38357/47780 [00:50<00:09, 983.23 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38474/47780 [00:50<00:09, 1031.87 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38581/47780 [00:51<00:08, 1035.51 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  81%|████████  | 38708/47780 [00:51<00:08, 1082.47 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38823/47780 [00:51<00:08, 1099.17 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  81%|████████▏ | 38934/47780 [00:51<00:08, 1097.83 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39047/47780 [00:51<00:07, 1105.25 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39159/47780 [00:51<00:08, 1072.14 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39269/47780 [00:51<00:08, 1036.09 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  82%|████████▏ | 39376/47780 [00:51<00:08, 1042.68 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39488/47780 [00:51<00:07, 1064.77 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39595/47780 [00:52<00:07, 1039.74 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39705/47780 [00:52<00:07, 1056.99 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  83%|████████▎ | 39811/47780 [00:52<00:07, 1039.25 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  84%|████████▎ | 39917/47780 [00:52<00:07, 1035.79 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40051/47780 [00:52<00:06, 1106.76 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40186/47780 [00:52<00:06, 1166.03 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  84%|████████▍ | 40318/47780 [00:52<00:06, 1206.26 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40455/47780 [00:52<00:05, 1250.52 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  85%|████████▍ | 40582/47780 [00:52<00:06, 1142.38 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  85%|████████▌ | 40700/47780 [00:53<00:06, 1124.51 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40860/47780 [00:53<00:05, 1252.16 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 40988/47780 [00:53<00:05, 1199.02 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  86%|████████▌ | 41111/47780 [00:53<00:05, 1172.24 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  86%|████████▋ | 41235/47780 [00:53<00:05, 1171.25 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41353/47780 [00:53<00:05, 1110.75 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41467/47780 [00:53<00:05, 1089.44 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41578/47780 [00:53<00:06, 988.41 examples/s] 
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41684/47780 [00:53<00:06, 961.89 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  87%|████████▋ | 41792/47780 [00:54<00:06, 992.91 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41893/47780 [00:54<00:06, 968.21 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 41996/47780 [00:54<00:05, 976.27 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42097/47780 [00:54<00:05, 974.51 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  88%|████████▊ | 42195/47780 [00:54<00:05, 973.47 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42294/47780 [00:54<00:05, 975.76 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  89%|████████▊ | 42392/47780 [00:54<00:05, 976.31 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42493/47780 [00:54<00:05, 982.56 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42594/47780 [00:54<00:05, 933.45 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  89%|████████▉ | 42688/47780 [00:54<00:05, 905.99 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42781/47780 [00:55<00:05, 864.77 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42870/47780 [00:55<00:05, 849.15 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  90%|████████▉ | 42957/47780 [00:55<00:05, 819.51 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43054/47780 [00:55<00:05, 856.79 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  90%|█████████ | 43155/47780 [00:55<00:05, 898.27 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43249/47780 [00:55<00:05, 857.11 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43337/47780 [00:55<00:05, 850.46 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43428/47780 [00:55<00:05, 862.12 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  91%|█████████ | 43515/47780 [00:55<00:04, 863.49 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43602/47780 [00:56<00:04, 847.53 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  91%|█████████▏| 43688/47780 [00:56<00:05, 813.02 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43794/47780 [00:56<00:04, 862.76 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43888/47780 [00:56<00:04, 878.57 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 43977/47780 [00:56<00:04, 835.12 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44075/47780 [00:56<00:04, 867.11 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  92%|█████████▏| 44176/47780 [00:56<00:03, 904.49 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44267/47780 [00:56<00:04, 843.54 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44353/47780 [00:56<00:04, 821.20 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44436/47780 [00:57<00:04, 808.36 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44518/47780 [00:57<00:04, 772.84 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44597/47780 [00:57<00:04, 721.00 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  93%|█████████▎| 44671/47780 [00:57<00:04, 689.65 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▎| 44742/47780 [00:57<00:04, 639.30 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44817/47780 [00:57<00:04, 656.53 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44884/47780 [00:57<00:04, 628.19 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 44962/47780 [00:57<00:04, 667.82 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45031/47780 [00:57<00:04, 668.50 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  94%|█████████▍| 45102/47780 [00:58<00:03, 673.18 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45170/47780 [00:58<00:04, 648.14 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45245/47780 [00:58<00:03, 662.94 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▍| 45316/47780 [00:58<00:03, 674.08 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45396/47780 [00:58<00:03, 691.16 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45475/47780 [00:58<00:03, 702.53 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45548/47780 [00:58<00:03, 707.13 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  95%|█████████▌| 45619/47780 [00:58<00:03, 681.67 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45689/47780 [00:58<00:03, 635.34 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45755/47780 [00:59<00:03, 613.12 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45818/47780 [00:59<00:03, 605.94 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45880/47780 [00:59<00:03, 603.97 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▌| 45941/47780 [00:59<00:03, 580.94 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46000/47780 [00:59<00:03, 569.44 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  96%|█████████▋| 46062/47780 [00:59<00:03, 563.36 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46130/47780 [00:59<00:02, 579.12 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46190/47780 [00:59<00:02, 555.59 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46249/47780 [00:59<00:02, 532.38 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46304/47780 [01:00<00:02, 521.99 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46362/47780 [01:00<00:02, 533.94 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46421/47780 [01:00<00:02, 546.62 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46483/47780 [01:00<00:02, 545.01 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  97%|█████████▋| 46539/47780 [01:00<00:02, 501.27 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46592/47780 [01:00<00:02, 490.76 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46643/47780 [01:00<00:02, 452.95 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46694/47780 [01:00<00:02, 465.98 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46743/47780 [01:01<00:02, 432.43 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46792/47780 [01:01<00:02, 421.05 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46841/47780 [01:01<00:02, 437.46 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46886/47780 [01:01<00:02, 424.46 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46930/47780 [01:01<00:02, 363.11 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 46968/47780 [01:01<00:02, 349.62 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47011/47780 [01:01<00:02, 366.67 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  98%|█████████▊| 47050/47780 [01:01<00:02, 325.15 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47084/47780 [01:02<00:02, 322.78 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47122/47780 [01:02<00:01, 330.92 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▊| 47157/47780 [01:02<00:01, 330.25 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47191/47780 [01:02<00:01, 322.18 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47225/47780 [01:02<00:01, 288.59 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47255/47780 [01:02<00:01, 269.66 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47288/47780 [01:02<00:01, 272.67 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47320/47780 [01:02<00:01, 283.08 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47349/47780 [01:02<00:01, 265.98 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47378/47780 [01:03<00:01, 257.13 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47406/47780 [01:03<00:01, 243.61 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47431/47780 [01:03<00:01, 218.59 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47454/47780 [01:03<00:01, 208.05 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47476/47780 [01:03<00:01, 182.98 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47499/47780 [01:03<00:01, 189.99 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47520/47780 [01:03<00:01, 189.69 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32):  99%|█████████▉| 47541/47780 [01:04<00:01, 189.78 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47561/47780 [01:04<00:01, 161.31 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47581/47780 [01:04<00:01, 164.34 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47600/47780 [01:04<00:01, 163.73 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47619/47780 [01:04<00:01, 160.36 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47637/47780 [01:04<00:00, 155.31 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47654/47780 [01:04<00:00, 133.54 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47668/47780 [01:05<00:00, 114.25 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47682/47780 [01:05<00:01, 96.75 examples/s] 
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47695/47780 [01:05<00:01, 72.35 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47705/47780 [01:05<00:01, 64.19 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47714/47780 [01:05<00:01, 60.53 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47721/47780 [01:06<00:01, 53.79 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47727/47780 [01:06<00:01, 52.44 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47734/47780 [01:06<00:00, 54.69 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47740/47780 [01:06<00:00, 54.41 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47746/47780 [01:06<00:00, 41.68 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47752/47780 [01:06<00:00, 36.86 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47759/47780 [01:07<00:00, 35.31 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47763/47780 [01:07<00:00, 34.85 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47769/47780 [01:07<00:00, 36.81 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47773/47780 [01:07<00:00, 36.41 examples/s]
[36m(head, rank=0, pid=3505)[0m Tokenizing train dataset (num_proc=32): 100%|█████████▉| 47777/47780 [01:07<00:00, 35.81 examples/s]Tokenizing train dataset (num_proc=32): 100%|██████████| 47780/47780 [01:10<00:00, 677.81 examples/s]
[36m(head, rank=0, pid=3505)[0m 
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):   0%|          | 0/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):   2%|▏         | 1000/47780 [00:13<10:31, 74.08 examples/s]
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):   4%|▍         | 2000/47780 [00:13<04:17, 177.49 examples/s]
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):  10%|█         | 5000/47780 [00:13<01:11, 600.69 examples/s]
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):  19%|█▉        | 9000/47780 [00:14<00:27, 1390.99 examples/s]
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):  27%|██▋       | 13000/47780 [00:14<00:14, 2457.16 examples/s]
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):  33%|███▎      | 16000/47780 [00:14<00:09, 3468.55 examples/s]
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):  40%|███▉      | 19000/47780 [00:14<00:06, 4788.23 examples/s]
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):  46%|████▌     | 22000/47780 [00:14<00:04, 6178.72 examples/s]
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):  52%|█████▏    | 25000/47780 [00:14<00:02, 7929.44 examples/s]
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):  64%|██████▍   | 30481/47780 [00:14<00:01, 12236.94 examples/s]
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):  71%|███████   | 33975/47780 [00:14<00:00, 14894.87 examples/s]
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):  77%|███████▋  | 36934/47780 [00:15<00:01, 8112.47 examples/s] 
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):  82%|████████▏ | 39399/47780 [00:16<00:01, 8068.61 examples/s]
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):  87%|████████▋ | 41371/47780 [00:16<00:00, 8322.76 examples/s]
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):  90%|████████▉ | 42850/47780 [00:16<00:00, 8660.93 examples/s]
[36m(head, rank=0, pid=3505)[0m Truncating train dataset (num_proc=32):  93%|█████████▎| 44329/47780 [00:16<00:00, 9177.03 examples/s]Truncating train dataset (num_proc=32): 100%|██████████| 47780/47780 [00:18<00:00, 2584.42 examples/s]
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m [2025-08-02 21:10:21,343] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 21:10:22,696] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):   9%|▉         | 4479/47780 [00:00<?, ? examples/s]Truncating train dataset (num_proc=32):   9%|▉         | 4479/47780 [00:00<?, ? examples/s]Truncating train dataset (num_proc=32):   9%|▉         | 4479/47780 [00:00<?, ? examples/s]Truncating train dataset (num_proc=32):   9%|▉         | 4479/47780 [00:00<?, ? examples/s]Truncating train dataset (num_proc=32):   9%|▉         | 4479/47780 [00:00<?, ? examples/s]Truncating train dataset (num_proc=32):   9%|▉         | 4479/47780 [00:00<?, ? examples/s]Truncating train dataset (num_proc=32):   9%|▉         | 4479/47780 [00:00<?, ? examples/s]
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(head, rank=0, pid=3505)[0m [2025-08-02 21:10:25,656] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 21:10:25,659] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 21:10:25,660] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 21:10:25,661] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 21:10:25,665] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 21:10:25,669] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 21:10:25,688] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(head, rank=0, pid=3505)[0m [2025-08-02 21:10:26,894] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m [2025-08-02 21:10:26,922] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m [2025-08-02 21:10:26,932] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m [2025-08-02 21:10:26,939] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m [2025-08-02 21:10:26,944] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m [2025-08-02 21:10:26,945] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(head, rank=0, pid=3505)[0m [2025-08-02 21:10:26,964] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):   9%|▉         | 4479/47780 [00:00<?, ? examples/s]Truncating train dataset (num_proc=32):  11%|█▏        | 5479/47780 [00:07<05:14, 134.42 examples/s]Truncating train dataset (num_proc=32):  11%|█▏        | 5479/47780 [00:07<05:14, 134.45 examples/s]Truncating train dataset (num_proc=32):  11%|█▏        | 5479/47780 [00:07<05:14, 134.44 examples/s]Truncating train dataset (num_proc=32):  11%|█▏        | 5479/47780 [00:07<05:14, 134.39 examples/s]Truncating train dataset (num_proc=32):  11%|█▏        | 5479/47780 [00:07<05:14, 134.39 examples/s]Truncating train dataset (num_proc=32):  11%|█▏        | 5479/47780 [00:07<05:14, 134.37 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  11%|█▏        | 5479/47780 [00:07<05:14, 134.34 examples/s]Truncating train dataset (num_proc=32):  14%|█▎        | 6479/47780 [00:07<02:09, 319.24 examples/s]Truncating train dataset (num_proc=32):  14%|█▎        | 6479/47780 [00:07<02:09, 319.11 examples/s]Truncating train dataset (num_proc=32):  14%|█▎        | 6479/47780 [00:07<02:09, 319.13 examples/s]Truncating train dataset (num_proc=32):  14%|█▎        | 6479/47780 [00:07<02:09, 319.09 examples/s]Truncating train dataset (num_proc=32):  14%|█▎        | 6479/47780 [00:07<02:09, 318.92 examples/s]Truncating train dataset (num_proc=32):  14%|█▎        | 6479/47780 [00:07<02:09, 318.92 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  14%|█▎        | 6479/47780 [00:07<02:09, 318.84 examples/s]Truncating train dataset (num_proc=32):  16%|█▌        | 7479/47780 [00:07<01:11, 563.87 examples/s]Truncating train dataset (num_proc=32):  16%|█▌        | 7479/47780 [00:07<01:11, 563.83 examples/s]Truncating train dataset (num_proc=32):  16%|█▌        | 7479/47780 [00:07<01:11, 563.72 examples/s]Truncating train dataset (num_proc=32):  16%|█▌        | 7479/47780 [00:07<01:11, 563.60 examples/s]Truncating train dataset (num_proc=32):  16%|█▌        | 7479/47780 [00:07<01:11, 563.43 examples/s]Truncating train dataset (num_proc=32):  16%|█▌        | 7479/47780 [00:07<01:11, 563.47 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  16%|█▌        | 7479/47780 [00:07<01:11, 563.58 examples/s]Truncating train dataset (num_proc=32):  22%|██▏       | 10479/47780 [00:08<00:25, 1469.37 examples/s]Truncating train dataset (num_proc=32):  22%|██▏       | 10479/47780 [00:08<00:25, 1468.64 examples/s]Truncating train dataset (num_proc=32):  22%|██▏       | 10479/47780 [00:08<00:25, 1468.32 examples/s]Truncating train dataset (num_proc=32):  22%|██▏       | 10479/47780 [00:08<00:25, 1466.79 examples/s]Truncating train dataset (num_proc=32):  22%|██▏       | 10479/47780 [00:08<00:25, 1466.30 examples/s]Truncating train dataset (num_proc=32):  22%|██▏       | 10479/47780 [00:08<00:25, 1465.61 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  22%|██▏       | 10479/47780 [00:08<00:25, 1464.44 examples/s]Truncating train dataset (num_proc=32):  24%|██▍       | 11479/47780 [00:08<00:21, 1714.11 examples/s]Truncating train dataset (num_proc=32):  24%|██▍       | 11479/47780 [00:08<00:21, 1713.70 examples/s]Truncating train dataset (num_proc=32):  24%|██▍       | 11479/47780 [00:08<00:21, 1714.52 examples/s]Truncating train dataset (num_proc=32):  24%|██▍       | 11479/47780 [00:08<00:21, 1715.24 examples/s]Truncating train dataset (num_proc=32):  24%|██▍       | 11479/47780 [00:08<00:21, 1712.73 examples/s]Truncating train dataset (num_proc=32):  24%|██▍       | 11479/47780 [00:08<00:21, 1711.71 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  24%|██▍       | 11479/47780 [00:08<00:21, 1712.77 examples/s]Truncating train dataset (num_proc=32):  26%|██▌       | 12479/47780 [00:08<00:17, 1996.41 examples/s]Truncating train dataset (num_proc=32):  26%|██▌       | 12479/47780 [00:08<00:17, 1998.98 examples/s]Truncating train dataset (num_proc=32):  26%|██▌       | 12479/47780 [00:08<00:17, 1995.63 examples/s]Truncating train dataset (num_proc=32):  26%|██▌       | 12479/47780 [00:08<00:17, 1994.08 examples/s]Truncating train dataset (num_proc=32):  26%|██▌       | 12479/47780 [00:08<00:17, 1994.46 examples/s]Truncating train dataset (num_proc=32):  26%|██▌       | 12479/47780 [00:08<00:17, 1995.15 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  26%|██▌       | 12479/47780 [00:08<00:17, 1992.82 examples/s]Truncating train dataset (num_proc=32):  28%|██▊       | 13479/47780 [00:08<00:15, 2249.04 examples/s]Truncating train dataset (num_proc=32):  28%|██▊       | 13479/47780 [00:08<00:15, 2246.59 examples/s]Truncating train dataset (num_proc=32):  28%|██▊       | 13479/47780 [00:08<00:15, 2241.84 examples/s]Truncating train dataset (num_proc=32):  28%|██▊       | 13479/47780 [00:08<00:15, 2240.71 examples/s]Truncating train dataset (num_proc=32):  28%|██▊       | 13479/47780 [00:08<00:15, 2239.69 examples/s]Truncating train dataset (num_proc=32):  28%|██▊       | 13479/47780 [00:08<00:15, 2240.09 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  28%|██▊       | 13479/47780 [00:08<00:15, 2244.21 examples/s]Truncating train dataset (num_proc=32):  34%|███▍      | 16479/47780 [00:09<00:08, 3805.08 examples/s]Truncating train dataset (num_proc=32):  34%|███▍      | 16479/47780 [00:09<00:08, 3802.75 examples/s]Truncating train dataset (num_proc=32):  34%|███▍      | 16479/47780 [00:09<00:08, 3811.76 examples/s]Truncating train dataset (num_proc=32):  34%|███▍      | 16479/47780 [00:09<00:08, 3802.91 examples/s]Truncating train dataset (num_proc=32):  34%|███▍      | 16479/47780 [00:09<00:08, 3803.10 examples/s]Truncating train dataset (num_proc=32):  34%|███▍      | 16479/47780 [00:09<00:08, 3796.39 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  34%|███▍      | 16479/47780 [00:09<00:08, 3794.22 examples/s]Truncating train dataset (num_proc=32):  39%|███▊      | 18479/47780 [00:09<00:05, 5074.16 examples/s]Truncating train dataset (num_proc=32):  39%|███▊      | 18479/47780 [00:09<00:05, 5065.40 examples/s]Truncating train dataset (num_proc=32):  39%|███▊      | 18479/47780 [00:09<00:05, 5058.74 examples/s]Truncating train dataset (num_proc=32):  39%|███▊      | 18479/47780 [00:09<00:05, 5059.32 examples/s]Truncating train dataset (num_proc=32):  39%|███▊      | 18479/47780 [00:09<00:05, 5058.27 examples/s]Truncating train dataset (num_proc=32):  39%|███▊      | 18479/47780 [00:09<00:05, 5056.01 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  39%|███▊      | 18479/47780 [00:09<00:05, 5061.65 examples/s]Truncating train dataset (num_proc=32):  41%|████      | 19479/47780 [00:09<00:05, 5495.06 examples/s]Truncating train dataset (num_proc=32):  41%|████      | 19479/47780 [00:09<00:05, 5492.64 examples/s]Truncating train dataset (num_proc=32):  41%|████      | 19479/47780 [00:09<00:05, 5482.21 examples/s]Truncating train dataset (num_proc=32):  41%|████      | 19479/47780 [00:09<00:05, 5475.24 examples/s]Truncating train dataset (num_proc=32):  41%|████      | 19479/47780 [00:09<00:05, 5458.12 examples/s]Truncating train dataset (num_proc=32):  41%|████      | 19479/47780 [00:09<00:05, 5439.81 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  41%|████      | 19479/47780 [00:09<00:05, 5453.17 examples/s]Truncating train dataset (num_proc=32):  45%|████▍     | 21479/47780 [00:09<00:04, 5686.71 examples/s]Truncating train dataset (num_proc=32):  45%|████▍     | 21479/47780 [00:09<00:04, 5699.03 examples/s]Truncating train dataset (num_proc=32):  45%|████▍     | 21479/47780 [00:09<00:04, 5678.66 examples/s]Truncating train dataset (num_proc=32):  45%|████▍     | 21479/47780 [00:09<00:04, 5682.57 examples/s]Truncating train dataset (num_proc=32):  45%|████▍     | 21479/47780 [00:09<00:04, 5671.39 examples/s]Truncating train dataset (num_proc=32):  45%|████▍     | 21479/47780 [00:09<00:04, 5660.63 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  45%|████▍     | 21479/47780 [00:09<00:04, 5656.26 examples/s]Truncating train dataset (num_proc=32):  47%|████▋     | 22479/47780 [00:10<00:04, 5526.73 examples/s]Truncating train dataset (num_proc=32):  47%|████▋     | 22479/47780 [00:10<00:04, 5511.16 examples/s]Truncating train dataset (num_proc=32):  47%|████▋     | 22479/47780 [00:10<00:04, 5510.86 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  47%|████▋     | 22479/47780 [00:10<00:04, 5499.96 examples/s]Truncating train dataset (num_proc=32):  47%|████▋     | 22479/47780 [00:10<00:04, 5111.35 examples/s]Truncating train dataset (num_proc=32):  47%|████▋     | 22479/47780 [00:10<00:04, 5107.97 examples/s]Truncating train dataset (num_proc=32):  47%|████▋     | 22479/47780 [00:10<00:04, 5108.32 examples/s]Truncating train dataset (num_proc=32):  51%|█████     | 24479/47780 [00:10<00:03, 7495.68 examples/s]Truncating train dataset (num_proc=32):  55%|█████▌    | 26479/47780 [00:10<00:02, 10038.77 examples/s]Truncating train dataset (num_proc=32):  55%|█████▌    | 26479/47780 [00:10<00:02, 10025.03 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  55%|█████▌    | 26479/47780 [00:10<00:02, 10008.90 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  58%|█████▊    | 27479/47780 [00:10<00:01, 10898.74 examples/s]Truncating train dataset (num_proc=32):  60%|█████▉    | 28479/47780 [00:10<00:01, 11340.62 examples/s]Truncating train dataset (num_proc=32):  60%|█████▉    | 28479/47780 [00:10<00:01, 10647.79 examples/s]Truncating train dataset (num_proc=32):  60%|█████▉    | 28479/47780 [00:10<00:01, 10501.64 examples/s]Truncating train dataset (num_proc=32):  60%|█████▉    | 28479/47780 [00:10<00:01, 10652.10 examples/s]Truncating train dataset (num_proc=32):  60%|█████▉    | 28479/47780 [00:10<00:01, 10498.72 examples/s]Truncating train dataset (num_proc=32):  60%|█████▉    | 28479/47780 [00:10<00:01, 10474.83 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  62%|██████▏   | 29479/47780 [00:10<00:01, 11624.46 examples/s]Truncating train dataset (num_proc=32):  64%|██████▍   | 30479/47780 [00:10<00:01, 11841.09 examples/s]Truncating train dataset (num_proc=32):  64%|██████▍   | 30479/47780 [00:10<00:01, 12018.90 examples/s]Truncating train dataset (num_proc=32):  64%|██████▍   | 30479/47780 [00:10<00:01, 12633.79 examples/s]Truncating train dataset (num_proc=32):  64%|██████▍   | 30479/47780 [00:10<00:01, 12012.60 examples/s]Truncating train dataset (num_proc=32):  64%|██████▍   | 30479/47780 [00:10<00:01, 11840.44 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  64%|██████▍   | 30479/47780 [00:10<00:01, 11990.48 examples/s]Truncating train dataset (num_proc=32):  66%|██████▌   | 31479/47780 [00:10<00:01, 11105.48 examples/s]Truncating train dataset (num_proc=32):  68%|██████▊   | 32479/47780 [00:10<00:01, 12220.33 examples/s]Truncating train dataset (num_proc=32):  68%|██████▊   | 32479/47780 [00:10<00:01, 12644.19 examples/s]Truncating train dataset (num_proc=32):  68%|██████▊   | 32479/47780 [00:10<00:01, 12060.24 examples/s]Truncating train dataset (num_proc=32):  68%|██████▊   | 32479/47780 [00:10<00:01, 12190.73 examples/s]Truncating train dataset (num_proc=32):  68%|██████▊   | 32479/47780 [00:10<00:01, 12014.89 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  68%|██████▊   | 32479/47780 [00:10<00:01, 12151.70 examples/s]Truncating train dataset (num_proc=32):  71%|███████   | 33972/47780 [00:11<00:03, 4132.68 examples/s] Truncating train dataset (num_proc=32):  71%|███████   | 33972/47780 [00:11<00:03, 4124.26 examples/s] Truncating train dataset (num_proc=32):  71%|███████   | 33972/47780 [00:11<00:02, 4700.41 examples/s] Truncating train dataset (num_proc=32):  71%|███████   | 33972/47780 [00:11<00:03, 4423.02 examples/s] Truncating train dataset (num_proc=32):  71%|███████   | 33972/47780 [00:11<00:03, 4247.84 examples/s] Truncating train dataset (num_proc=32):  71%|███████   | 33972/47780 [00:11<00:03, 4416.89 examples/s] 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  71%|███████   | 33972/47780 [00:11<00:03, 4110.40 examples/s] Truncating train dataset (num_proc=32):  74%|███████▍  | 35451/47780 [00:12<00:03, 3440.10 examples/s]Truncating train dataset (num_proc=32):  74%|███████▍  | 35451/47780 [00:12<00:03, 3261.97 examples/s]Truncating train dataset (num_proc=32):  74%|███████▍  | 35451/47780 [00:12<00:04, 3067.98 examples/s]Truncating train dataset (num_proc=32):  74%|███████▍  | 35451/47780 [00:12<00:04, 3063.70 examples/s]Truncating train dataset (num_proc=32):  74%|███████▍  | 35451/47780 [00:12<00:03, 3130.95 examples/s]Truncating train dataset (num_proc=32):  74%|███████▍  | 35451/47780 [00:12<00:03, 3255.19 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  74%|███████▍  | 35451/47780 [00:12<00:04, 3050.52 examples/s]Truncating train dataset (num_proc=32):  76%|███████▋  | 36438/47780 [00:12<00:03, 3278.79 examples/s]Truncating train dataset (num_proc=32):  76%|███████▋  | 36438/47780 [00:12<00:03, 2983.96 examples/s]Truncating train dataset (num_proc=32):  76%|███████▋  | 36438/47780 [00:12<00:03, 2978.96 examples/s]Truncating train dataset (num_proc=32):  76%|███████▋  | 36438/47780 [00:12<00:03, 2977.76 examples/s]Truncating train dataset (num_proc=32):  76%|███████▋  | 36438/47780 [00:12<00:03, 3033.51 examples/s]Truncating train dataset (num_proc=32):  76%|███████▋  | 36438/47780 [00:12<00:03, 3130.64 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  76%|███████▋  | 36438/47780 [00:12<00:03, 3129.20 examples/s]Truncating train dataset (num_proc=32):  78%|███████▊  | 37424/47780 [00:13<00:03, 3283.20 examples/s]Truncating train dataset (num_proc=32):  78%|███████▊  | 37424/47780 [00:13<00:03, 3087.66 examples/s]Truncating train dataset (num_proc=32):  78%|███████▊  | 37424/47780 [00:13<00:03, 3168.83 examples/s]Truncating train dataset (num_proc=32):  78%|███████▊  | 37424/47780 [00:13<00:03, 3038.57 examples/s]Truncating train dataset (num_proc=32):  78%|███████▊  | 37424/47780 [00:13<00:03, 3038.39 examples/s]Truncating train dataset (num_proc=32):  78%|███████▊  | 37424/47780 [00:13<00:03, 3162.17 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  78%|███████▊  | 37424/47780 [00:13<00:03, 3039.56 examples/s]Truncating train dataset (num_proc=32):  80%|████████  | 38410/47780 [00:13<00:03, 2622.95 examples/s]Truncating train dataset (num_proc=32):  80%|████████  | 38410/47780 [00:13<00:03, 2708.65 examples/s]Truncating train dataset (num_proc=32):  80%|████████  | 38410/47780 [00:13<00:03, 2621.68 examples/s]Truncating train dataset (num_proc=32):  80%|████████  | 38410/47780 [00:13<00:03, 2709.02 examples/s]Truncating train dataset (num_proc=32):  80%|████████  | 38410/47780 [00:13<00:03, 2650.07 examples/s]Truncating train dataset (num_proc=32):  80%|████████  | 38410/47780 [00:13<00:03, 2780.39 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  80%|████████  | 38410/47780 [00:13<00:03, 2592.98 examples/s]Truncating train dataset (num_proc=32):  83%|████████▎ | 39890/47780 [00:14<00:02, 2961.34 examples/s]Truncating train dataset (num_proc=32):  83%|████████▎ | 39890/47780 [00:14<00:02, 3018.90 examples/s]Truncating train dataset (num_proc=32):  83%|████████▎ | 39890/47780 [00:14<00:02, 3075.71 examples/s]Truncating train dataset (num_proc=32):  83%|████████▎ | 39890/47780 [00:14<00:02, 2979.38 examples/s]Truncating train dataset (num_proc=32):  83%|████████▎ | 39890/47780 [00:14<00:02, 2954.68 examples/s]Truncating train dataset (num_proc=32):  83%|████████▎ | 39890/47780 [00:14<00:02, 2967.85 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  83%|████████▎ | 39890/47780 [00:14<00:02, 3018.80 examples/s]Truncating train dataset (num_proc=32):  86%|████████▌ | 40876/47780 [00:14<00:01, 3601.47 examples/s]Truncating train dataset (num_proc=32):  86%|████████▌ | 40876/47780 [00:14<00:01, 3520.52 examples/s]Truncating train dataset (num_proc=32):  86%|████████▌ | 40876/47780 [00:14<00:01, 3513.45 examples/s]Truncating train dataset (num_proc=32):  86%|████████▌ | 40876/47780 [00:14<00:01, 3490.10 examples/s]Truncating train dataset (num_proc=32):  86%|████████▌ | 40876/47780 [00:14<00:01, 3544.09 examples/s]Truncating train dataset (num_proc=32):  86%|████████▌ | 40876/47780 [00:14<00:01, 3538.81 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  86%|████████▌ | 40876/47780 [00:14<00:01, 3483.78 examples/s]Truncating train dataset (num_proc=32):  90%|████████▉ | 42848/47780 [00:14<00:01, 3854.11 examples/s]Truncating train dataset (num_proc=32):  90%|████████▉ | 42848/47780 [00:14<00:01, 3858.32 examples/s]Truncating train dataset (num_proc=32):  90%|████████▉ | 42848/47780 [00:14<00:01, 3820.18 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  90%|████████▉ | 42848/47780 [00:14<00:01, 3880.15 examples/s]Truncating train dataset (num_proc=32):  92%|█████████▏| 43834/47780 [00:14<00:01, 3757.21 examples/s]Truncating train dataset (num_proc=32):  92%|█████████▏| 43834/47780 [00:14<00:01, 3751.13 examples/s]Truncating train dataset (num_proc=32):  92%|█████████▏| 43834/47780 [00:14<00:01, 3774.55 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  92%|█████████▏| 43834/47780 [00:14<00:01, 3793.30 examples/s]Truncating train dataset (num_proc=32):  95%|█████████▍| 45313/47780 [00:15<00:00, 4888.39 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  95%|█████████▍| 45313/47780 [00:15<00:00, 4858.97 examples/s]Truncating train dataset (num_proc=32):  95%|█████████▍| 45313/47780 [00:15<00:00, 4857.82 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  95%|█████████▍| 45313/47780 [00:15<00:00, 4893.69 examples/s]Truncating train dataset (num_proc=32):  99%|█████████▉| 47285/47780 [00:15<00:00, 6718.98 examples/s]Truncating train dataset (num_proc=32):  99%|█████████▉| 47285/47780 [00:15<00:00, 6700.93 examples/s]Truncating train dataset (num_proc=32):  99%|█████████▉| 47285/47780 [00:15<00:00, 6687.46 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  99%|█████████▉| 47285/47780 [00:15<00:00, 6673.83 examples/s]Truncating train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [00:25<00:00, 6718.98 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [00:25<00:00, 6700.93 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  89%|████████▊ | 42355/47780 [00:25<00:01, 3513.45 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  89%|████████▊ | 42355/47780 [00:25<00:01, 3483.78 examples/s]Truncating train dataset (num_proc=32):  99%|█████████▉| 47285/47780 [00:25<00:00, 6687.46 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  89%|████████▊ | 42355/47780 [00:25<00:01, 3538.81 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [00:27<00:00, 6673.83 examples/s]Truncating train dataset (num_proc=32):  90%|████████▉ | 42848/47780 [00:36<00:23, 211.73 examples/s] 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [00:36<00:00, 189.53 examples/s] Truncating train dataset (num_proc=32):  90%|████████▉ | 42848/47780 [00:36<00:23, 213.41 examples/s] 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  90%|████████▉ | 42848/47780 [00:36<00:23, 210.62 examples/s] 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  11%|█▏        | 5479/47780 [00:36<25:47, 27.33 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  19%|█▉        | 8972/47780 [00:36<04:00, 161.52 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [00:51<00:00, 266.58 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [00:51<00:00, 267.93 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  24%|██▍       | 11451/47780 [00:52<03:48, 159.25 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  51%|█████     | 24451/47780 [00:52<00:33, 702.32 examples/s]Truncating train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [00:53<00:00, 809.02 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 247.19 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [00:53<00:00, 809.01 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Completed Training in 247.22 seconds
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/e2e/train.py", line 712, in <module>
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     main()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/e2e/train.py", line 612, in main
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/e2e/train.py", line 104, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 840, in _prepare_dataset
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     dataset = truncate_dataset(dataset, args.max_length, map_kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/trl/data_utils.py", line 670, in truncate_dataset
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     dataset = dataset.map(truncate, batched=True, **map_kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 560, in wrapper
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3309, in map
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     for rank, done, content in iflatmap_unordered(
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/datasets/utils/py_utils.py", line 612, in iflatmap_unordered
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     yield queue.get(timeout=0.05)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "<string>", line 2, in get
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/multiprocess/managers.py", line 818, in _callmethod
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     kind, result = conn.recv()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/multiprocess/connection.py", line 254, in recv
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     return _ForkingPickler.loads(buf.getbuffer())
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/dill/_dill.py", line 303, in loads
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     return load(file, ignore, **kwds)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/dill/_dill.py", line 289, in load
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     return Unpickler(file, ignore=ignore, **kwds).load()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/dill/_dill.py", line 444, in load
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     obj = StockUnpickler.load(self)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/datasets/table.py", line 1027, in __setstate__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     table = _memory_mapped_arrow_table_from_file(path)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/datasets/table.py", line 63, in _memory_mapped_arrow_table_from_file
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     opened_stream = _memory_mapped_record_batch_reader_from_file(filename)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/datasets/table.py", line 49, in _memory_mapped_record_batch_reader_from_file
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     return pa.ipc.open_stream(memory_mapped_stream)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/pyarrow/ipc.py", line 187, in open_stream
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     return RecordBatchStreamReader(source, options=options,
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "/root/training/lib/python3.10/site-packages/pyarrow/ipc.py", line 52, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:     self._open(source, options=options, memory_pool=memory_pool)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "pyarrow/ipc.pxi", line 1038, in pyarrow.lib._RecordBatchStreamReader._open
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "pyarrow/error.pxi", line 155, in pyarrow.lib.pyarrow_internal_check_status
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]:   File "pyarrow/error.pxi", line 92, in pyarrow.lib.check_status
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank13]: pyarrow.lib.ArrowInvalid: Tried reading schema message, was null or length 0
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]: Traceback (most recent call last):
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/e2e/train.py", line 712, in <module>
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     main()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/e2e/train.py", line 612, in main
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     trainer = ProfilingSFTTrainer(**trainer_kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/e2e/train.py", line 104, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     super().__init__(*args, **kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 518, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     train_dataset = self._prepare_dataset(
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 840, in _prepare_dataset
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     dataset = truncate_dataset(dataset, args.max_length, map_kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/trl/data_utils.py", line 670, in truncate_dataset
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     dataset = dataset.map(truncate, batched=True, **map_kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 560, in wrapper
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3309, in map
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     for rank, done, content in iflatmap_unordered(
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/datasets/utils/py_utils.py", line 612, in iflatmap_unordered
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     yield queue.get(timeout=0.05)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "<string>", line 2, in get
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/multiprocess/managers.py", line 818, in _callmethod
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     kind, result = conn.recv()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/multiprocess/connection.py", line 254, in recv
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     return _ForkingPickler.loads(buf.getbuffer())
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/dill/_dill.py", line 303, in loads
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     return load(file, ignore, **kwds)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/dill/_dill.py", line 289, in load
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     return Unpickler(file, ignore=ignore, **kwds).load()
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/dill/_dill.py", line 444, in load
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     obj = StockUnpickler.load(self)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/datasets/table.py", line 1027, in __setstate__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     table = _memory_mapped_arrow_table_from_file(path)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/datasets/table.py", line 63, in _memory_mapped_arrow_table_from_file
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     opened_stream = _memory_mapped_record_batch_reader_from_file(filename)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/datasets/table.py", line 49, in _memory_mapped_record_batch_reader_from_file
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     return pa.ipc.open_stream(memory_mapped_stream)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/pyarrow/ipc.py", line 187, in open_stream
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     return RecordBatchStreamReader(source, options=options,
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "/root/training/lib/python3.10/site-packages/pyarrow/ipc.py", line 52, in __init__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:     self._open(source, options=options, memory_pool=memory_pool)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "pyarrow/ipc.pxi", line 1038, in pyarrow.lib._RecordBatchStreamReader._open
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "pyarrow/error.pxi", line 155, in pyarrow.lib.pyarrow_internal_check_status
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]:   File "pyarrow/error.pxi", line 92, in pyarrow.lib.check_status
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [rank15]: pyarrow.lib.ArrowInvalid: Tried reading schema message, was null or length 0
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [00:53<00:00, 806.31 examples/s] 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [00:53<00:00, 805.50 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [00:53<00:00, 805.41 examples/s] 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [00:53<00:00, 804.85 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32): 100%|█████████▉| 47778/47780 [00:53<00:00, 804.83 examples/s] 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m backward_prefetch is not supported in FSDP2. Setting backward prefetch to None.
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 21:11:18,390] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 21:11:18,401] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 21:11:18,425] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 21:11:18,473] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [2025-08-02 21:11:18,493] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  75%|███████▌  | 35944/47780 [00:54<00:09, 1289.34 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  86%|████████▌ | 40876/47780 [00:54<00:04, 1651.88 examples/s]
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Truncating train dataset (num_proc=32):  98%|█████████▊| 46792/47780 [00:54<00:00, 2281.70 examples/s]W0802 21:11:19.547000 1753586 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1753756 closing signal SIGTERM
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m W0802 21:11:19.548000 1753586 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1753757 closing signal SIGTERM
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m W0802 21:11:19.548000 1753586 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1753758 closing signal SIGTERM
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m W0802 21:11:19.549000 1753586 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1753759 closing signal SIGTERM
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m W0802 21:11:19.549000 1753586 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1753760 closing signal SIGTERM
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m W0802 21:11:19.550000 1753586 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1753761 closing signal SIGTERM
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m W0802 21:11:19.550000 1753586 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1753762 closing signal SIGTERM
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m E0802 21:11:20.573000 1753586 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 7 (pid: 1753763) of binary: /root/training/bin/python3
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Traceback (most recent call last):
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   File "/root/training/bin/accelerate", line 10, in <module>
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m     sys.exit(main())
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   File "/root/training/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m     args.func(args)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   File "/root/training/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1186, in launch_command
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m     multi_gpu_launcher(args)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   File "/root/training/lib/python3.10/site-packages/accelerate/commands/launch.py", line 815, in multi_gpu_launcher
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m     distrib_run.run(args)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   File "/root/training/lib/python3.10/site-packages/torch/distributed/run.py", line 883, in run
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m     elastic_launch(
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   File "/root/training/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 139, in __call__
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m     return launch_agent(self._config, self._entrypoint, list(args))
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   File "/root/training/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 270, in launch_agent
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m     raise ChildFailedError(
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ============================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m /e2e/train.py FAILED
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ------------------------------------------------------------
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Failures:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   <NO_OTHER_FAILURES>
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ------------------------------------------------------------
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m Root Cause (first observed failure):
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m [0]:
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   time      : 2025-08-02_21:11:19
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   host      : dd-3c0a52b3-worker1
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   rank      : 15 (local_rank: 7)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   exitcode  : 1 (pid: 1753763)
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   error_file: <N/A>
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m ============================================================
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m skypilot: cached mount is still uploading to remote
[36m(worker1, rank=1, pid=2715, ip=10.102.30.60)[0m skypilot: cached mount uploaded complete
[33m(raylet)[0m Raylet is terminated. Termination is unexpected. Possible reasons include: (1) SIGKILL by the user or system OOM killer, (2) Invalid memory access from Raylet causing SIGSEGV or SIGBUS, (3) Other termination signals. Last 20 lines of the Raylet logs:
    [state-dump] 	NodeManagerService.grpc_server.CommitBundleResources.HandleRequestImpl - 2 total (0 active), Execution time: mean = 79.401 us, total = 158.803 us, Queueing time: mean = 16.134 us, max = 16.152 us, min = 16.115 us, total = 32.267 us
    [state-dump] 	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch.OnReplyReceived - 2 total (0 active), Execution time: mean = 60.291 us, total = 120.582 us, Queueing time: mean = 566.869 us, max = 1.038 ms, min = 95.908 us, total = 1.134 ms
    [state-dump] 	NodeManagerService.grpc_server.PrepareBundleResources.HandleRequestImpl - 2 total (0 active), Execution time: mean = 100.059 us, total = 200.119 us, Queueing time: mean = 18.991 us, max = 24.314 us, min = 13.668 us, total = 37.982 us
    [state-dump] 	JobInfoGcsService.grpc_client.AddJob.OnReplyReceived - 1 total (0 active), Execution time: mean = 50.738 us, total = 50.738 us, Queueing time: mean = 19.601 us, max = 19.601 us, min = 19.601 us, total = 19.601 us
    [state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig.OnReplyReceived - 1 total (0 active), Execution time: mean = 17.485 ms, total = 17.485 ms, Queueing time: mean = 14.876 us, max = 14.876 us, min = 14.876 us, total = 14.876 us
    [state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 1 total (0 active), Execution time: mean = 44.314 us, total = 44.314 us, Queueing time: mean = 79.823 us, max = 79.823 us, min = 79.823 us, total = 79.823 us
    [state-dump] 	NodeManagerService.grpc_server.CancelResourceReserve - 1 total (0 active), Execution time: mean = 443.204 us, total = 443.204 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
    [state-dump] 	Subscriber.HandlePublishedMessage_GCS_NODE_INFO_CHANNEL - 1 total (0 active), Execution time: mean = 521.277 us, total = 521.277 us, Queueing time: mean = 161.092 us, max = 161.092 us, min = 161.092 us, total = 161.092 us
    [state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), Execution time: mean = 926.063 us, total = 926.063 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
    [state-dump] 	NodeInfoGcsService.grpc_client.GetInternalConfig - 1 total (0 active), Execution time: mean = 643.655 us, total = 643.655 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
    [state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo.OnReplyReceived - 1 total (0 active), Execution time: mean = 10.187 us, total = 10.187 us, Queueing time: mean = 13.006 us, max = 13.006 us, min = 13.006 us, total = 13.006 us
    [state-dump] 	NodeManagerService.grpc_server.CancelResourceReserve.HandleRequestImpl - 1 total (0 active), Execution time: mean = 157.139 us, total = 157.139 us, Queueing time: mean = 23.455 us, max = 23.455 us, min = 23.455 us, total = 23.455 us
    [state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo.OnReplyReceived - 1 total (0 active), Execution time: mean = 89.929 us, total = 89.929 us, Queueing time: mean = 9.393 us, max = 9.393 us, min = 9.393 us, total = 9.393 us
    [state-dump] 	JobInfoGcsService.grpc_client.AddJob - 1 total (0 active), Execution time: mean = 608.639 us, total = 608.639 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
    [state-dump] 	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), Execution time: mean = 417.123 us, total = 417.123 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
    [state-dump] 	JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), Execution time: mean = 444.572 us, total = 444.572 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
    [state-dump] 	NodeInfoGcsService.grpc_client.RegisterNode.OnReplyReceived - 1 total (0 active), Execution time: mean = 180.472 us, total = 180.472 us, Queueing time: mean = 13.530 us, max = 13.530 us, min = 13.530 us, total = 13.530 us
    [state-dump] DebugString() time ms: 0
    [state-dump] 
    [state-dump] 

command terminated with exit code 137
